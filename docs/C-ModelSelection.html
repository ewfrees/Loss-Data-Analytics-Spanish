<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Selección del Modelo y Estimación | Loss Data Analytics</title>
  <meta name="description" content="Chapter 4 Selección del Modelo y Estimación | Loss Data Analytics is an interactive, online, freely available text. - The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. - A subset of the book will be available in pdf format for low-cost printing. - The online text will be available in multiple languages to promote access to a worldwide audience." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Selección del Modelo y Estimación | Loss Data Analytics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Chapter 4 Selección del Modelo y Estimación | Loss Data Analytics is an interactive, online, freely available text. - The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. - A subset of the book will be available in pdf format for low-cost printing. - The online text will be available in multiple languages to promote access to a worldwide audience." />
  <meta name="github-repo" content="https://github.com/openacttexts/Loss-Data-Analytics" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Selección del Modelo y Estimación | Loss Data Analytics" />
  
  <meta name="twitter:description" content="Chapter 4 Selección del Modelo y Estimación | Loss Data Analytics is an interactive, online, freely available text. - The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. - A subset of the book will be available in pdf format for low-cost printing. - The online text will be available in multiple languages to promote access to a worldwide audience." />
  

<meta name="author" content="An open text authored by the Actuarial Community" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="C-Severity.html"/>
<link rel="next" href="C-AggLossModels.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<!-- Mathjax -->
<script type='text/x-mathjax-config'>
		MathJax.Hub.Config({
			extensions: ['tex2jax.js'],
			jax: ['input/TeX', 'output/HTML-CSS'],
			tex2jax: {
				inlineMath: [ ['$','$'], ['\\(','\\)'] ],
				displayMath: [ ['$$','$$'], ['\\[','\\]'] ],
				processEscapes: true
			},
			'HTML-CSS': { availableFonts: ['TeX'] }
		});
</script>

<!-- The following code is for the quizzes -->
<script src="https://surveyjs.azureedge.net/1.0.50/survey.jquery.js"></script>
<link href="https://surveyjs.azureedge.net/1.0.50/survey.css" type="text/css" rel="stylesheet"/>
<script src="https://cdnjs.cloudflare.com/ajax/libs/showdown/1.6.4/showdown.min.js"></script>  

<script>
function markdownConverterEWF() {  
//Create showdown markdown converter
var converter = new showdown.Converter();
converter.setOption('ghCompatibleHeaderId', true);
survey
    .onTextMarkdown
    .add(function (survey, options) {
        //convert the mardown text to html
        var str = converter.makeHtml(options.text);
        //remove root paragraphs <p></p>
        str = str.substring(3);
        str = str.substring(0, str.length - 4);
        //set html
        options.html = str;
         MathJax.Hub.Queue(['Typeset',MathJax.Hub, 'options']);
    });  
};
// Quiz Header info
const jsonHeader = { 
    showProgressBar: "bottom",
    showTimerPanel: "none",
    maxTimeToFinishPage: 10000,
    maxTimeToFinish: 25000,
    firstPageIsStarted: true,
    startSurveyText: "Start Quiz" //,
//    title: "Does This Make Sense?"
}
// One and Two question quizzes
function jsonSummary1EWF(json) {  
let jsonEnd1 = { 
completedHtml: 
json["pages"][1]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][1]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][1]["questions"][0]["correctAnswer"]
};  
return jsonEnd1;
};


function jsonSummary2EWF(json) {  
let jsonEnd2 = { 
completedHtml: 
json["pages"][1]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][1]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][1]["questions"][0]["correctAnswer"]
+"<br>"+
json["pages"][2]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][2]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][2]["questions"][0]["correctAnswer"]
};  
return jsonEnd2;
};

// Three, four, and five question quizzes
function jsonSummary3EWF(json) {  
let jsonEnd3 = { 
completedHtml: 
json["pages"][1]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][1]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][1]["questions"][0]["correctAnswer"]
+"<br>"+
json["pages"][2]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][2]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][2]["questions"][0]["correctAnswer"]
+"<br>"+
json["pages"][3]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][3]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][3]["questions"][0]["correctAnswer"]
};  
return jsonEnd3;
};

function jsonSummary4EWF(json) {  
jsonEnd4 = jsonSummary3EWF(json);
jsonEnd4.completedHtml = jsonEnd4.completedHtml +  
"<br>"+
json["pages"][4]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][4]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][4]["questions"][0]["correctAnswer"]
;  
return jsonEnd4;
};

function jsonSummary5EWF(json) {  
jsonEnd5 = jsonSummary4EWF(json);
jsonEnd5.completedHtml = jsonEnd5.completedHtml +  
"<br>"+
json["pages"][5]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][5]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][5]["questions"][0]["correctAnswer"]
;  
return jsonEnd5;
};

function jsonSummary6EWF(json) {  
jsonEnd6 = jsonSummary5EWF(json);
jsonEnd6.completedHtml = jsonEnd6.completedHtml +  
"<br>"+
json["pages"][6]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][6]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][6]["questions"][0]["correctAnswer"]
;  
return jsonEnd6;
};

function jsonSummary7EWF(json) {  
jsonEnd7 = jsonSummary6EWF(json);
jsonEnd7.completedHtml = jsonEnd7.completedHtml +  
"<br>"+
json["pages"][7]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][7]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][7]["questions"][0]["correctAnswer"]
;  
return jsonEnd7;
};

function jsonSummary8EWF(json) {  
jsonEnd8 = jsonSummary7EWF(json);
jsonEnd8.completedHtml = jsonEnd8.completedHtml +  
"<br>"+
json["pages"][8]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][8]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][8]["questions"][0]["correctAnswer"]
;  
return jsonEnd8;
};

function jsonSummary9EWF(json) {  
jsonEnd9 = jsonSummary8EWF(json);
jsonEnd9.completedHtml = jsonEnd9.completedHtml +  
"<br>"+
json["pages"][9]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][9]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][9]["questions"][0]["correctAnswer"]
;  
return jsonEnd9;
};


function jsonSummary10EWF(json) {  
jsonEnd10 = jsonSummary9EWF(json);
jsonEnd10.completedHtml = jsonEnd10.completedHtml +  
"<br>"+
json["pages"][10]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][10]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][10]["questions"][0]["correctAnswer"]
;  
return jsonEnd10;
};


function jsonSummary11EWF(json) {  
jsonEnd11 = jsonSummary10EWF(json);
jsonEnd11.completedHtml = jsonEnd11.completedHtml +  
"<br>"+
json["pages"][11]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][11]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][11]["questions"][0]["correctAnswer"]
;  
return jsonEnd11;
};



</script>  
<!-- This completes the code for the quizzes -->


<!-- Various toggle functions used throughout --> 
<script language="javascript">
function toggle(id1,id2) {
	var ele = document.getElementById(id1); var text = document.getElementById(id2);
	if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Mostrar Solución";}
		else {ele.style.display = "block"; text.innerHTML = "Ocultar Solución";}}
function togglecode(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Mostrar Código R";}
      else {ele.style.display = "block"; text.innerHTML = "Ocultar Código R";}}
function toggleEX(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Mostrar Ejemplo";}
      else {ele.style.display = "block"; text.innerHTML = "Ocultar Ejemplo";}}
function toggleTheory(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Mostrar Teoría";}
      else {ele.style.display = "block"; text.innerHTML = "Ocultar Teoría";}}
function toggleQuiz(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Mostrar Solución de Prueba";}
      else {ele.style.display = "block"; text.innerHTML = "Ocultar Solución de Prueba";}}      
</script>

<!-- A few functions for revealing definitions -->
<script language="javascript">
<!--   $( function() {
    $("#tabs").tabs();
  } ); -->

$(document).ready(function(){
    $('[data-toggle="tooltip"]').tooltip();
});

$(document).ready(function(){
    $('[data-toggle="popover"]').popover(); 
});
</script>

<script language="javascript">
function openTab(evt, tabName) {
    var i, tabcontent, tablinks;
    tabcontent = document.getElementsByClassName("tabcontent");
    for (i = 0; i < tabcontent.length; i++) {
        tabcontent[i].style.display = "none";
    }
    tablinks = document.getElementsByClassName("tablinks");
    for (i = 0; i < tablinks.length; i++) {
        tablinks[i].className = tablinks[i].className.replace(" active", "");
    }
    document.getElementById(tabName).style.display = "block";
    evt.currentTarget.className += " active";
}

// Get the element with id="defaultOpen" and click on it
document.getElementById("defaultOpen").click();
</script>


<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-DF6W196L8Q"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-DF6W196L8Q');
</script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Loss Data Analytics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#contributors"><i class="fa fa-check"></i>Contributors</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#reviewers"><i class="fa fa-check"></i>Reviewers</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#for-our-readers"><i class="fa fa-check"></i>For our Readers</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="C-Intro.html"><a href="C-Intro.html"><i class="fa fa-check"></i><b>1</b> Introducción a la Analítica de Datos de Pérdida</a><ul>
<li class="chapter" data-level="1.1" data-path="C-Intro.html"><a href="C-Intro.html#S:Intro"><i class="fa fa-check"></i><b>1.1</b> Relevancia de la Analítica para las Actividades de Seguros</a><ul>
<li class="chapter" data-level="1.1.1" data-path="C-Intro.html"><a href="C-Intro.html#naturaleza-y-relevancia-del-seguro"><i class="fa fa-check"></i><b>1.1.1</b> Naturaleza y relevancia del seguro</a></li>
<li class="chapter" data-level="1.1.2" data-path="C-Intro.html"><a href="C-Intro.html#qué-es-la-analítica-de-datos-según-su-nombre-en-inglés-analytics"><i class="fa fa-check"></i><b>1.1.2</b> ¿Qué es la Analítica de datos (según su nombre en inglés, Analytics)?</a></li>
<li class="chapter" data-level="1.1.3" data-path="C-Intro.html"><a href="C-Intro.html#S:InsProcesses"><i class="fa fa-check"></i><b>1.1.3</b> Procesos en los seguros</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="C-Intro.html"><a href="C-Intro.html#S:PredModApps"><i class="fa fa-check"></i><b>1.2</b> Operaciones de la Compañía de Seguros</a><ul>
<li class="chapter" data-level="1.2.1" data-path="C-Intro.html"><a href="C-Intro.html#inicio-del-seguro"><i class="fa fa-check"></i><b>1.2.1</b> Inicio del seguro</a></li>
<li class="chapter" data-level="1.2.2" data-path="C-Intro.html"><a href="C-Intro.html#renovación-del-seguro"><i class="fa fa-check"></i><b>1.2.2</b> Renovación del seguro</a></li>
<li class="chapter" data-level="1.2.3" data-path="C-Intro.html"><a href="C-Intro.html#gestión-de-productos-y-siniestros"><i class="fa fa-check"></i><b>1.2.3</b> Gestión de productos y siniestros</a></li>
<li class="chapter" data-level="1.2.4" data-path="C-Intro.html"><a href="C-Intro.html#S:Reserving"><i class="fa fa-check"></i><b>1.2.4</b> Provisiones</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="C-Intro.html"><a href="C-Intro.html#S:LGPIF"><i class="fa fa-check"></i><b>1.3</b> Caso de Estudio: Fondo de Propiedad de Wisconsin</a><ul>
<li class="chapter" data-level="1.3.1" data-path="C-Intro.html"><a href="C-Intro.html#S:OutComes"><i class="fa fa-check"></i><b>1.3.1</b> Variables de siniestralidad del fondo: frecuencia y severidad</a></li>
<li class="chapter" data-level="1.3.2" data-path="C-Intro.html"><a href="C-Intro.html#S:FundVariables"><i class="fa fa-check"></i><b>1.3.2</b> Variables de clasificación del fondo</a></li>
<li class="chapter" data-level="1.3.3" data-path="C-Intro.html"><a href="C-Intro.html#operativa-del-fondo"><i class="fa fa-check"></i><b>1.3.3</b> Operativa del fondo</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="C-Intro.html"><a href="C-Intro.html#Intro-further-reading-and-resources"><i class="fa fa-check"></i><b>1.4</b> Más Recursos y Colaboradores</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html"><i class="fa fa-check"></i><b>2</b> Modelización de la Frecuencia</a><ul>
<li class="chapter" data-level="2.1" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:frequency-distributions"><i class="fa fa-check"></i><b>2.1</b> Distribuciones de Frecuencias</a><ul>
<li class="chapter" data-level="2.1.1" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:how-frequency-augments-severity-information"><i class="fa fa-check"></i><b>2.1.1</b> Cómo la frecuencia incrementa la información sobre la cuantía</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:basic-frequency-distributions"><i class="fa fa-check"></i><b>2.2</b> Distribuciones de Frecuencias Elementales</a><ul>
<li class="chapter" data-level="2.2.1" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:foundations"><i class="fa fa-check"></i><b>2.2.1</b> Fundamentos</a></li>
<li class="chapter" data-level="2.2.2" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:generating-functions"><i class="fa fa-check"></i><b>2.2.2</b> Funciones Generadoras de Momentos y de Probabilidad</a></li>
<li class="chapter" data-level="2.2.3" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:important-frequency-distributions"><i class="fa fa-check"></i><b>2.2.3</b> Distribuciones de Frecuencias Importantes</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:the-a-b-0-class"><i class="fa fa-check"></i><b>2.3</b> La Clase (a, b, 0)</a></li>
<li class="chapter" data-level="2.4" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:estimating-frequency-distributions"><i class="fa fa-check"></i><b>2.4</b> Estimación de las Distribuciones de Frecuencias</a><ul>
<li class="chapter" data-level="2.4.1" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:parameter-estimation"><i class="fa fa-check"></i><b>2.4.1</b> Estimación de los parámetros</a></li>
<li class="chapter" data-level="2.4.2" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:frequency-distributions-mle"><i class="fa fa-check"></i><b>2.4.2</b> MLE de las distribuciones de frecuencias</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:other-frequency-distributions"><i class="fa fa-check"></i><b>2.5</b> Otras Distribuciones de Frecuencias</a><ul>
<li class="chapter" data-level="2.5.1" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:zero-truncation-or-modification"><i class="fa fa-check"></i><b>2.5.1</b> Modificación o Truncamiento en Cero</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:mixture-distributions"><i class="fa fa-check"></i><b>2.6</b> Distribuciones Mixtas</a></li>
<li class="chapter" data-level="2.7" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:goodness-of-fit"><i class="fa fa-check"></i><b>2.7</b> Bondad del Ajuste</a></li>
<li class="chapter" data-level="2.8" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:exercises"><i class="fa fa-check"></i><b>2.8</b> Ejercicios</a></li>
<li class="chapter" data-level="2.9" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#Freq-further-reading-and-resources"><i class="fa fa-check"></i><b>2.9</b> Recursos Adicionales y Autores</a><ul>
<li class="chapter" data-level="2.9.1" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:rcode"><i class="fa fa-check"></i><b>2.9.1</b> TS 2.A. Código R para Gráficos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="C-Severity.html"><a href="C-Severity.html"><i class="fa fa-check"></i><b>3</b> Modelización de la Severidad de las Pérdidas</a><ul>
<li class="chapter" data-level="3.1" data-path="C-Severity.html"><a href="C-Severity.html#S:BasicQuantities"><i class="fa fa-check"></i><b>3.1</b> Cantidades Distribucionales Básicas</a><ul>
<li class="chapter" data-level="3.1.1" data-path="C-Severity.html"><a href="C-Severity.html#S:Chap3Moments"><i class="fa fa-check"></i><b>3.1.1</b> Momentos</a></li>
<li class="chapter" data-level="3.1.2" data-path="C-Severity.html"><a href="C-Severity.html#cuantiles"><i class="fa fa-check"></i><b>3.1.2</b> Cuantiles</a></li>
<li class="chapter" data-level="3.1.3" data-path="C-Severity.html"><a href="C-Severity.html#función-generatriz-de-momentos"><i class="fa fa-check"></i><b>3.1.3</b> Función generatriz de momentos</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="C-Severity.html"><a href="C-Severity.html#S:ContinuousDistn"><i class="fa fa-check"></i><b>3.2</b> Distribuciones Continuas para Modelizar la Severidad de las Pérdidas</a><ul>
<li class="chapter" data-level="3.2.1" data-path="C-Severity.html"><a href="C-Severity.html#S:Loss:Gamma"><i class="fa fa-check"></i><b>3.2.1</b> Distribución gamma</a></li>
<li class="chapter" data-level="3.2.2" data-path="C-Severity.html"><a href="C-Severity.html#distribución-pareto"><i class="fa fa-check"></i><b>3.2.2</b> Distribución Pareto</a></li>
<li class="chapter" data-level="3.2.3" data-path="C-Severity.html"><a href="C-Severity.html#S:LS:Weibull"><i class="fa fa-check"></i><b>3.2.3</b> Distribución Weibull</a></li>
<li class="chapter" data-level="3.2.4" data-path="C-Severity.html"><a href="C-Severity.html#distribución-beta-generalizada-de-segundo-tipo"><i class="fa fa-check"></i><b>3.2.4</b> Distribución Beta Generalizada de segundo tipo</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="C-Severity.html"><a href="C-Severity.html#MethodsCreation"><i class="fa fa-check"></i><b>3.3</b> Métodos para Crear Distribuciones Nuevas</a><ul>
<li class="chapter" data-level="3.3.1" data-path="C-Severity.html"><a href="C-Severity.html#funciones-de-variables-aleatorias-y-sus-distribuciones"><i class="fa fa-check"></i><b>3.3.1</b> Funciones de variables aleatorias y sus distribuciones</a></li>
<li class="chapter" data-level="3.3.2" data-path="C-Severity.html"><a href="C-Severity.html#multiplicación-por-una-constante"><i class="fa fa-check"></i><b>3.3.2</b> Multiplicación por una constante</a></li>
<li class="chapter" data-level="3.3.3" data-path="C-Severity.html"><a href="C-Severity.html#elevación-a-una-potencia"><i class="fa fa-check"></i><b>3.3.3</b> Elevación a una potencia</a></li>
<li class="chapter" data-level="3.3.4" data-path="C-Severity.html"><a href="C-Severity.html#exponenciación"><i class="fa fa-check"></i><b>3.3.4</b> Exponenciación</a></li>
<li class="chapter" data-level="3.3.5" data-path="C-Severity.html"><a href="C-Severity.html#mixturas-finitas"><i class="fa fa-check"></i><b>3.3.5</b> Mixturas finitas</a></li>
<li class="chapter" data-level="3.3.6" data-path="C-Severity.html"><a href="C-Severity.html#mixturas-continuas"><i class="fa fa-check"></i><b>3.3.6</b> Mixturas continuas</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="C-Severity.html"><a href="C-Severity.html#S:CoverageModifications"><i class="fa fa-check"></i><b>3.4</b> Modificaciones de Cobertura</a><ul>
<li class="chapter" data-level="3.4.1" data-path="C-Severity.html"><a href="C-Severity.html#S:PolicyDeduct"><i class="fa fa-check"></i><b>3.4.1</b> Franquicias</a></li>
<li class="chapter" data-level="3.4.2" data-path="C-Severity.html"><a href="C-Severity.html#S:PolicyLimits"><i class="fa fa-check"></i><b>3.4.2</b> Límites de la póliza</a></li>
<li class="chapter" data-level="3.4.3" data-path="C-Severity.html"><a href="C-Severity.html#coseguro-e-inflación"><i class="fa fa-check"></i><b>3.4.3</b> Coseguro e inflación</a></li>
<li class="chapter" data-level="3.4.4" data-path="C-Severity.html"><a href="C-Severity.html#S:Chap3Reinsurance"><i class="fa fa-check"></i><b>3.4.4</b> Reaseguro</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="C-Severity.html"><a href="C-Severity.html#S:MaxLikeEstimation"><i class="fa fa-check"></i><b>3.5</b> Estimación por Máxima Verosimilitud</a><ul>
<li class="chapter" data-level="3.5.1" data-path="C-Severity.html"><a href="C-Severity.html#estimadores-de-máxima-verosimilitud-para-datos-completos"><i class="fa fa-check"></i><b>3.5.1</b> Estimadores de máxima verosimilitud para datos completos</a></li>
<li class="chapter" data-level="3.5.2" data-path="C-Severity.html"><a href="C-Severity.html#S:Loss:MLEModified"><i class="fa fa-check"></i><b>3.5.2</b> Estimadores por máxima verosimilitud usando datos modificados</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="C-Severity.html"><a href="C-Severity.html#LM-further-reading-and-resources"><i class="fa fa-check"></i><b>3.6</b> Recursos y Contribuciones Adicionales</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html"><i class="fa fa-check"></i><b>4</b> Selección del Modelo y Estimación</a><ul>
<li class="chapter" data-level="4.1" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#S:MS:NonParInf"><i class="fa fa-check"></i><b>4.1</b> Inferencia No Paramétrica</a><ul>
<li class="chapter" data-level="4.1.1" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#estimación-no-paramétrica"><i class="fa fa-check"></i><b>4.1.1</b> Estimación No Paramétrica</a></li>
<li class="chapter" data-level="4.1.2" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#S:MS:ToolsModelSelection"><i class="fa fa-check"></i><b>4.1.2</b> Herramientas para la Selección de Modelos y Diagnósticos</a></li>
<li class="chapter" data-level="4.1.3" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#valores-iniciales"><i class="fa fa-check"></i><b>4.1.3</b> Valores Iniciales</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#S:MS:ModelSelection"><i class="fa fa-check"></i><b>4.2</b> Selección del Modelo</a><ul>
<li class="chapter" data-level="4.2.1" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#selección-del-modelo-iterativa"><i class="fa fa-check"></i><b>4.2.1</b> Selección del Modelo Iterativa</a></li>
<li class="chapter" data-level="4.2.2" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#selección-de-modelo-basada-en-un-conjunto-de-datos-de-entrenamiento"><i class="fa fa-check"></i><b>4.2.2</b> Selección de Modelo basada en un Conjunto de Datos de Entrenamiento</a></li>
<li class="chapter" data-level="4.2.3" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#selección-de-modelo-basada-en-un-conjunto-de-datos-de-prueba"><i class="fa fa-check"></i><b>4.2.3</b> Selección de Modelo basada en un Conjunto de Datos de Prueba</a></li>
<li class="chapter" data-level="4.2.4" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#selección-del-modelo-basada-en-validación-cruzada"><i class="fa fa-check"></i><b>4.2.4</b> Selección del Modelo basada en Validación Cruzada</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#S:MS:ModifiedData"><i class="fa fa-check"></i><b>4.3</b> Estimación utilizando Datos Modificados</a><ul>
<li class="chapter" data-level="4.3.1" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#estimación-paramétrica-usando-datos-modificados"><i class="fa fa-check"></i><b>4.3.1</b> Estimación Paramétrica usando Datos Modificados</a></li>
<li class="chapter" data-level="4.3.2" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#estimación-no-paramétrica-utilizando-datos-modificados"><i class="fa fa-check"></i><b>4.3.2</b> Estimación no Paramétrica Utilizando Datos Modificados</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#S:MS:BayesInference"><i class="fa fa-check"></i><b>4.4</b> Inferencia Bayesiana</a><ul>
<li class="chapter" data-level="4.4.1" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#S:IntroBayes"><i class="fa fa-check"></i><b>4.4.1</b> Introducción a la Inferencia Bayesiana</a></li>
<li class="chapter" data-level="4.4.2" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#modelo-bayesiano"><i class="fa fa-check"></i><b>4.4.2</b> Modelo Bayesiano</a></li>
<li class="chapter" data-level="4.4.3" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#inferencia-bayesiana"><i class="fa fa-check"></i><b>4.4.3</b> Inferencia Bayesiana</a></li>
<li class="chapter" data-level="4.4.4" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#S:ConjugateDistributions"><i class="fa fa-check"></i><b>4.4.4</b> Distribuciones Conjugadas</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#MS:further-reading-and-resources"><i class="fa fa-check"></i><b>4.5</b> Más Recursos y Colaboradores</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html"><i class="fa fa-check"></i><b>5</b> Modelos de Pérdidas Agregadas</a><ul>
<li class="chapter" data-level="5.1" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#introducción"><i class="fa fa-check"></i><b>5.1</b> Introducción</a></li>
<li class="chapter" data-level="5.2" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#modelo-de-riesgo-individual"><i class="fa fa-check"></i><b>5.2</b> Modelo de Riesgo Individual</a></li>
<li class="chapter" data-level="5.3" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#modelo-de-riesgo-colectivo"><i class="fa fa-check"></i><b>5.3</b> Modelo de Riesgo Colectivo</a><ul>
<li class="chapter" data-level="5.3.1" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#momentos-y-distribución"><i class="fa fa-check"></i><b>5.3.1</b> Momentos y distribución</a></li>
<li class="chapter" data-level="5.3.2" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#seguro-stop-loss"><i class="fa fa-check"></i><b>5.3.2</b> Seguro Stop-loss</a></li>
<li class="chapter" data-level="5.3.3" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#resultados-analíticos"><i class="fa fa-check"></i><b>5.3.3</b> Resultados analíticos</a></li>
<li class="chapter" data-level="5.3.4" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#distribución-tweedie"><i class="fa fa-check"></i><b>5.3.4</b> Distribución Tweedie</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#cálculo-de-la-distribución-de-pérdidas-agregadas"><i class="fa fa-check"></i><b>5.4</b> Cálculo de la Distribución de Pérdidas Agregadas</a><ul>
<li class="chapter" data-level="5.4.1" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#método-recursivo"><i class="fa fa-check"></i><b>5.4.1</b> Método recursivo</a></li>
<li class="chapter" data-level="5.4.2" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#simulación"><i class="fa fa-check"></i><b>5.4.2</b> Simulación</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#efectos-de-la-modificación-de-las-coberturas"><i class="fa fa-check"></i><b>5.5</b> Efectos de la Modificación de las Coberturas</a><ul>
<li class="chapter" data-level="5.5.1" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#impacto-de-la-exposición-en-la-frecuencia"><i class="fa fa-check"></i><b>5.5.1</b> Impacto de la exposición en la frecuencia</a></li>
<li class="chapter" data-level="5.5.2" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#S:MS:DedImpactClmFreq"><i class="fa fa-check"></i><b>5.5.2</b> Impacto de los deducibles en la frecuencia de siniestros</a></li>
<li class="chapter" data-level="5.5.3" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#impacto-de-las-modificaciones-de-la-póliza-en-la-siniestralidad-agregada"><i class="fa fa-check"></i><b>5.5.3</b> Impacto de las modificaciones de la póliza en la siniestralidad agregada</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#AL-further-reading-and-resources"><i class="fa fa-check"></i><b>5.6</b> Otros Recursos y Colaboradores</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="C-Simulation.html"><a href="C-Simulation.html"><i class="fa fa-check"></i><b>6</b> Simulación y Remuestreo</a><ul>
<li class="chapter" data-level="6.1" data-path="C-Simulation.html"><a href="C-Simulation.html#S:SimulationFundamentals"><i class="fa fa-check"></i><b>6.1</b> Fundamentos de la Simulación</a><ul>
<li class="chapter" data-level="6.1.1" data-path="C-Simulation.html"><a href="C-Simulation.html#generación-de-observaciones-uniformes-independientes"><i class="fa fa-check"></i><b>6.1.1</b> Generación de observaciones uniformes independientes</a></li>
<li class="chapter" data-level="6.1.2" data-path="C-Simulation.html"><a href="C-Simulation.html#S:InverseTransform"><i class="fa fa-check"></i><b>6.1.2</b> Método de la transformada inversa</a></li>
<li class="chapter" data-level="6.1.3" data-path="C-Simulation.html"><a href="C-Simulation.html#precisión-de-la-simulación"><i class="fa fa-check"></i><b>6.1.3</b> Precisión de la simulación</a></li>
<li class="chapter" data-level="6.1.4" data-path="C-Simulation.html"><a href="C-Simulation.html#S:SimulationStatInference"><i class="fa fa-check"></i><b>6.1.4</b> Simulación e inferencia estadística</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="C-Simulation.html"><a href="C-Simulation.html#S:Bootstrap"><i class="fa fa-check"></i><b>6.2</b> Bootstrapping y Remuestreo</a><ul>
<li class="chapter" data-level="6.2.1" data-path="C-Simulation.html"><a href="C-Simulation.html#fundamentos-del-bootstrap"><i class="fa fa-check"></i><b>6.2.1</b> Fundamentos del Bootstrap</a></li>
<li class="chapter" data-level="6.2.2" data-path="C-Simulation.html"><a href="C-Simulation.html#precisión-del-bootstrap-sesgo-desviación-estándar-y-mse-error-cuadrático-medio-en-sus-siglas-en-inglés"><i class="fa fa-check"></i><b>6.2.2</b> Precisión del bootstrap: Sesgo, desviación estándar, y MSE (error cuadrático medio, en sus siglas en inglés)</a></li>
<li class="chapter" data-level="6.2.3" data-path="C-Simulation.html"><a href="C-Simulation.html#intervalos-de-confianza"><i class="fa fa-check"></i><b>6.2.3</b> Intervalos de confianza</a></li>
<li class="chapter" data-level="6.2.4" data-path="C-Simulation.html"><a href="C-Simulation.html#S:ParametricBootStrap"><i class="fa fa-check"></i><b>6.2.4</b> Bootstrap paramétrico</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="C-Simulation.html"><a href="C-Simulation.html#S:CrossValidation"><i class="fa fa-check"></i><b>6.3</b> Validación Cruzada</a><ul>
<li class="chapter" data-level="6.3.1" data-path="C-Simulation.html"><a href="C-Simulation.html#validación-cruzada-k-fold"><i class="fa fa-check"></i><b>6.3.1</b> Validación cruzada k-fold</a></li>
<li class="chapter" data-level="6.3.2" data-path="C-Simulation.html"><a href="C-Simulation.html#validación-cruzada-dejando-uno-fuera"><i class="fa fa-check"></i><b>6.3.2</b> Validación cruzada dejando uno fuera</a></li>
<li class="chapter" data-level="6.3.3" data-path="C-Simulation.html"><a href="C-Simulation.html#validación-cruzada-y-bootstrap"><i class="fa fa-check"></i><b>6.3.3</b> Validación cruzada y Bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="C-Simulation.html"><a href="C-Simulation.html#S:ImportanceSampling"><i class="fa fa-check"></i><b>6.4</b> Importance Sampling</a></li>
<li class="chapter" data-level="6.5" data-path="C-Simulation.html"><a href="C-Simulation.html#S:MCMC"><i class="fa fa-check"></i><b>6.5</b> Monte Carlo Markov Chain (MCMC)</a><ul>
<li class="chapter" data-level="6.5.1" data-path="C-Simulation.html"><a href="C-Simulation.html#hastings-metropolis"><i class="fa fa-check"></i><b>6.5.1</b> Hastings Metropolis</a></li>
<li class="chapter" data-level="6.5.2" data-path="C-Simulation.html"><a href="C-Simulation.html#muestreo-de-gibbs"><i class="fa fa-check"></i><b>6.5.2</b> Muestreo de Gibbs</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="C-Simulation.html"><a href="C-Simulation.html#Simulation:further-reading-and-resources"><i class="fa fa-check"></i><b>6.6</b> Recursos Adicionales y Colaboradores</a><ul>
<li class="chapter" data-level="6.6.1" data-path="C-Simulation.html"><a href="C-Simulation.html#ts-6.a.-bootstrap-applications-in-predictive-modeling"><i class="fa fa-check"></i><b>6.6.1</b> TS 6.A. Bootstrap Applications in Predictive Modeling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="C-PremiumFoundations.html"><a href="C-PremiumFoundations.html"><i class="fa fa-check"></i><b>7</b> Fundamentos de la Prima</a><ul>
<li class="chapter" data-level="7.1" data-path="C-PremiumFoundations.html"><a href="C-PremiumFoundations.html#S:IntroductionRatemaking"><i class="fa fa-check"></i><b>7.1</b> Introducción a la Tarificación</a></li>
<li class="chapter" data-level="7.2" data-path="C-PremiumFoundations.html"><a href="C-PremiumFoundations.html#S:AggRateMaking"><i class="fa fa-check"></i><b>7.2</b> Métodos de Tarificación Conjunta</a><ul>
<li class="chapter" data-level="7.2.1" data-path="C-PremiumFoundations.html"><a href="C-PremiumFoundations.html#S:PurePremium"><i class="fa fa-check"></i><b>7.2.1</b> Método de la Prima Pura</a></li>
<li class="chapter" data-level="7.2.2" data-path="C-PremiumFoundations.html"><a href="C-PremiumFoundations.html#S:LossRatio"><i class="fa fa-check"></i><b>7.2.2</b> Método de la Ratio de Siniestralidad</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="C-PremiumFoundations.html"><a href="C-PremiumFoundations.html#S:PricingPrinciples"><i class="fa fa-check"></i><b>7.3</b> Principios de Tarificación</a><ul>
<li class="chapter" data-level="7.3.1" data-path="C-PremiumFoundations.html"><a href="C-PremiumFoundations.html#principios-de-tarificación"><i class="fa fa-check"></i><b>7.3.1</b> Principios de Tarificación</a></li>
<li class="chapter" data-level="7.3.2" data-path="C-PremiumFoundations.html"><a href="C-PremiumFoundations.html#propiedades-de-los-principios-de-tarificación"><i class="fa fa-check"></i><b>7.3.2</b> Propiedades de los Principios de Tarificación</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="C-PremiumFoundations.html"><a href="C-PremiumFoundations.html#S:HeterogeneousRisks"><i class="fa fa-check"></i><b>7.4</b> Riesgos Heterogéneos</a><ul>
<li class="chapter" data-level="7.4.1" data-path="C-PremiumFoundations.html"><a href="C-PremiumFoundations.html#S:ExposureToRisk"><i class="fa fa-check"></i><b>7.4.1</b> Exposición al Riesgo</a></li>
<li class="chapter" data-level="7.4.2" data-path="C-PremiumFoundations.html"><a href="C-PremiumFoundations.html#S:RatingFactors"><i class="fa fa-check"></i><b>7.4.2</b> Factores de Tarificación</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="C-PremiumFoundations.html"><a href="C-PremiumFoundations.html#S:TrendDevelopment"><i class="fa fa-check"></i><b>7.5</b> Desarrollo y Tendencia</a><ul>
<li class="chapter" data-level="7.5.1" data-path="C-PremiumFoundations.html"><a href="C-PremiumFoundations.html#exposiciones-y-primas"><i class="fa fa-check"></i><b>7.5.1</b> Exposiciones y Primas</a></li>
<li class="chapter" data-level="7.5.2" data-path="C-PremiumFoundations.html"><a href="C-PremiumFoundations.html#siniestros-reclamaciones-y-pagos"><i class="fa fa-check"></i><b>7.5.2</b> Siniestros, Reclamaciones y Pagos</a></li>
<li class="chapter" data-level="7.5.3" data-path="C-PremiumFoundations.html"><a href="C-PremiumFoundations.html#S:CompareMethods"><i class="fa fa-check"></i><b>7.5.3</b> Comparación de los Métodos de Prima Pura y Ratio de Siniestralidad</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="C-PremiumFoundations.html"><a href="C-PremiumFoundations.html#S:GiniStatistic"><i class="fa fa-check"></i><b>7.6</b> Selección de Prima</a><ul>
<li class="chapter" data-level="7.6.1" data-path="C-PremiumFoundations.html"><a href="C-PremiumFoundations.html#curva-de-lorenz-clásica"><i class="fa fa-check"></i><b>7.6.1</b> Curva de Lorenz Clásica</a></li>
<li class="chapter" data-level="7.6.2" data-path="C-PremiumFoundations.html"><a href="C-PremiumFoundations.html#curva-de-rendimiento-y-estadístico-de-gini"><i class="fa fa-check"></i><b>7.6.2</b> Curva de Rendimiento y Estadístico de Gini</a></li>
<li class="chapter" data-level="7.6.3" data-path="C-PremiumFoundations.html"><a href="C-PremiumFoundations.html#validación-cruzada"><i class="fa fa-check"></i><b>7.6.3</b> Validación Cruzada</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="C-PremiumFoundations.html"><a href="C-PremiumFoundations.html#otros-recursos-y-colaboradores"><i class="fa fa-check"></i><b>7.7</b> Otros Recursos y Colaboradores</a><ul>
<li class="chapter" data-level="" data-path="C-PremiumFoundations.html"><a href="C-PremiumFoundations.html#ts-7.a.-regulación-de-la-tarificación"><i class="fa fa-check"></i>TS 7.A. Regulación de la Tarificación</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="C-RiskClass.html"><a href="C-RiskClass.html"><i class="fa fa-check"></i><b>8</b> Clasificación de Riesgos</a><ul>
<li class="chapter" data-level="8.1" data-path="C-RiskClass.html"><a href="C-RiskClass.html#S:RC:Introduction"><i class="fa fa-check"></i><b>8.1</b> Introducción</a></li>
<li class="chapter" data-level="8.2" data-path="C-RiskClass.html"><a href="C-RiskClass.html#S:RC:PoissonRegression"><i class="fa fa-check"></i><b>8.2</b> Modelo de Regresión de Poisson</a><ul>
<li class="chapter" data-level="8.2.1" data-path="C-RiskClass.html"><a href="C-RiskClass.html#S:RC:Need.Poi.reg"><i class="fa fa-check"></i><b>8.2.1</b> Necesidad de la Regresión de Poisson</a></li>
<li class="chapter" data-level="8.2.2" data-path="C-RiskClass.html"><a href="C-RiskClass.html#regresión-de-poisson"><i class="fa fa-check"></i><b>8.2.2</b> Regresión de Poisson</a></li>
<li class="chapter" data-level="8.2.3" data-path="C-RiskClass.html"><a href="C-RiskClass.html#incorporación-de-la-exposición"><i class="fa fa-check"></i><b>8.2.3</b> Incorporación de la exposición</a></li>
<li class="chapter" data-level="8.2.4" data-path="C-RiskClass.html"><a href="C-RiskClass.html#ejercicios-3"><i class="fa fa-check"></i><b>8.2.4</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="C-RiskClass.html"><a href="C-RiskClass.html#S:CatVarMultiTarriff"><i class="fa fa-check"></i><b>8.3</b> Variables Categóricas y Tarifa Multiplicativa</a><ul>
<li class="chapter" data-level="8.3.1" data-path="C-RiskClass.html"><a href="C-RiskClass.html#factores-de-tarificación-y-tarifa"><i class="fa fa-check"></i><b>8.3.1</b> Factores de Tarificación y Tarifa</a></li>
<li class="chapter" data-level="8.3.2" data-path="C-RiskClass.html"><a href="C-RiskClass.html#modelo-de-tarifa-multiplicativa"><i class="fa fa-check"></i><b>8.3.2</b> Modelo de Tarifa Multiplicativa</a></li>
<li class="chapter" data-level="8.3.3" data-path="C-RiskClass.html"><a href="C-RiskClass.html#regresión-de-poisson-para-la-tarifa-multiplicativa"><i class="fa fa-check"></i><b>8.3.3</b> Regresión de Poisson para la Tarifa Multiplicativa</a></li>
<li class="chapter" data-level="8.3.4" data-path="C-RiskClass.html"><a href="C-RiskClass.html#ejemplos-numéricos"><i class="fa fa-check"></i><b>8.3.4</b> Ejemplos numéricos</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="C-RiskClass.html"><a href="C-RiskClass.html#RC:further-reading-and-resources"><i class="fa fa-check"></i><b>8.4</b> Más Recursos y Colaboradores</a><ul>
<li class="chapter" data-level="" data-path="C-RiskClass.html"><a href="C-RiskClass.html#ts-8.a-estimación-de-modelos-de-regresión-de-poisson"><i class="fa fa-check"></i>TS 8.A – Estimación de Modelos de Regresión de Poisson</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="C-Credibility.html"><a href="C-Credibility.html"><i class="fa fa-check"></i><b>9</b> Tarificación Basada en la Experiencia Mediante Teoría de la Credibilidad</a><ul>
<li class="chapter" data-level="9.1" data-path="C-Credibility.html"><a href="C-Credibility.html#introducción-a-las-aplicaciones-de-la-teoría-de-la-credibilidad"><i class="fa fa-check"></i><b>9.1</b> Introducción a las Aplicaciones de la Teoría de la Credibilidad</a></li>
<li class="chapter" data-level="9.2" data-path="C-Credibility.html"><a href="C-Credibility.html#credibilidad-de-fluctuación-limitada"><i class="fa fa-check"></i><b>9.2</b> Credibilidad de Fluctuación Limitada</a><ul>
<li class="chapter" data-level="9.2.1" data-path="C-Credibility.html"><a href="C-Credibility.html#S:frequency"><i class="fa fa-check"></i><b>9.2.1</b> Credibilidad Completa para la Frecuencia de Siniestralidad</a></li>
<li class="chapter" data-level="9.2.2" data-path="C-Credibility.html"><a href="C-Credibility.html#credibilidad-completa-para-la-siniestralidad-agregada-y-la-prima-pura"><i class="fa fa-check"></i><b>9.2.2</b> Credibilidad Completa para la Siniestralidad Agregada y la Prima Pura</a></li>
<li class="chapter" data-level="9.2.3" data-path="C-Credibility.html"><a href="C-Credibility.html#credibilidad-completa-para-la-severidad"><i class="fa fa-check"></i><b>9.2.3</b> Credibilidad Completa para la Severidad</a></li>
<li class="chapter" data-level="9.2.4" data-path="C-Credibility.html"><a href="C-Credibility.html#credibilidad-parcial"><i class="fa fa-check"></i><b>9.2.4</b> Credibilidad parcial</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="C-Credibility.html"><a href="C-Credibility.html#credibilidad-de-bühlmann"><i class="fa fa-check"></i><b>9.3</b> Credibilidad de Bühlmann</a><ul>
<li class="chapter" data-level="9.3.1" data-path="C-Credibility.html"><a href="C-Credibility.html#S:EPV-VHM-Z"><i class="fa fa-check"></i><b>9.3.1</b> Credibilidad Z, <em>EPV</em>, y <em>VHM</em></a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="C-Credibility.html"><a href="C-Credibility.html#credibilidad-de-bühlmann-straub"><i class="fa fa-check"></i><b>9.4</b> Credibilidad de Bühlmann-Straub</a></li>
<li class="chapter" data-level="9.5" data-path="C-Credibility.html"><a href="C-Credibility.html#Cred-further-reading-and-resources"><i class="fa fa-check"></i><b>9.5</b> Otros Recursos y Colaboradores</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="C-PortMgt.html"><a href="C-PortMgt.html"><i class="fa fa-check"></i><b>10</b> Gestión de Carteras de Seguros incluyendo Reaseguro</a><ul>
<li class="chapter" data-level="10.1" data-path="C-PortMgt.html"><a href="C-PortMgt.html#introducción-a-las-carteras-de-seguros"><i class="fa fa-check"></i><b>10.1</b> Introducción a las Carteras de Seguros</a></li>
<li class="chapter" data-level="10.2" data-path="C-PortMgt.html"><a href="C-PortMgt.html#S:Tails"><i class="fa fa-check"></i><b>10.2</b> Colas de las Distribuciones</a><ul>
<li class="chapter" data-level="10.2.1" data-path="C-PortMgt.html"><a href="C-PortMgt.html#clasificación-basada-en-los-momentos"><i class="fa fa-check"></i><b>10.2.1</b> Clasificación Basada en los Momentos</a></li>
<li class="chapter" data-level="10.2.2" data-path="C-PortMgt.html"><a href="C-PortMgt.html#comparación-basada-en-el-comportamiento-de-colas-con-límites"><i class="fa fa-check"></i><b>10.2.2</b> Comparación basada en el comportamiento de colas con límites</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="C-PortMgt.html"><a href="C-PortMgt.html#S:RiskMeasure"><i class="fa fa-check"></i><b>10.3</b> Medidas de Riesgo</a><ul>
<li class="chapter" data-level="10.3.1" data-path="C-PortMgt.html"><a href="C-PortMgt.html#medidas-de-riesgo-coherentes"><i class="fa fa-check"></i><b>10.3.1</b> Medidas de Riesgo Coherentes</a></li>
<li class="chapter" data-level="10.3.2" data-path="C-PortMgt.html"><a href="C-PortMgt.html#valor-en-riesgo"><i class="fa fa-check"></i><b>10.3.2</b> Valor en Riesgo</a></li>
<li class="chapter" data-level="10.3.3" data-path="C-PortMgt.html"><a href="C-PortMgt.html#cola-del-valor-en-riesgo"><i class="fa fa-check"></i><b>10.3.3</b> Cola del Valor en Riesgo</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="C-PortMgt.html"><a href="C-PortMgt.html#S:Reinsurance"><i class="fa fa-check"></i><b>10.4</b> Reaseguro</a><ul>
<li class="chapter" data-level="10.4.1" data-path="C-PortMgt.html"><a href="C-PortMgt.html#S:ProportionalRe"><i class="fa fa-check"></i><b>10.4.1</b> Reaseguro Proporcional</a></li>
<li class="chapter" data-level="10.4.2" data-path="C-PortMgt.html"><a href="C-PortMgt.html#S:NonProportionalRe"><i class="fa fa-check"></i><b>10.4.2</b> Reaseguro No-Proporcional</a></li>
<li class="chapter" data-level="10.4.3" data-path="C-PortMgt.html"><a href="C-PortMgt.html#S:AdditionalRe"><i class="fa fa-check"></i><b>10.4.3</b> Acuerdos de Reaseguro Adicionales</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="C-PortMgt.html"><a href="C-PortMgt.html#recursos-y-colaboradores-adicionales"><i class="fa fa-check"></i><b>10.5</b> Recursos y Colaboradores adicionales</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="C-LossReserves.html"><a href="C-LossReserves.html"><i class="fa fa-check"></i><b>11</b> Provisiones</a><ul>
<li class="chapter" data-level="11.1" data-path="C-LossReserves.html"><a href="C-LossReserves.html#S:motivation"><i class="fa fa-check"></i><b>11.1</b> Motivación</a><ul>
<li class="chapter" data-level="11.1.1" data-path="C-LossReserves.html"><a href="C-LossReserves.html#S:claim-types"><i class="fa fa-check"></i><b>11.1.1</b> Siniestros cerrados, IBNR, y RBNS</a></li>
<li class="chapter" data-level="11.1.2" data-path="C-LossReserves.html"><a href="C-LossReserves.html#por-qué-reservar"><i class="fa fa-check"></i><b>11.1.2</b> ¿Por qué reservar?</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="C-LossReserves.html"><a href="C-LossReserves.html#S:Data"><i class="fa fa-check"></i><b>11.2</b> Datos de provisiones</a><ul>
<li class="chapter" data-level="11.2.1" data-path="C-LossReserves.html"><a href="C-LossReserves.html#de-micro-a-macro"><i class="fa fa-check"></i><b>11.2.1</b> De Micro a Macro</a></li>
<li class="chapter" data-level="11.2.2" data-path="C-LossReserves.html"><a href="C-LossReserves.html#triángulos-de-desarrollo"><i class="fa fa-check"></i><b>11.2.2</b> Triángulos de desarrollo</a></li>
<li class="chapter" data-level="11.2.3" data-path="C-LossReserves.html"><a href="C-LossReserves.html#notación-de-provisiones"><i class="fa fa-check"></i><b>11.2.3</b> Notación de provisiones</a></li>
<li class="chapter" data-level="11.2.4" data-path="C-LossReserves.html"><a href="C-LossReserves.html#S:Rcode"><i class="fa fa-check"></i><b>11.2.4</b> Código R para resumir datos de provisión de pérdidas</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="C-LossReserves.html"><a href="C-LossReserves.html#S:Chain-ladder"><i class="fa fa-check"></i><b>11.3</b> Chain-Ladder</a><ul>
<li class="chapter" data-level="11.3.1" data-path="C-LossReserves.html"><a href="C-LossReserves.html#S:DeterministicCL"><i class="fa fa-check"></i><b>11.3.1</b> Chain-Ladder Determinista</a></li>
<li class="chapter" data-level="11.3.2" data-path="C-LossReserves.html"><a href="C-LossReserves.html#modelo-chain-ladder-de-distribución-libre-de-mack"><i class="fa fa-check"></i><b>11.3.2</b> Modelo Chain-ladder de distribución libre de Mack</a></li>
<li class="chapter" data-level="11.3.3" data-path="C-LossReserves.html"><a href="C-LossReserves.html#código-r-para-las-predicciones-chain-ladder"><i class="fa fa-check"></i><b>11.3.3</b> Código R para las predicciones Chain-Ladder</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="C-LossReserves.html"><a href="C-LossReserves.html#S:GLMs"><i class="fa fa-check"></i><b>11.4</b> GLMs y Bootstrap para provisiones</a><ul>
<li class="chapter" data-level="11.4.1" data-path="C-LossReserves.html"><a href="C-LossReserves.html#especificación-del-modelo"><i class="fa fa-check"></i><b>11.4.1</b> Especificación del modelo</a></li>
<li class="chapter" data-level="11.4.2" data-path="C-LossReserves.html"><a href="C-LossReserves.html#estimación-y-predicción-del-modelo"><i class="fa fa-check"></i><b>11.4.2</b> Estimación y predicción del modelo</a></li>
<li class="chapter" data-level="11.4.3" data-path="C-LossReserves.html"><a href="C-LossReserves.html#bootstrap"><i class="fa fa-check"></i><b>11.4.3</b> Bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="C-LossReserves.html"><a href="C-LossReserves.html#LossRe:further-reading-and-resources"><i class="fa fa-check"></i><b>11.5</b> Recursos adicionales y contribuciones</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="C-BonusMalus.html"><a href="C-BonusMalus.html"><i class="fa fa-check"></i><b>12</b> Experience Rating using Bonus-Malus</a><ul>
<li class="chapter" data-level="12.1" data-path="C-BonusMalus.html"><a href="C-BonusMalus.html#S:ERBM:Intro"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="C-BonusMalus.html"><a href="C-BonusMalus.html#S:ERBM:NCD"><i class="fa fa-check"></i><b>12.2</b> NCD System in Several Countries</a><ul>
<li class="chapter" data-level="12.2.1" data-path="C-BonusMalus.html"><a href="C-BonusMalus.html#ncd-system-in-malaysia"><i class="fa fa-check"></i><b>12.2.1</b> NCD System in Malaysia</a></li>
<li class="chapter" data-level="12.2.2" data-path="C-BonusMalus.html"><a href="C-BonusMalus.html#ncd-system-in-other-countries"><i class="fa fa-check"></i><b>12.2.2</b> NCD System in Other Countries</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="C-BonusMalus.html"><a href="C-BonusMalus.html#S:ERBM:BMS"><i class="fa fa-check"></i><b>12.3</b> BMS and Markov Chain Model</a><ul>
<li class="chapter" data-level="12.3.1" data-path="C-BonusMalus.html"><a href="C-BonusMalus.html#transition-probability"><i class="fa fa-check"></i><b>12.3.1</b> Transition Probability</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="C-BonusMalus.html"><a href="C-BonusMalus.html#S:ERBM:StatDist"><i class="fa fa-check"></i><b>12.4</b> BMS and Stationary Distribution</a><ul>
<li class="chapter" data-level="12.4.1" data-path="C-BonusMalus.html"><a href="C-BonusMalus.html#stationary-distribution"><i class="fa fa-check"></i><b>12.4.1</b> Stationary Distribution</a></li>
<li class="chapter" data-level="12.4.2" data-path="C-BonusMalus.html"><a href="C-BonusMalus.html#r-program-for-stationary-distribution"><i class="fa fa-check"></i><b>12.4.2</b> R Program for Stationary Distribution</a></li>
<li class="chapter" data-level="12.4.3" data-path="C-BonusMalus.html"><a href="C-BonusMalus.html#premium-evolution"><i class="fa fa-check"></i><b>12.4.3</b> Premium Evolution</a></li>
<li class="chapter" data-level="12.4.4" data-path="C-BonusMalus.html"><a href="C-BonusMalus.html#r-program-for-premium-evolution"><i class="fa fa-check"></i><b>12.4.4</b> R Program for Premium Evolution</a></li>
<li class="chapter" data-level="12.4.5" data-path="C-BonusMalus.html"><a href="C-BonusMalus.html#convergence-rate"><i class="fa fa-check"></i><b>12.4.5</b> Convergence Rate</a></li>
<li class="chapter" data-level="12.4.6" data-path="C-BonusMalus.html"><a href="C-BonusMalus.html#r-program-for-convergence-rate"><i class="fa fa-check"></i><b>12.4.6</b> R Program for Convergence Rate</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="C-BonusMalus.html"><a href="C-BonusMalus.html#S:PremRtg"><i class="fa fa-check"></i><b>12.5</b> BMS and Premium Rating</a><ul>
<li class="chapter" data-level="12.5.1" data-path="C-BonusMalus.html"><a href="C-BonusMalus.html#premium-rating"><i class="fa fa-check"></i><b>12.5.1</b> Premium Rating</a></li>
<li class="chapter" data-level="12.5.2" data-path="C-BonusMalus.html"><a href="C-BonusMalus.html#frequency-model-poisson-and-negative-binomial-regressions"><i class="fa fa-check"></i><b>12.5.2</b> Frequency Model – Poisson and Negative Binomial Regressions</a></li>
<li class="chapter" data-level="12.5.3" data-path="C-BonusMalus.html"><a href="C-BonusMalus.html#premium-rating-with-bonus-malus-data"><i class="fa fa-check"></i><b>12.5.3</b> Premium Rating with Bonus-Malus Data</a></li>
<li class="chapter" data-level="12.5.4" data-path="C-BonusMalus.html"><a href="C-BonusMalus.html#premium-rating-without-bonus-malus-data"><i class="fa fa-check"></i><b>12.5.4</b> Premium Rating without Bonus-Malus Data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="C-DataSystems.html"><a href="C-DataSystems.html"><i class="fa fa-check"></i><b>13</b> Datos y Sistemas</a><ul>
<li class="chapter" data-level="13.1" data-path="C-DataSystems.html"><a href="C-DataSystems.html#datos"><i class="fa fa-check"></i><b>13.1</b> Datos</a><ul>
<li class="chapter" data-level="13.1.1" data-path="C-DataSystems.html"><a href="C-DataSystems.html#tipos-y-fuentes-de-datos"><i class="fa fa-check"></i><b>13.1.1</b> Tipos y Fuentes de Datos</a></li>
<li class="chapter" data-level="13.1.2" data-path="C-DataSystems.html"><a href="C-DataSystems.html#estructuras-de-datos-y-almacenamiento"><i class="fa fa-check"></i><b>13.1.2</b> Estructuras de Datos y Almacenamiento</a></li>
<li class="chapter" data-level="13.1.3" data-path="C-DataSystems.html"><a href="C-DataSystems.html#calidad-de-los-datos"><i class="fa fa-check"></i><b>13.1.3</b> Calidad de los Datos</a></li>
<li class="chapter" data-level="13.1.4" data-path="C-DataSystems.html"><a href="C-DataSystems.html#limpieza-de-los-datos"><i class="fa fa-check"></i><b>13.1.4</b> Limpieza de los Datos</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="C-DataSystems.html"><a href="C-DataSystems.html#análisis-preliminar-de-los-datos"><i class="fa fa-check"></i><b>13.2</b> Análisis Preliminar de los Datos</a><ul>
<li class="chapter" data-level="13.2.1" data-path="C-DataSystems.html"><a href="C-DataSystems.html#S:process"><i class="fa fa-check"></i><b>13.2.1</b> Proceso de Análisis de Datos</a></li>
<li class="chapter" data-level="13.2.2" data-path="C-DataSystems.html"><a href="C-DataSystems.html#exploratorio-versus-confirmatorio"><i class="fa fa-check"></i><b>13.2.2</b> Exploratorio versus Confirmatorio</a></li>
<li class="chapter" data-level="13.2.3" data-path="C-DataSystems.html"><a href="C-DataSystems.html#supervisado-versus-no-supervisado"><i class="fa fa-check"></i><b>13.2.3</b> Supervisado versus No Supervisado</a></li>
<li class="chapter" data-level="13.2.4" data-path="C-DataSystems.html"><a href="C-DataSystems.html#paramétricos-versus-no-paramétricos"><i class="fa fa-check"></i><b>13.2.4</b> Paramétricos versus No Paramétricos</a></li>
<li class="chapter" data-level="13.2.5" data-path="C-DataSystems.html"><a href="C-DataSystems.html#S:expred"><i class="fa fa-check"></i><b>13.2.5</b> Explicación versus Predicción</a></li>
<li class="chapter" data-level="13.2.6" data-path="C-DataSystems.html"><a href="C-DataSystems.html#modelación-de-datos-versus-modelación-algorítmica"><i class="fa fa-check"></i><b>13.2.6</b> Modelación de Datos versus Modelación Algorítmica</a></li>
<li class="chapter" data-level="13.2.7" data-path="C-DataSystems.html"><a href="C-DataSystems.html#análisis-de-grandes-volúmenes-de-datos-big-data"><i class="fa fa-check"></i><b>13.2.7</b> Análisis de Grandes Volúmenes de Datos (Big Data)</a></li>
<li class="chapter" data-level="13.2.8" data-path="C-DataSystems.html"><a href="C-DataSystems.html#análisis-reproducibles"><i class="fa fa-check"></i><b>13.2.8</b> Análisis Reproducibles</a></li>
<li class="chapter" data-level="13.2.9" data-path="C-DataSystems.html"><a href="C-DataSystems.html#problemas-éticos"><i class="fa fa-check"></i><b>13.2.9</b> Problemas Éticos</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="C-DataSystems.html"><a href="C-DataSystems.html#técnicas-de-análisis-de-datos"><i class="fa fa-check"></i><b>13.3</b> Técnicas de Análisis de Datos</a><ul>
<li class="chapter" data-level="13.3.1" data-path="C-DataSystems.html"><a href="C-DataSystems.html#técnicas-exploratorias"><i class="fa fa-check"></i><b>13.3.1</b> Técnicas exploratorias</a></li>
<li class="chapter" data-level="13.3.2" data-path="C-DataSystems.html"><a href="C-DataSystems.html#técnicas-confirmatorias"><i class="fa fa-check"></i><b>13.3.2</b> Técnicas confirmatorias</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="C-DataSystems.html"><a href="C-DataSystems.html#algunas-funciones-de-r"><i class="fa fa-check"></i><b>13.4</b> Algunas funciones de R</a></li>
<li class="chapter" data-level="13.5" data-path="C-DataSystems.html"><a href="C-DataSystems.html#resumen"><i class="fa fa-check"></i><b>13.5</b> Resumen</a></li>
<li class="chapter" data-level="13.6" data-path="C-DataSystems.html"><a href="C-DataSystems.html#DS:further-reading-and-resources"><i class="fa fa-check"></i><b>13.6</b> Otros recursos y colaboradores</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html"><i class="fa fa-check"></i><b>14</b> Dependence Modeling</a><ul>
<li class="chapter" data-level="14.1" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#S:VarTypes"><i class="fa fa-check"></i><b>14.1</b> Variable Types</a><ul>
<li class="chapter" data-level="14.1.1" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#S:QuaVar"><i class="fa fa-check"></i><b>14.1.1</b> Qualitative Variables</a></li>
<li class="chapter" data-level="14.1.2" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#S:QuanVar"><i class="fa fa-check"></i><b>14.1.2</b> Quantitative Variables</a></li>
<li class="chapter" data-level="14.1.3" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#multivariate-variables"><i class="fa fa-check"></i><b>14.1.3</b> Multivariate Variables</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#S:Measures"><i class="fa fa-check"></i><b>14.2</b> Classic Measures of Scalar Associations</a><ul>
<li class="chapter" data-level="14.2.1" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#association-measures-for-quantitative-variables"><i class="fa fa-check"></i><b>14.2.1</b> Association Measures for Quantitative Variables</a></li>
<li class="chapter" data-level="14.2.2" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#rank-based-measures"><i class="fa fa-check"></i><b>14.2.2</b> Rank Based Measures</a></li>
<li class="chapter" data-level="14.2.3" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#nominal-variables"><i class="fa fa-check"></i><b>14.2.3</b> Nominal Variables</a></li>
<li class="chapter" data-level="14.2.4" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#ordinal-variables"><i class="fa fa-check"></i><b>14.2.4</b> Ordinal Variables</a></li>
<li class="chapter" data-level="14.2.5" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#interval-variables"><i class="fa fa-check"></i><b>14.2.5</b> Interval Variables</a></li>
<li class="chapter" data-level="14.2.6" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#discrete-and-continuous-variables"><i class="fa fa-check"></i><b>14.2.6</b> Discrete and Continuous Variables</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#S:Copula"><i class="fa fa-check"></i><b>14.3</b> Introduction to Copulas</a></li>
<li class="chapter" data-level="14.4" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#S:CopAppl"><i class="fa fa-check"></i><b>14.4</b> Application Using Copulas</a><ul>
<li class="chapter" data-level="14.4.1" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#data-description"><i class="fa fa-check"></i><b>14.4.1</b> Data Description</a></li>
<li class="chapter" data-level="14.4.2" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#marginal-models"><i class="fa fa-check"></i><b>14.4.2</b> Marginal Models</a></li>
<li class="chapter" data-level="14.4.3" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#probability-integral-transformation"><i class="fa fa-check"></i><b>14.4.3</b> Probability Integral Transformation</a></li>
<li class="chapter" data-level="14.4.4" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#joint-modeling-with-copula-function"><i class="fa fa-check"></i><b>14.4.4</b> Joint Modeling with Copula Function</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#S:CopTyp"><i class="fa fa-check"></i><b>14.5</b> Types of Copulas</a><ul>
<li class="chapter" data-level="14.5.1" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#elliptical-copulas"><i class="fa fa-check"></i><b>14.5.1</b> Elliptical Copulas</a></li>
<li class="chapter" data-level="14.5.2" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#archimedian-copulas"><i class="fa fa-check"></i><b>14.5.2</b> Archimedian Copulas</a></li>
<li class="chapter" data-level="14.5.3" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#properties-of-copulas"><i class="fa fa-check"></i><b>14.5.3</b> Properties of Copulas</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#S:CopImp"><i class="fa fa-check"></i><b>14.6</b> Why is Dependence Modeling Important?</a></li>
<li class="chapter" data-level="14.7" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#Dep:further-reading-and-resources"><i class="fa fa-check"></i><b>14.7</b> Further Resources and Contributors</a><ul>
<li class="chapter" data-level="" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#ts-14.a.-other-classic-measures-of-scalar-associations"><i class="fa fa-check"></i>TS 14.A. Other Classic Measures of Scalar Associations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="C-AppA.html"><a href="C-AppA.html"><i class="fa fa-check"></i><b>15</b> Apéndice A: Revisión de la Inferencia Estadística</a><ul>
<li class="chapter" data-level="15.1" data-path="C-AppA.html"><a href="C-AppA.html#S:AppA:BASIC"><i class="fa fa-check"></i><b>15.1</b> Conceptos Básicos</a><ul>
<li class="chapter" data-level="15.1.1" data-path="C-AppA.html"><a href="C-AppA.html#muestreo-aleatorio"><i class="fa fa-check"></i><b>15.1.1</b> Muestreo Aleatorio</a></li>
<li class="chapter" data-level="15.1.2" data-path="C-AppA.html"><a href="C-AppA.html#distribución-muestral"><i class="fa fa-check"></i><b>15.1.2</b> Distribución Muestral</a></li>
<li class="chapter" data-level="15.1.3" data-path="C-AppA.html"><a href="C-AppA.html#teorema-central-del-límite"><i class="fa fa-check"></i><b>15.1.3</b> Teorema Central del Límite</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="C-AppA.html"><a href="C-AppA.html#S:AppA:PE"><i class="fa fa-check"></i><b>15.2</b> Estimación Puntual y Propiedades</a><ul>
<li class="chapter" data-level="15.2.1" data-path="C-AppA.html"><a href="C-AppA.html#método-de-estimación-de-momentos"><i class="fa fa-check"></i><b>15.2.1</b> Método de Estimación de Momentos</a></li>
<li class="chapter" data-level="15.2.2" data-path="C-AppA.html"><a href="C-AppA.html#S:AppA:MLE"><i class="fa fa-check"></i><b>15.2.2</b> Estimación por Máxima Verosimilitud</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="C-AppA.html"><a href="C-AppA.html#S:AppA:IE"><i class="fa fa-check"></i><b>15.3</b> Estimación de Intervalo</a><ul>
<li class="chapter" data-level="15.3.1" data-path="C-AppA.html"><a href="C-AppA.html#S:AppA:IE:ED"><i class="fa fa-check"></i><b>15.3.1</b> Distribución Exacta para la Media de Muestra Normal</a></li>
<li class="chapter" data-level="15.3.2" data-path="C-AppA.html"><a href="C-AppA.html#propiedades-de-muestra-grande-del-estimador-mle"><i class="fa fa-check"></i><b>15.3.2</b> Propiedades de Muestra Grande del Estimador MLE</a></li>
<li class="chapter" data-level="15.3.3" data-path="C-AppA.html"><a href="C-AppA.html#intervalo-de-confianza"><i class="fa fa-check"></i><b>15.3.3</b> Intervalo de confianza</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="C-AppA.html"><a href="C-AppA.html#S:AppA:HT"><i class="fa fa-check"></i><b>15.4</b> Pruebas de Hipótesis</a><ul>
<li class="chapter" data-level="15.4.1" data-path="C-AppA.html"><a href="C-AppA.html#conceptos-básicos"><i class="fa fa-check"></i><b>15.4.1</b> Conceptos Básicos</a></li>
<li class="chapter" data-level="15.4.2" data-path="C-AppA.html"><a href="C-AppA.html#contraste-t-student-basado-en-el-estimador-mle"><i class="fa fa-check"></i><b>15.4.2</b> Contraste <span class="math inline">\(t\)</span>-Student Basado en el Estimador MLE</a></li>
<li class="chapter" data-level="15.4.3" data-path="C-AppA.html"><a href="C-AppA.html#S:AppA:HT:LRT"><i class="fa fa-check"></i><b>15.4.3</b> Prueba de la Razón de Verosimilitud</a></li>
<li class="chapter" data-level="15.4.4" data-path="C-AppA.html"><a href="C-AppA.html#S:AppA:HT:IC"><i class="fa fa-check"></i><b>15.4.4</b> Criterios de Información</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="C-AppB.html"><a href="C-AppB.html"><i class="fa fa-check"></i><b>16</b> Apéndice B: Esperanzas Iteradas</a><ul>
<li class="chapter" data-level="16.1" data-path="C-AppB.html"><a href="C-AppB.html#S:AppB:CD"><i class="fa fa-check"></i><b>16.1</b> Distribución Condicionada y Esperanza Condicional</a><ul>
<li class="chapter" data-level="16.1.1" data-path="C-AppB.html"><a href="C-AppB.html#distribución-condicional"><i class="fa fa-check"></i><b>16.1.1</b> Distribución Condicional</a></li>
<li class="chapter" data-level="16.1.2" data-path="C-AppB.html"><a href="C-AppB.html#caso-continuo"><i class="fa fa-check"></i><b>16.1.2</b> Caso Continuo</a></li>
<li class="chapter" data-level="16.1.3" data-path="C-AppB.html"><a href="C-AppB.html#esperanza-condicional-y-varianza-condicional"><i class="fa fa-check"></i><b>16.1.3</b> Esperanza Condicional y Varianza Condicional</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="C-AppB.html"><a href="C-AppB.html#S:AppB:IE"><i class="fa fa-check"></i><b>16.2</b> Esperanzas Iteradas y Varianza Total</a><ul>
<li class="chapter" data-level="16.2.1" data-path="C-AppB.html"><a href="C-AppB.html#ley-de-las-esperanzas-iteradas"><i class="fa fa-check"></i><b>16.2.1</b> Ley de las Esperanzas Iteradas</a></li>
<li class="chapter" data-level="16.2.2" data-path="C-AppB.html"><a href="C-AppB.html#ley-de-la-varianza-total"><i class="fa fa-check"></i><b>16.2.2</b> Ley de la Varianza Total</a></li>
<li class="chapter" data-level="16.2.3" data-path="C-AppB.html"><a href="C-AppB.html#aplicación"><i class="fa fa-check"></i><b>16.2.3</b> Aplicación</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="C-AppB.html"><a href="C-AppB.html#S:AppConjugateDistributions"><i class="fa fa-check"></i><b>16.3</b> Distribuciones Conjugadas</a><ul>
<li class="chapter" data-level="16.3.1" data-path="C-AppB.html"><a href="C-AppB.html#familia-exponencial-lineal"><i class="fa fa-check"></i><b>16.3.1</b> Familia Exponencial Lineal</a></li>
<li class="chapter" data-level="16.3.2" data-path="C-AppB.html"><a href="C-AppB.html#distribuciones-conjugadas"><i class="fa fa-check"></i><b>16.3.2</b> Distribuciones Conjugadas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="C-AppC.html"><a href="C-AppC.html"><i class="fa fa-check"></i><b>17</b> Apéndice C: Teoría de la Máxima Verosimilitud</a><ul>
<li class="chapter" data-level="17.1" data-path="C-AppC.html"><a href="C-AppC.html#S:AppC:LF"><i class="fa fa-check"></i><b>17.1</b> Función de Verosimilitud</a><ul>
<li class="chapter" data-level="17.1.1" data-path="C-AppC.html"><a href="C-AppC.html#la-función-de-verosimilitud-y-de-log-verosimilitud"><i class="fa fa-check"></i><b>17.1.1</b> La Función de Verosimilitud y de Log-verosimilitud</a></li>
<li class="chapter" data-level="17.1.2" data-path="C-AppC.html"><a href="C-AppC.html#propiedades-de-las-funciones-de-verosimilitud"><i class="fa fa-check"></i><b>17.1.2</b> Propiedades de las Funciones de Verosimilitud</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="C-AppC.html"><a href="C-AppC.html#S:AppC:MLE"><i class="fa fa-check"></i><b>17.2</b> Estimadores de Máxima Verosimilitud</a><ul>
<li class="chapter" data-level="17.2.1" data-path="C-AppC.html"><a href="C-AppC.html#definición-y-derivación-del-estimador-mle"><i class="fa fa-check"></i><b>17.2.1</b> Definición y Derivación del Estimador MLE</a></li>
<li class="chapter" data-level="17.2.2" data-path="C-AppC.html"><a href="C-AppC.html#propiedades-asintóticas-del-estimador-mle"><i class="fa fa-check"></i><b>17.2.2</b> Propiedades Asintóticas del Estimador MLE</a></li>
<li class="chapter" data-level="17.2.3" data-path="C-AppC.html"><a href="C-AppC.html#uso-de-la-estimación-de-máxima-verosimilitud"><i class="fa fa-check"></i><b>17.2.3</b> Uso de la Estimación de Máxima Verosimilitud</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="C-AppC.html"><a href="C-AppC.html#S:AppC:SI"><i class="fa fa-check"></i><b>17.3</b> Inferencia Estadística Basada en la Estimación de Báxima Verosimilitud</a><ul>
<li class="chapter" data-level="17.3.1" data-path="C-AppC.html"><a href="C-AppC.html#contraste-de-hipótesis"><i class="fa fa-check"></i><b>17.3.1</b> Contraste de Hipótesis</a></li>
<li class="chapter" data-level="17.3.2" data-path="C-AppC.html"><a href="C-AppC.html#S:AppC:MLEModelVal"><i class="fa fa-check"></i><b>17.3.2</b> Validación del Modelo y MLE</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="C-SummaryDistributions.html"><a href="C-SummaryDistributions.html"><i class="fa fa-check"></i><b>18</b> Apéndice D: Resumen de Distribuciones</a><ul>
<li class="chapter" data-level="18.1" data-path="C-SummaryDistributions.html"><a href="C-SummaryDistributions.html#distribuciones-discretas"><i class="fa fa-check"></i><b>18.1</b> Distribuciones Discretas</a><ul>
<li class="chapter" data-level="18.1.1" data-path="C-SummaryDistributions.html"><a href="C-SummaryDistributions.html#la-clase-ab0"><i class="fa fa-check"></i><b>18.1.1</b> La clase (a,b,0)</a></li>
<li class="chapter" data-level="18.1.2" data-path="C-SummaryDistributions.html"><a href="C-SummaryDistributions.html#la-clase-ab1"><i class="fa fa-check"></i><b>18.1.2</b> La clase (a,b,1)</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="C-SummaryDistributions.html"><a href="C-SummaryDistributions.html#distribuciones-continuas"><i class="fa fa-check"></i><b>18.2</b> Distribuciones Continuas</a><ul>
<li class="chapter" data-level="18.2.1" data-path="C-SummaryDistributions.html"><a href="C-SummaryDistributions.html#distribuciones-un-parámetro"><i class="fa fa-check"></i><b>18.2.1</b> Distribuciones Un Parámetro</a></li>
<li class="chapter" data-level="18.2.2" data-path="C-SummaryDistributions.html"><a href="C-SummaryDistributions.html#distribuciones-dos-parámetros"><i class="fa fa-check"></i><b>18.2.2</b> Distribuciones Dos Parámetros</a></li>
<li class="chapter" data-level="18.2.3" data-path="C-SummaryDistributions.html"><a href="C-SummaryDistributions.html#distribuciones-tres-parámetros"><i class="fa fa-check"></i><b>18.2.3</b> Distribuciones Tres Parámetros</a></li>
<li class="chapter" data-level="18.2.4" data-path="C-SummaryDistributions.html"><a href="C-SummaryDistributions.html#distribución-cuatro-parámetros"><i class="fa fa-check"></i><b>18.2.4</b> Distribución Cuatro Parámetros</a></li>
<li class="chapter" data-level="18.2.5" data-path="C-SummaryDistributions.html"><a href="C-SummaryDistributions.html#otras-distribuciones"><i class="fa fa-check"></i><b>18.2.5</b> Otras Distribuciones</a></li>
<li class="chapter" data-level="18.2.6" data-path="C-SummaryDistributions.html"><a href="C-SummaryDistributions.html#distribuciones-con-soporte-finito"><i class="fa fa-check"></i><b>18.2.6</b> Distribuciones con Soporte Finito</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="C-SummaryDistributions.html"><a href="C-SummaryDistributions.html#valor-esperado-limitado"><i class="fa fa-check"></i><b>18.3</b> Valor Esperado Limitado</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="divider"></li>
<li><a href="https://github.com/OpenActTexts/Loss-Data-Analytics" target="blank">Loss Data Analytics on GitHub</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Loss Data Analytics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="C:ModelSelection" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Selección del Modelo y Estimación</h1>
<p><em>Vista Previa del Capítulo</em>. En los Capítulos <a href="C-Frequency-Modeling.html#C:Frequency-Modeling">2</a> y <a href="C-Severity.html#C:Severity">3</a> se han descrito cómo ajustar los modelos paramétricos a datos que miden, respectivamente, la frecuencia y la severidad de los eventos analizados. Este capítulo se centra en la selección de los modelos. Inicialmente, para comparar modelos paramétricos alternativos, es útil describir los datos sin referencia a una distribución paramétrica específica. La Sección <a href="C-ModelSelection.html#S:MS:NonParInf">4.1</a> describe en que consiste la estimación no paramétrica, cómo podemos usarla para comparar modelos paramétricos alternativos y cómo, a partir de la misma, pueden obtenerse valores iniciales que permitan implementar procedimientos paramétricos. El proceso de selección del modelo se resume en la Sección <a href="C-ModelSelection.html#S:MS:ModelSelection">4.2</a>. Aunque la descripción se centra en el análisis de datos continuos, el mismo procedimiento puede usarse para datos discretos o datos que provienen de una combinación híbrida de datos discretos y continuos.</p>
<p>La selección y la estimación del modelo son aspectos fundamentales de la modelización estadística. Para proporcionar una idea de cómo se pueden adaptar a esquemas de muestreo alternativos, la Sección <a href="C-ModelSelection.html#S:MS:ModifiedData">4.3</a> describe la estimación con datos agrupados, censurados y truncados (siguiendo la introducción de la Sección <a href="C-Severity.html#S:MaxLikeEstimation">3.5</a>). Para ver cómo los procedimientos de selección y estimación se pueden adaptar a modelos alternativos, el capítulo se cierra con la Sección <a href="C-ModelSelection.html#S:MS:BayesInference">4.4</a> sobre inferencia bayesiana, un procedimiento alternativo donde los parámetros (típicamente desconocidos) se tratan como variables aleatorias.</p>
<div id="S:MS:NonParInf" class="section level2">
<h2><span class="header-section-number">4.1</span> Inferencia No Paramétrica</h2>
<hr />
<p>En esta sección se aprende a:</p>
<ul>
<li>Estimación de momentos, cuantiles y distribuciones sin referencia a una distribución paramétrica.</li>
<li>Resumir los datos gráficamente sin referencia a una distribución paramétrica</li>
<li>Determinar medidas que resuman las desviaciones de un ajuste paramétrico de un ajuste no paramétrico</li>
<li>Use estimadores no paramétricos para aproximar los parámetros que se pueden usar para iniciar un procedimiento de estimación paramétrica</li>
</ul>
<hr />
<div id="estimación-no-paramétrica" class="section level3">
<h3><span class="header-section-number">4.1.1</span> Estimación No Paramétrica</h3>
<p>En la Sección <a href="C-Frequency-Modeling.html#S:basic-frequency-distributions">2.2</a> para la frecuencia y en la Sección <a href="C-Severity.html#S:BasicQuantities">3.1</a> para la severidad, aprendimos cómo describir una distribución mediante el cálculo de las medias, las varianzas, los cuantiles/percentiles, etc.. Para aproximar estas medidas de resumen utilizando un conjunto de datos, una estrategia es:</p>
<ol style="list-style-type: lower-roman">
<li>asumir una forma paramétrica para una distribución, como una binomial negativa para la frecuencia o una distribución gamma para la severidad,</li>
<li>estimar los parámetros de esa distribución, y luego</li>
<li>usar la distribución con los parámetros estimados para calcular la medida de resumen deseada.</li>
</ol>
<p>Ésta es la aproximación <strong>paramétrica</strong>. Otra estrategia es estimar la medida de resumen deseada directamente a partir de las observaciones <em>sin</em> referencia a un modelo paramétrico. No es sorprendente que esto se conozca como aproximación <a href="#" class="tooltip" style="color:green"><strong>no paramétrica</strong><span style="font-size:8pt"> Una forma de inferencia que no se basa en una modelo paramétrico.</span></a></p>
<p>Comencemos por considerar el tipo más básico de esquema de muestreo y supongamos que las observaciones son realizaciones de un conjunto de variables aleatorias <span class="math inline">\(X_1, \ldots, X_n\)</span> que son <a href="#" class="tooltip" style="color:green"><em>iid</em><span style="font-size:8pt"> independientes e idénticamente distribuidas</span></a> generadas por una distribución poblacional desconocida <span class="math inline">\(F(\cdot)\)</span>. Un modo equivalente de explicarlo es que <span class="math inline">\(X_1, \ldots, X_n\)</span>, es una <em>muestra aleatoria</em> (con remplazamiento) de <span class="math inline">\(F(\cdot)\)</span>. Para mostrar cómo funciona todo esto, a continuación se describen los estimadores no paramétricos de muchas medidas importantes que resumen una distribución.</p>
<div id="S:MS:MomentEstimator" class="section level4">
<h4><span class="header-section-number">4.1.1.1</span> Estimadores de Momentos</h4>
<p>En la Sección <a href="C-Frequency-Modeling.html#S:generating-functions">2.2.2</a> aprendimos como definir momentos para la frecuencia y en la Sección <a href="C-Severity.html#S:Chap3Moments">3.1.1</a> para la severidad. En particular, el <span class="math inline">\(k\)</span>-ésimo momento, <span class="math inline">\(\mathrm{E~}[X^k] = \mu^{\prime}_k\)</span>, resume muchos aspectos de la distribución para distintos valores de <em>k</em>. Aquí, <span class="math inline">\(\mu^{\prime}_k\)</span> es comúnmente denominado el <em>k</em>-ésimo momento <em>poblacional</em>, para distinguirlo del <em>k</em>-ésimo momento muestral,
<span class="math display">\[
\frac{1}{n} \sum_{i=1}^n X_i^k,
\]</span>
que es el estimador no paramétrico correspondiente. En las aplicaciones, <span class="math inline">\(k\)</span> es normalmente un número entero positivo, aunque no es necesario que lo sea.</p>
<p>Un caso particular importante es el primer momento donde <em>k=1</em>. En este caso, el símbolo principal (<span class="math inline">\(\prime\)</span>) y el subíndice <span class="math inline">\(1\)</span> generalmente se eliminan y se usa <span class="math inline">\(\mu=\mu^{\prime}_1\)</span> para denotar la media de la población o, simplemente, la <em>media</em>. El estimador en la muestra correspondiente para <span class="math inline">\(\mu\)</span> se llama <em>media muestral</em>, denotada con una barra en la parte superior de la variable aleatoria:
<span class="math display">\[
\bar{X} =\frac{1}{n} \sum_{i=1}^n X_i.
\]</span>
Otro tipo de medida a modo de resumen que es de interés es el <span class="math inline">\(k\)</span><em>-ésimo momento central</em>, <span class="math inline">\(\mathrm{E~} [(X-\mu)^k] = \mu_k\)</span>. Comúnmente, <span class="math inline">\(\mu^{\prime}_k\)</span> se llama el <span class="math inline">\(k\)</span>-ésimo momento <em>ordinario</em> para distinguirlo del momento central <span class="math inline">\(\mu_k\)</span>. Un estimador no paramétrico, o muestral, de <span class="math inline">\(\mu_k\)</span> es
<span class="math display">\[
\frac{1}{n} \sum_{i=1}^n \left(X_i - \bar{X}\right)^k .
\]</span>
El segundo momento central (<span class="math inline">\(k=2\)</span>) es un caso importante para el que generalmente asignamos un nuevo símbolo, <span class="math inline">\(\sigma^2=\mathrm{E~} [(X-\mu)^2]\)</span>, conocido como la <em>varianza</em>. Las propiedades del estimador de momentos muestral de la varianza, <span class="math inline">\(n^{-1}\sum_{i=1}^n\left (X_i-\bar{X}\right)^2\)</span>, se han estudiado ampliamente y por lo tanto es natural que se hayan propuesto muchas variaciones. La variación más utilizada es aquella en la que el tamaño real de la muestra se reduce en uno, por lo que definimos
<span class="math display">\[
s^2 = \frac{1}{n-1} \sum_{i=1}^n \left(X_i - \bar{X}\right)^2.
\]</span>
Aquí, el estadístico <span class="math inline">\(s^2\)</span> se conoce como <em>varianza muestral</em>. Dividir por <em>n-1</em> en lugar de por <em>n</em> importa poco cuando se dispone de un tamaño de muestra <em>n</em> en miles, como es frecuente en las aplicaciones en seguros. De este modo, el estimador resultante es insesgado, en el sentido de que <span class="math inline">\(\mathrm{E ~} s^2=\sigma^2\)</span>, una propiedad deseable particularmente cuando se interpretan los resultados de un análisis.</p>
</div>
<div id="función-de-distribución-empírica" class="section level4">
<h4><span class="header-section-number">4.1.1.2</span> Función de Distribución Empírica</h4>
<p>Hemos visto como calcular los estimadores no paramétricos del momento <em>k</em>-ésimo <span class="math inline">\(\mathrm{E ~} X^k\)</span>. Del mismo modo, para cualquier función conocida <span class="math inline">\(\mathrm{g}(\cdot)\)</span>, podemos estimar <span class="math inline">\(\mathrm {E ~}\mathrm{g}(X)\)</span> usando <span class="math inline">\(n^{-1}\sum_{i=1}^n\mathrm{g}(X_i)\)</span>.</p>
<p>Ahora supongamos que fijamos un valor de <em>x</em> y consideramos la función <span class="math inline">\(\mathrm{g}(X)=I(X \le x)\)</span>. Aquí, la notación <span class="math inline">\(I(\cdot)\)</span> es la función del indicador; devuelve 1 si el evento <span class="math inline">\((\cdot)\)</span> es verdadero y 0 en caso contrario. Para esta elección de <span class="math inline">\(\mathrm{g}(\cdot)\)</span>, el valor esperado es <span class="math inline">\(\mathrm{E ~}I(X \le x)=\Pr(X \le x)=F(x)\)</span>, la función de distribución evaluada en un punto fijo <em>x</em>. Usando el principio analógico, definimos el estimador no paramétrico de la función de distribución
<span class="math display">\[
\begin{aligned}
F_n(x)
&amp;=  \frac{1}{n} \sum_{i=1}^n I\left(X_i \le x\right) \\
&amp;=  \frac{\text{número de observaciones menores o iguales a } x}{n}. 
\end{aligned}
\]</span>
Como el estimador no paramétrico <span class="math inline">\(F_n(\cdot)\)</span> se basa solo en observaciones y no asume una familia paramétrica para la distribución, también se conoce como <strong>función de distribución empírica</strong>.</p>
<p><strong>Ejemplo 4.1.1. Conjunto de Datos Ficticios</strong>. Como ilustración, considere un conjunto de datos ficticio o “Toy Dataset” de <span class="math inline">\(n=10\)</span> observaciones. Determinar la función de distribución empírica.</p>
<span class="math display">\[
{\small
\begin{array}{c|cccccccccc}
\hline
i &amp;1&amp;2&amp;3&amp;4&amp;5&amp;6&amp;7&amp;8&amp;9&amp;10 \\
X_i&amp; 10 &amp;15 &amp;15 &amp;15 &amp;20 &amp;23 &amp;23 &amp;23 &amp;23 &amp;30\\
\hline
\end{array}
}
\]</span>
<h5 style="text-align: center;">
<a id="displayTextExampleSelect.1.1" href="javascript:toggleEX('toggleExampleSelect.1.1','displayTextExampleSelect.1.1');"><i><strong>Mostrar la Solución del Ejemplo</strong></i></a>
</h5>
<div id="toggleExampleSelect.1.1" style="display: none">
<p>Debe verificar que la media de la muestra es <span class="math inline">\(\bar{X}=19,7\)</span> y que la varianza de la muestra es <span class="math inline">\(s^2=34,45556\)</span>. La función de distribución empírica correspondiente es
<span class="math display">\[
\begin{aligned}
F_n(x) &amp;=
\left\{
\begin{array}{ll}
0 &amp; \text{ for }\ x&lt;10 \\
0,1 &amp; \text{ for }\ 10 \leq x&lt;15 \\
0,4 &amp; \text{ for }\ 15 \leq x&lt;20 \\
0,5 &amp; \text{ for }\ 20 \leq x&lt;23 \\
0,9 &amp; \text{ for }\ 23 \leq x&lt;30 \\
1 &amp; \text{ for }\ x \geq 30,
\end{array}
\right.\end{aligned}
\]</span></p>
<p>que se muestra en el siguiente gráfico en la Figura <a href="C-ModelSelection.html#fig:EDFToy">4.1</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:EDFToy"></span>
<img src="LossDataAnalytics_files/figure-html/EDFToy-1.png" alt="Función de Distribución Empírica de un Ejemplo con Datos Ficticios" width="60%" />
<p class="caption">
Figure 4.1: Función de Distribución Empírica de un Ejemplo con Datos Ficticios
</p>
</div>
<h5 style="text-align: center;">
<a id="displayTextToy.4f" href="javascript:togglecode('toggleToy','displayTextToy.4f');"><i><strong>Mostrar código R</strong></i></a>
</h5>
<div id="toggleToy" style="display: none">
<pre><code>(xExample &lt;- c(10,rep(15,3),20,rep(23,4),30))
PercentilesxExample &lt;- ecdf(xExample)
plot(PercentilesxExample, main=&quot;&quot;,xlab=&quot;x&quot;)</code></pre>
</div>
</div>
<hr />
</div>
<div id="S:MS:QuantileEstimator" class="section level4">
<h4><span class="header-section-number">4.1.1.3</span> Cuartiles, Percentiles y Cuantiles</h4>
<p>Anteriormente ya hemos visto la <em>mediana</em>, que es el número tal que aproximadamente la mitad de un conjunto de datos está por debajo (o por encima). El <strong>primer cuartil</strong> es el número tal que aproximadamente el 25% de los datos está debajo de él y el <em>tercer cuartil</em> es el número tal que aproximadamente el 75% de los datos está debajo de él. Un <span class="math inline">\(100p\)</span> <strong>percentil</strong> es el número tal que <span class="math inline">\(100\times p\)</span> por ciento de los datos están debajo de él.</p>
<p>Para generalizar este concepto, se considera una función de distribución <span class="math inline">\(F(\cdot)\)</span>, que puede o no ser continua, y sea <span class="math inline">\(q\)</span> una fracción para la cual <span class="math inline">\(0&lt;q&lt;1\)</span>. Queremos definir un cuantil, digamos <span class="math inline">\(q_F\)</span>, para que sea un número tal que <span class="math inline">\(F(q_F) \approx q\)</span>. Observe que cuando <span class="math inline">\(q=0,5\)</span>, <span class="math inline">\(q_F\)</span> es la mediana; cuando <span class="math inline">\(q=0,25\)</span>, <span class="math inline">\(q_F\)</span> es el primer cuartil, y así sucesivamente. Por lo tanto, un cuantil generaliza los conceptos de mediana, cuartiles y percentiles.</p>
<p>Para ser precisos, para un determinado valor de <span class="math inline">\(0&lt;q&lt;1\)</span>, se define el <span class="math inline">\(q\)</span>-<strong>ésimo cuantil</strong> <span class="math inline">\(q_F\)</span> como <em>cualquier</em> número que satisfaga
<span class="math display" id="eq:Quantile">\[\begin{equation}
  F(q_F-) \le q \le F(q_F)
  \tag{4.1}
\end{equation}\]</span></p>
<p>Aquí, la notación <span class="math inline">\(F(x-)\)</span> significa evaluar la función <span class="math inline">\(F(\cdot)\)</span> como el límite por la izquierda.</p>
<p>Para comprender mejor esta definición, veamos algunos casos especiales. Primero, considere el caso en el que <span class="math inline">\(X\)</span> es una variable aleatoria continua para que la función de distribución <span class="math inline">\(F(\cdot)\)</span> no tenga puntos de salto, como se ilustra en la Figura <a href="C-ModelSelection.html#fig:Quantile1">4.2</a>. En esta figura, se muestran algunas fracciones, <span class="math inline">\(q_1\)</span>, <span class="math inline">\(q_2\)</span> y <span class="math inline">\(q_3\)</span> con sus cuantiles correspondientes <span class="math inline">\(q_{F,1}\)</span>, <span class="math inline">\(q_{F,2}\)</span> y <span class="math inline">\(q_{F,3}\)</span>. En cada caso se puede ver que <span class="math inline">\(F(q_F-)=F(q_F)\)</span>, de modo que hay un cuantil único. Al igual que podemos encontrar una inversa de la función de distribución única para cualquier <span class="math inline">\(0&lt;q&lt;1\)</span>, podemos escribir <span class="math inline">\(q_F=F^{-1}(q)\)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:Quantile1"></span>
<img src="LossDataAnalytics_files/figure-html/Quantile1-1.png" alt="Caso de Cuantil Continuo" width="60%" />
<p class="caption">
Figure 4.2: Caso de Cuantil Continuo
</p>
</div>
<p>La figura <a href="C-ModelSelection.html#fig:Quantile2">4.3</a> muestra tres casos de funciones de distribución. El panel izquierdo corresponde al caso continuo recién discutido. El panel central muestra un punto de salto similar a los que ya vimos en la función de distribución empírica de la Figura <a href="C-ModelSelection.html#fig:EDFToy">4.1</a>. Para el valor de <span class="math inline">\(q\)</span> que se muestra en este panel, todavía tenemos un valor único del cuantil <span class="math inline">\(q_F\)</span>. Aunque hay muchos valores de <span class="math inline">\(q\)</span> tales que <span class="math inline">\(F(q_F-) \le q \le F(q_F)\)</span>, para un valor particular de <span class="math inline">\(q\)</span>, solo hay una solución para la ecuación <a href="C-ModelSelection.html#eq:Quantile">(4.1)</a>. El panel de la derecha muestra una situación en la que el cuantil no puede determinarse de manera única para el <span class="math inline">\(q\)</span> que se muestra, ya que hay un rango de <span class="math inline">\(q_F\)</span> que satisfacen la ecuación <a href="C-ModelSelection.html#eq:Quantile">(4.1)</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:Quantile2"></span>
<img src="LossDataAnalytics_files/figure-html/Quantile2-1.png" alt="Tres Casos de Cuantiles" width="90%" />
<p class="caption">
Figure 4.3: Tres Casos de Cuantiles
</p>
</div>
<hr />
<strong>Ejemplo 4.1.2. Conjunto de Datos Ficticios: Continuación.</strong>
Se determinan los cuantiles correspondientes a los percentiles 20, 50 y 95.
<h5 style="text-align: center;">
<a id="displayTextExampleSelect.1.2" href="javascript:toggleEX('toggleExampleSelect.1.2','displayTextExampleSelect.1.2');"><i><strong>Mostrar la solución del Ejemplo </strong></i></a>
</h5>
<div id="toggleExampleSelect.1.2" style="display: none">
<p><strong>Solución</strong>.
Se considera la Figura <a href="C-ModelSelection.html#fig:EDFToy">4.1</a>. El caso de <span class="math inline">\(q=0,20\)</span> corresponde al panel central, por lo que el percentil 20 es 15. El caso de <span class="math inline">\(q=0,50\)</span> corresponde al panel derecho, por lo que la mediana es cualquier número entre 20 y 23, ambos inclusive. Muchos paquetes de software usan el promedio de 21,5 (por ejemplo, <code>R</code>, como se ve a continuación). Para el percentil 95, la solución es 30. Podemos ver en el gráfico que 30 también corresponde a los percentiles 99 y 99,99.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" title="1"><span class="kw">quantile</span>(xExample, <span class="dt">probs=</span><span class="kw">c</span>(<span class="fl">0.2</span>, <span class="fl">0.5</span>, <span class="fl">0.95</span>), <span class="dt">type=</span><span class="dv">6</span>)</a></code></pre></div>
<pre><code>##  20%  50%  95% 
## 15.0 21.5 30.0</code></pre>
</div>
<hr />
<p>Al tomar un promedio ponderado entre las observaciones de datos, los cuantiles empíricos suavizados pueden asemejarse a los casos como el panel derecho en la Figura <a href="C-ModelSelection.html#fig:Quantile2">4.3</a>. El <span class="math inline">\(q\)</span>-ésimo <em>cuartil empírico suavizado</em> se define como
<span class="math display">\[
\hat{\pi}_q = (1-h) X_{(j)} + h X_{(j+1)}
\]</span>
donde <span class="math inline">\(j=\lfloor(n+1)q\rfloor\)</span>, <span class="math inline">\(h=(n+1)q-j\)</span>, y <span class="math inline">\(X_{(1)}, \ldots, X_{(n)}\)</span> son los valores ordenados (conocidos como los <em>estadísticos de orden</em>) correspondientes a <span class="math inline">\(X_1, \ldots, X_n\)</span>. Cabe señalar que <span class="math inline">\(\hat{\pi}_q\)</span> es simplemente una interpolación lineal entre <span class="math inline">\(X_{(j)}\)</span> y <span class="math inline">\(X_{(j+1)}\)</span>.</p>
<p><strong>Ejemplo 4.1.3. Conjunto de Datos Ficticios: Continuación.</strong>
Se determinan los percentiles 50-ésimo y 20-ésimo alisados.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleSelect.1.3" href="javascript:toggleEX('toggleExampleSelect.1.3','displayTextExampleSelect.1.3');"><i><strong>Mostrar la solución del Ejemplo</strong></i></a>
</h5>
<div id="toggleExampleSelect.1.3" style="display: none">
<p><strong>Solución</strong>
Se toma <span class="math inline">\(n=10\)</span> y <span class="math inline">\(q=0,5\)</span>. De modo que, <span class="math inline">\(j=\lfloor(11)0,5 \rfloor= \lfloor 5,5 \rfloor=5\)</span> y <span class="math inline">\(h=(11)(0,5)-5=0,5\)</span>. Por tanto, el 50-ésimo cuantil empírico alisado es
<span class="math display">\[\hat{\pi}_{0,5} = (1-0,5) X_{(5)} + (0,5) X_{(6)} = 0,5 (20) + (0,5)(23) = 21,5.\]</span>
Ahora se toma <span class="math inline">\(n=10\)</span> y <span class="math inline">\(q=0,2\)</span>. En este caso, <span class="math inline">\(j=\lfloor(11)0,2\rfloor=\lfloor 2,2 \rfloor=2\)</span> y <span class="math inline">\(h=(11)(0,2)-2=0,2\)</span>. Entonces, el 20-ésimo cuantil empírico alisado es
<span class="math display">\[\hat{\pi}_{0,2} = (1-0,2) X_{(2)} + (0,2) X_{(3)} = 0,2 (15) + (0,8)(15) = 15.\]</span></p>
</div>
<hr />
</div>
<div id="estimadores-de-la-densidad" class="section level4">
<h4><span class="header-section-number">4.1.1.4</span> Estimadores de la Densidad</h4>
<p><strong>Variable Discreta.</strong> Cuando la variable aleatoria es discreta, estimar la función de masa de probabilidad <span class="math inline">\(f(x)=\Pr(X = x)\)</span> es sencillo. Simplemente usamos el promedio del indicador <span class="math inline">\(I(X_i = x)\)</span> en la muestra, definido como</p>
<p><span class="math display">\[f_n(x) = \frac{1}{n} \sum_{i=1}^n I(X_i = x).\]</span></p>
<p><strong>Variable Continua Dentro de un Grupo.</strong> Para una variable aleatoria continua, se considera una formulación discretizada en la que el dominio de <span class="math inline">\(F(\cdot)\)</span> está dividido por las constantes <span class="math inline">\(\{c_0 &lt;c_1 &lt;\cdots &lt;c_k\}\)</span> en intervalos de la forma <span class="math inline">\([c_{j-1}, c_j)\)</span>, por <span class="math inline">\(j = 1, \ldots, k\)</span>. Los datos observados se “agrupan” en función del intervalo en el que caen. Entonces, podríamos usar la definición básica de la función de masa de probabilidad empírica, o una variación como
<span class="math display">\[f_n(x) = \frac{n_j}{n \times (c_j - c_{j-1})}  \ \ \ \ \ \ c_{j-1} \le x &lt; c_j,\]</span>
donde <span class="math inline">\(n_j\)</span> es el número de observaciones (<span class="math inline">\(X_i\)</span>) que caen en el intervalo <span class="math inline">\([c_{j-1}, c_j)\)</span>.</p>
<p><strong>Variable Continua (no agrupada).</strong> Extendiendo esta noción a situaciones en las que observamos datos individuales, se debe tener en cuenta que siempre podemos crear agrupaciones arbitrarias y usar esta fórmula. Más formalmente, dada <span class="math inline">\(b&gt;0\)</span> una constante positiva que toma un valor reducido y se conoce como <strong>ancho de banda (bandwidth)</strong>, se define el estimador de la densidad como</p>
<p><span class="math display" id="eq:KDF">\[\begin{equation}
  f_n(x) = \frac{1}{2nb} \sum_{i=1}^n I(x-b &lt; X_i \le x + b)
  \tag{4.2}
\end{equation}\]</span></p>
<h5 style="text-align: center;">
<a id="displayTheory.1" href="javascript:toggleTheory('Theorykerneldensity','displayTheory.1');"><i><strong>Mostrar un fragmento de Teoría</strong></i></a>
</h5>
<div id="Theorykerneldensity" style="display: none">
<hr />
<p>La idea es que el estimador <span class="math inline">\(f_n(x)\)</span> en la ecuación <a href="C-ModelSelection.html#eq:KDF">(4.2)</a> es la media sobre <span class="math inline">\(n\)</span> <a href="#" class="tooltip" style="color:green"><em>iid</em><span style="font-size:8pt"> independientes e idénticamente distribuidas </span></a> realizaciones de una variable aleatoria con media</p>
<p><span class="math display">\[
\begin{aligned}
\mathrm{E~ } \frac{1}{2b} I(x-b &lt; X \le x + b) &amp;=  \frac{1}{2b}\left(F(x+b)-F(x-b)\right) \\
&amp;=  \frac{1}{2b} \left( \left\{ F(x) + b F^{\prime}(x) + b^2 C_1\right\}
\left\{ F(x) - b F^{\prime}(x) + b^2 C_2\right\} \right) \\
&amp;=  F^{\prime}(x) + b \frac{C_1-C_2}{2} \rightarrow  F^{\prime}(x) = f(x),
\end{aligned}
\]</span></p>
<p>como <span class="math inline">\(b \rightarrow 0\)</span>. Esto es, <span class="math inline">\(f_n(x)\)</span> es un estimador asintóticamente insesgado de <span class="math inline">\(f(x)\)</span> (su esperanza se acerca al valor verdadero a medida que el tamaño de la muestra tiende a infinito). Este desarrollo supone cierta suavización de <span class="math inline">\(F(\cdot)\)</span>, en particular, se deriva dos veces con respecto a <span class="math inline">\(x\)</span>, pero no hace suposiciones sobre la forma de la función de distribución <span class="math inline">\(F\)</span>. Debido a esto, se dice que el estimador de densidad <span class="math inline">\(f_n\)</span> es <em>no paramétrico</em>.</p>
<hr />
</div>
<p>Más generalmente, se define el <strong>estimador núcleo (kernel) de la densidad </strong> de la función de <a href="#" class="tooltip" style="color:green"><em>pdf</em><span style="font-size:8pt"> función de densidad de probabilidad</span></a> en <em>x</em> como</p>
<p><span class="math display" id="eq:kernelDens">\[\begin{equation} 
  f_n(x) = \frac{1}{nb} \sum_{i=1}^n w\left(\frac{x-X_i}{b}\right) ,
  \tag{4.3}
\end{equation}\]</span></p>
<p>donde <span class="math inline">\(w\)</span> es una función de densidad de probabilidad centrada en 0. Se tiene que tener en cuenta que la ecuación <a href="C-ModelSelection.html#eq:KDF">(4.2)</a> simplemente se convierte en el estimador núcleo de la densidad donde <span class="math inline">\(w(x) =\frac{1}{2} I(-1 &lt;x \le 1)\)</span>, también conocido como <em>núcleo uniforme</em>. Otras opciones comunes para <span class="math inline">\(w\)</span> se muestran en <a href="#tab:41">Table 4.1</a>.</p>
<p><a id=tab:41></a></p>
<p><span class="math display">\[
{\small
\begin{matrix}
\text{Table 4.1: Opciones más comunes como Núcleo del Estimador de la Densidad}\\
\begin{array}{l|cc}
\hline
\text{Kernel} &amp;  w(x) \\
\hline
\text{Uniforme } &amp;  \frac{1}{2}I(-1 &lt; x \le 1) \\
\text{Triángulo} &amp;  (1-|x|)\times I(|x| \le 1) \\
\text{Epanechnikov} &amp; \frac{3}{4}(1-x^2) \times I(|x| \le 1) \\
\text{Gausiana} &amp; \phi(x) \\
\hline
\end{array}\end{matrix}
}
\]</span></p>
<p>Siendo <span class="math inline">\(\phi(\cdot)\)</span> la función de densidad normal estándar. Como veremos en el siguiente ejemplo, la elección del ancho de banda <span class="math inline">\(b\)</span> viene dada por la existencia de un <em>equilibrio entre sesgo-varianza</em>, es decir, entre las coincidencias con las características locales de la distribución y la reducción de la dispersión.</p>
<hr />
<p><strong>Ejemplo 4.1.4. Fondo Inmobiliario.</strong>
La figura <a href="C-ModelSelection.html#fig:Density2">4.4</a> muestra un histograma (con rectángulos grises sombreados) de los logaritmo de los costes de los siniestros en propiedades del año 2010. La curva gruesa (azul) representa la densidad estimada con el núcleo gaussiano, donde el ancho de banda se seleccionó automáticamente utilizando una regla ad-hoc basada en el tamaño de la muestra y la dispersión de los datos. Para este conjunto de datos, el ancho de banda resultó ser <span class="math inline">\(b = 0,3255\)</span>. A modo comparativo, la curva discontinua (roja) representa el estimador de la densidad con un ancho de banda igual a 0,1 y la curva verde, más suave, utiliza un ancho de banda de 1. Como se anticipó, el ancho de banda más pequeño (0,1) implica realizar promedios locales sobre menos datos para obtener una mejor idea del comportamiento local, pero al precio de una mayor dispersión. En contraste, el mayor ancho de banda (1) suaviza las fluctuaciones locales, produciendo una curva más suave que puede perder perturbaciones reales en el promedio local. Para aplicaciones actuariales, utilizamos principalmente el estimador núcleo de la densidad para obtener una impresión visual rápida de los datos. Desde esta perspectiva, simplemente puede usarse la regla ad-hoc predeterminada para la selección del ancho de banda, sabiendo que se tiene la capacidad de cambiarla dependiendo de la situación en cuestión.</p>
<div class="figure" style="text-align: center"><span id="fig:Density2"></span>
<img src="LossDataAnalytics_files/figure-html/Density2-1.png" alt="Histograma de los Logaritmo de los Costes de los Siniestros en Propiedades con Estimador Núcleo de la Densidad Superpuesto" width="70%" />
<p class="caption">
Figure 4.4: Histograma de los Logaritmo de los Costes de los Siniestros en Propiedades con Estimador Núcleo de la Densidad Superpuesto
</p>
</div>
<h5 style="text-align: center;">
<a id="displaykpdf" href="javascript:togglecode('togglekpdf','displaykpdf');"><i><strong>Mostrar código R</strong></i></a>
</h5>
<div id="togglekpdf" style="display: none">
<pre><code>#Comparación de Densidad
hist(log(ClaimData$Claim), main=&quot;&quot;, ylim=c(0,.35),xlab=&quot;Log Costes&quot;, freq=FALSE, col=&quot;lightgray&quot;)
lines(density(log(ClaimData$Claim)), col=&quot;blue&quot;,lwd=2.5)
lines(density(log(ClaimData$Claim), bw=1), col=&quot;green&quot;)
lines(density(log(ClaimData$Claim), bw=.1), col=&quot;red&quot;, lty=3)
legend(&quot;topright&quot;, c(&quot;b=0.3255 (default)&quot;, &quot;b=0.1&quot;, &quot;b=1.0&quot;), lty=c(1,3,1),
            lwd=c(2.5,1,1), col=c(&quot;blue&quot;, &quot;red&quot;, &quot;green&quot;), cex=1)</code></pre>
</div>
<hr />
<p>Los estimadores no paramétricos de la densidad, como el estimador núcleo, se usan habitualmente en la práctica. Este mismo concepto también se puede ampliar para dar versiones suavizadas de una función de distribución empírica. Dada la definición del estimador núcleo de la densidad, el <em>estimador núcleo de la función de distribución </em> se puede obtener como</p>
<p><span class="math display">\[
\begin{aligned}
\hat{F}_n(x) = \frac{1}{n} \sum_{i=1}^n W\left(\frac{x-X_i}{b}\right).\end{aligned}
\]</span></p>
<p>donde <span class="math inline">\(W\)</span> es la función de distribución asociada con la densidad del núcleo <span class="math inline">\(w\)</span>. Para ilustrarlo, para el núcleo uniforme, tenemos <span class="math inline">\(w(y) = \frac{1}{2}I(-1 &lt; y \le 1)\)</span>, de modo que</p>
<p><span class="math display">\[
\begin{aligned}
W(y) =
\begin{cases}
0 &amp;            y&lt;-1\\
\frac{y+1}{2}&amp; -1 \le y &lt; 1 \\
1 &amp; y \ge 1 \\
\end{cases}\end{aligned} .
\]</span></p>
<hr />
<p><strong>Ejemplo 4.1.5. Pregunta de Examen Actuarial.</strong></p>
<p>Se estudian cinco individuos para estimar el tiempo desde el inicio de una enfermedad hasta la muerte. Los tiempos de muerte son:</p>
<p><span class="math display">\[
\begin{array}{ccccc}
2 &amp; 3 &amp; 3 &amp; 3 &amp; 7  \\
\end{array}.
\]</span></p>
<p>Usando un núcleo triangular con ancho de banda <span class="math inline">\(2\)</span>, calcular la función de densidad estimada en 2,5.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleSelect.1.5" href="javascript:toggleEX('toggleExampleSelect.1.5','displayTextExampleSelect.1.5');"><i><strong>Mostrar la solución del Ejemplo</strong></i></a>
</h5>
<div id="toggleExampleSelect.1.5" style="display: none">
<p><strong>Solución.</strong>
Para la estimación núcleo de la densidad tenemos
<span class="math display">\[f_n(x) = \frac{1}{nb} \sum_{i=1}^n w\left(\frac{x-X_i}{b}\right),\]</span>
donde <span class="math inline">\(n=5\)</span>, <span class="math inline">\(b=2\)</span>, y <span class="math inline">\(x=2,5\)</span>. Para un kernel triangular, <span class="math inline">\(w(x) = (1-|x|)\times I(|x| \le 1)\)</span>. Así,</p>
<p><span class="math display">\[
\begin{array}{c|c|c}
\hline
X_i &amp; \frac{x-X_i}{b} &amp; w\left(\frac{x-X_i}{b} \right) \\
\hline
2 &amp; \frac{2,5-2}{2}=\frac{1}{4} &amp;  (1-\frac{1}{4})(1) = \frac{3}{4} \\
\hline
3 &amp; &amp; \\
3 &amp; \frac{2,5-3}{2}=\frac{-1}{4} &amp; \left(1-\left| \frac{-1}{4} \right| \right)(1) = \frac{3}{4} \\
3 &amp; &amp; \\
\hline
7 &amp; \frac{2,5-7}{2}=-2,25 &amp; (1-|-2,25|)(0) = 0\\
\hline
\end{array}
\]</span></p>
<p>Entonces la estimación núcleo de la densidad es <span class="math display">\[f_n(x) = \frac{1}{5(2)}\left( \frac{3}{4} + (3) \frac{3}{4} + 0 \right) = \frac{3}{10}\]</span></p>
</div>
<hr />
</div>
<div id="principio-de-plug-in" class="section level4">
<h4><span class="header-section-number">4.1.1.5</span> Principio de Plug-in</h4>
<p>Una forma de crear un estimador no paramétrico es usar el principio <em>de analogía</em> o <em>plug-in</em> donde se reemplaza la <em>cdf</em> <span class="math inline">\(F\)</span> desconocida por un estimador conocido como la <em>cdf</em> empírica <span class="math inline">\(F_n\)</span>. Por tanto, si estamos tratando de estimar <span class="math inline">\(\mathrm{E}~\mathrm{g}(X)=\mathrm{E}_F~\mathrm{g}(X)\)</span> para una función genérica <em>g</em>, entonces se define un estimador noparamétrico como <span class="math inline">\(\mathrm{E}_{F_n}~\mathrm{g}(X)=n^{-1}\sum_{i=1}^n\mathrm{g}(X_i)\)</span>.</p>
<p>Para ver su funcionamiento, como un caso particular de <em>g</em> consideramos la <em>ratio de eliminación de pérdidas</em> presentada en la Sección 3.4.1, <span class="math display">\[LER(d)=\frac{\mathrm{E~}(\min(X,d) )}{\mathrm{E~}(X)}\]</span> para un deducible fijo <span class="math inline">\(d\)</span>.</p>
<p><strong>Ejemplo. 4.1.11. Siniestros con Daños Corporales y Ratio de Eliminación de Pérdidas </strong></p>
<p>Utilizamos una muestra de 432 siniestros cerrados de automóvil ocurridos en Boston de <span class="citation">Derrig, Ostaszewski, and Rempala (<a href="#ref-derrig2001applications" role="doc-biblioref">2001</a>)</span>. Las pérdidas se registran para los pagos por daños corporales derivados en los accidentes de automóvil. Las pérdidas no están sujetas a deducibles, pero están sujetas a varios límites de póliza, también disponibles en los datos. Se obtiene que sólo 17 de 432 (<span class="math inline">\(\approx\)</span> 4%) estaban sujetas al límite en la póliza y, por ello, ignoraremos estos datos en esta ilustración.</p>
<p>La pérdida promedio pagada es 6906. Figura <a href="C-ModelSelection.html#fig:BIClaims">4.5</a> muestra otros aspectos de la distribución.</p>
<p>En concreto, el panel izquierdo muestra la función de distribución empírica, el panel derecho proporciona un gráfico de la densidad no paramétrica.</p>
<div class="figure" style="text-align: center"><span id="fig:BIClaims"></span>
<img src="LossDataAnalytics_files/figure-html/BIClaims-1.png" alt="Siniestros por daños corporales. La figura de la izquierda proporciona la función de distribución empírica. La figura de la derecha presenta un gráfico de la densidad no paramétrica." width="672" />
<p class="caption">
Figure 4.5: Siniestros por daños corporales. La figura de la izquierda proporciona la función de distribución empírica. La figura de la derecha presenta un gráfico de la densidad no paramétrica.
</p>
</div>
<p>El impacto de las pérdidas por lesiones corporales se puede mitigar mediante la imposición de límites o la compra de pólizas de reaseguro (consulte la Sección 10.3). Para cuantificar el impacto de estas herramientas de mitigación de riesgos, es común calcular el índice de eliminación de pérdida o <em>loss elimination ratio (LER)</em> como se introdujo en la Sección 3.4.1. La función de distribución no está disponible y se debe estimar de alguna manera. Usando el principio <em>plug-in</em>, un estimador no paramétrico se puede definir como
<span class="math display">\[
LER_n(d) = \frac{n^{-1} \sum_{i=1}^n \min(X_i,d)}{n^{-1} \sum_{i=1}^n X_i} = \frac{\sum_{i=1}^n \min(X_i,d)}{\sum_{i=1}^n X_i} .
\]</span></p>
La figura <a href="C-ModelSelection.html#fig:BIClaims">4.5</a> muestra el estimador <span class="math inline">\(LER_n(d)\)</span> para varias opciones de <em>d</em>. Por ejemplo, si <span class="math inline">\(d=14.000\)</span>, resulta que <span class="math inline">\(LER_n(14000)\approx\)</span> 0.9768. Imponer un límite de 14.000 significa que esperamos retener 97.68 porcentaje de siniestros.
<div class="figure" style="text-align: center"><span id="fig:LER"></span>
<img src="LossDataAnalytics_files/figure-html/LER-1.png" alt="LER para siniestros por daños corporales. La figura presenta el índice de eliminación de pérdidas (LER) en función del deducible d." width="672" />
<p class="caption">
Figure 4.6: LER para siniestros por daños corporales. La figura presenta el índice de eliminación de pérdidas (LER) en función del deducible d.
</p>
</div>
</div>
</div>
<div id="S:MS:ToolsModelSelection" class="section level3">
<h3><span class="header-section-number">4.1.2</span> Herramientas para la Selección de Modelos y Diagnósticos</h3>
<p>En la sección anterior se introdujeron estimadores no paramétricos en los que no se asumía una forma paramétrica sobre las distribuciones subyacentes. Sin embargo, en muchas aplicaciones actuariales, los analistas buscan emplear un ajuste paramétrico de una distribución para facilitar la explicación y la capacidad de extenderla fácilmente a situaciones más complejas, como incluir variables explicativas en un entorno de regresión. Al ajustar una distribución paramétrica, un analista podría intentar usar una distribución gamma para representar un conjunto de datos de pérdida. Sin embargo, otro analista podría preferir usar una distribución de Pareto. ¿Cómo se sabe qué modelo <strong>seleccionar</strong>?</p>
<p>Se pueden utilizar herramientas no paramétricas para corroborar la selección de modelos paramétricos. Esencialmente, el enfoque es calcular las medidas de resumen seleccionadas bajo un modelo paramétrico ajustado y compararlo con el valor correspondiente bajo el modelo no paramétrico. Como el no paramétrico no asume una distribución específica y es simplemente una función de los datos, se utiliza como punto de referencia para evaluar cómo de bien la distribución/modelo paramétrico representa los datos. Esta comparación puede alertar al analista de deficiencias en el modelo paramétrico y, a veces, señalar formas de mejorar la especificación paramétrica. Los procedimientos orientados a evaluar la validez de un modelo se conocen como <strong>diagnóstico del modelo</strong>.</p>
<div id="S:MS:GraphComparison" class="section level4">
<h4><span class="header-section-number">4.1.2.1</span> Comparación Gráfica de Distribuciones</h4>
<p>Ya hemos visto la técnica de superponer gráficos para fines de comparación. Para reforzar la aplicación de esta técnica, la Figura @ref(fig: ComparisonCDFPDF) compara la distribución empírica con dos distribuciones paramétricas ajustadas. El gráfico izquierdo muestra las funciones de distribución de las distribuciones de siniestros. Los puntos que forman una curva “en forma de S” representan la función de distribución empírica en cada observación. La curva azul gruesa proporciona los valores correspondientes para la distribución gamma ajustada y el púrpura claro corresponde a la distribución de Pareto ajustada. Como la distribución de Pareto está mucho más cerca de la función de distribución empírica que la de la gamma, esto nos proporciona una evidencia de que la Pareto es el mejor modelo para este conjunto de datos. El gráfico derecho ofrece información similar para la función de densidad y proporciona un mensaje coherente. Basado (sólo) en estos gráficos, la distribución de Pareto es la opción preferida para el analista.</p>
<div class="figure" style="text-align: center"><span id="fig:ComparisonCDFPDF"></span>
<img src="LossDataAnalytics_files/figure-html/ComparisonCDFPDF-1.png" alt="Distribución paramétrica versus paramétrica ajustada y funciones de densidad. El gráfico de la izquierda compara las funciones de distribución, con los puntos correspondientes a la distribución empírica, la curva azul gruesa correspondiente a la gamma ajustada y la curva de color púrpura claro correspondiente al Pareto ajustado. El gráfico de la derecha compara estas tres distribuciones resumidas usando funciones de densidad de probabilidad." width="80%" />
<p class="caption">
Figure 4.7: Distribución paramétrica versus paramétrica ajustada y funciones de densidad. El gráfico de la izquierda compara las funciones de distribución, con los puntos correspondientes a la distribución empírica, la curva azul gruesa correspondiente a la gamma ajustada y la curva de color púrpura claro correspondiente al Pareto ajustado. El gráfico de la derecha compara estas tres distribuciones resumidas usando funciones de densidad de probabilidad.
</p>
</div>
<p>Otra forma de comparar la idoneidad de dos modelos ajustados es a partir del gráfico de <strong>probabilidad-probabilidad (<span class="math inline">\(pp\)</span>)</strong>. Un gráfico <span class="math inline">\(pp\)</span> compara las probabilidades acumuladas en dos modelos. Para nuestro propósito, estos dos modelos son la función de distribución empírica no paramétrica y el modelo paramétrico ajustado. La Figura @ref(fig: PPPlot) muestra los gráficos <span class="math inline">\(pp\)</span> para los datos del Fondo de la Propiedad. La gamma ajustada está a la izquierda y la Pareto ajustada está a la derecha, en comparación con la misma función de distribución empírica de los datos. La línea recta representa la igualdad entre las dos distribuciones que se comparan, por lo que son deseables los puntos cercanos a la línea. Como se vio en demostraciones anteriores, la Pareto está mucho más cerca de la distribución empírica que la gamma, lo que proporciona evidencia adicional de que la Pareto es el mejor modelo.</p>
<div class="figure" style="text-align: center"><span id="fig:PPPlot"></span>
<img src="LossDataAnalytics_files/figure-html/PPPlot-1.png" alt="Gráficos de Probabilidad-Probabilidad ($pp$). Los ejes horizontales representan la función de distribución empírica en cada observación. En el gráfico izquierdo, la función de distribución correspondiente a la gamma se muestra en el eje vertical. El gráfico de la derecha muestra la distribución de Pareto ajustada. Las líneas de $y=x$ se superponen." width="80%" />
<p class="caption">
Figure 4.8: Gráficos de Probabilidad-Probabilidad (<span class="math inline">\(pp\)</span>). Los ejes horizontales representan la función de distribución empírica en cada observación. En el gráfico izquierdo, la función de distribución correspondiente a la gamma se muestra en el eje vertical. El gráfico de la derecha muestra la distribución de Pareto ajustada. Las líneas de <span class="math inline">\(y=x\)</span> se superponen.
</p>
</div>
<p>Un gráfico <span class="math inline">\(pp\)</span> es útil en parte porque no se requiere escala artificial, como con la superposición de densidades en la Figura @ref(fig: ComparisonCDFPDF), en la que cambiamos a la escala logarítmica para visualizar mejor los datos. El Capítulo 4 <em>Suplemento técnico A.1</em> introduce una variación del diagrama <span class="math inline">\(pp\)</span> conocido como <em>curva de Lorenz</em>; Ésta es una herramienta importante para evaluar la desigualdad de ingresos. Además, los gráficos <span class="math inline">\(pp\)</span> están disponibles en entornos multivariantes en los que hay más de una variable disponible. Sin embargo, una limitación del gráfico <span class="math inline">\(pp\)</span> es que, debido a que es un gráfico de funciones de distribución <em>acumulativas</em>, a veces puede resultar difícil detectar <em>dónde</em> una distribución paramétrica ajustada es deficiente. Como alternativa, se usa frecuentemente un gráfico <strong>cuantil-cuantil (<span class="math inline">\(qq\)</span>)</strong>, como se muestra en la Figura <a href="C-ModelSelection.html#fig:QQPlot">4.9</a>.</p>
<p>El gráfico <span class="math inline">\(qq\)</span> compara dos modelos ajustados a través de sus cuantiles. Al igual que con los gráficos <span class="math inline">\(pp\)</span>, comparamos el modelo no paramétrico con un modelo ajustado paramétrico. Los cuantiles se pueden evaluar en cada punto del conjunto de datos o en una cuadrícula (por ejemplo, en <span class="math inline">\(0, 0,001, 0,002, \ldots, 0,999, 1.000\)</span>), dependiendo de la aplicación. En la Figura <a href="C-ModelSelection.html#fig:QQPlot">4.9</a>, para cada punto en la cuadrícula mencionada, el eje horizontal muestra el cuantil empírico y el eje vertical muestra el correspondiente cuantil paramétrico ajustado (gamma para los dos gráficos superiores, Pareto para los dos inferiores). Los cuantiles se trazan en la escala original en los gráficos izquierdos y en la escala logarítmica en los gráficos derechos para permitirnos ver dónde una distribución ajustada es deficiente. La línea recta representa la igualdad entre la distribución empírica y la distribución ajustada. A partir de estos gráficos, nuevamente vemos que en general la Pareto se ajusta mejor que la gamma. Además, el gráfico inferior derecho sugiere que la distribución de Pareto muestra un buen ajuste con valores grandes, pero proporciona un peor ajuste para valores pequeños.</p>
<div class="figure" style="text-align: center"><span id="fig:QQPlot"></span>
<img src="LossDataAnalytics_files/figure-html/QQPlot-1.png" alt="Gráficos Cuantil-Cuantil ($qq$). Los ejes horizontales representan los cuantiles empíricos en cada observación. Los gráficos de la derecha están representados sobre una base logarítmica. El eje vertical contiene los cuantiles de las distribuciones ajustadas; los cuantiles gamma están en los gráficos superiores, los cuantiles de Pareto están en los gráficos inferiores." width="80%" />
<p class="caption">
Figure 4.9: Gráficos Cuantil-Cuantil (<span class="math inline">\(qq\)</span>). Los ejes horizontales representan los cuantiles empíricos en cada observación. Los gráficos de la derecha están representados sobre una base logarítmica. El eje vertical contiene los cuantiles de las distribuciones ajustadas; los cuantiles gamma están en los gráficos superiores, los cuantiles de Pareto están en los gráficos inferiores.
</p>
</div>
<hr />
<p><strong>Ejemplo 4.1.6. Pregunta de Examen Actuarial.</strong>
La siguiente figura muestra un gráfico <span class="math inline">\(pp\)</span> de una distribución ajustada en comparación con una muestra.</p>
<p><img src="LossDataAnalytics_files/figure-html/unnamed-chunk-22-1.png" width="40%" style="display: block; margin: auto;" /></p>
<p>Comente las dos distribuciones con respecto a la cola izquierda, la cola derecha y las probabilidades medianas.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleSelect.1.6" href="javascript:toggleEX('toggleExampleSelect.1.6','displayTextExampleSelect.1.6');"><i><strong>Mostrar la solución del ejemplo</strong></i></a>
</h5>
<div id="toggleExampleSelect.1.6" style="display: none">
<p><strong>Solución.</strong>
La cola de la distribución ajustada es demasiado gruesa a la izquierda, demasiado delgada a la derecha, y la distribución ajustada tiene menos probabilidad alrededor de la mediana que la muestra. Para ver esto, recuerde que el gráfico <span class="math inline">\(pp\)</span> representa gráficamente la distribución acumulada de dos distribuciones en sus ejes (empírica en el eje <span class="math inline">\(x\)</span> y ajustada en el eje <span class="math inline">\(y\)</span> en este caso). Para valores pequeños de <span class="math inline">\(x\)</span>, el modelo ajustado asigna una mayor probabilidad de estar por debajo de ese valor que el que se produjo en la muestra (es decir, <span class="math inline">\(F(x)&gt;F_n(x)\)</span>). Esto indica que el modelo tiene una cola izquierda más pesada que los datos. Para valores grandes de <span class="math inline">\(x\)</span>, el modelo nuevamente asigna una mayor probabilidad de estar por debajo de ese valor y, por lo tanto, menos probabilidad de estar por encima de ese valor (es decir, <span class="math inline">\(S(x)&lt;S_n(x)\)</span>. Esto indica que el modelo tiene una cola derecha más fina que los datos. Además, a medida que avanzamos de 0,4 a 0,6 en el eje horizontal (mirando así el 20% medio de los datos), el gráfico <span class="math inline">\(pp\)</span> aumenta aproximadamente de 0,3 a 0,4. Esto indica que el modelo asigna sólo alrededor del 10% de la probabilidad en este rango.</p>
</div>
<hr />
</div>
<div id="S:MS:Tools:Stats" class="section level4">
<h4><span class="header-section-number">4.1.2.2</span> Comparación Estadística de Distribuciones</h4>
<p>Para seleccionar un modelo es útil realizar las representaciones gráficas previas. Sin embargo, para mostrar los resultados, puede ser necesario complementar los gráficos con estadísticos de selección que resumen la bondad de ajuste del modelo. La <a href="#tab:42">Tabla 4.2</a> proporciona tres estadísticos de bondad de ajuste de uso frecuente. En esta tabla, <span class="math inline">\(F_n\)</span> es la distribución empírica, <span class="math inline">\(F\)</span> es la distribución ajustada o hipotética, y <span class="math inline">\(F_i=F(x_i)\)</span>.</p>
<p><a id=tab:42></a></p>
<p><span class="math display">\[
{\small
\begin{matrix}
\text{Tabla 4.2: Tres Estadísticos de Bondad de Ajuste } \\
\begin{array}{l|cc}
\hline
\text{Estadístico} &amp; \text{Definición} &amp; \text{Expresión Computacional} \\
\hline
\text{Kolmogorov-} &amp; \max_x |F_n(x) - F(x)| &amp; \max(D^+, D^-) \text{ donde} \\
~~~\text{Smirnov} &amp;&amp; D^+ = \max_{i=1, \ldots, n} \left|\frac{i}{n} - F_i\right| \\
&amp;&amp; D^- = \max_{i=1, \ldots, n} \left| F_i - \frac{i-1}{n} \right| \\
\text{Cramer-von Mises} &amp; n \int (F_n(x) - F(x))^2 f(x) dx &amp; \frac{1}{12n} + \sum_{i=1}^n \left(F_i - (2i-1)/n\right)^2 \\
\text{Anderson-Darling} &amp; n \int \frac{(F_n(x) - F(x))^2}{F(x)(1-F(x))} f(x) dx &amp; -n-\frac{1}{n} \sum_{i=1}^n (2i-1) \log\left(F_i(1-F_{n+1-i})\right)^2 \\
\hline
\end{array} \\
\end{matrix}
}
\]</span></p>
<p>El <em>estadístico de Kolmogorov-Smirnov</em> es igual a la diferencia absoluta máxima entre la función de distribución ajustada y la función de distribución empírica. En lugar de comparar diferencias entre puntos individuales, el estadístico de <em>Cramer-von Mises</em> integra la diferencia entre las funciones de distribución empíricas y ajustadas en todo el rango de valores. El estadístico de <em>Anderson-Darling</em> también integra esta diferencia en el rango de valores, aunque ponderada por la inversa de la varianza. Por lo tanto, pone mayor énfasis en las colas de la distribución (es decir, cuando <span class="math inline">\(F(x)\)</span> o <span class="math inline">\(1-F(x)=S(x)\)</span> es pequeño).</p>
<hr />
<p><strong>Ejemplo 4.1.7. Pregunta de Examen Actuarial (modificada).</strong>
Una muestra de pagos de siniestros es:</p>
<p><span class="math display">\[
\begin{array}{ccccc}
29 &amp; 64 &amp; 90 &amp; 135 &amp; 182  \\
\end{array}
\]</span></p>
<p>Comparar la distribución empírica de siniestros con una distribución exponencial con una media de <span class="math inline">\(100\)</span> calculando el valor del estadístico de prueba de Kolmogorov-Smirnov.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleSelect.1.7" href="javascript:toggleEX('toggleExampleSelect.1.7','displayTextExampleSelect.1.7');"><i><strong>Mostrar solución del ejemplo</strong></i></a>
</h5>
<div id="toggleExampleSelect.1.7" style="display: none">
<p><strong>Solución.</strong>
Para una distribución exponencial con una media de <span class="math inline">\(100\)</span>, la función de distribución acumulada es <span class="math inline">\(F(x)=1-e^{-x/100}\)</span>. Así,
<span class="math display">\[
\begin{array}{ccccc}
\hline
x &amp; F(x) &amp; F_n(x) &amp; F_n(x-) &amp; \max(|F(x)-F_n(x)|,|F(x)-F_n(x-)|) \\
\hline
29  &amp; 0,2517 &amp; 0,2 &amp; 0   &amp; \max(0,0517, 0,2517) = 0,2517 \\
64  &amp; 0,4727 &amp; 0,4 &amp; 0,2 &amp; \max(0,0727, 0,2727) = 0,2727 \\
90  &amp; 0,5934 &amp; 0,6 &amp; 0,4 &amp; \max(0,0066, 0,1934) = 0,1934 \\
135 &amp; 0,7408 &amp; 0,8 &amp; 0,6 &amp; \max(0,0592, 0,1408) = 0,1408 \\
182 &amp; 0,8380 &amp; 1   &amp; 0,8 &amp; \max(0,1620, 0,0380) = 0,1620 \\
\hline
\end{array}
\]</span></p>
<p>El estadístico de la prueba de Kolmogorov-Smirnov es, por lo tanto, <span class="math inline">\(KS = \max(0,2517, 0,2727, 0,1934, 0,1408, 0,1620) = 0,2727\)</span>.</p>
</div>
<hr />
</div>
</div>
<div id="valores-iniciales" class="section level3">
<h3><span class="header-section-number">4.1.3</span> Valores Iniciales</h3>
<p>Los métodos de momentos y basados en la coincidencia de percentiles son métodos de estimación no paramétricos que proporcionan alternativas a la máxima verosimilitud. Generalmente, la máxima verosimilitud es la técnica preferida porque emplea los datos de manera más eficiente. (Consulte el Capítulo <a href="C-AppC.html#C:AppC">17</a> del Apéndice para obtener las definiciones precisas de eficiencia). Sin embargo, los métodos de momentos y coincidencia de percentiles son útiles porque son más fáciles de interpretar y, por lo tanto, permiten que el actuario o el analista explique los procedimientos a terceros. Además, el procedimiento de estimación numérica (por ejemplo, si se realiza en ‘R’) para la máxima verosimilitud es iterativo y requiere valores iniciales para comenzar el proceso recursivo. Aunque muchos problemas son robustos ante la elección de los valores iniciales, en algunas situaciones complejas, puede ser importante tener un valor inicial cercano al valor óptimo (desconocido). El método de los momentos y la coincidencia de percentiles son técnicas que pueden producir estimaciones deseables sin un elevado coste en términos computacionales y, por lo tanto, pueden usarse como un <em>valor inicial</em> para estimar los parámetros por máxima verosimilitud.</p>
<div id="método-de-momentos" class="section level4">
<h4><span class="header-section-number">4.1.3.1</span> Método de Momentos</h4>
<p>Con el <strong>método de momentos</strong>, aproximamos los momentos de la distribución paramétrica utilizando los momentos empíricos (no paramétricos) descritos en la Sección <a href="C-ModelSelection.html#S:MS:MomentEstimator">4.1.1.1</a>. Entonces podemos obtener algebraicamente las estimaciones de los parámetros.
***</p>
<p><strong>Ejemplo 4.1.8. Fondo de Propiedad.</strong>
Para el fondo inmobiliario de 2010, hay <span class="math inline">\(n=1.377\)</span> siniestros individuales (en miles de dólares) con</p>
<p><span class="math display">\[m_1 = \frac{1}{n} \sum_{i=1}^n X_i = 26,62259 \ \ \ \
\text{y} \ \ \ \
 m_2 = \frac{1}{n} \sum_{i=1}^n X_i^2 = 136.154,6 .\]</span></p>
<p>Ajustar los parámetros de las distribuciones gamma y Pareto utilizando el método de los momentos.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleSelect.1.8" href="javascript:toggleEX('toggleExampleSelect.1.8','displayTextExampleSelect.1.8');"><i><strong>Mostrar solución del ejemplo</strong></i></a>
</h5>
<div id="toggleExampleSelect.1.8" style="display: none">
<p><strong>Solución.</strong></p>
<p>Para ajustar una distribución gamma, tenemos <span class="math inline">\(\mu_1=\alpha\theta\)</span> y <span class="math inline">\(\mu_2^{\prime}=\alpha(\alpha+1)\theta^2\)</span>. Al resolver ambas ecuaciones para obtener la estimación por el método de los momentos, mediante cálculos sencillos se muestra que</p>
<p><span class="math display">\[\alpha = \frac{\mu_1^2}{\mu_2^{\prime}-\mu_1^2}  \ \ \ \text{y} \ \ \  \theta = \frac{\mu_2^{\prime}-\mu_1^2}{\mu_1}.\]</span></p>
<p>Por lo tanto, los estimadores por el método de los momentos son
<span class="math display">\[
\begin{aligned}
\hat{\alpha} &amp;=  \frac{26,62259^2}{136154,6-26,62259^2} = 0,005232809 \\
\hat{\theta} &amp;=  \frac{136154,6-26,62259^2}{26,62259} = 5.087,629.
\end{aligned}
\]</span></p>
<p>A modo de comparación, los valores obtenidos por máxima verosimilitud son <span class="math inline">\(\hat{\alpha}_{MLE}=0,2905959\)</span> y <span class="math inline">\(\hat{\theta}_{MLE}=91,61378\)</span>, por lo que hay grandes discrepancias entre las estimaciones obtenidas con los dos procedimientos. Esto es una indicación, como hemos visto antes, de que el modelo gamma no se ajusta bien.</p>
<p>En contraste, ahora se asume una distribución de Pareto, de modo que <span class="math inline">\(\mu_1 = \theta/(\alpha -1)\)</span> y <span class="math inline">\(\mu_2^{\prime} = 2\theta^2/((\alpha-1)(\alpha-2) )\)</span>. mediante cálculos sencillos se muestra que</p>
<p><span class="math display">\[\alpha = 1+ \frac{\mu_2^{\prime}}{\mu_2^{\prime}-\mu_1^2} \ \ \ \
\text{and} \ \ \ \ \
 \theta = (\alpha-1)\mu_1.\]</span></p>
<p>Por lo tanto, los estimadores por el método de los momentos son
<span class="math display">\[
\begin{aligned}
\hat{\alpha} &amp;=  1+ \frac{136154,6}{136154,6-26,62259^2} = 2,005233 \\
\hat{\theta} &amp;=  (2,005233-1) \cdot 26,62259 = 26,7619
\end{aligned}
\]</span></p>
<p>Los valores estimados por máxima verosimilitud son <span class="math inline">\(\hat{\alpha}_{MLE}=0,9990936\)</span> y <span class="math inline">\(\hat{\theta}_{MLE}=2,2821147\)</span>. Es interesante que <span class="math inline">\(\hat{\alpha}_{MLE}&lt;1\)</span>; para la distribución de Pareto, recuerde que <span class="math inline">\(\alpha&lt;1\)</span> significa que la media es infinita. Esto es otro indicio de que el conjunto de datos de siniestros de la propiedad tiene una distribución de cola larga y pesada.</p>
</div>
<hr />
<p>Como se sugiere en el ejemplo anterior, existe flexibilidad con el método de los momentos. Por ejemplo, podríamos haber igualado el segundo y el tercer momento en lugar del primero y el segundo, obteniendo diferentes estimadores. Además, no hay garantía de que exista una solución para cada problema. Adicionalmente, con datos censurados o truncados, hacer coincidir los momentos es solo posible para algunos problemas, y en general, es un escenario más complejo. Finalmente, para distribuciones donde los momentos no existen o son infinitos, el método de momentos no se puede aplicar. Como alternativa, se puede usar la técnica de coincidencia de percentiles.</p>
</div>
<div id="coincidencia-de-percentiles" class="section level4">
<h4><span class="header-section-number">4.1.3.2</span> Coincidencia de percentiles</h4>
<p>Bajo el método de <strong>coincidencia de percentiles</strong>, aproximamos los cuantiles o percentiles de la distribución paramétrica utilizando los cuantiles o percentiles empíricos (no paramétricos) descritos en la Sección <a href="C-ModelSelection.html#S:MS:QuantileEstimator">4.1.1.3</a>.</p>
<hr />
<p><strong>Ejemplo 4.1.9. Fondo de propiedad.</strong></p>
<p>Para el fondo inmobiliario de 2010, ilustramos la correspondencia en cuantiles. En concreto, la distribución de Pareto es intuitivamente sencilla debido a la expresión cerrada para los cuantiles. Recuerde que la función de distribución para la distribución de Pareto es</p>
<p><span class="math display">\[F(x) = 1 - \left(\frac{\theta}{x+\theta}\right)^{\alpha}.\]</span>
Mediante sencillos cálculos se muestra que podemos expresar el cuantil como</p>
<p><span class="math display">\[F^{-1}(q) = \theta \left( (1-q)^{-1/\alpha} -1 \right).\]</span>
for a fraction <span class="math inline">\(q\)</span>, <span class="math inline">\(0&lt;q&lt;1\)</span>.</p>
<p>Determinar las estimaciones de los parámetros de la distribución de Pareto utilizando los cuantiles empíricos 25 y 95.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleSelect.1.9" href="javascript:toggleEX('toggleExampleSelect.1.9','displayTextExampleSelect.1.9');"><i><strong>Mostrar solución del ejemplo</strong></i></a>
</h5>
<div id="toggleExampleSelect.1.9" style="display: none">
<p><strong>Solución.</strong></p>
<p>El percentil 25 (el primer cuartil) es <span class="math inline">\(0,78853\)</span> y el percentil 95 es <span class="math inline">\(50,98293\)</span> (ambos en miles de dólares). Con dos ecuaciones</p>
<p><span class="math display">\[0,78853 = \theta \left( 1- (1-0,25)^{-1/\alpha} \right) \ \ \ \ \text{y} \ \ \ \ 50,98293 = \theta \left( 1- (1-0,95)^{-1/\alpha} \right)\]</span>
y dos incógnitas, la solución es
<span class="math display">\[\hat{\alpha} = 0,9412076 \ \ \ \ \ \text{y} \ \ \ \
\hat{\theta} = 2,205617 .\]</span>
Observamos aquí que se requiere una rutina numérica para estas soluciones ya que no hay una solución analítica disponible. Además, recuerde que las estimaciones de máxima verosimilitud son <span class="math inline">\(\hat{\alpha}_{MLE}=0,9990936\)</span> y <span class="math inline">\(\hat{\theta}_{MLE} = 2,2821147\)</span>, por lo que la coincidencia de percentiles proporciona una mejor aproximación para la distribución de Pareto que el método de los momentos.</p>
</div>
<hr />
<p><strong>Ejemplo 4.1.10. Pregunta de Examen Actuarial.</strong></p>
<p>Te dan:</p>
<ol style="list-style-type: lower-roman">
<li>Las pérdidas siguen una distribución loglogística con función de distribución acumulada:
<span class="math display">\[F(x) = \frac{\left(x/\theta\right)^{\gamma}}{1+\left(x/\theta\right)^{\gamma}}\]</span></li>
<li>La muestra de pérdidas es:</li>
</ol>
<p><span class="math display">\[
\begin{array}{ccccccccccc}
10 &amp;35 &amp;80 &amp;86 &amp;90 &amp;120 &amp;158 &amp;180 &amp;200 &amp;210 &amp;1500 \\
\end{array}
\]</span></p>
<p>Estimar <span class="math inline">\(\theta\)</span> mediante la coincidencia de percentiles, utilizando las estimaciones de percentiles empíricos suavizados del 40 y 80.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleSelect.1.10" href="javascript:toggleEX('toggleExampleSelect.1.10','displayTextExampleSelect.1.10');"><i><strong>Mostrar solución del ejemplo</strong></i></a>
</h5>
<div id="toggleExampleSelect.1.10" style="display: none">
<p><strong>Solución.</strong>
Con 11 observaciones, tenemos <span class="math inline">\(j=\lfloor(n+1)q\rfloor = \lfloor 12(0,4) \rfloor = \lfloor 4,8\rfloor=4\)</span> y <span class="math inline">\(h=(n+1)q-j = 12(0,4)-4=0,8\)</span>. Por interpolación, la estimación del percentil 40 empírico suavizado es <span class="math inline">\(\hat{\pi}_{0,4} = (1-h) X_{(j)} + h X_{(j+1)} = 0,2(86)+0,8(90)=89,2\)</span>.</p>
<p>Del mismo modo, para la estimación del percentil 80 empírico suavizado, tenemos <span class="math inline">\(12(0,8)=9,6\)</span> entonces la estimación es <span class="math inline">\(\hat{\pi}_{0,8} = 0,4(200)+0,6(210)=206\)</span>.</p>
<p>Usando la distribución acumulada loglogística, necesitamos resolver las siguientes dos ecuaciones para los parámetros <span class="math inline">\(\theta\)</span> y <span class="math inline">\(\gamma\)</span>:
<span class="math display">\[0,4=\frac{(89,2/\theta)^\gamma}{1+(89,2/\theta)^\gamma} \ \ \ \text{y} \ \ \ \   0,8=\frac{(206/\theta)^\gamma}{1+(206+\theta)^\gamma}\]</span></p>
<p>Resolviendo para cada expresión entre paréntesis da <span class="math inline">\(\frac{2}{3}=(89,2/\theta)^\gamma\)</span> y <span class="math inline">\(4=(206/\theta)^\gamma\)</span>. Sustituyendo la razón de la segunda ecuación en la primera da <span class="math inline">\(6=(206/89,2)^\gamma \Rightarrow \gamma=\frac{\ln(6)}{\ln(206/89,2)} = 2,1407\)</span>. Entonces <span class="math inline">\(4^{1/2,1407}=206/\theta \Rightarrow \theta=107,8\)</span></p>
</div>
<hr />
<p>Al igual que el método de los momentos, la coincidencia de percentiles es también muy sensible en el sentido de que muchos estimadores pueden basarse en coincidencias de percentiles; por ejemplo, un actuario puede basar la estimación en los percentiles 25 y 95, mientras que otro actuario utiliza los percentiles 20 y 80. En general, estos estimadores serán diferentes y no hay una razón convincente para preferir uno sobre el otro. Por otro lado, como con el método de los momentos, la coincidencia de percentiles es atractiva porque proporciona una técnica que se puede aplicar fácilmente en distintas situaciones y tiene una base intuitiva. Aunque la mayoría de las aplicaciones actuariales usan estimadores de máxima verosimilitud, puede ser conveniente utilizar enfoques alternativos como el método de momentos y la coincidencia de percentiles.</p>
</div>
</div>
</div>
<div id="S:MS:ModelSelection" class="section level2">
<h2><span class="header-section-number">4.2</span> Selección del Modelo</h2>
<hr />
<p>En esta sección, se aprende a:</p>
<ul>
<li>Describir el proceso iterativo de especificación y de selección de modelo.</li>
<li>Esquematizar los pasos necesarios para seleccionar un modelo paramétrico.</li>
<li>Describir los peligros de la selección del modelo basándose únicamente en datos en muestra en comparación con las ventajas de la validación del modelo fuera de muestra.</li>
</ul>
<hr />
<p>En esta sección se subraya la idea de que la selección de modelos es un proceso iterativo en el que los modelos se (re)formulan cíclicamente y se prueban para determinar su idoneidad antes de usarlos para la inferencia. Después de una descripción general, describimos el proceso de selección del modelo basado en:</p>
<ul>
<li>un conjunto de datos en muestra o de entrenamiento,</li>
<li>un conjunto de datos fuera de la muestra o de prueba, y</li>
<li>un método que combina estos enfoques conocido como <strong>validación cruzada</strong>.</li>
</ul>
<div id="selección-del-modelo-iterativa" class="section level3">
<h3><span class="header-section-number">4.2.1</span> Selección del Modelo Iterativa</h3>
<p>En nuestro desarrollo examinamos los datos gráficamente, hipotetizamos la estructura de un modelo y comparamos los datos con un modelo candidato para formular un modelo mejorado. <span class="citation">Box (<a href="#ref-box1980sampling" role="doc-biblioref">1980</a>)</span> lo describe como un <em>proceso iterativo</em> el cual se muestra en la Figura <a href="C-ModelSelection.html#fig:Iterative">4.10</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:Iterative"></span>
<img src="Figures/F5Iterative.png" alt="El proceso iterativo de especificación del modelo." width="80%" />
<p class="caption">
Figure 4.10: El proceso iterativo de especificación del modelo.
</p>
</div>
<p>Este proceso iterativo proporciona un mecanismo útil para estructurar el proceso de especificación de un modelo para representar un conjunto de datos.</p>
<ol style="list-style-type: decimal">
<li>El primer paso, la etapa de formulación del modelo, se logra examinando los datos gráficamente y utilizando el conocimiento previo de las relaciones, como la teoría económica o la práctica de la industria.</li>
<li>El segundo paso en el proceso iterativo consiste en el ajuste basado en los supuestos del modelo especificado. Estas suposiciones deben ser consistentes con los datos para hacer un uso válido del modelo.</li>
<li>El tercer paso es el de <em>comprobación de diagnóstico</em>; los datos y el modelo deben ser coherentes entre sí antes de poder hacer inferencias adicionales. La verificación de diagnóstico es una parte importante de la formulación del modelo; puede revelar errores cometidos en pasos anteriores y proporcionar formas de corregir estos errores.</li>
</ol>
<p>El proceso iterativo también enfatiza las habilidades que se necesitan para que la analítica funcione. Primero, se necesita estar dispuesto a resumir la información numéricamente y representarla gráficamente. En segundo lugar, es importante desarrollar una comprensión de las propiedades del modelo. Debe comprenderse cómo se comporta un modelo probabilístico para hacer coincidir un conjunto de datos con él. Tercero, las propiedades teóricas del modelo también son importantes para inferir relaciones generales basadas en el comportamiento de los datos.</p>
</div>
<div id="selección-de-modelo-basada-en-un-conjunto-de-datos-de-entrenamiento" class="section level3">
<h3><span class="header-section-number">4.2.2</span> Selección de Modelo basada en un Conjunto de Datos de Entrenamiento</h3>
<p>Es común referirse a un conjunto de datos utilizado para el análisis como un conjunto de datos <em>en muestra</em> o <em>de entrenamiento</em>. Las técnicas disponibles para seleccionar un modelo dependen de si los resultados <span class="math inline">\(X\)</span> son discretos, continuos o un híbrido de los dos, aunque los principios son los mismos.</p>
<p><strong>Gráfico y otras medidas de resumen básicas.</strong> Comenzar resumiendo los datos gráficamente y con estadísticos que no se basen en una forma paramétrica específica, como se describe en la Sección <a href="C-ModelSelection.html#S:MS:NonParInf">4.1</a>. En concreto, es necesario representar gráficamente tanto la distribución empírica como las funciones de densidad. Particularmente, para los datos de pérdidas que contienen muchos ceros y que pueden ser asimétricos, decidir la escala apropiada (por ejemplo, logarítmica) puede representar algunas dificultades. Para datos discretos, a menudo se prefieren las tablas. Determinar los momentos muestrales, como la media y la varianza, así como los cuantiles seleccionados, incluidos el mínimo, el máximo y la mediana. Para datos discretos, la moda (o el valor más frecuente) suele ser útil.</p>
<p>Estos resúmenes, así como el conocimiento de la práctica profesional, permiten proponer uno o más modelos paramétricos candidatos. En general, se debe comenzar con los modelos paramétricos más simples (por ejemplo, la exponencial de un parámetro antes de una gamma de dos parámetros), introduciendo gradualmente más complejidad en el proceso de modelización.</p>
<p>Evaluar el modelo paramétrico candidato numérica y gráficamente. Para los gráficos, se pueden utilizar las herramientas introducidas en la Sección <a href="C-ModelSelection.html#S:MS:ToolsModelSelection">4.1.2</a> como los gráficos <span class="math inline">\(pp\)</span> y <span class="math inline">\(qq\)</span>. Para las evaluaciones numéricas, examinar la importancia estadística de los parámetros e intentar eliminar los parámetros que no proporcionan información adicional.</p>
<p><strong>Pruebas de razón de verosimilitud.</strong> Para comparar ajustes del modelo, si un modelo es un subconjunto de otro, entonces se puede utilizar una prueba de razón de verosimilitud; el enfoque general para la prueba de razón de verosimilitud se describe en las Secciones <a href="C-AppA.html#S:AppA:HT:LRT">15.4.3</a> y <a href="C-AppC.html#S:AppC:MLEModelVal">17.3.2</a>.</p>
<p><strong>Estadísticos de bondad del ajuste.</strong> En general, los modelos no son subconjuntos unos de otros, por lo que los estadísticos generales de bondad del ajuste son útiles para comparar modelos. <em>Los criterios de información</em> son un tipo de estadístico de bondad de ajuste. Los ejemplos más utilizados son el Criterio de Información de Akaike (<em>AIC</em>) y el Criterio de Información Bayesiano (<em>BIC</em>) de Schwarz; se mencionan frecuentemente porque pueden generalizarse fácilmente a entornos multivariantes. La Sección <a href="C-AppA.html#S:AppA:HT:IC">15.4.4</a> proporciona una descripción de estos estadísticos.</p>
<p>Para seleccionar la distribución adecuada, los estadísticos que comparan un ajuste paramétrico con una alternativa no paramétrica, descritos en la Sección <a href="C-ModelSelection.html#S:MS:Tools:Stats">4.1.2.2</a>, son útiles para la comparación de modelos. Para datos discretos, generalmente se prefiere un estadístico de <em>bondad de ajuste</em> (como se describe en la Sección <a href="C-Frequency-Modeling.html#S:goodness-of-fit">2.7</a>), ya que es más intuitivo y más simple de explicar.</p>
</div>
<div id="selección-de-modelo-basada-en-un-conjunto-de-datos-de-prueba" class="section level3">
<h3><span class="header-section-number">4.2.3</span> Selección de Modelo basada en un Conjunto de Datos de Prueba</h3>
<p><strong>Validación del modelo</strong> es el proceso de confirmar que el modelo propuesto es apropiado, especialmente a la luz de los propósitos de la investigación. Una limitación importante del proceso de selección de modelos basado solo en datos de muestra es que puede ser susceptible a <em>indagación de datos (data-snooping)</em>, es decir, ajustar una gran cantidad de modelos a un solo conjunto de datos. Al analizar una gran cantidad de modelos, podemos sobreajustar los datos y subestimar la variación natural en nuestra representación.</p>
<p>Seleccionar un modelo basado solo en datos de muestra tampoco es compatible con el objetivo de la <strong>inferencia predictiva</strong>. Particularmente, en aplicaciones actuariales nuestro objetivo es hacer declaraciones sobre la <em>nueva</em> experiencia en lugar de sobre el conjunto de datos disponible. Por ejemplo, utilizamos la experiencia de siniestros de un año para desarrollar un modelo que se pueda usar para fijar el precio de los contratos de seguro para el año siguiente. Como analogía, podemos pensar en el conjunto de datos de entrenamiento como experiencia de un año que se utiliza para predecir el comportamiento del conjunto de datos de prueba del próximo año.</p>
<p>Podemos superar estas limitaciones utilizando una técnica a veces conocida como <strong>validación fuera de muestra</strong>. La situación ideal es tener disponibles dos conjuntos de datos, uno para entrenamiento o desarrollo del modelo y otro para prueba o validación del modelo. Inicialmente desarrollamos uno o varios modelos en el primer conjunto de datos que llamamos nuestros modelos <em>candidatos</em>. Luego, el rendimiento relativo de los modelos candidatos se puede medir en el segundo conjunto de datos. De esta manera, los datos utilizados para validar el modelo no se ven afectados por los procedimientos utilizados para formular el modelo.</p>
<p><strong>División aleatoria de los datos.</strong> Desafortunadamente, rara vez estarán disponibles dos conjuntos de datos para el investigador. Sin embargo, podemos implementar el proceso de validación dividiendo el conjunto de datos en submuestras de <strong>entrenamiento</strong> y <strong>prueba</strong>, respectivamente. La Figura <a href="C-ModelSelection.html#fig:ModelValidation">4.11</a> ilustra la división de los datos.</p>
<div class="figure" style="text-align: center"><span id="fig:ModelValidation"></span>
<img src="LossDataAnalytics_files/figure-html/ModelValidation-1.png" alt="Validación del modelo. Un conjunto de datos se divide aleatoriamente en dos submuestras." width="60%" />
<p class="caption">
Figure 4.11: Validación del modelo. Un conjunto de datos se divide aleatoriamente en dos submuestras.
</p>
</div>
<p>Diferentes proporciones se recomiendan para la asignación a las muestras de entrenamiento y prueba. <span class="citation">Snee (<a href="#ref-snee1977validation" role="doc-biblioref">1977</a>)</span> sugiere que la división de datos no se realice a menos que el tamaño de la muestra sea moderadamente grande. Las pautas de <span class="citation">Picard and Berk (<a href="#ref-picard1990data" role="doc-biblioref">1990</a>)</span> muestran que cuanto mayor sea el número de parámetros a estimar, mayor será la proporción de observaciones necesarias para la submuestra de entrenamiento del modelo.</p>
<p><strong>Estadísticos de validación del modelo.</strong> Gran parte de la literatura que respalda el establecimiento de un proceso de validación del modelo se basa en modelos de regresión y clasificación que puede considerarse como un problema <em>input-output</em> (<span class="citation">James et al. (<a href="#ref-james2013introduction" role="doc-biblioref">2013</a>)</span>). Es decir, tenemos varias entradas <span class="math inline">\(x_1,\ldots,x_k\)</span> que están relacionadas con una salida <span class="math inline">\(y\)</span> a través de una función como</p>
<p><span class="math display">\[y=\mathrm{g}\left(x_1,\ldots,x_k\right).\]</span></p>
<p>Se utiliza la muestra de entrenamiento para desarrollar una estimación de <span class="math inline">\(\mathrm{g}\)</span>, digamos, <span class="math inline">\(\hat{\mathrm{g}}\)</span>, y luego se calibra la distancia entre los resultados observados y las predicciones usando un criterio de la forma
<span class="math display" id="eq:OutSampleCriter">\[\begin{equation}
\sum_i \mathrm{d}(y_i,\hat{\mathrm{g}}\left(x_{i1}, \ldots, x_{ik}\right) ) .
\tag{4.4}
\end{equation}\]</span></p>
<p>Aquí, la suma <em>i</em> se realiza sobre los datos de prueba. En muchas aplicaciones de regresión es común usar la distancia euclidiana al cuadrado de la forma <span class="math inline">\(\mathrm{d}(y_i,\mathrm{g})=(y_i-\mathrm{g})^2\)</span>. En aplicaciones actuariales, la distancia euclidiana <span class="math inline">\(\mathrm{d}(y_i,\mathrm{g})=|y_i-\mathrm{g}|\)</span> a menudo se prefiere debido a la naturaleza asimétrica de los datos (valores extremos grandes de <span class="math inline">\(y\)</span> pueden tener un gran impacto en la medida). El Capítulo <a href="C-PremiumFoundations.html#C:PremiumFoundations">7</a> describe otra medida, el <em>índice de Gini</em>, que es útil en aplicaciones actuariales, particularmente cuando hay una gran proporción de ceros en los datos de siniestros (correspondientes a ningún siniestro).</p>
<p><strong>Selección de una distribución.</strong> Nuestro enfoque hasta ahora ha sido seleccionar una distribución para un conjunto de datos que pueda usarse para la modelización actuarial sin entradas adicionales <span class="math inline">\(x_1,\ldots,x_k\)</span>. Incluso en este problema más fundamental, el enfoque de validación del modelo es adecuado. Si basamos toda la inferencia solo en datos de la muestra, entonces la tendencia es seleccionar modelos más complicados de lo necesario. Por ejemplo, se podría seleccionar una distribución con cuatro parámetros como la GB2, distribución beta generalizada de segundo tipo, cuando solo se necesita una Pareto con dos parámetros. Criterios de información como <a href="#" class="tooltip" style="color:green"><em>AIC</em><span style="font-size:8pt"> criterio de información de Akaike</span></a> y <a href="#" class="tooltip" style="color:green"><em>BIC</em><span style="font-size:8pt"> criterio de información Bayesiano</span></a> que incluyen penalizaciones a la complejidad del modelo y, por lo tanto, proporcionan cierta protección, con el uso de una muestra de prueba son la mejor garantía para lograr modelos parsimoniosos. Una cita a menudo atribuida a Albert Einstein, indica queremos “utilizar el modelo más simple (sencillo) posible pero no el más simple (simplón)”.</p>
</div>
<div id="selección-del-modelo-basada-en-validación-cruzada" class="section level3">
<h3><span class="header-section-number">4.2.4</span> Selección del Modelo basada en Validación Cruzada</h3>
<p>Aunque la validación fuera de la muestra es el estándar más valioso en la modelización predictiva, no siempre es práctico hacerlo. La razón principal es que tenemos tamaños de muestra limitados y el criterio de selección de modelo fuera de muestra en la ecuación <a href="C-ModelSelection.html#eq:OutSampleCriter">(4.4)</a> depende de una división <em>aleatoria</em> de los datos. Lo anterior genera que diferentes analistas, incluso cuando utilizan el mismo conjunto de datos y el mismo enfoque para la modelización, puedan seleccionar diferentes modelos. Esto puede ocurrir en aplicaciones actuariales ya que se utilizan conjuntos de datos asimétricos en los que hay una elevada probabilidad de obtener algunos valores muy grandes y los valores grandes pueden tener un gran impacto en las estimaciones de los parámetros.</p>
<p><strong>Procedimiento de Validación Cruzada.</strong> Alternativamente, se puede utilizar <strong>validación cruzada</strong>, de la siguiente forma.</p>
<p>-El procedimiento se inicia mediante el uso de un mecanismo aleatorio para dividir los datos en <em>K</em> subconjuntos denominados <em>pliegues</em>. Los analistas suelen utilizar de 5 a 10.
-Después se utilizan las primeras <em>K</em> -1 submuestras para estimar los parámetros del modelo. Luego, se “predicen” los resultados para la submuestra <em>K</em>-ésima y se aplica una medida como las definidas en la ecuación <a href="C-ModelSelection.html#eq:OutSampleCriter">(4.4)</a> para describir el ajuste.
-Ahora, se repite para cada una de las <em>K</em> submuestras, utilizando un estadístico acumulativo fuera de muestra para describir el ajuste.</p>
<p>Repetir estos pasos para varios modelos candidatos y elegir el modelo con el estadístico acumulativo fuera de muestra más bajo.</p>
<p>La validación cruzada se utiliza frecuentemente porque retiene la naturaliza predictiva del proceso de validación del modelo fuera de muestra pero, debido a la reutilización de los datos, es más estable que el procedimiento basado en muestras aleatorias.</p>
</div>
</div>
<div id="S:MS:ModifiedData" class="section level2">
<h2><span class="header-section-number">4.3</span> Estimación utilizando Datos Modificados</h2>
<hr />
<p>En esta sección, se aprende a:</p>
<ul>
<li>Describir datos agrupados, censurados y truncados.</li>
<li>Estimar distribuciones paramétricas basadas en datos agrupados, censurados y truncados</li>
<li>Estimar distribuciones no paramétricas basadas en datos agrupados, censurados y truncados</li>
</ul>
<hr />
<div id="estimación-paramétrica-usando-datos-modificados" class="section level3">
<h3><span class="header-section-number">4.3.1</span> Estimación Paramétrica usando Datos Modificados</h3>
<p>La teoría básica y muchas aplicaciones se basan en observaciones <em>individuales</em> que son “<em>completas</em>” y “<em>no modificadas</em>”, como hemos visto en la sección anterior. La sección <a href="C-Severity.html#S:MaxLikeEstimation">3.5</a> introduce el concepto de observaciones que están “<em>modificadas</em>” debido a dos tipos comunes de limitaciones: <strong>censura</strong> y <strong>truncamiento</strong>. Por ejemplo, se suele pensar que un deducible o franquicia de seguros genera datos truncados (desde la izquierda) o los límites de la póliza genera datos censurados (desde la derecha). Este es el punto de vista del asegurador primario (el vendedor del seguro). Sin embargo, como veremos en el Capítulo <a href="C-PortMgt.html#C:PortMgt">10</a>, un reasegurador (un asegurador de una compañía de seguros) no puede observar reclamaciones menores a una cantidad, solo si existe la reclamación, un ejemplo de censura desde la izquierda. En esta sección se cubre toda la gama de alternativas. Específicamente, esta sección abordará los métodos de estimación paramétrica para tres alternativas a los datos individuales, completos y no modificados: <strong>datos censurados por intervalos</strong> disponibles solo en grupos, datos limitados o <strong>censurados</strong>, y datos que no pueden ser observados debido a <strong>truncamiento</strong>.</p>
<div id="S:MS:GroupedData" class="section level4">
<h4><span class="header-section-number">4.3.1.1</span> Estimación Paramétrica utilizando Datos Agrupados</h4>
<p>Considerar una muestra de tamaño <span class="math inline">\(n\)</span> observada a partir de la distribución <span class="math inline">\(F(\cdot)\)</span>, pero en grupos, de modo que solo conocemos el grupo en el que cayó cada observación, no el valor exacto. Esto se conoce como datos <strong>agrupados</strong> o <strong>censurados por intervalos</strong>. Por ejemplo, podemos estar viendo dos años consecutivos de registros anuales de empleados. Las personas empleadas en el primer año pero no en el segundo se han ido en algún momento durante el año. Con una fecha de salida exacta (datos individuales), podríamos calcular la cantidad de tiempo que estuvieron en la empresa. Sin la fecha de salida (datos agrupados), solo sabemos que partieron en algún momento durante un intervalo de un año.</p>
<p>Formalizando esta idea, supongamos que hay <span class="math inline">\(k\)</span> grupos o intervalos delimitados por límites <span class="math inline">\(c_0&lt;c_1&lt;\cdots&lt;c_k\)</span>. Para cada observación solo se conoce el intervalo en el que cayó (por ejemplo, <span class="math inline">\((c_{j-1},c_j)\)</span>), no el valor exacto. Por lo tanto, solo sabemos el número de observaciones en cada intervalo. Las constantes <span class="math inline">\(\{c_0&lt;c_1&lt;\cdots&lt;c_k\}\)</span> forman alguna partición del dominio de <span class="math inline">\(F(\cdot)\)</span>. Entonces, la probabilidad de que una observación <span class="math inline">\(X_i\)</span> caiga en el intervalo <span class="math inline">\(j\)</span>-ésimo es
<span class="math display">\[\Pr\left (X_i \in (c_{j-1},c_j] \right)=F(c_j)-F(c_{j-1}).\]</span></p>
<p>La función de masa de probabilidad correspondiente para una observación es</p>
<p><span class="math display">\[
\begin{aligned}
f(x) &amp;=
\begin{cases}
F(c_1) - F(c_{0}) &amp;   \text{if }\ x \in (c_{0}, c_1]\\
\vdots &amp; \vdots \\
F(c_k) - F(c_{k-1}) &amp;   \text{if }\ x \in (c_{k-1}, c_k]\\
\end{cases} \\
&amp;= \prod_{j=1}^k \left\{F(c_j) - F(c_{j-1})\right\}^{I(x \in (c_{j-1}, c_j])}
\end{aligned}
\]</span></p>
<p>Ahora, se define <span class="math inline">\(n_j\)</span> como el número de observaciones que caen en el intervalo <span class="math inline">\(j\)</span>-ésimo, <span class="math inline">\((c_{j-1}, c_j]\)</span>. Por lo tanto, la función de verosimilitud (con respecto al(los) parámetro(s) <span class="math inline">\(\theta\)</span>) es</p>
<p><span class="math display">\[
\begin{aligned}
\mathcal{L}(\theta) = \prod_{j=1}^n f(x_i) = \prod_{j=1}^k \left\{F(c_j) - F(c_{j-1})\right\}^{n_j}
\end{aligned}
\]</span>
y el logaritmo de la función de verosimilitud es
<span class="math display">\[
\begin{aligned}
L(\theta) = \ln \mathcal{L}(\theta) = \ln \prod_{j=1}^n f(x_i) = \sum_{j=1}^k n_j \ln \left\{F(c_j) - F(c_{j-1})\right\}
\end{aligned}
\]</span></p>
<p>Entonces, maximizar la función de verosimilitud (o, de manera equivalente, maximizar el logaritmo de la función de verosimilitud) generará los estimadores por máxima verosimilitud para los datos agrupados.</p>
<p><strong>Ejemplo 4.3.1. Pregunta de Examen Actuarial.</strong></p>
<p>Te dan:</p>
<ol style="list-style-type: lower-roman">
<li>Las pérdidas siguen una distribución exponencial con media <span class="math inline">\(\theta\)</span>.</li>
<li>Una muestra aleatoria de 20 pérdidas se distribuye de la siguiente manera:
<span class="math display">\[
{\small
\begin{array}{l|c}
\hline
\text{Rango de Pérdidas} &amp; \text{Frecuencia} \\
\hline
[0,1000] &amp; 7 \\
(1000,2000] &amp; 6 \\
(2000,\infty) &amp; 7 \\
\hline
\end{array}
}
\]</span></li>
</ol>
<p>Calcular la estimación máximo verosímil de <span class="math inline">\(\theta\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleSelect.3.1" href="javascript:toggleEX('toggleExampleSelect.3.1','displayTextExampleSelect.3.1');"><i><strong>Mostrar solución del ejemplo</strong></i></a>
</h5>
<div id="toggleExampleSelect.3.1" style="display: none">
<p><strong>Solución.</strong>
<span class="math display">\[
\begin{aligned}
\mathcal{L}(\theta) &amp;= F(1000)^7[F(2000)-F(1000)]^6[1-F(2000)]^7 \\
&amp;= (1-e^{-1000/\theta})^7(e^{-1000/\theta} - e^{-2000/\theta})^6(e^{-2000/\theta})^7 \\
&amp;= (1-p)^7(p-p^2)^6(p^2)^7 \\
&amp;= p^{20}(1-p)^{13}
\end{aligned}
\]</span></p>
<p>donde <span class="math inline">\(p=e^{-1000/\theta}\)</span>. Maximizar esta expresión con respecto a <span class="math inline">\(p\)</span> es equivalente a maximizar la verosimilitud con respecto a <span class="math inline">\(\theta\)</span>. El máximo ocurre en <span class="math inline">\(p=\frac{20}{33}\)</span> y entonces <span class="math inline">\(\hat{\theta}=\frac{-1000}{\ln(20/33)}=1996,90\)</span>.</p>
</div>
<hr />
</div>
<div id="datos-censurados" class="section level4">
<h4><span class="header-section-number">4.3.1.2</span> Datos Censurados</h4>
<p>La <strong>censura</strong> ocurre cuando registramos solo un valor límite para una observación. La forma más común es <strong>censurar por la derecha</strong>, en la cual registramos el valor <em>más pequeño</em> entre el “verdadero” de la variable dependiente y una variable de censura. Usando notación, supongamos que <span class="math inline">\(X\)</span> representa un resultado de interés, como la pérdida debido a un evento asegurado o el tiempo hasta un evento. La cuantía de censura se denota como <span class="math inline">\(C_U\)</span>. Como observaciones censuradas por la derecha, registramos <span class="math inline">\(X_U^{\ast}=\min(X,C_U)=X\wedge C_U\)</span>. También registramos si se ha producido o no la censura. Supongamos que <span class="math inline">\(\delta_U=I(X \leq C_U)\)</span> sea una variable binaria que es 0 si se produce la censura y 1 si no es así.</p>
<p>Para el ejemplo que vimos en la Sección <a href="C-Severity.html#S:PolicyLimits">3.4.2</a>, <span class="math inline">\(C_U\)</span> puede representar el límite superior de cobertura de una póliza de seguro (utilizamos <span class="math inline">\(u\)</span> para el límite superior en esa sección). La pérdida puede exceder el valor <span class="math inline">\(C_U\)</span>, pero la aseguradora solo guarda <span class="math inline">\(C_U\)</span> en sus registros como la cantidad pagada y no guarda el valor de la pérdida real <span class="math inline">\(X\)</span>.</p>
<p>De manera similar, con la <strong>censura por la izquierda</strong>, registramos el valor <em>más grande</em> entre la variable de interés y la variable de censura. Si se usa <span class="math inline">\(C_L\)</span> para representar la cantidad de censura, registramos <span class="math inline">\(X_L^{\ast}=\max(X,C_L)\)</span> junto con el indicador de censura <span class="math inline">\(\delta_L=I(X\geq C_L)\)</span>.</p>
<p>Como ejemplo, tenemos una breve introducción al reaseguro, seguro para aseguradores, en la Sección <a href="C-Severity.html#S:Chap3Reinsurance">3.4.4</a> y se verá más en el Capítulo <a href="C-PortMgt.html#C:PortMgt">10</a>. Supongamos que una reaseguradora cubrirá las pérdidas de la aseguradora mayores a <span class="math inline">\(C_L\)</span>; esto significa que el reasegurador es responsable del exceso de <span class="math inline">\(X_L^{\ast}\)</span> sobre <span class="math inline">\(C_L\)</span>. Usando notación, esto es <span class="math inline">\(Y=X_L^{\ast}-C_L\)</span>. Para ver esto, primero considere el caso donde la pérdida del titular de la póliza <span class="math inline">\(X&lt;C_L\)</span>. Luego, el asegurador pagará el siniestro completo y <span class="math inline">\(Y=C_L-C_L=0\)</span>, sin pérdida para el reasegurador. Para el segundo caso, si la pérdida <span class="math inline">\(X\ge C_L\)</span>, entonces <span class="math inline">\(Y=X-C_L\)</span> representa las reclamaciones retenidas por el reasegurador. Dicho de otra manera, si ocurre una pérdida, el reasegurador registra la cuantía real si excede del límite <span class="math inline">\(C_L\)</span> o, de lo contrario, solo registra que tuvo una pérdida de <span class="math inline">\(0\)</span>.</p>
</div>
<div id="datos-truncados" class="section level4">
<h4><span class="header-section-number">4.3.1.3</span> Datos Truncados</h4>
<p>Las observaciones censuradas se registran para su estudio, aunque de forma limitada. En contraste, los resultados <strong>truncados</strong> son un tipo de datos ausentes. Un resultado se trunca potencialmente cuando la disponibilidad de una observación depende del resultado.</p>
<p>En el seguro, es común que las observaciones sean <strong>truncadas por la izquierda</strong> en <span class="math inline">\(C_L\)</span> cuando la cantidad es
<span class="math display">\[
\begin{aligned}
Y &amp;=
\left\{
\begin{array}{cl}
\text{nosotros no observamos }X &amp; X &lt; C_L \\
X &amp; X \geq C_L
\end{array}
\right.\end{aligned} .
\]</span></p>
<p>En otras palabras, si <span class="math inline">\(X\)</span> es menor que el umbral <span class="math inline">\(C_L\)</span>, entonces no se observa.</p>
<p>Para un ejemplo que vimos en la Sección <a href="C-Severity.html#S:PolicyDeduct">3.4.1</a>, <span class="math inline">\(C_L\)</span> puede representar el deducible de una póliza de seguro (utilizamos <span class="math inline">\(d\)</span> para el deducible en esa sección). Si la pérdida asegurada es menor que el deducible, entonces el asegurador no puede observar ni registrar la pérdida. Si la pérdida excede el deducible, el exceso de <span class="math inline">\(X-C_L\)</span> es el siniestro que cubre la aseguradora. En la Sección <a href="C-Severity.html#S:PolicyDeduct">3.4.1</a>, definimos la pérdida por pago como
<span class="math display">\[
Y^{P} = \left\{ \begin{matrix}
\text{Indefinido} &amp; X \le d \\
X - d &amp; X &gt; d 
\end{matrix} \right. ,
\]</span>
de modo que si una pérdida excede un deducible, registramos la cuantía en exceso <span class="math inline">\(X-d\)</span>. Esto es muy importante cuando se consideran las cuantías que pagará la aseguradora. Sin embargo, para propósitos de estimación de esta sección, importa poco si restamos una constante conocida como <span class="math inline">\(C_L=d\)</span>. Entonces, para nuestra variable truncada <span class="math inline">\(Y\)</span>, usamos la convención más simple y no restamos <span class="math inline">\(d\)</span>.</p>
<p>De manera similar para datos <strong>truncados por la derecha</strong>, si <span class="math inline">\(X\)</span> excede un umbral <span class="math inline">\(C_U\)</span>, entonces no se observa. En este caso, la cantidad es
<span class="math display">\[
\begin{aligned}
Y &amp;=
\left\{
\begin{array}{cl}
X &amp; X \leq C_U \\
\text{nosotros no observamos }X &amp; X &gt; C_U.
\end{array}
\right.\end{aligned}
\]</span></p>
<p>Los ejemplos clásicos de truncamiento por la derecha incluyen <span class="math inline">\(X\)</span> como medida de distancia a una estrella. Cuando la distancia excede un cierto nivel <span class="math inline">\(C_U\)</span>, la estrella ya no es observable.</p>
<p>La Figura <a href="C-ModelSelection.html#fig:CensorTrunc">4.12</a> compara observaciones truncadas y censuradas. Los valores de <span class="math inline">\(X\)</span> que son mayores que el límite “superior” <span class="math inline">\(C_U\)</span> no se observan (truncados a la derecha), mientras que los valores de <span class="math inline">\(X\)</span> que son menores que el límite “inferior” <span class="math inline">\(C_L\)</span> se observan, pero se observan como <span class="math inline">\(C_L\)</span> en lugar del valor real de <span class="math inline">\(X\)</span> (censura a la izquierda).</p>
<div class="figure" style="text-align: center"><span id="fig:CensorTrunc"></span>
<img src="LossDataAnalytics_files/figure-html/CensorTrunc-1.png" alt="Censura y Truncamiento" width="60%" />
<p class="caption">
Figure 4.12: Censura y Truncamiento
</p>
</div>
<hr />
<h5 style="text-align: center;">
<a id="displayTextExampleMort.4f" href="javascript:toggleEX('toggleExampleMort','displayTextExampleMort.4f');"><i><strong>Mostrar ejemplo de estudio de mortalidad </strong></i></a>
</h5>
<div id="toggleExampleMort" style="display: none">
<p><strong>Ejemplo: estudio de mortalidad.</strong> Supongamos que se está realizando un estudio de dos años de mortalidad de sujetos de alto riesgo, comenzando el 1 de enero de 2010 y terminando el 1 de enero de 2012. Figura <a href="C-ModelSelection.html#fig:Mortality">4.13</a> representa gráficamente los seis tipos de sujetos reclutados. Para cada sujeto, el comienzo de la flecha representa que el sujeto fue reclutado y el final de la flecha representa el tiempo del evento. Por lo tanto, la flecha representa el tiempo de exposición.</p>
<div class="figure" style="text-align: center"><span id="fig:Mortality"></span>
<img src="LossDataAnalytics_files/figure-html/Mortality-1.png" alt="Cronología de varios sujetos en prueba en un estudio de mortalidad" width="60%" />
<p class="caption">
Figure 4.13: Cronología de varios sujetos en prueba en un estudio de mortalidad
</p>
</div>
<ul>
<li><strong>Tipo A: Censurado por la derecha. </strong>Este sujeto está vivo al principio y al final del estudio. Debido a que no se conoce el momento de la muerte al final del estudio, está censurado correctamente. La mayoría de los sujetos son de tipo A.</li>
<li><strong>Tipo B- Información completa</strong> está disponible para un sujeto tipo B. El sujeto está vivo al comienzo del estudio y la muerte ocurre dentro del período de observación.</li>
<li><strong>Tipo C: Censurado por la derecha y truncado a la izquierda.</strong> Un sujeto de tipo C está censurado por la derecha, ya que la muerte ocurre después del período de observación. Sin embargo, el sujeto ingresó después del inicio del estudio y se dice que tiene un <em>tiempo de entrada retrasado</em>. Debido a que el sujeto no habría sido observado si la muerte hubiera ocurrido antes de la entrada, se trunca a la izquierda.</li>
<li><strong>Tipo D: truncado por la izquierda.</strong> Un sujeto de tipo D también ha retrasado la entrada. Debido a que la muerte ocurre dentro del período de observación, este individuo no está censurado a la derecha.</li>
<li><strong>Tipo E: truncado por la izquierda.</strong> Un sujeto tipo E no está incluido en el estudio porque la muerte ocurre antes del período de observación.</li>
<li><strong>Tipo F: truncado por la derecha.</strong> Del mismo modo, un sujeto tipo F no está incluido porque el tiempo de entrada ocurre después del período de observación.</li>
</ul>
</div>
<hr />
<p>Para resumir, para el resultado <span class="math inline">\(X\)</span> y las constantes <span class="math inline">\(C_L\)</span> y <span class="math inline">\(C_U\)</span>,</p>
<table>
<thead>
<tr class="header">
<th align="right">Tipo de Limitación</th>
<th align="center">Variable Limitada</th>
<th align="center">Registro de Información</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">Censura por drcha.</td>
<td align="center"><span class="math inline">\(X_U^{\ast}= \min(X,C_U)\)</span></td>
<td align="center"><span class="math inline">\(\delta_U= I(X \leq C_U)\)</span></td>
</tr>
<tr class="even">
<td align="right">Censura por izda.</td>
<td align="center"><span class="math inline">\(X_L^{\ast}= \max(X,C_L)\)</span></td>
<td align="center"><span class="math inline">\(\delta_L= I(X \geq C_L)\)</span></td>
</tr>
<tr class="odd">
<td align="right">Censura por intervalo</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="right">Truncamiento drcha.</td>
<td align="center"><span class="math inline">\(X\)</span></td>
<td align="center">observa <span class="math inline">\(X\)</span> si <span class="math inline">\(X \leq C_U\)</span></td>
</tr>
<tr class="odd">
<td align="right">Truncamiento izda.</td>
<td align="center"><span class="math inline">\(X\)</span></td>
<td align="center">observa <span class="math inline">\(X\)</span> si <span class="math inline">\(X \geq C_L\)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="estimación-paramétrica-utilizando-datos-censurados-y-truncados" class="section level4">
<h4><span class="header-section-number">4.3.1.4</span> Estimación paramétrica utilizando datos censurados y truncados</h4>
<p>Para simplificar, asumimos valores de censura no aleatorios y una variable continua <span class="math inline">\(X\)</span>. Empezamos considerando el caso de datos censurados a la derecha donde registramos <span class="math inline">\(X_U^{\ast}=\min(X,C_U)\)</span> y el indicador de censura <span class="math inline">\(\delta=I(X \leq C_U)\)</span>. Si la censura ocurre, de modo que <span class="math inline">\(\delta = 0\)</span>, entonces <span class="math inline">\(X\geq C_U\)</span> y la probabilidad es <span class="math inline">\(\Pr(X \geq C_U)=1-F(C_U)\)</span>. Si la censura no ocurre, de modo que <span class="math inline">\(\delta=1\)</span>, entonces <span class="math inline">\(X&lt;C_U\)</span> y la verosimilitud es <span class="math inline">\(f(x)\)</span>. Resumiendo, tenemos la verosimilitud de una sola observación como</p>
<p><span class="math display">\[
\begin{aligned}
\left\{
\begin{array}{ll}
1-F(C_U) &amp; \text{if }\delta=0 \\
f(x) &amp; \text{if } \delta = 1 
\end{array}
\right. = \left\{ f(x)\right\}^{\delta} \left\{1-F(C_U)\right\}^{1-\delta} .
\end{aligned}
\]</span></p>
<p>La expresión de a la derecha nos permite presentar la verosimilitud de manera más compacta. Ahora, para una muestra <em>iid</em> de tamaño <span class="math inline">\(n\)</span>, la verosimilitud es</p>
<p><span class="math display">\[
\mathcal{L} = 
\prod_{i=1}^n \left\{ f(x_i)\right\}^{\delta_i} \left\{1-F(C_{Ui})\right\}^{1-\delta_i} = \prod_{\delta_i=1} f(x_i) \prod_{\delta_i=0} \{1-F(C_{Ui})\},
\]</span></p>
<p>con tiempos de censura potenciales <span class="math inline">\(\{C_{U1},\ldots, C_{Un} \}\)</span>. Aquí, la notación “<span class="math inline">\(\prod_{\delta_i=1}\)</span>” significa el producto de las observaciones sin censura, y de manera similar para “<span class="math inline">\(\prod_{\delta_i=0}\)</span>”.</p>
<p>Por otro lado, los datos truncados se tratan en inferencia de verosimilitud mediante probabilidades condicionadas. En concreto, ajustamos la contribución a la verosimilitud dividiendo por la probabilidad de que se haya observado la variable. En resumen, tenemos las siguientes contribuciones a la función de verosimilitud para seis tipos de resultados:
<span class="math display">\[
{\small
\begin{array}{lc}
\hline
\text{Resultado} &amp; \text{Contribución en la Verosimilitud} \\
\hline
\text{Valor exacto} &amp; f(x) \\
\text{Censura por la derecha} &amp; 1-F(C_U) \\
\text{Censura por la izquierda} &amp; F(C_L) \\
\text{Truncamiento por la derecha} &amp; f(x)/F(C_U) \\
\text{Truncamiento por la izquierda} &amp; f(x)/(1-F(C_L)) \\
\text{Censura por intervalo } &amp; F(C_U)-F(C_L) \\
\hline
\end{array}
}
\]</span></p>
<p>Para resultados conocidos y datos censurados, la verosimilitud es
<span class="math display">\[\mathcal{L}(\theta) = \prod_{E} f(x_i) \prod_{R} \{1-F(C_{Ui})\} \prod_{L}
F(C_{Li}) \prod_{I} (F(C_{Ui})-F(C_{Li})),\]</span>
donde “<span class="math inline">\(\prod_{E}\)</span>” es el producto sobre las observaciones con valores Exactos (<em>E</em>), y de manera similar para los datos censurados por la Derecha (<em>R</em>), Izquierda (<em>L</em>) y en Intervalo (<em>I</em>).</p>
<p>Para datos censurados por la derecha y truncados por la izquierda, la probabilidad es
<span class="math display">\[\mathcal{L} = \prod_{E} \frac{f(x_i)}{1-F(C_{Li})} \prod_{R} \frac{1-F(C_{Ui})}{1-F(C_{Li})},\]</span>
y de manera similar para otras combinaciones. Para obtener más información, considere lo siguiente.</p>
<hr />
<h5 style="text-align: center;">
<a id="displayTextExampleEXP.4f" href="javascript:toggleEX('toggleExampleEXP','displayTextExampleEXP.4f');"><i><strong>Mostrar caso particular – Distribución Exponencial</strong></i></a>
</h5>
<div id="toggleExampleEXP" style="display: none">
<p><strong>Caso especial: Distribución exponencial.</strong> Considere los datos que están censurados por la derecha y truncados por la izquierda, con variables aleatorias <span class="math inline">\(X_i\)</span> que se distribuyen exponencialmente con media <span class="math inline">\(\theta\)</span>. Con estas especificaciones, recuerde que <span class="math inline">\(f(x) = \theta^{-1} \exp(-x/\theta)\)</span> y <span class="math inline">\(F(x) = 1-\exp(-x/\theta)\)</span>.</p>
<p>Para este caso particular, la log verosimilitud es</p>
<p><span class="math display">\[
\begin{aligned}
L(\theta) &amp;= \sum_{E} \left\{ \ln f(x_i) - \ln (1-F(C_{Li})) \right\} + \sum_{R}\left\{ \ln (1-F(C_{Ui}))- \ln (1-\mathrm{F}(C_{Li})) \right\}\\
&amp;= \sum_{E} (-\ln \theta -(x_i-C_{Li})/\theta ) -\sum_{R} (C_{Ui}-C_{Li})/\theta .
\end{aligned}
\]</span></p>
<p>Para simplificar la notación, definimos <span class="math inline">\(\delta_i=I(X_i\geq C_{Ui})\)</span> como una variable binaria que indica la censura a la derecha. Sea <span class="math inline">\(X_i^{\ast\ast} = \min(X_i,C_{Ui})-C_{Li}\)</span> la cantidad que la variable observada excede el límite inferior de truncamiento. Con esto, la log verosimilitud es</p>
<p><span class="math display" id="eq:EXPloglik">\[\begin{equation}
  L(\theta) =  - \sum_{i=1}^n ((1-\delta_i) \ln \theta + \frac{x_i^{\ast \ast}}{\theta}).
  \tag{4.5}
\end{equation}\]</span></p>
<p>Derivando con respecto al parámetro <span class="math inline">\(\theta\)</span> e igualando a cero se obtiene el estimador de máxima verosimilitud
<span class="math display">\[\widehat{\theta}  = \frac{1}{n_u} \sum_{i=1}^n  x_i^{\ast \ast},\]</span></p>
<p>donde <span class="math inline">\(n_u = \sum_i (1-\delta_i)\)</span> es el número de datos no censurados.</p>
</div>
<hr />
<p><strong>Ejemplo 4.3.2. Pregunta de Examen Actuarial.</strong>
Te dan:</p>
<ol style="list-style-type: lower-roman">
<li>Una muestra de pérdidas es: 600 700 900</li>
<li>No hay información disponible sobre pérdidas de 500 o menos.</li>
<li>Se supone que las pérdidas siguen una distribución exponencial con media <span class="math inline">\(\theta\)</span>.</li>
</ol>
<p>Calcular el estimador de máxima verosimilitud de <span class="math inline">\(\theta\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleSelect.3.2" href="javascript:toggleEX('toggleExampleSelect.3.2','displayTextExampleSelect.3.2');"><i><strong>Mostrar solución del ejemplo</strong></i></a>
</h5>
<div id="toggleExampleSelect.3.2" style="display: none">
<p><strong>Solución.</strong>
Estas observaciones se truncan en 500. La contribución de cada observación a la función de verosimilitud es
<span class="math display">\[\frac{f(x)}{1-F(500)} = \frac{\theta^{-1}e^{-x/\theta}}{e^{-500/\theta}}\]</span></p>
<p>Entonces la función de verosimilitud es</p>
<p><span class="math display">\[\mathcal{L}(\theta)= \frac{\theta^{-1} e^{-600/\theta} \theta^{-1} e^{-700/\theta} \theta^{-1} e^{-900/\theta}}{(e^{-500/\theta})^3} = \theta^{-3}e^{-700/\theta}\]</span></p>
<p>El logaritmo de la verosimilitud es</p>
<p><span class="math display">\[L(\theta) = \ln\mathcal{L}(\theta) = -3\ln \theta - 700\theta^{-1}\]</span></p>
<p>Maximizando esta expresión, estableciendo la derivada con respecto a <span class="math inline">\(\theta\)</span> igual a 0, tenemos</p>
<p><span class="math display">\[L&#39;(\theta) = -3\theta^{-1} + 700\theta^{-2} = 0 \ \Rightarrow \ \hat{\theta} = \frac{700}{3} = 233,33\]</span></p>
</div>
<hr />
<p><strong>Ejemplo 4.3.3. Pregunta de Examen Actuarial.</strong>
Se le proporciona la siguiente información sobre una muestra aleatoria:</p>
<ol style="list-style-type: lower-roman">
<li>El tamaño de la muestra es igual a cinco.</li>
<li>La muestra es de una distribución de Weibull con <span class="math inline">\(\tau = 2\)</span>.</li>
<li>Se sabe que dos de las observaciones de la muestra exceden 50, y las tres observaciones restantes son 20, 30 y 45.</li>
</ol>
<p>Calcule el estimador de máxima verosimilitud de <span class="math inline">\(\theta\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleSelect.3.3" href="javascript:toggleEX('toggleExampleSelect.3.3','displayTextExampleSelect.3.3');"><i><strong>Mostrar solución del ejemplo</strong></i></a>
</h5>
<div id="toggleExampleSelect.3.3" style="display: none">
<p><strong>Solución.</strong> La función de verosimilitud es</p>
<p><span class="math display">\[
\begin{aligned} 
\mathcal{L}(\theta) &amp;= f(20) f(30) f(45) [1-F(50)]^2 \\
&amp;= \frac{2(20/\theta)^2 e^{-(20/\theta)^2}}{20} \frac{2(30/\theta)^2 e^{-(30/\theta)^2}}{30} \frac{2(45/\theta)^2 e^{-(45/\theta)^2}}{45}(e^{-(50/\theta)^2})^2 \\
&amp;\propto \frac{1}{\theta^6} e^{-8325/\theta^2}
\end{aligned}
\]</span></p>
<p>El logaritmo natural de la expresión anterior es <span class="math inline">\(-6\ln\theta-\frac{8325}{\theta^2}\)</span>. Maximizando esta expresión al fijar su derivada igual a 0, obtenemos</p>
<p><span class="math display">\[\frac{-6}{\theta} + \frac{16650}{\theta^3} = 0 \ \Rightarrow \ \hat{\theta} = \left(\frac{16650}{6}\right)^{\frac{1}{2}} = 52,6783\]</span></p>
</div>
<hr />
</div>
</div>
<div id="estimación-no-paramétrica-utilizando-datos-modificados" class="section level3">
<h3><span class="header-section-number">4.3.2</span> Estimación no Paramétrica Utilizando Datos Modificados</h3>
<p>Los estimadores no paramétricos proporcionan puntos de referencia útiles, por lo que es útil comprender los procedimientos de estimación para datos agrupados, censurados y truncados.</p>
<div id="datos-agrupados" class="section level4">
<h4><span class="header-section-number">4.3.2.1</span> Datos Agrupados</h4>
<p>Como hemos visto en la Sección <a href="C-ModelSelection.html#S:MS:GroupedData">4.3.1.1</a>, las observaciones pueden agruparse (también denominadas censuradas por intervalos) en el sentido de que solo las observamos como pertenecientes a uno de los <span class="math inline">\(k\)</span> intervalos de la forma <span class="math inline">\((c_{j-1},c_j]\)</span>, para <span class="math inline">\(j=1,\ldots,k\)</span>. En los límites, la función de distribución empírica se define de la manera habitual:</p>
<p><span class="math display">\[
F_n(c_j) = \frac{\text{número de observaciones } \le c_j}{n}.
\]</span></p>
<p>Para otros valores de <span class="math inline">\(x \in (c_{j-1},c_j)\)</span>, podemos estimar la función de distribución con el estimador <em>ogive</em>, que interpola linealmente entre <span class="math inline">\(F_n(c_{j-1})\)</span> y <span class="math inline">\(F_n(c_j)\)</span>, es decir, los valores de los límites <span class="math inline">\(F_n(c_{j-1})\)</span> y <span class="math inline">\(F_n (c_j)\)</span> están conectados con una línea recta. Esto puede expresarse formalmente como
<span class="math display">\[F_n(x) = \frac{c_j-x}{c_j-c_{j-1}} F_n(c_{j-1}) + \frac{x-c_{j-1}}{c_j-c_{j-1}} F_n(c_j) \ \ \ \text{para } c_{j-1} \le x &lt; c_j\]</span></p>
<p>La densidad correspondiente es
<span class="math display">\[f_n(x) = F^{\prime}_n(x) = \frac{F_n(c_j)-F_n(c_{j-1})}{c_j - c_{j-1}} \ \ \  \text{para } c_{j-1} \le x &lt; c_j .\]</span></p>
<hr />
<p><strong>Ejemplo 4.3.4. Pregunta de Examen Actuarial.</strong></p>
<p>Se le proporciona la siguiente información sobre los cantidades reclamadas para 100 siniestros:</p>
<p><span class="math display">\[
{\small
\begin{array}{r|c}
\hline
\text{Tamaño del Siniestro} &amp;  \text{Número de Siniestros } \\
\hline
0 – 1.000 &amp; 16 \\
1.000 – 3.000 &amp; 22 \\
3.000 – 5.000 &amp; 25 \\
5.000 – 10.000 &amp; 18 \\
10.000 – 25.000 &amp; 10 \\
25.000 – 50.000 &amp; 5 \\
50.000 – 100.000 &amp; 3 \\
\text{mayor  } 100.000 &amp; 1 \\
\hline
\end{array}
}
\]</span></p>
<p>Usando el estimador <em>ogive</em>, calcule la estimación de la probabilidad de que un siniestro elegido al azar esté entre 2000 y 6000.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleSelect.3.4" href="javascript:toggleEX('toggleExampleSelect.3.4','displayTextExampleSelect.3.4');"><i><strong>Mostrar solución del ejemplo</strong></i></a>
</h5>
<div id="toggleExampleSelect.3.4" style="display: none">
<p><strong>Solución.</strong>
En los límites, la función de distribución empírica se define de la manera habitual, por lo que tenemos
<span class="math display">\[F_{100}(1000) = 0,16, \ F_{100}(3000)=0,38, \ F_{100}(5000)=0,63, \ F_{100}(10000)=0,81.\]</span>
Para otros tamaños del siniestro, el estimador <em>ogive</em> interpola linealmente entre estos valores:
<span class="math display">\[F_{100}(2000) = 0,5F_{100}(1000) + 0,5F_{100}(3000) = 0,5(0,16)+0,5(0,38)=0,27\]</span> <span class="math display">\[F_{100}(6000)=0,8F_{100}(5000)+0,2F_{100}(10000) = 0,8(0,63)+0,2(0,81)=0,666\]</span>
Por lo tanto, la probabilidad de que una reclamación esté entre 2000 y 6000 es <span class="math inline">\(F_{100}(6000) - F_{100}(2000) = 0,666-0,27 = 0,396\)</span>.</p>
</div>
<hr />
</div>
<div id="función-de-distribución-empírica-censurada-por-la-derecha" class="section level4">
<h4><span class="header-section-number">4.3.2.2</span> Función de Distribución Empírica Censurada por la Derecha</h4>
<p>Puede ser útil calibrar los estimadores paramétricos con métodos no paramétricos que no se basen en una forma paramétrica de la distribución. El estimador de límite de producto propuesto por <span class="citation">(Kaplan and Meier <a href="#ref-kaplan1958" role="doc-biblioref">1958</a>)</span> es un estimador de la función de distribución bien conocido en presencia de censura.</p>
<p><strong>Motivación para el Estimador de Límite de Producto de Kaplan-Meier.</strong> Para explicar por qué el límite de producto funciona tan bien con observaciones censuradas, volvamos primero al caso “habitual” sin censura. Aquí, la función de distribución empírica <span class="math inline">\(F_n(x)\)</span> es un estimador <em>insesgado</em> de la función de distribución <span class="math inline">\(F(x)\)</span>. Esto se debe a que <span class="math inline">\(F_n(x)\)</span> es el promedio de las variables indicadoras, cada una de las cuales es insesgada, es decir, <span class="math inline">\(\mathrm{E~}I(X_i \le x) = \Pr(X_i \le x) = F(x)\)</span>.</p>
<p>Ahora supongamos que la variable aleatoria está censurada por la derecha por una cantidad límite, por ejemplo, <span class="math inline">\(C_U\)</span>, de modo que registramos el menor de los dos, <span class="math inline">\(X^* = \min(X, C_U)\)</span>. Para valores de <span class="math inline">\(x\)</span> que son menores que <span class="math inline">\(C_U\)</span>, la variable indicadora todavía proporciona un estimador insesgado de la función de distribución antes de alcanzar el límite de censura. Es decir, <span class="math inline">\(\mathrm{E ~}I(X^* \le x) = F(x)\)</span> porque <span class="math inline">\(I(X^* \le x) = I(X \le x)\)</span> para <span class="math inline">\(x&lt;C_U\)</span>. Del mismo modo, <span class="math inline">\(\mathrm{E~}I(X^*&gt; x) = 1-F(x) = S(x)\)</span>. En cambio, para <span class="math inline">\(x&gt;C_U\)</span>, <span class="math inline">\(I(X^* \le x)\)</span> en general no es un estimador insesgado de <span class="math inline">\(F(x)\)</span>.</p>
<p>Como alternativa, consideremos <em>dos</em> variables aleatorias que tienen diferentes límites de censura. Por ejemplo, supongamos que observamos <span class="math inline">\(X_1^* = \min(X_1, 5)\)</span> y <span class="math inline">\(X_2^* = \min(X_2, 10)\)</span>, donde <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> son extracciones independientes de la misma distribución. Para <span class="math inline">\(x\le 5\)</span>, la función de distribución empírica <span class="math inline">\(F_2(x)\)</span> es un estimador insesgado de <span class="math inline">\(F(x)\)</span>. Sin embargo, para <span class="math inline">\(5&lt;x \le 10\)</span>, la primera observación no puede usarse para la función de distribución debido a la limitación de censura. En cambio, la estrategia desarrollada por <span class="citation">(Kaplan and Meier <a href="#ref-kaplan1958" role="doc-biblioref">1958</a>)</span> es usar <span class="math inline">\(S_2(5)\)</span> como estimador de <span class="math inline">\(S(5)\)</span> y luego usar la segunda observación para estimar la función de supervivencia condicional a la supervivencia al tiempo 5, <span class="math inline">\(\Pr(X&gt;x|X&gt;5) = \frac {S(x)}{S(5)}\)</span>. Específicamente, para <span class="math inline">\(5&lt;x \le 10\)</span>, el estimador de la función de supervivencia es</p>
<p><span class="math display">\[
\hat{S}(x) = S_2(5) \times I(X_2^* &gt; x ) .
\]</span></p>
<p><strong>Estimador del límite de producto de Kaplan-Meier.</strong> Ampliando esta idea, para cada observación <span class="math inline">\(i\)</span>, sea <span class="math inline">\(u_i\)</span> el límite superior de censura (<span class="math inline">\(= \infty\)</span> si no hay censura). Por lo tanto, el valor registrado es <span class="math inline">\(x_i\)</span> en el caso de no censura y <span class="math inline">\(u_i\)</span> si hay censura. Supongamos que <span class="math inline">\(t_{1}&lt;\cdots&lt;t_{k}\)</span> sean <span class="math inline">\(k\)</span> puntos distintos en los que se produce una pérdida sin censura, y que <span class="math inline">\(s_j\)</span> sea el número de pérdidas sin censura <span class="math inline">\(x_i\)</span>’s en <span class="math inline">\(t_{j}\)</span>. El <strong>conjunto de riesgo</strong> correspondiente es el número de observaciones que están activas (no censuradas) en un valor <em>menor que</em> <span class="math inline">\(t_{j}\)</span>, denotado como <span class="math inline">\(R_j=\sum_{i = 1}^n I(x_i \geq t_{j})+\sum_{i = 1}^n I(u_i \geq t_{j})\)</span>.</p>
<p>Con esta notación, el <strong>estimador del límite de producto</strong> de la función de distribución es
<span class="math display" id="eq:KaplanMeier">\[\begin{equation}
\hat{F}(x) =
\left\{
\begin{array}{ll}
0 &amp; x&lt;t_{1} \\
1-\prod_{j:t_{j} \leq x}\left( 1-\frac{s_j}{R_{j}}\right) &amp; x \geq t_{1} 
\end{array}
\right. .\tag{4.6}
\end{equation}\]</span></p>
<p>Como de costumbre, la estimación correspondiente de la función de supervivencia es <span class="math inline">\(\hat{S}(x) = 1 - \hat{F}(x)\)</span>.</p>
<hr />
<p><strong>Ejemplo 4.3.5. Pregunta de Examen Actuarial.</strong>
La siguiente es una muestra de 10 pagos:</p>
<p><span class="math display">\[
\begin{array}{cccccccccc}
4 &amp;4 &amp;5+ &amp;5+ &amp;5+ &amp;8 &amp;10+ &amp;10+ &amp;12 &amp;15 \\
\end{array}
\]</span></p>
<p>donde <span class="math inline">\(+\)</span> indica que una pérdida ha excedido el límite de la póliza.</p>
<p>Usando el estimador de límite de producto de Kaplan-Meier, calcule la probabilidad de que la pérdida en una póliza exceda 11, <span class="math inline">\(\hat{S}(11)\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleSelect.3.5" href="javascript:toggleEX('toggleExampleSelect.3.5','displayTextExampleSelect.3.5');"><i><strong>Mostrar solución del ejemplo</strong></i></a>
</h5>
<div id="toggleExampleSelect.3.5" style="display: none">
<p><strong>Solución.</strong>
Hay cuatro tiempos de eventos (observaciones no censuradas). Para cada tiempo <span class="math inline">\(t_j\)</span>, podemos calcular el número de eventos <span class="math inline">\(s_j\)</span> y el conjunto de riesgo <span class="math inline">\(R_j\)</span> de la siguiente manera:</p>
<p><span class="math display">\[
\begin{array}{cccc}
\hline
j &amp; t_j &amp; s_j &amp; R_j \\
\hline
1 &amp; 4 &amp; 2 &amp; 10 \\
2 &amp; 8 &amp; 1 &amp; 5 \\
3 &amp; 12 &amp; 1 &amp; 2 \\
4 &amp; 15 &amp; 1 &amp; 1 \\
\hline
\end{array}
\]</span></p>
<p>Asi, la estimación de Kaplan-Meier de <span class="math inline">\(S(11)\)</span> es
<span class="math display">\[
\begin{aligned}
\hat{S}(11) &amp;= \prod_{j:t_j\leq 11} \left( 1- \frac{s_j}{R_j} \right) =  \prod_{j=1}^{2} \left( 1- \frac{s_j}{R_j} \right)\\
&amp;= \left(1-\frac{2}{10} \right) \left(1-\frac{1}{5} \right) = (0,8)(0,8)= 0,64. \\
\end{aligned}
\]</span></p>
</div>
<hr />
<p><strong>Ejemplo. 4.3.6. Siniestros con Daños Corporales.</strong> Consideramos nuevamente los datos de la aplicación de <span class="citation">Derrig, Ostaszewski, and Rempala (<a href="#ref-derrig2001applications" role="doc-biblioref">2001</a>)</span> de siniestros por daños corporales en automóviles en Boston, que se presentaron en el Ejemplo 4.1.11. En ese ejemplo, omitimos los siniestros 17 que fueron censurados por los límites de la póliza. Ahora, incluimos el conjunto de datos completo y utilizamos el estimador del límite de producto de Kaplan-Meier para estimar la función de supervivencia. Esto se muestra en la Figura <a href="C-ModelSelection.html#fig:KMSurvival">4.14</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:KMSurvival"></span>
<img src="LossDataAnalytics_files/figure-html/KMSurvival-1.png" alt="Estimación de Kaplan-Meier de la función de supervivencia para siniestros por daños corporales " width="672" />
<p class="caption">
Figure 4.14: Estimación de Kaplan-Meier de la función de supervivencia para siniestros por daños corporales
</p>
</div>
<h5 style="text-align: center;">
<a id="displayTextKaplanMeier.4f" href="javascript:togglecode('toggleKaplanMeier','displayTextKaplanMeier.4f');"><i><strong>Mostrar código R</strong></i></a>
</h5>
<div id="toggleKaplanMeier" style="display: none">
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" title="1"><span class="kw">library</span>(survival)                <span class="co"># para Surv(), survfit()</span></a>
<a class="sourceLine" id="cb21-2" title="2"><span class="co">## KM estimación</span></a>
<a class="sourceLine" id="cb21-3" title="3">KM0 &lt;-<span class="st"> </span><span class="kw">survfit</span>(<span class="kw">Surv</span>(AmountPaid, UnCensored) <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,  <span class="dt">type=</span><span class="st">&quot;kaplan-meier&quot;</span>, <span class="dt">data=</span>BIData)</a>
<a class="sourceLine" id="cb21-4" title="4"><span class="kw">plot</span>(KM0, <span class="dt">conf.int=</span><span class="ot">FALSE</span>, <span class="dt">xlab=</span><span class="st">&quot;x&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;Supervivencia de Kaplan Meier &quot;</span>)</a></code></pre></div>
</div>
<hr />
</div>
<div id="función-de-distribución-empírica-censurada-por-la-derecha-truncada-por-la-izquierda" class="section level4">
<h4><span class="header-section-number">4.3.2.3</span> Función de Distribución Empírica Censurada por la Derecha, Truncada por la Izquierda</h4>
<p>Además de la censura por la derecha, ahora ampliamos el marco para permitir datos truncados por la izquierda. Como antes, para cada observación <span class="math inline">\(i\)</span>, sea <span class="math inline">\(u_i\)</span> el límite superior de censura (<span class="math inline">\(= \infty\)</span> si no hay censura). Además, sea <span class="math inline">\(d_i\)</span> el límite inferior de truncamiento (0 si no hay truncamiento). Por lo tanto, el valor registrado (si es mayor que <span class="math inline">\(d_i\)</span>) es <span class="math inline">\(x_i\)</span> en el caso de no censura y <span class="math inline">\(u_i\)</span> si hay censura. Supongamos que <span class="math inline">\(t_{1} &lt;\cdots &lt;t_{k}\)</span> son <span class="math inline">\(k\)</span> puntos distintos en los que se produce un evento de interés, y que <span class="math inline">\(s_j\)</span> son el número de eventos registrados <span class="math inline">\(x_i\)</span>’s en el punto de tiempo <span class="math inline">\(t_{j}\)</span>. El conjunto de riesgos correspondiente es
<span class="math display">\[R_j = \sum_{i=1}^n I(x_i \geq t_{j}) + \sum_{i=1}^n I(u_i \geq t_{j}) - \sum_{i=1}^n I(d_i \geq t_{j}).\]</span></p>
<p>Con esta nueva definición del conjunto de riesgos, el estimador del límite de producto de la función de distribución es como en la ecuación <a href="C-ModelSelection.html#eq:KaplanMeier">(4.6)</a>.</p>
<p><strong>Fórmula de Greenwood</strong>. <span class="citation">(Greenwood <a href="#ref-greenwood1926" role="doc-biblioref">1926</a>)</span> obtuvo la fórmula para que la varianza estimada del estimador de límite de producto sea
<span class="math display">\[\widehat{Var}(\hat{F}(x)) = (1-\hat{F}(x))^{2} \sum _{j:t_{j} \leq x} \dfrac{s_j}{R_{j}(R_{j}-s_j)}.\]</span></p>
<p>El método de <code>R</code> <code>survfit</code> utiliza un objeto de datos de supervivencia y crea un nuevo objeto que contiene la estimación de Kaplan-Meier de la función de supervivencia junto con los intervalos de confianza. El método de Kaplan-Meier (<code>type = 'kaplan-meier'</code>) se usa por defecto para construir una estimación de la curva de supervivencia. La función de supervivencia discreta resultante tiene puntos de masa en los tiempos de evento observados (fechas de alta) <span class="math inline">\(t_j\)</span>, donde la probabilidad de supervivencia de un evento a esa duración se estima como el número de eventos observados en la duración <span class="math inline">\(s_j\)</span> dividido por el número de sujetos expuestos o ‘en riesgo’ justo antes de la duración del evento <span class="math inline">\(R_j\)</span>.</p>
<p>Dos tipos alternativos de estimación también están disponibles para el método <code>survfit</code>. La alternativa (<code>type='fh2'</code>) maneja los empates, en esencia, al suponer que ocurren varios eventos con la misma duración en un orden arbitrario. Otra alternativa (<code>type='fleming-harrington'</code>) usa el estimador de Nelson-Aalen (see <span class="citation">(Aalen <a href="#ref-aalen1978" role="doc-biblioref">1978</a>)</span>) en la estimación de la <strong>función de riesgo (hazard) acumulado</strong> para obtener una estimación de la función de supervivencia. El riesgo acumulado estimado <span class="math inline">\(\hat{H}(x)\)</span> comienza en cero y se incrementa en cada evento observado de duración <span class="math inline">\(t_j\)</span> por el número de eventos <span class="math inline">\(s_j\)</span> dividido por el número en riesgo <span class="math inline">\(R_j\)</span>. Con la misma notación anterior, el estimador de <strong>Nelson-Aalen</strong> de la función de distribución es</p>
<p><span class="math display">\[
\begin{aligned}
\hat{F}_{NA}(x) &amp;=
\left\{
\begin{array}{ll}
0 &amp; x&lt;t_{1} \\
1- \exp \left(-\sum_{j:t_{j} \leq x}\frac{s_j}{R_j} \right) &amp; x \geq t_{1} 
\end{array}
\right. .\end{aligned}
\]</span></p>
<p>Cabe tener en cuenta que la expresión anterior es el resultado del estimador de Nelson-Aalen de la función de riesgo acumulado
<span class="math display">\[\hat{H}(x) = \sum_{j: t_j \leq x}\frac{s_j}{R_j}\]</span>
y la relación entre la función de supervivencia y la función de riesgo acumulado es <span class="math inline">\(\hat{S}_{NA}(x) = e^{-\hat{H}(x)}\)</span>.</p>
<hr />
<p><strong>Ejemplo 4.3.7. Pregunta de Examen Actuarial.</strong></p>
<p>Para la observación <span class="math inline">\(i\)</span> de un estudio de supervivencia:</p>
<ul>
<li><span class="math inline">\(d_i\)</span> es el punto de truncamiento a la izquierda</li>
<li><span class="math inline">\(x_i\)</span> es el valor observado si no está censurado a la derecha</li>
<li><span class="math inline">\(u_i\)</span> es el valor observado si se censura a la derecha</li>
</ul>
<p>Te dan:</p>
<p><span class="math display">\[
{\small
\begin{array}{c|cccccccccc}
\hline
\text{Observación } (i) &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7 &amp; 8 &amp; 9 &amp; 10\\ \hline
d_i &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1,3 &amp; 1,5 &amp; 1,6\\
x_i &amp; 0,9 &amp; - &amp; 1,5 &amp; - &amp; - &amp; 1,7 &amp; - &amp; 2,1 &amp; 2,1 &amp; - \\
u_i &amp; - &amp; 1,2 &amp; - &amp; 1,5 &amp; 1,6 &amp; - &amp; 1,7 &amp; - &amp; - &amp; 2,3 \\
\hline
\end{array}
}
\]</span></p>
<p>Calcular la estimación del límite de producto de Kaplan-Meier, <span class="math inline">\(\hat{S}(1,6)\)</span></p>
<h5 style="text-align: center;">
<a id="displayTextExampleSelect.3.6" href="javascript:toggleEX('toggleExampleSelect.3.6','displayTextExampleSelect.3.6');"><i><strong>Mostrar solución del ejemplo</strong></i></a>
</h5>
<div id="toggleExampleSelect.3.6" style="display: none">
<p><strong>Solución.</strong> Recordemos el conjunto de riesgo <span class="math inline">\(R_j = \sum_{i=1}^n \left\{ I(x_i \geq t_{j}) + I(u_i \geq t_{j}) - I(d_i \geq t_{j}) \right\}\)</span>. Entonces</p>
<p><span class="math display">\[
\begin{array}{ccccc}
\hline
j &amp; t_j &amp; s_j &amp; R_j &amp; \hat{S}(t_j) \\
\hline
1  &amp; 0,9   &amp; 1   &amp; 10-3 = 7 &amp; 1-\frac{1}{7} = \frac{6}{7} \\
2  &amp; 1,5   &amp; 1   &amp; 8-2 = 6  &amp; \frac{6}{7}\left( 1 - \frac{1}{6} \right) = \frac{5}{7}\\
3  &amp; 1,7   &amp; 1   &amp; 5-0 = 5  &amp; \frac{5}{7}\left( 1 - \frac{1}{5} \right) = \frac{4}{7}\\
4  &amp; 2,1   &amp; 2   &amp; 3        &amp; \frac{4}{7}\left( 1 - \frac{2}{3}\right) = \frac{4}{21}\\
\hline
\end{array}
\]</span></p>
<p>La estimación de Kaplan-Meier es por lo tanto <span class="math inline">\(\hat{S}(1,6) = \frac{5}{7}\)</span>.</p>
</div>
<hr />
<p><strong>Ejemplo 4.3.8. Pregunta de Examen Actuarial. – Continuación.</strong></p>
<ol style="list-style-type: lower-alpha">
<li>Usando el estimador de Nelson-Aalen, calcular la probabilidad de que la pérdida en una póliza exceda 11, <span class="math inline">\(\hat{S}_{NA}(11)\)</span>.</li>
<li>Calcular la aproximación de Greenwood de la varianza de la estimación del límite del producto <span class="math inline">\(\hat{S}(11)\)</span>.</li>
</ol>
<h5 style="text-align: center;">
<a id="displayTextExampleSelect.3.7" href="javascript:toggleEX('toggleExampleSelect.3.7','displayTextExampleSelect.3.7');"><i><strong>Mostrar solución del ejemplo</strong></i></a>
</h5>
<div id="toggleExampleSelect.3.7" style="display: none">
<p><strong>Solución.</strong>
Como antes, hay cuatro tiempos con eventos (observaciones no censuradas). Para cada tiempo <span class="math inline">\(t_j\)</span> podemos calcular el número de eventos <span class="math inline">\(s_j\)</span> y el conjunto de riesgo <span class="math inline">\(R_j\)</span> de la siguiente manera:
<span class="math display">\[
\begin{array}{cccc}
\hline
j &amp; t_j &amp; s_j &amp; R_j \\
\hline
1 &amp; 4 &amp; 2 &amp; 10 \\
2 &amp; 8 &amp; 1 &amp; 5 \\
3 &amp; 12 &amp; 1 &amp; 2 \\
4 &amp; 15 &amp; 1 &amp; 1 \\
\hline
\end{array}
\]</span></p>
<p>El estimador de Nelson-Aalen de <span class="math inline">\(S(11)\)</span> es <span class="math inline">\(\hat{S}_{NA}(11)=e^{-\hat{H}(11)} = e^{-0,4} = 0,67\)</span>, de modo que
<span class="math display">\[
\begin{aligned}
\hat{H}(11) &amp;= \sum_{j:t_j\leq 11} \frac{s_j}{R_j}  = \sum_{j=1}^{2} \frac{s_j}{R_j}  \\
&amp;= \frac{2}{10} + \frac{1}{5}  = 0,2 + 0,2 = 0,4 .\\
\end{aligned}
\]</span>
Del ejercicio anterior, la estimación de Kaplan-Meier de <span class="math inline">\(S(11)\)</span> es <span class="math inline">\(\hat{S}(11) = 0,64\)</span>. Entonces, la estimación de Greenwood de la varianza de la estimación del límite del producto de <span class="math inline">\(S(11)\)</span> es
<span class="math display">\[
\begin{aligned}
\widehat{Var}(\hat{S}(11)) &amp;= (\hat{S}(11))^2 \sum_{j:t_j\leq 11} \frac{s_j}{R_j(R_j-s_j)}
&amp;= (0,64)^2 \left(\frac{2}{10(8)} + \frac{1}{5(4)} \right)  = 0,0307. \\
\end{aligned}
\]</span></p>
</div>
<hr />
</div>
</div>
</div>
<div id="S:MS:BayesInference" class="section level2">
<h2><span class="header-section-number">4.4</span> Inferencia Bayesiana</h2>
<hr />
<p>En esta sección aprende a:</p>
<ul>
<li>Describir el modelo bayesiano como una alternativa al enfoque frecuentista y resumir los cinco componentes de este enfoque de modelización.</li>
<li>Describir las distribuciones a posteriori de los parámetros y utilizar estas distribuciones para predecir nuevos resultados.</li>
<li>Utilizar distribuciones conjugadas para determinar las distribuciones a posteriori de los parámetros.</li>
</ul>
<hr />
<div id="S:IntroBayes" class="section level3">
<h3><span class="header-section-number">4.4.1</span> Introducción a la Inferencia Bayesiana</h3>
<p>Hasta este punto, nuestros métodos inferenciales se han centrado en el entorno <strong>frecuentista</strong>, en el que se extraen muestras repetidamente de una población. El vector de parámetros <span class="math inline">\(\boldsymbol \theta\)</span> es fijo pero desconocido, mientras que los resultados <span class="math inline">\(X\)</span> son realizaciones procedentes de variables aleatorias.</p>
<p>En contraste, bajo el marco <strong>Bayesiano</strong>, consideramos los parámetros del modelo y los datos como variables aleatorias. No estamos seguros de los valores de los parámetros <span class="math inline">\(\boldsymbol \theta\)</span> y utilizamos herramientas de probabilidad para reflejar esta incertidumbre.</p>
<p>Para tener una idea del marco bayesiano, recordemos primero la regla de Bayes
<span class="math display">\[
\Pr(parámetros|datos) = \frac{\Pr(datos|parámetros) \times \Pr(parámetros)}{\Pr(datos)}
\]</span></p>
<p>donde</p>
<ul>
<li><span class="math inline">\(\Pr(parámetros)\)</span> es la distribución de los parámetros, conocida como la distribución <em>a priori</em>.</li>
<li><span class="math inline">\(\Pr(datos|parámetros)\)</span> es la distribución de muestreo. En un contexto frecuentista, se usa para realizar inferencias sobre los parámetros y se conoce como <em>probabilidad</em>.</li>
<li><span class="math inline">\(\Pr(parámetros|datos)\)</span> es la distribución de los parámetros que han observado los datos, conocidos como la distribución <em>a posteriori</em>.</li>
<li><span class="math inline">\(\Pr(datos)\)</span> es la distribución marginal de los datos. Generalmente se obtiene integrando (o sumando) la distribución conjunta de datos y parámetros sobre los valores de los parámetros.</li>
</ul>
<p><strong>¿Por qué Bayes?</strong> Hay varias ventajas del enfoque bayesiano. Primero, podemos describir la distribución completa de parámetros condicionada a los datos. Esto nos permite, por ejemplo, proporcionar resultados de probabilidad con respecto a la verosimilitud de los parámetros. En segundo lugar, el enfoque bayesiano proporciona una alternativa unificada para estimar parámetros. Algunos métodos no bayesianos, como los mínimos cuadrados, requieren un enfoque separado para estimar los componentes de la varianza. Por el contrario, en los métodos bayesianos, todos los parámetros se pueden tratar de manera similar. Esto es conveniente para explicar los resultados a los usuarios del análisis de datos. Tercero, este enfoque permite a los analistas combinar información previa conocida de otras fuentes con los datos de manera coherente. Este tema se desarrolla en detalle en el capítulo de credibilidad. Cuarto, el análisis bayesiano es particularmente útil para pronosticar respuestas futuras.</p>
<p><strong>Caso particular de Poisson - Gamma.</strong> Para desarrollar el método bayesiano de forma intuitiva, consideramos el caso de Poisson-Gamma que ocupa un lugar destacado en las aplicaciones actuariales. La idea es considerar un conjunto de variables aleatorias <span class="math inline">\(X_1,\ldots, X_n\)</span>, donde cada <span class="math inline">\(X_i\)</span> podría representar el número de siniestros para el titular de la póliza <em>i</em>-ésima. Supongamos que <span class="math inline">\(X_i\)</span> tiene una distribución de Poisson con parámetro <span class="math inline">\(\lambda\)</span>, análoga a la probabilidad que vimos por primera vez en el Capítulo <a href="C-Frequency-Modeling.html#C:Frequency-Modeling">2</a>. En un contexto no bayesiano (o frecuentista), el parámetro <span class="math inline">\(\lambda\)</span> se ve como una cantidad desconocida que no es aleatoria (se dice que es “fija”). En el contexto bayesiano, el parámetro desconocido <span class="math inline">\(\lambda\)</span> se considera incierto y se modeliza como una variable aleatoria. En este caso particular, utilizamos la distribución gamma para reflejar esta incertidumbre, la distribución a priori.</p>
<p>Pensemos en el siguiente esquema de muestreo en dos etapas para argumentar esta configuración probabilística.</p>
<ol style="list-style-type: decimal">
<li>En la primera etapa, el parámetro <span class="math inline">\(\lambda\)</span> se extrae de una distribución gamma.</li>
<li>En la segunda etapa, para ese valor de <span class="math inline">\(\lambda\)</span>, hay <span class="math inline">\(n\)</span> extracciones de la misma distribución de Poisson, que son independientes, condicionadas a <span class="math inline">\(\lambda\)</span>.</li>
</ol>
<p>De esta configuración sencilla, surgen algunas conclusiones importantes.</p>
<ul>
<li>La distribución de <span class="math inline">\(X_i\)</span> ya no es Poisson. Para el caso particular, es una distribución binomial negativa (ver el siguiente “Fragmento de teoría”).</li>
<li>Las variables aleatorias <span class="math inline">\(X_1, \ldots, X_n\)</span> no son independientes. Esto se debe a que comparten la variable aleatoria común <span class="math inline">\(\lambda\)</span>.</li>
<li>Como en el contexto frecuentista, el objetivo es hacer afirmaciones sobre los valores probables de los parámetros, tales como <span class="math inline">\(\lambda\)</span>, dado los datos observados <span class="math inline">\(X_1, \ldots, X_n\)</span>. Sin embargo, debido a que ahora tanto el parámetro como los datos son variables aleatorias, podemos usar el lenguaje de probabilidad condicionada para hacer tales afirmaciones. Como veremos en la Sección <a href="C-ModelSelection.html#S:ConjugateDistributions">4.4.4</a>, resulta que la distribución de <span class="math inline">\(\lambda\)</span> dados los datos <span class="math inline">\(X_1, \ldots, X_n\)</span> también es gamma (con parámetros actualizados), un resultado que simplifica la tarea de inferir valores probables del parámetro <span class="math inline">\(\lambda\)</span>.</li>
</ul>
<h5 style="text-align: center;">
<a id="displayTheory.2" href="javascript:toggleTheory('TheoryBayesPoisson','displayTheory.2');"><i><strong>Mostrar un fragmento de teoría </strong></i></a>
</h5>
<div id="TheoryBayesPoisson" style="display: none">
<hr />
<p>Demostremos que la distribución de <span class="math inline">\(X\)</span> es binomial negativa. Suponemos que la distribución de <span class="math inline">\(X\)</span> dada <span class="math inline">\(\lambda\)</span> es Poisson, de modo que
<span class="math display">\[
\Pr(X = x|\lambda) = \frac{\lambda^x}{\Gamma(x+1)} e^{-\lambda} ,
\]</span>
usando la notación <span class="math inline">\(\Gamma(x+1) = x!\)</span> para el entero <span class="math inline">\(x\)</span>. Suponga que <span class="math inline">\(\lambda\)</span> es una extracción de una distribución gamma con parámetros fijos, por ejemplo, <span class="math inline">\(\alpha\)</span> y <span class="math inline">\(\theta\)</span>, por lo que esto tiene <a href="#" class="tooltip" style="color:green"><em>pdf</em><span style="font-size:8pt"> función de probabilidad de densidad</span></a>
<span class="math display">\[
f(\lambda) = \frac{\lambda^{\alpha-1}}{\theta^{\alpha}\Gamma(\alpha)}\exp(-\lambda/\theta).
\]</span>
Sabemos que una <em>pdf</em> integra uno. Para facilitar el desarrollo, definimos el parámetro recíproco <span class="math inline">\(\theta_r = 1/\theta\)</span> y así tenemos
<span class="math display">\[
\int_0^{\infty} f(\lambda) ~d\lambda =1 ~~~ ==&gt; ~~~ \theta_r^{-\alpha} \Gamma(\alpha) = \int_0^{\infty} \lambda^{\alpha-1} \exp\left(-\lambda\theta_r\right) ~
d\lambda .
\]</span>
A partir del Capítulo de Apéndice <a href="C-AppB.html#C:AppB">16</a> en esperanzas iteradas, tenemos que la <a href="#" class="tooltip" style="color:green"><em>pmf</em><span style="font-size:8pt"> función masa de probabilidad</span></a> de <span class="math inline">\(X\)</span> se puede calcular de forma iterada como</p>
<p><span class="math display">\[
\begin{aligned}
\Pr(X = x) 
&amp;=  \mathrm{E} \left\{\Pr(X = x|\lambda)\right\}\\
&amp;=  \int_0^{\infty} \Pr(X = x|\lambda) f(\lambda) ~d\lambda \\
&amp;=  \int_0^{\infty} \frac{\lambda^x}{\Gamma(x+1)} e^{-\lambda} \frac{\lambda^{\alpha-1}}{\theta^{\alpha}\Gamma(\alpha)}\exp(-\lambda/\theta) ~d\lambda\\
&amp;=  \frac{1}{\theta^{\alpha}\Gamma(x+1)\Gamma(\alpha)} \int_0^{\infty} \lambda^{x+\alpha-1} \exp\left(-\lambda(1+\frac{1}{\theta})\right) ~d\lambda \\
&amp;=  \frac{1}{\theta^{\alpha}\Gamma(x+1)\Gamma(\alpha)} \Gamma(x+\alpha)\left(1+\frac{1}{\theta}\right)^{-(x+\alpha)} \\
&amp;=  \frac{\Gamma(x+\alpha)}{\Gamma(x+1)\Gamma(\alpha)}\left(\frac{1}{1+\theta}\right)^{\alpha} \left(\frac{\theta}{1+\theta}\right)^{x} .\\
\end{aligned} 
\]</span>
Aquí, utilizamos la igualdad de distribución gamma con la sustitución <span class="math inline">\(\theta_r = 1+1/\theta\)</span>. Como se puede ver en la Sección<a href="C-Frequency-Modeling.html#S:negative-binomial-distribution">2.2.3.3</a>, ésta es una distribución binomial negativa con parámetro <span class="math inline">\(r = \alpha\)</span> y <span class="math inline">\(\beta = \theta\)</span>.</p>
<hr />
</div>
<p>En este capítulo, usamos ejemplos sencillos que se pueden hacer a mano para ilustrar los fundamentos. Para una implementación práctica, los analistas dependen en gran medida de los métodos de simulación que utilizan métodos computacionales modernos como la simulación Markov Chain Monte Carlo (<em>MCMC</em>). Realizaremos una introducción a las técnicas de simulación en el Capítulo <a href="C-Simulation.html#C:Simulation">6</a>, pero las técnicas más intensivas como <em>MCMC</em> requieren referencias adicionales. Ver @ hartman2016 para una introducción a los métodos bayesianos computacionales desde una perspectiva actuarial.</p>
</div>
<div id="modelo-bayesiano" class="section level3">
<h3><span class="header-section-number">4.4.2</span> Modelo Bayesiano</h3>
<p>Con el desarrollo intuitivo de la Sección anterior <a href="C-ModelSelection.html#S:IntroBayes">4.4.1</a>, ahora reformulamos el modelo bayesiano con un poco más de precisión utilizando la notación matemática. Para simplificar, este resumen supone que tanto los resultados como los parámetros son variables aleatorias continuas. En los ejemplos, a veces le pedimos al lector que aplique estos mismos principios a versiones discretas. Conceptualmente, tanto los casos continuos como los discretos son iguales; mecánicamente, uno reemplaza un<a href="#" class="tooltip" style="color:green"><em>pdf</em><span style="font-size:8pt"> función de densidad de probabilidad</span></a> por una <a href="#" class="tooltip" style="color:green"><em>pmf</em><span style="font-size:8pt"> función masa de probabilidad</span></a> y una integral por una suma.</p>
<p>Como se indicó anteriormente, bajo la perspectiva bayesiana, los parámetros y los datos del modelo se consideran aleatorios. Nuestra incertidumbre sobre los parámetros del proceso subyacente de generación de datos se refleja en el uso de herramientas de probabilidad.</p>
<p><strong>Distribución A Priori.</strong>
En concreto, pensemos en los parámetros <span class="math inline">\(\boldsymbol \theta\)</span> como un vector aleatorio y denotemos <span class="math inline">\(\pi(\boldsymbol \theta)\)</span> a la distribución de posibles resultados. Éste es el conocimiento que tenemos antes de que se observen los resultados y se denomina distribución a priori. Por lo general, la distribución a priori es una distribución regular y, por lo tanto, se integra o suma uno, dependiendo de si <span class="math inline">\(\boldsymbol \theta\)</span> es continuo o discreto. Sin embargo, podemos estar muy inseguros (o no tener idea) sobre la distribución de <span class="math inline">\(\boldsymbol \theta\)</span>; la maquinaria bayesiana permite la siguiente situación
<span class="math display">\[\int \pi(\theta) d\theta = \infty, \]</span>
en cuyo caso <span class="math inline">\(\pi(\cdot)\)</span> se denomina una <strong>impropia prior (improper prior)</strong>.</p>
<p><strong>Distribución del Modelo.</strong>
La distribución de resultados dado un valor supuesto de <span class="math inline">\(\boldsymbol \theta\)</span> se conoce como la distribución del modelo y se denota como <span class="math inline">\(f(x|\boldsymbol \theta) = f_{X|\boldsymbol \theta}(x|\boldsymbol \theta)\)</span>. Esta es la función habitual de masa o densidad frecuentista. Ésta es simplemente la probabilidad en el contexto frecuentista y, por lo tanto, también es conveniente usar esto como un descriptor para la distribución del modelo.</p>
<p><strong>Distribución conjunta.</strong> La distribución de resultados y parámetros del modelo es, como era de esperar, conocida como la distribución conjunta y se denota como <span class="math inline">\(f(x, \boldsymbol \theta) = f(x|\boldsymbol \theta) \pi(\boldsymbol \theta)\)</span>.</p>
<p><strong>Distribución marginal de resultados.</strong> La distribución de resultados puede expresarse como
<span class="math display">\[f(x) = \int f(x | \boldsymbol \theta)\pi(\boldsymbol \theta) ~d \boldsymbol \theta.\]</span></p>
<p>Esto es análogo a una distribución de mixtura frecuentista. En la distribución de la mixtura, combinamos (o “mezclamos”) diferentes subpoblaciones. En el contexto bayesiano, la distribución marginal es una combinación de diferentes realizaciones de parámetros (en algunos contextos, se puede pensar que se combinan diferentes “estados de la naturaleza”).</p>
<p><strong>Distribución a posteriori de los parámetros.</strong> Después de observar los resultados (de ahí la terminología “a posteriori”), se puede usar el teorema de Bayes para escribir la distribución como
<span class="math display">\[\pi(\boldsymbol \theta | x) =\frac{f(x , \boldsymbol \theta)}{f(x)} =\frac{f(x|\boldsymbol \theta )\pi(\boldsymbol \theta)}{f(x)}\]</span>
La idea es actualizar el conocimiento de la distribución de <span class="math inline">\(\boldsymbol \theta\)</span> (<span class="math inline">\(\pi(\boldsymbol \theta)\)</span>) con los datos <span class="math inline">\(x\)</span>. Determinar los valores potenciales de los parámetros es un aspecto importante de la inferencia estadística.</p>
</div>
<div id="inferencia-bayesiana" class="section level3">
<h3><span class="header-section-number">4.4.3</span> Inferencia Bayesiana</h3>
<div id="describiendo-la-distribución-a-posteriori-de-los-parámetros" class="section level4">
<h4><span class="header-section-number">4.4.3.1</span> Describiendo la Distribución A Posteriori de los Parámetros</h4>
<p>Una forma de describir una distribución es mediante intervalos de confianza. Para describiri la distribución de los parámetros <em>a posteriori</em>, se dice que el intervalo <span class="math inline">\([a, b]\)</span> es un intervalo de <span class="math inline">\(100(1- \alpha)\%\)</span> de <em>credibilidad</em> para <span class="math inline">\(\boldsymbol \theta\)</span> si
<span class="math display">\[\Pr(a \le \theta \le b | \mathbf{x}) \ge 1- \alpha.\]</span></p>
<p>Como alternativa, se puede realizar el análisis de decisión clásico. En esta configuración, la función de pérdida <span class="math inline">\(l(\hat{\theta}, \theta)\)</span> determina el coste pagado por usar la estimación <span class="math inline">\(\hat{\theta}\)</span> en lugar del verdadero <span class="math inline">\(\theta\)</span>. La <strong>estimación de Bayes</strong> es el valor que minimiza la pérdida esperada <span class="math inline">\(\mathrm{E~}[l(\hat{\theta}, \theta)]\)</span>. Algunos casos especiales importantes incluyen:
<span class="math display">\[
{\small
\begin{array}{cll}
\hline
\text{Función de Pérdida} l(\hat{\theta}, \theta) &amp; \text{Descripción} &amp; \text{Estimación de Bayes } \\
\hline 
(\hat{\theta}- \theta)^2 &amp; \text{Pérdida de error al cuadrado} &amp; \mathrm{E}(\theta|X) \\
|\hat{\theta}- \theta| &amp; \text{Pérdida de desviación absoluta} &amp; \text{Mediana de} \pi(\theta|x) \\
I(\hat{\theta} =\theta) &amp; \text{Pérdida cero-uno (para probabilidades discretas)} &amp; \text{Moda de } \pi(\theta|x) \\
\hline
\end{array}
}
\]</span></p>
<p>Minimizar la pérdida esperada es un método riguroso para proporcionar un “mejor supuesto” sobre un valor probable de un parámetro, comparable a un estimador frecuentista del parámetro desconocido (fijo).</p>
<hr />
<p><strong>Ejemplo 4.4.1. Pregunta de Examen Actuarial.</strong>
Te dan:</p>
<ol style="list-style-type: lower-roman">
<li>En una cartera de riesgos, cada asegurado puede tener como máximo un siniestro por año.</li>
<li>La probabilidad de siniestro para un asegurado durante un año es <span class="math inline">\(q\)</span>.</li>
<li>La densidad a priori es
<span class="math display">\[\pi(q) = q^3/0,07, \ \ \ 0,6 &lt;q &lt;0,8\]</span></li>
</ol>
<p>Un asegurado seleccionado al azar tiene un siniestro en el año 1 y cero siniestros en el año 2. Para este asegurado, calcular la probabilidad a posteriori de que <span class="math inline">\(0,7 &lt;q &lt;0,8\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleSelect.4.1" href="javascript:toggleEX('toggleExampleSelect.4.1','displayTextExampleSelect.4.1');"><i><strong>Mostrar solución del ejemplo</strong></i></a>
</h5>
<div id="toggleExampleSelect.4.1" style="display: none">
<p><strong>Solución.</strong>
La densidad a posteriori es proporcional al producto de la función de probabilidad y la densidad a priori. Así,
<span class="math display">\[\pi(q|1,0) \propto f(1|q)\ f(0|q)\ \pi(q) \propto q(1-q)q^3 = q^4-q^5.\]</span></p>
<p>Para obtener la densidad a posteriori exacta, integramos la función anterior en su rango <span class="math inline">\((0,6, 0,8)\)</span></p>
<p><span class="math display">\[\int_{0,6}^{0,8} q^4-q^5 dq = \frac{q^5}{5} - \left. \frac{q^6}{6} \right|_{0,6}^{0,8} = 0,014069 \ \Rightarrow \ \pi(q|1,0)=\frac{q^4-q^5}{0,014069}.\]</span></p>
<p>Entonces
<span class="math display">\[\Pr(0,7&lt;q&lt;0,8|1,0)= \int_{0,7}^{0,8} \frac{q^4-q^5}{0,014069}dq = 0,5572.\]</span></p>
</div>
<hr />
<p><strong>Ejemplo 4.4.2. Pregunta de Examen Actuarial.</strong></p>
<p>Te dan:</p>
<ol style="list-style-type: lower-roman">
<li>La distribución a priori del parámetro <span class="math inline">\(\Theta\)</span> tiene una función de densidad de probabilidad: <span class="math display">\[\pi(\theta) = \frac{1}{\theta^2}, \ \ 1 &lt;\theta &lt;\infty \]</span></li>
<li>Dado <span class="math inline">\(\Theta = \theta\)</span>, la cuantía de los siniestros sigue una distribución de Pareto con parámetros <span class="math inline">\(\alpha = 2\)</span> y <span class="math inline">\(\theta\)</span>.</li>
</ol>
Se observa una siniestr de 3. Calcular la probabilidad a posteriori de que <span class="math inline">\(\Theta\)</span> exceda 2.
<h5 style="text-align: center;">
<a id="displayTextExampleSelect.4.2" href="javascript:toggleEX('toggleExampleSelect.4.2','displayTextExampleSelect.4.2');"><i><strong>Mostrar solución del ejemplo</strong></i></a>
</h5>
<div id="toggleExampleSelect.4.2" style="display: none">
<p><em>Solución:</em> La densidad a posteriori, dada una observación con valor 3 es</p>
<p><span class="math display">\[\pi(\theta|3) =  \frac{f(3|\theta)\pi(\theta)}{\int_1^\infty f(3|\theta)\pi(\theta)d\theta} =
\frac{\frac{2\theta^2}{(3+\theta)^3}\frac{1}{\theta^2}}{\int_1^\infty 2(3+\theta)^{-3} d\theta} =
\frac{2(3+\theta)^{-3}}{\left. -(3+\theta)^{-2}\right|_1^\infty} = 32(3+\theta)^{-3}, \ \ \theta &gt; 1.\]</span></p>
<p>Entonces</p>
<p><span class="math display">\[\Pr(\Theta&gt;2|3) = \int_2^\infty 32(3+\theta)^{-3}d\theta = \left. -16(3+\theta)^{-2} \right|_2^\infty = \frac{16}{25} = 0,64.\]</span></p>
</div>
<hr />
</div>
<div id="distribución-predictiva-bayesiana" class="section level4">
<h4><span class="header-section-number">4.4.3.2</span> Distribución Predictiva Bayesiana</h4>
<p>Para otro tipo de inferencia estadística, a menudo es interesante “predecir” el valor de un resultado aleatorio que aún no se ha observado. En particular, para los nuevos datos <span class="math inline">\(y\)</span>, la <strong>distribución predictiva</strong> es <span class="math display">\[f(y|x) = \int f(y|\theta)\pi(\theta | x) d \theta.\]</span>
A veces también se le llama distribución “a posteriori” ya que la distribución de los nuevos datos está condicionada a un conjunto base de datos.</p>
<p>Usando el error al cuadrado como la función de pérdida, la <strong>predicción bayesiana</strong> de <span class="math inline">\(Y\)</span> es
<span class="math display">\[
\begin{aligned}
\mathrm{E}(Y|X) &amp;=  \int ~y f(y|X) dy = \int y \left(\int f(y|\theta) \pi(\theta|X) d\theta \right) dy \\
&amp;=  \int  \mathrm{E}(Y|\theta) \pi(\theta|X) ~d\theta .
\end{aligned}
\]</span>
Como se señaló anteriormente, para algunas situaciones la distribución de los parámetros es discreta, no continua. Tener un conjunto discreto de posibles parámetros nos permite pensar en ellos como “estados de la naturaleza” alternativos, lo que proporciona una interpretación útil.</p>
<hr />
<p><strong>Ejemplo 4.4.3. Pregunta de Examen Actuarial.</strong>
Para una póliza en particular, las probabilidades condicionadas del número anual de siniestros, dado <span class="math inline">\(\Theta = \theta\)</span>, y la distribución de probabilidad de <span class="math inline">\(\Theta\)</span> son las siguientes:</p>
<p><span class="math display">\[
{\small
\begin{array}{l|ccc}
\hline
\text{Número de Siniestros} &amp; 0 &amp; 1 &amp; 2 \\
\text{Probabilidad} &amp; 2\theta &amp; \theta &amp; 1-3\theta \\
\hline
\end{array}
}
\]</span></p>
<p><span class="math display">\[
{\small
\begin{array}{l|cc}
\hline
\theta &amp; 0,05 &amp; 0,30 \\
\text{Probabilidad} &amp; 0,80 &amp; 0,20 \\
\hline
\end{array}
}
\]</span></p>
<p>Se observan dos siniestros en el año 1. Calcular la predicción bayesiana del número de siniestros en el año 2.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleSelect.4.3" href="javascript:toggleEX('toggleExampleSelect.4.3','displayTextExampleSelect.4.3');"><i><strong>Mostrar solución del ejemplo</strong></i></a>
</h5>
<div id="toggleExampleSelect.4.3" style="display: none">
<p><strong>Solución.</strong>
Comenzamos con la distribución a posteriori del parámetro
<span class="math display">\[
\Pr(\theta|X) = \frac{\Pr(X|\theta)\Pr(\theta)}{\sum_{\theta}\Pr(X|\theta)\Pr(\theta)}
\]</span>
de modo que
<span class="math display">\[
\begin{aligned} 
\Pr(\theta=0,05|X=2) &amp;= \frac{\Pr(X=2|\theta=0,05)\Pr(\theta=0,05)}
{\Pr(X=2|\theta=0,05)\Pr(\theta=0,05)+\Pr(X=2|\theta=0,3)\Pr(\theta=0,3)}\\
&amp;=\frac{(1-3\times 0,05)(0,8)}{(1-3\times 0,05)(0,8)+(1-3\times 0,3)(0,2)}= \frac{68}{70}.
\end{aligned} 
\]</span></p>
<p>Así, <span class="math inline">\(\Pr(\theta=0,3|X=1)= 1 - \Pr(\theta=0,05|X=1) = \frac{2}{70}\)</span>.</p>
<p>De la distribución del modelo, tenemos
<span class="math display">\[
E(X|\theta) = 0 \times 2\theta + 1 \times \theta + 2 \times (1-3\theta) = 2 - 5 \theta.
\]</span>
Así,</p>
<p><span class="math display">\[
\begin{aligned}
E(Y|X)
&amp;=   \sum_{\theta}  \mathrm{E}(Y|\theta) \pi(\theta|X) \\
&amp;= \mathrm{E}(Y|\theta=0,05) \pi(\theta=0,05|X)+\mathrm{E}(Y|\theta=0,3) \pi(\theta=0,3|X)\\
&amp;= ( 2 - 5 (0,05))\frac{68}{70} + ( 2 - 5 (0,3))\frac{2}{70} = 1,714.
\end{aligned}
\]</span></p>
</div>
<hr />
<p><strong>Ejemplo 4.4.4. Pregunta de Examen Actuarial.</strong></p>
<p>Te dan:</p>
<ol style="list-style-type: lower-roman">
<li>Las pérdidas de las pólizas de seguro de una compañía siguen una distribución de Pareto con función de densidad de probabilidad:
<span class="math display">\[
f(x | \theta) = \frac{\theta}{(x + \theta)^2}, \ \ 0 &lt;x &lt;\infty
\]</span></li>
<li>Para la mitad de las pólizas de la compañía <span class="math inline">\(\theta = 1\)</span>, mientras que para la otra mitad <span class="math inline">\(\theta = 3\)</span>.</li>
</ol>
<p>Para una póliza seleccionada al azar, las pérdidas en el año 1 fueron 5. Calcular la probabilidad a posteriori de que las pérdidas para esta póliza en el año 2 excedan de 8.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleSelect.4.4" href="javascript:toggleEX('toggleExampleSelect.4.4','displayTextExampleSelect.4.4');"><i><strong>Mostrar solución del ejemplo</strong></i></a>
</h5>
<div id="toggleExampleSelect.4.4" style="display: none">
<p><strong>Solución.</strong></p>
<p>Se nos da la distribución a priori de <span class="math inline">\(\theta\)</span> como $ (= 1) = (= 3) = $, la distribución condicional <span class="math inline">\(f (x | \theta)\)</span>, y el hecho de que observamos <span class="math inline">\(X_1 = 5\)</span>. El objetivo es encontrar la probabilidad predictiva <span class="math inline">\(\Pr(X_2&gt; 8 | X_1 = 5)\)</span>.</p>
<p>Las probabilidades a posteriori son</p>
<p><span class="math display">\[
\begin{aligned}
\Pr(\theta=1|X_1=5) &amp;= \frac{f(5|\theta=1)\Pr(\theta=1)}{f(5|\theta=1)\Pr(\theta=1) + f(5|\theta=3)\Pr(\theta=3)} \\
&amp;= \frac{\frac{1}{36}(\frac{1}{2})}{\frac{1}{36}(\frac{1}{2})+\frac{3}{64}(\frac{1}{2})} = \frac{\frac{1}{72}}{\frac{1}{72} + \frac{3}{128}} = \frac{16}{43}
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
\Pr(\theta=3|X_1=5) &amp;= \frac{f(5|\theta=3)\Pr(\theta=3)}{f(5|\theta=1)\Pr(\theta=1) + f(5|\theta=3)\Pr(\theta=3)} \\
&amp;= 1-\Pr(\theta=1|X_1=5) = \frac{27}{43}
\end{aligned}
\]</span></p>
<p>Tener en cuenta que la probabilidad condicionada de que las pérdidas excedan de 8 es
<span class="math display">\[
\begin{aligned}
\Pr(X_2&gt;8|\theta) &amp;= \int_8^\infty f(x|\theta)dx \\
&amp;= \int_8^\infty \frac{\theta}{(x+\theta)^2}dx = \left. -\frac{\theta}{x+\theta} \right|_8^\infty = \frac{\theta}{8 + \theta}
\end{aligned}
\]</span></p>
<p>La probabilidad predictiva es, por lo tanto,</p>
<p><span class="math display">\[
\begin{aligned}
\Pr(X_2&gt;8|X_1=5) &amp;= \Pr(X_2&gt;8|\theta=1) \Pr(\theta=1|X_1=5) + \Pr(X_2&gt;8|\theta=3) \Pr(\theta=3 | X_1=5) \\
&amp;= \frac{1}{8+1}\left( \frac{16}{43}\right) + \frac{3}{8+3} \left( \frac{27}{43}\right) = 0,2126
\end{aligned}
\]</span></p>
</div>
<hr />
<p><strong>Ejemplo 4.4.5. Pregunta de Examen Actuarial.</strong></p>
<p>Te dan:</p>
<ol style="list-style-type: lower-roman">
<li>La probabilidad de que un asegurado tenga al menos una pérdida durante cualquier año es <span class="math inline">\(p\)</span>.</li>
<li>La distribución a priori de <span class="math inline">\(p\)</span> es uniforme en <span class="math inline">\([0, 0,5]\)</span>.</li>
<li>Se observa a un asegurado durante 8 años y tiene al menos una pérdida cada año.</li>
</ol>
<p>Calcular la probabilidad a posteriori de que el asegurado tenga al menos una pérdida durante el Año 9.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleSelect.4.5" href="javascript:toggleEX('toggleExampleSelect.4.5','displayTextExampleSelect.4.5');"><i><strong>Mostrar solución del ejemplo</strong></i></a>
</h5>
<div id="toggleExampleSelect.4.5" style="display: none">
<p><strong>Solución.</strong>
La densidad de probabilidad a posteriori es<span class="math display">\[
\begin{aligned}
\pi(p|1,1,1,1,1,1,1,1) &amp;\propto \Pr(1,1,1,1,1,1,1,1|p)\ \pi(p) = p^8(2) \propto p^8 \\ 
\Rightarrow \pi(p|1,1,1,1,1,1,1,1) &amp;= \frac{p^8}{\int_0^5 p^8 dp} = \frac{p^8}{(0,5^9)/9} = 9(0,5^{-9})p^8
\end{aligned}
\]</span></p>
<p>Por lo tanto, la probabilidad a posteriori de que el asegurado tenga al menos una pérdida durante el Año 9 es</p>
<p><span class="math display">\[
\begin{aligned}
\Pr(X_9=1|1,1,1,1,1,1,1,1) &amp;= \int_0^5 \Pr(X_9=1|p) \pi(p|1,1,1,1,1,1,1,1) dp \\
&amp;= \int_0^5 p(9)(0,5^{-9})p^8 dp = 9(0,5^{-9})(0,5^{10})/10 = 0,45
\end{aligned}
\]</span></p>
</div>
<hr />
<p><strong>Ejemplo 4.4.6. Pregunta de Examen Actuarial.</strong>
Te dan:</p>
<ol style="list-style-type: lower-roman">
<li>Cada riesgo tiene como máximo una reclamación cada año.<span class="math display">\[
{\small
\begin{array}{ccc}
\hline
\text{Tipo de Riesgo } &amp; \text{Probabilidad A Priori } &amp; \text{Probabilidad Anual de Reclamación } \\
\hline
\text{I} &amp; 0,7 &amp; 0,1 \\
\text{II} &amp; 0,2 &amp; 0,2 \\
\text{III} &amp; 0,1 &amp; 0,4 \\
\hline
\end{array}
}
\]</span></li>
</ol>
<p>Un riesgo elegido al azar tiene tres reclamaciones durante los años 1-6. Calcular la probabilidad a posteriori de una reclamación por este riesgo en el año 7.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleSelect.4.6" href="javascript:toggleEX('toggleExampleSelect.4.6','displayTextExampleSelect.4.6');"><i><strong>Mostrar solución del ejemplo</strong></i></a>
</h5>
<div id="toggleExampleSelect.4.6" style="display: none">
<p><strong>Solución.</strong>
Las probabilidades son de una distribución binomial con 6 ensayos en los que se observaron 3 sucesos.</p>
<p><span class="math display">\[
\begin{aligned} 
\Pr(3|\text{I}) &amp;= {6 \choose 3} (0,1^3)(0,9^3) = 0,01458 \\
\Pr(3|\text{II}) &amp;= {6 \choose 3} (0,2^3)(0,8^3) = 0,08192 \\
\Pr(3|\text{III}) &amp;= {6 \choose 3} (0,4^3)(0,6^3) = 0,27648
\end{aligned}
\]</span></p>
<p>La probabilidad de observar tres sucesos es
<span class="math display">\[
\begin{aligned} \Pr(3) &amp;= \Pr(3|\text{I})\Pr(\text{I}) + \Pr(3|\text{II})\Pr(\text{II}) + \Pr(3|\text{III})\Pr(\text{III}) \\
&amp;=  0,7(0,01458) + 0,2(0,08192) + 0,1(0,27648) = 0,054238
\end{aligned}
\]</span></p>
<p>Las tres probabilidades a posteriori son
<span class="math display">\[
\begin{aligned}
\Pr(\text{I}|3) &amp;= \frac{\Pr(3|\text{I})\Pr(\text{I})}{\Pr(3)} = \frac{0,7(0,01458)}{0,054238} = 0,18817 \\
\Pr(\text{II}|3) &amp;= \frac{\Pr(3|\text{II})\Pr(\text{II})}{\Pr(3)} = \frac{0,2(0,08192)}{0,054238} = 0,30208 \\
\Pr(\text{III}|3) &amp;= \frac{\Pr(3|\text{III})\Pr(\text{III})}{\Pr(3)} = \frac{0,1(0,27648)}{0,054238} = 0,50975 
\end{aligned}
\]</span></p>
<p>La probabilidad a posteriori de una reclamación es, entonces,
<span class="math display">\[
\begin{aligned} 
\Pr(\text{siniestro} | 3) &amp;= \Pr(\text{claim}|\text{I})\Pr(\text{I} | 3) + \Pr(\text{siniestro} | \text{II})\Pr(\text{II} | 3) + \Pr(\text{siniestro} | \text{III}) \Pr(\text{III} | 3) \\ 
&amp;= 0,1(0,18817) + 0,2(0,30208) + 0,4(0,50975) = 0,28313
\end{aligned}
\]</span></p>
</div>
<hr />
</div>
</div>
<div id="S:ConjugateDistributions" class="section level3">
<h3><span class="header-section-number">4.4.4</span> Distribuciones Conjugadas</h3>
<p>En el marco bayesiano, la clave para la inferencia estadística es comprender la distribución a posteriori de los parámetros. Como se describe en la Sección @ref(S: IntroBayes), el análisis de datos basado en métodos bayesianos utiliza técnicas computacionalmente intensivas como simulación
<a href="#" class="tooltip" style="color:green"><em>MCMC</em><span style="font-size:8pt"> Markov Chain Monte Carlo</span></a>. Otro enfoque para calcular distribuciones a posteriori se basa en <strong>distribuciones conjugadas</strong>. Aunque este enfoque está disponible solo para un número limitado de distribuciones, tiene el atractivo de que proporciona expresiones de forma cerrada para las distribuciones, lo que permite una fácil interpretación de los resultados.</p>
<p>Para relacionar las distribuciones a priori y a posteriori de los parámetros, tenemos la relación</p>
<p><span class="math display">\[
\begin{array}{ccc}
\pi(\boldsymbol \theta | x) &amp; = &amp; \frac{f(x|\boldsymbol \theta )\pi(\boldsymbol \theta)}{f(x)}  \\
 &amp; \propto  &amp; f(x|\boldsymbol \theta ) \pi(\boldsymbol \theta) \\
\text{a posteriori} &amp; \text{es proporcional a} &amp; \text{verosimilitud} \times \text{a priori} .
\end{array}
\]</span></p>
<p>Para distribuciones conjugadas, la a posteriori y la a priori provienen de la misma familia de distribuciones. La siguiente ilustración analiza el caso particular de Poisson-gamma, el más conocido en aplicaciones actuariales.</p>
<p><strong>Caso Particular – Poisson-Gamma - Continuación.</strong> Supongamos una distribución de modelo de Poisson(<span class="math inline">\(\lambda\)</span>) y que <span class="math inline">\(\lambda\)</span> siga una distribución a priori gamma(<span class="math inline">\(\alpha, \theta\)</span>). En este caso, la distribución a posteriori de <span class="math inline">\(\lambda\)</span> dados los datos sigue una distribución gamma con nuevos parámetros <span class="math inline">\(\alpha_{post} = \sum_i x_i + \alpha\)</span> y <span class="math inline">\(\theta_{post} = 1/(n + 1 /\theta)\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleConj.4f" href="javascript:toggleEX('toggleExampleConj','displayTextExampleConj.4f');"><i><strong>Mostrar detalles del caso particular </strong></i></a>
</h5>
<div id="toggleExampleConj" style="display: none">
<p><strong>Caso Particular – Poisson-Gamma – Continuación.</strong> La distribución del modelo es
<span class="math display">\[f(\mathbf{x} | \lambda) = \prod_{i=1}^n \frac{\lambda^{x_i} e^{-\lambda}}{x_i!} .\]</span></p>
<p>La distribución a priori es</p>
<p><span class="math display">\[\pi(\lambda) = \frac{\left(\lambda/\theta\right)^{\alpha} \exp(-\lambda/\theta)}{\lambda \Gamma(\alpha)}.\]</span>
Por lo tanto, la distribución a posteriori es proporcional a
<span class="math display">\[
\begin{aligned}
\pi(\lambda | \mathbf{x}) &amp;\propto f(\mathbf{x}|\theta ) \pi(\lambda) \\
&amp;= C \lambda^{\sum_i x_i + \alpha -1} \exp(-\lambda(n+1/\theta))
\end{aligned}
\]</span></p>
<p>donde <span class="math inline">\(C\)</span> es una constante. Se aprecia que se trata de una distribución gamma con nuevos parámetros <span class="math inline">\(\alpha_{post} = \sum_i x_i + \alpha\)</span> y <span class="math inline">\(\theta_{post} = 1/(n + 1/\theta)\)</span>. Por lo tanto, la distribución gamma es una conjugada a priori para la distribución del modelo de Poisson.</p>
</div>
<hr />
<p><strong>Ejemplo 4.4.7. Pregunta de Examen Actuarial.</strong></p>
<p>Te dan:</p>
<ol style="list-style-type: lower-roman">
<li>La distribución condicionada del número de siniestros por titular de la póliza es una Poisson con un promedio de <span class="math inline">\(\lambda\)</span>.</li>
<li>La variable <span class="math inline">\(\lambda\)</span> tiene una distribución gamma con los parámetros <span class="math inline">\(\alpha\)</span> y <span class="math inline">\(\theta\)</span>.</li>
<li>Para los asegurados con 1 siniestro en el Año 1, la predicción de Bayes para el número de siniestros en el Año 2 es 0,15.</li>
<li>Para los asegurados con un promedio de 2 siniestros por año en el año 1 y en el año 2, la predicción de Bayes para el número de siniestros en el año 3 es de 0,20.</li>
</ol>
<p>Calcular <span class="math inline">\(\theta\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleSelect.4.7" href="javascript:toggleEX('toggleExampleSelect.4.7','displayTextExampleSelect.4.7');"><i><strong>Mostrar solución del ejemplo</strong></i></a>
</h5>
<div id="toggleExampleSelect.4.7" style="display: none">
<p><strong>Solución.</strong></p>
<p>Dado que la distribución condicionada del número de siniestros por asegurado, <span class="math inline">\(E(X | \lambda) = Var(X | \lambda) = \lambda\)</span>, la predicción de Bayes es</p>
<p><span class="math display">\[
\begin{aligned}
\mathrm{E}(X_2|X_1)
&amp;= \int \mathrm{E}(X_2|\lambda) \pi(\lambda|X_1) d\lambda = \alpha_{new} \theta_{new}
\end{aligned}
\]</span>
porque la distribución a posteriori es gamma con parámetros <span class="math inline">\(\alpha_{new}\)</span> y <span class="math inline">\(\theta_{new}\)</span>.</p>
<p>Para el año 1, tenemos
<span class="math display">\[
0,15 = (X_1 + \alpha) \times \frac{1}{n+1/\theta} = (1 + \alpha) \times \frac{1}{1+1/\theta},
\]</span>
de modo que <span class="math inline">\(0,15(1+1/\theta)= 1 + \alpha\)</span>. Para el año 2, tenemos
<span class="math display">\[
0,2 = (X_1+X_2 + \alpha) \times \frac{1}{n+1/\theta} = (4 + \alpha) \times \frac{1}{2+1/\theta},
\]</span>
de modo que <span class="math inline">\(0,2(2+1/\theta)= 4 + \alpha\)</span>. Igualando estos resultados
<span class="math display">\[
0,2(2+1/\theta)=3 + 0,15(1+1/\theta)
\]</span>
resulta que <span class="math inline">\(\theta = 1/55 = 0,018182\)</span>.</p>
</div>
<hr />
<p>Las expresiones de forma cerrada significan que los resultados se pueden interpretar y calcular fácilmente; por lo tanto, las distribuciones conjugadas son útiles en la práctica actuarial. Otros dos casos especiales utilizados ampliamente son:</p>
<ul>
<li>La incertidumbre de los parámetros se describe mediante una distribución beta y los resultados tienen una distribución binomial (condicionada al parámetro).</li>
<li>La incertidumbre de los parámetros se describe mediante una distribución normal y los resultados se distribuyen condicionalmente como normales.</li>
</ul>
<p>Resultados adicionales sobre las distribuciones conjugadas se resumen en la Sección del Apéndice <a href="C-AppB.html#S:AppConjugateDistributions">16.3</a>.</p>
</div>
</div>
<div id="MS:further-reading-and-resources" class="section level2">
<h2><span class="header-section-number">4.5</span> Más Recursos y Colaboradores</h2>
<div id="ejercicios-1" class="section level4 unnumbered">
<h4>Ejercicios</h4>
<p>Aquí hay un conjunto de ejercicios que guían al lector a través de algunos de los fundamentos teóricos de <strong>Análisis de la Función de Pérdida</strong>. Cada tutorial se basa en una o más preguntas de los exámenes actuariales profesionales, generalmente el Examen C de la Sociedad de Actuarios.</p>
<p style="text-align: center;">
<a href="http://www.ssc.wisc.edu/~jfrees/loss-data-analytics/loss-data-analytics-model-selection/">Tutoriales guiados de Selección de Modelo</a>
</p>
</div>
<div id="autores" class="section level4 unnumbered">
<h4>Autores</h4>
<ul>
<li><strong>Edward W. (Jed) Frees</strong> y <strong>Lisa Gao</strong>, University of Wisconsin-Madison, son los principales autores de la versión inicial de este capítulo. Email: <a href="mailto:jfrees@bus.wisc.edu" class="email">jfrees@bus.wisc.edu</a> para comentarios sobre el capítulo y sugerencias de mejora.</li>
<li>Los revisores del capítulo incluyen: Andrew Kwon-Nakamura, Hirokazu (Iwahiro) Iwasawa, Eren Dodd.</li>
<li>Traducción al español: Catalina Bolancé (Universitat de Barcelona).</li>
</ul>

</div>
</div>
</div>
<h3>Bibliography</h3>
<div id="refs" class="references">
<div id="ref-aalen1978">
<p>Aalen, Odd. 1978. “Nonparametric Inference for a Family of Counting Processes.” <em>The Annals of Statistics</em> 6 (4): 701–26.</p>
</div>
<div id="ref-box1980sampling">
<p>Box, George EP. 1980. “Sampling and Bayes’ Inference in Scientific Modelling and Robustness.” <em>Journal of the Royal Statistical Society. Series A (General)</em>, 383–430.</p>
</div>
<div id="ref-derrig2001applications">
<p>Derrig, Richard A, Krzysztof M Ostaszewski, and Grzegorz A Rempala. 2001. “Applications of Resampling Methods in Actuarial Practice.” In <em>Proceedings of the Casualty Actuarial Society</em>, 87:322–64. Casualty Actuarial Society.</p>
</div>
<div id="ref-greenwood1926">
<p>Greenwood, Major. 1926. “The Errors of Sampling of the Survivorship Tables.” In <em>Reports on Public Health and Statistical Subjects</em>. Vol. 33. London: Her Majesty’s Stationary Office.</p>
</div>
<div id="ref-james2013introduction">
<p>James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. <em>An Introduction to Statistical Learning</em>. Vol. 112. Springer.</p>
</div>
<div id="ref-kaplan1958">
<p>Kaplan, Edward L., and Paul Meier. 1958. “Nonparametric Estimation from Incomplete Observations.” <em>Journal of the American Statistical Association</em> 53 (282): 457–81.</p>
</div>
<div id="ref-picard1990data">
<p>Picard, Richard R., and Kenneth N. Berk. 1990. “Data Splitting.” <em>The American Statistician</em> 44 (2): 140–47.</p>
</div>
<div id="ref-snee1977validation">
<p>Snee, Ronald D. 1977. “Validation of Regression Models: Methods and Examples.” <em>Technometrics</em> 19 (4): 415–28.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="C-Severity.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="C-AggLossModels.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["LossDataAnalytics.pdf", "LossDataAnalytics.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
