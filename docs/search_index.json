[
["index.html", "Loss Data Analytics Preface Acknowledgements Contributors Reviewers For our Readers", " Loss Data Analytics An open text authored by the Actuarial Community Preface Date: 01 February 2021 Book Description Loss Data Analytics is an interactive, online, freely available text. The online version contains many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. A subset of the book is available for offline reading in pdf and EPUB formats. The online text will be available in multiple languages to promote access to a worldwide audience. What will success look like? The online text will be freely available to a worldwide audience. The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. Moreover, a subset of the book will be available in pdf format for low-cost printing. The online text will be available in multiple languages to promote access to a worldwide audience. How will the text be used? This book will be useful in actuarial curricula worldwide. It will cover the loss data learning objectives of the major actuarial organizations. Thus, it will be suitable for classroom use at universities as well as for use by independent learners seeking to pass professional actuarial examinations. Moreover, the text will also be useful for the continuing professional development of actuaries and other professionals in insurance and related financial risk management industries. Why is this good for the profession? An online text is a type of open educational resource (OER). One important benefit of an OER is that it equalizes access to knowledge, thus permitting a broader community to learn about the actuarial profession. Moreover, it has the capacity to engage viewers through active learning that deepens the learning process, producing analysts more capable of solid actuarial work. Why is this good for students and teachers and others involved in the learning process? Cost is often cited as an important factor for students and teachers in textbook selection (see a recent post on the $400 textbook). Students will also appreciate the ability to “carry the book around” on their mobile devices. Why loss data analytics? The intent is that this type of resource will eventually permeate throughout the actuarial curriculum. Given the dramatic changes in the way that actuaries treat data, loss data seems like a natural place to start. The idea behind the name loss data analytics is to integrate classical loss data models from applied probability with modern analytic tools. In particular, we recognize that big data (including social media and usage based insurance) are here to stay and that high speed computation is readily available. Project Goal The project goal is to have the actuarial community author our textbooks in a collaborative fashion. To get involved, please visit our Open Actuarial Textbooks Project Site. Acknowledgements Edward Frees acknowledges the John and Anne Oros Distinguished Chair for Inspired Learning in Business which provided seed money to support the project. Frees and his Wisconsin colleagues also acknowledge a Society of Actuaries Center of Excellence Grant that provided funding to support work in dependence modeling and health initiatives. Wisconsin also provided an education innovation grant that provided partial support for the many students who have worked on this project. We acknowledge the Society of Actuaries for permission to use problems from their examinations. We thank Rob Hyndman, Monash University, for allowing us to use his excellent style files to produce the online version of the book. We thank Yihui Xie and his colleagues at Rstudio for the R bookdown package that allows us to produce this book. We also wish to acknowledge the support and sponsorship of the International Association of Black Actuaries in our joint efforts to provide actuarial educational content to all. Contributors The project goal is to have the actuarial community author our textbooks in a collaborative fashion. The following contributors have taken a leadership role in developing Loss Data Analytics. Zeinab Amin is the Director of the Actuarial Science Program and Associate Dean for Undergraduate Studies of the School of Sciences and Engineering at the American University in Cairo (AUC). Amin holds a PhD in Statistics and is an Associate of the Society of Actuaries. Amin is the recipient of the 2016 Excellence in Academic Service Award and the 2009 Excellence in Teaching Award from AUC. Amin has designed and taught a variety of statistics and actuarial science courses. Amin’s current area of research includes quantitative risk assessment, reliability assessment, general statistical modelling, and Bayesian statistics. Katrien Antonio, KU Leuven Jan Beirlant, KU Leuven Arthur Charpentier is a professor in the Department of Mathematics at the Université du Québec á Montréal. Prior to that, he worked at a large general insurance company in Hong Kong, China, and the French Federation of Insurers in Paris, France. He received a MS on mathematical economics at Université Paris Dauphine and a MS in actuarial science at ENSAE (National School of Statistics) in Paris, and a PhD degree from KU Leuven, Belgium. His research interests include econometrics, applied probability and actuarial science. He has published several books (the most recent one on Computational Actuarial Science with R, CRC) and papers on a variety of topics. He is a Fellow of the French Institute of Actuaries, and was in charge of the ‘Data Science for Actuaries’ program from 2015 to 2018. Curtis Gary Dean is the Lincoln Financial Distinguished Professor of Actuarial Science at Ball State University. He is a Fellow of the Casualty Actuarial Society and a CFA charterholder. He has extensive practical experience as an actuary at American States Insurance, SAFECO, and Travelers. He has served the CAS and actuarial profession as chair of the Examination Committee, first editor-in-chief for Variance: Advancing the Science of Risk, and as a member of the Board of Directors and the Executive Council. He contributed a chapter to Predictive Modeling Applications in Actuarial Science published by Cambridge University Press. Edward W. (Jed) Frees is an emeritus professor, formerly the Hickman-Larson Chair of Actuarial Science at the University of Wisconsin-Madison. He is a Fellow of both the Society of Actuaries and the American Statistical Association. He has published extensively (a four-time winner of the Halmstad and Prize for best paper published in the actuarial literature) and has written three books. He also is a co-editor of the two-volume series Predictive Modeling Applications in Actuarial Science published by Cambridge University Press. Guojun Gan is an assistant professor in the Department of Mathematics at the University of Connecticut, where he has been since August 2014. Prior to that, he worked at a large life insurance company in Toronto, Canada for six years. He received a BS degree from Jilin University, Changchun, China, in 2001 and MS and PhD degrees from York University, Toronto, Canada, in 2003 and 2007, respectively. His research interests include data mining and actuarial science. He has published several books and papers on a variety of topics, including data clustering, variable annuity, mathematical finance, applied statistics, and VBA programming. Lisa Gao is a PhD candidate in the Risk and Insurance department at the University of Wisconsin-Madison. She holds a BMath in Actuarial Science and Statistics from the University of Waterloo and is an Associate of the Society of Actuaries. José Garrido, Concordia University Lei (Larry) Hua is an Associate Professor of Actuarial Science at Northern Illinois University. He earned a PhD degree in Statistics from the University of British Columbia. He is an Associate of the Society of Actuaries. His research work focuses on multivariate dependence modeling for non-Gaussian phenomena and innovative applications for financial and insurance industries. Noriszura Ismail is a Professor and Head of Actuarial Science Program, Universiti Kebangsaan Malaysia (UKM). She specializes in Risk Modelling and Applied Statistics. She obtained her BSc and MSc (Actuarial Science) in 1991 and 1993 from University of Iowa, and her PhD (Statistics) in 2007 from UKM. She also passed several papers from Society of Actuaries in 1994. She has received several research grants from Ministry of Higher Education Malaysia (MOHE) and UKM, totaling about MYR1.8 million. She has successfully supervised and co-supervised several PhD students (13 completed and 11 on-going). She currently has about 180 publications, consisting of 88 journals and 95 proceedings. Joseph H.T. Kim, Ph.D., FSA, CERA, is Associate Professor of Applied Statistics at Yonsei University, Seoul, Korea. He holds a Ph.D. degree in Actuarial Science from the University of Waterloo, at which he taught as Assistant Professor. He also worked in the life insurance industry. He has published papers in Insurance Mathematics and Economics, Journal of Risk and Insurance, Journal of Banking and Finance, ASTIN Bulletin, and North American Actuarial Journal, among others. Nii-Armah Okine is a dissertator at the business school of University of Wisconsin-Madison with a major in actuarial science. He obtained his master’s degree in Actuarial science from Illinois State University. His research interests includes micro-level reserving, joint longitudinal-survival modeling, dependence modelling, micro insurance and machine learning. Margie Rosenberg - University of Wisconsin Emine Selin Sarıdaş is a doctoral candidate in the Statistics department of Mimar Sinan University. She holds a bachelor degree in Actuarial Science with a minor in Economics and a master degree in Actuarial Science from Hacettepe University. Her research interest includes dependence modeling, regression, loss models and life contingencies. Peng Shi is an associate professor in the Risk and Insurance Department at the Wisconsin School of Business. He is also the Charles &amp; Laura Albright Professor in Business and Finance. Professor Shi is an Associate of the Casualty Actuarial Society (ACAS) and a Fellow of the Society of Actuaries (FSA). He received a Ph.D. in actuarial science from the University of Wisconsin-Madison. His research interests are problems at the intersection of insurance and statistics. He has won several research awards, including the Charles A. Hachemeister Prize, the Ronald Bornhuetter Loss Reserve Prize, and the American Risk and Insurance Association Prize. Nariankadu D. Shyamalkumar (Shyamal) is an associate professor in the Department of Statistics and Actuarial Science at The University of Iowa. He is an Associate of the Society of Actuaries, and has volunteered in various elected and non-elected roles within the SoA. Having a broad theoretical interest as well as interest in computing, he has published in prominent actuarial, computer science, probability theory, and statistical journals. Moreover, he has worked in the financial industry, and since then served as an independent consultant to the insurance industry. He has experience educating actuaries in both Mexico and the US, serving in the roles of directing an undergraduate program, and as a graduate adviser for both masters and doctoral students. Jianxi Su is an Assistant Professor at the Department of Statistics at Purdue University. He is the Associate Director of Purdue’s Actuarial Science. Prior to joining Purdue in 2016, he completed the PhD at York University (2012-2015). He obtained the Fellow of the Society of Actuaries (FSA) in 2017. His research expertise are in dependence modelling, risk management, and pricing. During the PhD candidature, Jianxi also worked as a research associate at the Model Validation and ORSA Implementation team of Sun Life Financial (Toronto office). Tim Verdonck is associate professor at the University of Antwerp. He has a degree in Mathematics and a PhD in Science: Mathematics, obtained at the University of Antwerp. During his PhD he successfully took the Master in Insurance and the Master in Financial and Actuarial Engineering, both at KU Leuven. His research focuses on the adaptation and application of robust statistical methods for insurance and finance data. Krupa Viswanathan is an Associate Professor in the Risk, Insurance and Healthcare Management Department in the Fox School of Business, Temple University. She is an Associate of the Society of Actuaries. She teaches courses in Actuarial Science and Risk Management at the undergraduate and graduate levels. Her research interests include corporate governance of insurance companies, capital management, and sentiment analysis. She received her Ph.D. from The Wharton School of the University of Pennsylvania. Reviewers Our goal is to have the actuarial community author our textbooks in a collaborative fashion. Part of the writing process involves many reviewers who generously donated their time to help make this book better. They are: Yair Babab Chunsheng Ban, Ohio State University Vytaras Brazauskas, University of Wisconsin - Milwaukee Chun Yong Chew, Universiti Tunku Abdul Rahman (UTAR) Eren Dodd, University of Southampton Gordon Enderle, University of Wisconsin - Madison Rob Erhardt, Wake Forest University Runhun Feng, University of Illinois Liang (Jason) Hong, Robert Morris University Fei Huang, Australian National University Hirokazu (Iwahiro) Iwasawa Himchan Jeong, University of Connecticut Min Ji, Towson University Paul Herbert Johnson, University of Wisconsin - Madison Samuel Kolins, Lebonan Valley College Andrew Kwon-Nakamura, Zurich North America Ambrose Lo, University of Iowa Mark Maxwell, University of Texas at Austin Tatjana Miljkovic, Miami University Bell Ouelega, American University in Cairo Zhiyu (Frank) Quan, University of Connecticut Jiandong Ren, Western University Rajesh V. Sahasrabuddhe, Oliver Wyman Ranee Thiagarajah, Illinois State University Ping Wang, Saint Johns University Chengguo Weng, University of Waterloo Toby White, Drake University Michelle Xia, Northern Illinois University Di (Cindy) Xu, University of Nebraska - Lincoln Lina Xu, Columbia University Lu Yang, University of Amsterdam Jorge Yslas, University of Copenhagen Jeffrey Zheng, Temple University Hongjuan Zhou, Arizona State University For our Readers We hope that you find this book worthwhile and even enjoyable. For your convenience, at our Github Landing site (https://openacttexts.github.io/), you will find links to the book that you can (freely) download for offline reading, including a pdf version (for Adobe Acrobat) and an EPUB version suitable for mobile devices. Data for running our examples are available at the same site. In developing this book, we are emphasizing the online version that has lots of great features such as a glossary, code and solutions to examples that you can be revealed interactively. For example, you will find that the statistical code is hidden and can only be seen by clicking on terms such as R Code for Frequency Table Insample &lt;- read.csv(&quot;Insample.csv&quot;, header=T, na.strings=c(&quot;.&quot;), stringsAsFactors=FALSE) Insample2010 &lt;- subset(Insample, Year==2010) table(Insample2010$Freq) We hide the code because we don’t want to insist that you use the R statistical software (although we like it). Still, we encourage you to try some statistical code as you read the book – we have opted to make it easy to learn R as you go. We have even set up a separate R Code for Loss Data Analytics site to explain more of the details of the code. Freely available, interactive textbooks represent a new venture in actuarial education and we need your input. Although a lot of effort has gone into the development, we expect hiccoughs. Please let your instructor know about opportunities for improvement, write us through our project site, or contact chapter contributors directly with suggested improvements. "],
["C-Intro.html", "Chapter 1 Introduction to Loss Data Analytics 1.1 Relevance of Analytics to Insurance Activities 1.2 Insurance Company Operations 1.3 Case Study: Wisconsin Property Fund 1.4 Further Resources and Contributors", " Chapter 1 Introduction to Loss Data Analytics Chapter Preview. This book introduces readers to methods of analyzing insurance data. Section 1.1 begins with a discussion of why the use of data is important in the insurance industry. Section 1.2 gives a general overview of the purposes of analyzing insurance data which is reinforced in the Section 1.3 case study. Naturally, there is a huge gap between the broad goals summarized in the overview and a case study application; this gap is covered through the methods and techniques of data analysis covered in the rest of the text. 1.1 Relevance of Analytics to Insurance Activities In this section, you learn how to: Summarize the importance of insurance to consumers and the economy Describe analytics Identify data generating events associated with the timeline of a typical insurance contract 1.1.1 Nature and Relevance of Insurance This book introduces the process of using data to make decisions in an insurance context. It does not assume that readers are familiar with insurance but introduces insurance concepts as needed. If you are new to insurance, then it is probably easiest to think about an insurance policy that covers the contents of an apartment or house that you are renting (known as renters insurance) or the contents and property of a building that is owned by you or a friend (known as homeowners insurance). Another common example is automobile insurance. In the event of an accident, this policy may cover damage to your vehicle, damage to other vehicles in the accident, as well as medical expenses of those injured in the accident. One way to think about the nature of insurance is who buys it. Renters, homeowners, and auto insurance are examples of personal insurance in that these are policies issued to people. Businesses also buy insurance, such as coverage on their properties, and this is known as commercial insurance. The seller, an insurance company, is also known as an insurer. Even insurance companies need insurance; this is known as reinsurance. Another way to think about the nature of insurance is the type of risk being covered. In the U.S., policies such as renters and homeowners are known as property insurance whereas a policy such as auto that covers medical damages to people is known as casualty insurance. In the rest of the world, these are both known as nonlife or general insurance, to distinguish them from life insurance. Both life and non-life insurances are important components of the world economy. The Insurance Information Institute (2016) estimates that direct insurance premiums in the world for 2014 was 2,654,549 for life and 2,123,699 for non-life; these figures are in millions of U.S. dollars. As noted earlier, the total represents 6.2% of the world GDP. Put another way, life accounts for 55.5% of insurance premiums and 3.4% of world GDP whereas non-life accounts for 44.5% of insurance premiums and 2.8% of world GDP. Both life and non-life represent important economic activities. Insurance may not be as entertaining as the sports industry (another industry that depends heavily on data) but it does affect the financial livelihoods of many. By almost any measure, insurance is a major economic activity. On a global level, insurance premiums comprised about 6.2% of the world gross domestic product (GDP) in 2014, (Insurance Information Institute 2016). As examples, premiums accounted for 18.9% of GDP in Taiwan (the highest in the study) and represented 7.3% of GDP in the United States. On a personal level, almost everyone owning a home has insurance to protect themselves in the event of a fire, hailstorm, or some other calamitous event. Almost every country requires insurance for those driving a car. In sum, although not particularly entertaining, insurance plays an important role in the economies of nations and the lives of individuals. 1.1.2 What is Analytics? Insurance is a data-driven industry. Like all major corporations and organizations, insurers use data when trying to decide how much to pay employees, how many employees to retain, how to market their services and products, how to forecast financial trends, and so on. These represent general areas of activities that are not specific to the insurance industry. Although each industry has its own data nuances and needs, the collection, analysis and use of data is an activity shared by all, from the internet giants to the small business, by public and governmental organizations, and is not specific to the insurance industry. You will find that the data collection and analysis methods and tools introduced in this text are relevant for all. In any data-driven industry, analytics is a key to deriving and extracting information from data. But what is analytics? Making data-driven business decisions has been described as business analytics, business intelligence, and data science. These terms, among others, are sometimes used interchangeably and sometimes refer to distinct applications. Business intelligence may focus on processes of collecting data, often through databases and data warehouses, whereas business analytics utilizes tools and methods for statistical analyses of data. In contrast to these two terms that emphasize business applications, the term data science can encompass broader data related applications in many scientific domains. For our purposes, we use the term analytics to refer to the process of using data to make decisions. This process involves gathering data, understanding concepts and models of uncertainty, making general inferences, and communicating results. When introducing data methods in this text, we will focus on losses that arise from, or related to, obligations in insurance contracts. This could be the amount of damage to one’s apartment under a renter’s insurance agreement, the amount needed to compensate someone that you hurt in a driving accident, and the like. We call these obligations insurance claim. With this focus, we will be able to introduce and directly use generally applicable statistical tools and techniques. 1.1.3 Insurance Processes Yet another way to think about the nature of insurance is by the duration of an insurance contract, known as the term. This text will focus on short-term insurance contracts. By short-term, we mean contracts where the insurance coverage is typically provided for a year or six months. Most commercial and personal contracts are for a year so that will be our default duration. An important exception is U.S. auto policies that are often six months in length. In contrast, we typically think of life insurance as a long-term contract where the default is to have a multi-year contract. For example, if a person 25 years old purchases a whole life policy that pays upon death of the insured and that person does not die until age 100, then the contract is in force for 75 years. There are other important differences between life and non-life products. In life insurance, the benefit amount is often stipulated in the contract provisions. In contrast, most non-life contracts provide for compensation of insured losses which are unknown before the accident. (There are usually limits placed on the compensation amounts.) In a life insurance contract that stretches over many years, the time value of money plays a prominent role. In a non-life contract, the random amount of compensation takes priority. In both life and non-life insurances, the frequency of claims is very important. For many life insurance contracts, the insured event (such as death) happens only once. In contrast, for non-life insurances such as automobile, it is common for individuals (especially young male drivers) to get into more than one accident during a year. So, our models need to reflect this observation; we will introduce different frequency models that you may also see when studying life insurance. For short-term insurance, the framework of the probabilistic model is straightforward. We think of a one-period model (the period length, e.g., one year, will be specified in the situation). At the beginning of the period, the insured pays the insurer a known premium that is agreed upon by both parties to the contract. At the end of the period, the insurer reimburses the insured for a (possibly multivariate) random loss. This framework will be developed as we proceed; but we first focus on integrating this framework with concerns about how the data may arise. From an insurer’s viewpoint, contracts may be only for a year but they tend to be renewed. Moreover, payments arising from claims during the year may extend well beyond a single year. One way to describe the data arising from operations of an insurance company is to use a timeline granular approach. A process approach provides an overall view of the events occurring during the life of an insurance contract, and their nature – random or planned, loss events (claims) and contract changes events, and so forth. In this micro oriented view, we can think about what happens to a contract at various stages of its existence. Figure 1.1 traces a timeline of a typical insurance contract. Throughout the life of the contract, the company regularly processes events such as premium collection and valuation, described in Section 1.2; these are marked with an x on the timeline. Non-regular and unanticipated events also occur. To illustrate, \\(\\mathrm{t}_2\\) and \\(\\mathrm{t}_4\\) mark the event of an insurance claim (some contracts, such as life insurance, can have only a single claim). Times \\(\\mathrm{t}_3\\) and \\(\\mathrm{t}_5\\) mark events when a policyholder wishes to alter certain contract features, such as the choice of a deductible or the amount of coverage. From a company perspective, one can even think about the contract initiation (arrival, time \\(\\mathrm{t}_1\\)) and contract termination (departure, time \\(\\mathrm{t}_6\\)) as uncertain events. (Alternatively, for some purposes, you may condition on these events and treat them as certain.) Figure 1.1: Timeline of a Typical Insurance Policy. Arrows mark the occurrences of random events. Each x marks the time of scheduled events that are typically non-random. Show Quiz Solution 1.2 Insurance Company Operations In this section, you learn how to: Describe five major operational areas of insurance companies. Identify the role of data and analytics opportunities within each operational area. Armed with insurance data, the end goal is to use data to make decisions. We will learn more about methods of analyzing and extrapolating data in future chapters. To begin, let us think about why we want to do the analysis. We will take the insurance company’s viewpoint (not the insured person) and introduce ways of bringing money in, paying it out, managing costs, and making sure that we have enough money to meet obligations. The emphasis is on insurance-specific operations rather than on general business activities such as advertising, marketing, and human resources management. Specifically, in many insurance companies, it is customary to aggregate detailed insurance processes into larger operational units; many companies use these functional areas to segregate employee activities and areas of responsibilities. Actuaries, other financial analysts, and insurance regulators work within these units and use data for the following activities: Initiating Insurance. At this stage, the company makes a decision as to whether or not to take on a risk (the underwriting stage) and assign an appropriate premium (or rate). Insurance analytics has its actuarial roots in ratemaking, where analysts seek to determine the right price for the right risk. Renewing Insurance. Many contracts, particularly in general insurance, have relatively short durations such as 6 months or a year. Although there is an implicit expectation that such contracts will be renewed, the insurer has the opportunity to decline coverage and to adjust the premium. Analytics is also used at this policy renewal stage where the goal is to retain profitable customers. Claims Management. Analytics has long been used in (1) detecting and preventing claims fraud, (2) managing claim costs, including identifying the appropriate support for claims handling expenses, as well as (3) understanding excess layers for reinsurance and retention. Loss Reserving. Analytic tools are used to provide management with an appropriate estimate of future obligations and to quantify the uncertainty of those estimates. Solvency and Capital Allocation. Deciding on the requisite amount of capital and on ways of allocating capital among alternative investments are also important analytics activities. Companies must understand how much capital is needed so that they will have sufficient flow of cash available to meet their obligations at the times they are expected to materialize (solvency). This is an important question that concerns not only company managers but also customers, company shareholders, regulatory authorities, as well as the public at large. Related to issues of how much capital is the question of how to allocate capital to differing financial projects, typically to maximize an investor’s return. Although this question can arise at several levels, insurance companies are typically concerned with how to allocate capital to different lines of business within a firm and to different subsidiaries of a parent firm. Although data represent a critical component of solvency and capital allocation, other components including the local and global economic framework, the financial investments environment, and quite specific requirements according to the regulatory environment of the day, are also important. Because of the background needed to address these components, we will not address solvency, capital allocation, and regulation issues in this text. Nonetheless, for all operating functions, we emphasize that analytics in the insurance industry is not an exercise that a small group of analysts can do by themselves. It requires an insurer to make significant investments in their information technology, marketing, underwriting, and actuarial functions. As these areas represent the primary end goals of the analysis of data, additional background on each operational unit is provided in the following subsections. 1.2.1 Initiating Insurance Setting the price of an insurance product can be a perplexing problem. This is in contrast to other industries such as manufacturing where the cost of a product is (relatively) known and provides a benchmark for assessing a market demand price. Similarly, in other areas of financial services, market prices are available and provide the basis for a market-consistent pricing structure of products. However, for many lines of insurance, the cost of a product is uncertain and market prices are unavailable. Expectations of the random cost is a reasonable place to start for a price. (If you have studied finance, then you will recall that an expectation is the optimal price for a risk-neutral insurer.) It has been traditional in insurance pricing to begin with the expected cost. Insurers then add margins to this, to account for the product’s riskiness, expenses incurred in servicing the product, and an allowance for profit/surplus of the company. Use of expected costs as a foundation for pricing is prevalent in some lines of the insurance business. These include automobile and homeowners insurance. For these lines, analytics has served to sharpen the market by making the calculation of the product’s expected cost more precise. The increasing availability of the internet to consumers has also promoted transparency in pricing; in today’s marketplace, consumers have ready access to competing quotes from a host of insurers. Insurers seek to increase their market share by refining their risk classification systems, thus achieving a better approximation of the products’ prices and enabling cream-skimming underwriting strategies (“cream-skimming” is a phrase used when the insurer underwrites only the best risks). Recent surveys (e.g., Earnix (2013)) indicate that pricing is the most common use of analytics among insurers. Underwriting, the process of classifying risks into homogeneous categories and assigning policyholders to these categories, lies at the core of ratemaking. Policyholders within a class (category) have similar risk profiles and so are charged the same insurance price. This is the concept of an actuarially fair premium; it is fair to charge different rates to policyholders only if they can be separated by identifiable risk factors. An early article, Two Studies in Automobile Insurance Ratemaking (Bailey and LeRoy 1960), provided a catalyst to the acceptance of analytic methods in the insurance industry. This paper addresses the problem of classification ratemaking. It describes an example of automobile insurance that has five use classes cross-classified with four merit rating classes. At that time, the contribution to premiums for use and merit rating classes were determined independently of each other. Thinking about the interacting effects of different classification variables is a more difficult problem. 1.2.2 Renewing Insurance Insurance is a type of financial service and, like many service contracts, insurance coverage is often agreed upon for a limited time period at which time coverage commitments are complete. Particularly for general insurance, the need for coverage continues and so efforts are made to issue a new contract providing similar coverage, when the existing contract comes to the end of its term. This is called policy renewal. Renewal issues can also arise in life insurance, e.g., term (temporary) life insurance. At the same time other contracts, such as life annuities, terminate upon the insured’s death and so issues of renewability are irrelevant. In the absence of legal restrictions, at renewal the insurer has the opportunity to: accept or decline to underwrite the risk; and determine a new premium, possibly in conjunction with a new classification of the risk. Risk classification and rating at renewal is based on two types of information. First, at the initial stage, the insurer has available many rating variables upon which decisions can be made. Many variables will not change, e.g., sex, whereas others are likely to have changed, e.g., age, and still others may or may not change, e.g., credit score. Second, unlike the initial stage, at renewal the insurer has available a history of policyholder’s loss experience, and this history can provide insights into the policyholder that are not available from rating variables. Modifying premiums with claims history is known as experience rating, also sometimes referred to as merit rating. Experience rating methods are either applied retrospectively or prospectively. With retrospective methods, a refund of a portion of the premium is provided to the policyholder in the event of favorable (to the insurer) experience. Retrospective premiums are common in life insurance arrangements (where policyholders earn dividends in the U.S., bonuses in the U.K., and profit sharing in Israeli term life coverage). In general insurance, prospective methods are more common, where favorable insured experience is rewarded through a lower renewal premium. Claims history can provide information about a policyholder’s risk appetite. For example, in personal lines it is common to use a variable to indicate whether or not a claim has occurred in the last three years. As another example, in a commercial line such as worker’s compensation, one may look to a policyholder’s average claim frequency or severity over the last three years. Claims history can reveal information that is otherwise hidden (to the insurer) about the policyholder. 1.2.3 Claims and Product Management In some of areas of insurance, the process of paying claims for insured events is relatively straightforward. For example, in life insurance, a simple death certificate is all that is needed to pay the benefit amount as provided in the contract. However, in non-life areas such as property and casualty insurance, the process can be much more complex. Think about even a relatively simple insured event such as automobile accident. Here, it is often required to determine which party is at fault, one needs to assess damage to all of the vehicles and people involved in the incident, both insured and non-insured, the expenses incurred in assessing the damages must be assessed, and so forth. The process of determining coverage, legal liability, and settling claims is known as claims adjustment. Insurance managers sometimes use the phrase claims leakage to mean dollars lost through claims management inefficiencies. There are many ways in which analytics can help manage the claims process, c.f., Gorman and Swenson (2013). Historically, the most important has been fraud detection. The claim adjusting process involves reducing information asymmetry (the claimant knows what happened; the company knows some of what happened). Mitigating fraud is an important part of the claims management process. Fraud detection is only one aspect of managing claims. More broadly, one can think about claims management as consisting of the following components: Claims triaging. Just as in the medical world, early identification and appropriate handling of high cost claims (patients, in the medical world), can lead to dramatic savings. For example, in workers compensation, insurers look to achieve early identification of those claims that run the risk of high medical costs and a long payout period. Early intervention into these cases could give insurers more control over the handling of the claim, the medical treatment, and the overall costs with an earlier return-to-work. Claims processing. The goal is to use analytics to identify routine situations that are anticipated to have small payouts. More complex situations may require more experienced adjusters and legal assistance to appropriately handle claims with high potential payouts. Adjustment decisions. Once a complex claim has been identified and assigned to an adjuster, analytic driven routines can be established to aid subsequent decision-making processes. Such processes can also be helpful for adjusters in developing case reserves, an estimate of the insurer’s future liability. This is an important input to the insurer’s loss reserves, described in Section 1.2.4. In addition to the insured’s reimbursement for losses, the insurer also needs to be concerned with another source of revenue outflow, expenses. loss adjustment expenses are part of an insurer’s cost of managing claims. Analytics can be used to reduce expenses directly related to claims handling (allocated) as well as general staff time for overseeing the claims processes (unallocated). The insurance industry has high operating costs relative to other portions of the financial services sectors. In addition to claims payments, there are many other ways in which insurers use data to manage their products. We have already discussed the need for analytics in underwriting, that is, risk classification at the initial acquisition and renewal stages. Insurers are also interested in which policyholders elect to renew their contract and, as with other products, monitor customer loyalty. Analytics can also be used to manage the portfolio, or collection, of risks that an insurer has acquired. When the risk is initially obtained, the insurer’s risk can be managed by imposing contract parameters that modify contract payouts. Chapters 3 and 10 describe common modifications including coinsurance, deductibles and policy upper limits. After the contract has been agreed upon with an insured, the insurer may still modify its net obligation by entering into a reinsurance agreement. This type of agreement is with a reinsurer, an insurer of an insurer. It is common for insurance companies to purchase insurance on its portfolio of risks to gain protection from unusual events, just as people and other companies do. 1.2.4 Loss Reserving An important feature that distinguishes insurance from other sectors of the economy is the timing of the exchange of considerations. In manufacturing, payments for goods are typically made at the time of a transaction. In contrast, for insurance, money received from a customer occurs in advance of benefits or services; these are rendered at a later date when the insured event occurs. This leads to the need to hold a reservoir of wealth to meet future obligations in respect to obligations made, and to gain the trust of the insureds that the company will be able to fulfill its commitments. The size of this reservoir of wealth, and the importance of ensuring its adequacy, is a major concern for the insurance industry. Setting aside money for unpaid claims is known as loss reserving; in some jurisdictions, reserves are also known as technical provisions. We saw in Figure 1.1 several times at which a company summarizes its financial position; these times are known as valuation dates. Claims that arise prior to valuation dates have typically been paid, are in the process of being paid, or are about to be paid; claims in the future of these valuation dates are unknown. A company must estimate these outstanding liabilities when determining its financial strength. Accurately determining loss reserves is important to insurers for many reasons. Loss reserves represent an anticipated claim that the insurer owes its customers. Under-reserving may result in a failure to meet claim liabilities. Conversely, an insurer with excessive reserves may present a weaker financial position than it truly has. Reserves provide an estimate for the unpaid cost of insurance that can be used for pricing contracts. Loss reserving is required by laws and regulations. The public has a strong interest in the financial strength and solvency of insurers. In addition to insurance company management and regulators, other stakeholders such as investors and customers make decisions that depend on company loss reserves. Loss reserving is a topic where there are substantive differences between life and general (also known as property and casualty, or non-life), insurance. In life insurance, the severity (amount of loss) is often not a source of uncertainty as payouts are specified in the contract. The frequency, driven by mortality of the insured, is a concern. However, because of the length of time for settlement of life insurance contracts, the time value of money uncertainty as measured from issue to date of payment can dominate frequency concerns. For example, for an insured who purchases a life contract at age 20, it would not be unusual for the contract to still be open in 60 years time, when the insured celebrates his or her 80th birthday. See, for example, Bowers et al. (1986) or Dickson, Hardy, and Waters (2013) for introductions to reserving for life insurance. Show Quiz Solution 1.3 Case Study: Wisconsin Property Fund In this section, we use the Wisconsin Property Fund as a case study. You learn how to: Describe how data generating events can produce data of interest to insurance analysts. Produce relevant summary statistics for each variable. Describe how these summary statistics can be used in each of the major operational areas of an insurance company. Let us illustrate the kind of data under consideration and the goals that we wish to achieve by examining the Local Government Property Insurance Fund (LGPIF), an insurance pool administered by the Wisconsin Office of the Insurance Commissioner. The LGPIF was established to provide property insurance for local government entities that include counties, cities, towns, villages, school districts, and library boards. The fund insures local government property such as government buildings, schools, libraries, and motor vehicles. The fund covers all property losses except those resulting from flood, earthquake, wear and tear, extremes in temperature, mold, war, nuclear reactions, and embezzlement or theft by an employee. The fund covers over a thousand local government entities who pay approximately \\$25 million in premiums each year and receive insurance coverage of about \\$75 billion. State government buildings are not covered; the LGPIF is for local government entities that have separate budgetary responsibilities and who need insurance to moderate the budget effects of uncertain insurable events. Coverage for local government property has been made available by the State of Wisconsin since 1911, thus providing a wealth of historical data. In this illustration, we restrict consideration to claims from coverage of building and contents; we do not consider claims from motor vehicles and specialized equipment owned by local entities (such as snow plowing machines). We also consider only claims that are closed, with obligations fully met. 1.3.1 Fund Claims Variables: Frequency and Severity At a fundamental level, insurance companies accept premiums in exchange for promises to compensate a policyholder upon the occurrence of an insured event. Indemnification is the compensation provided by the insurer for incurred hurt, loss, or damage that is covered by the policy. This compensation is also known as a claim. The extent of the payout, known as the severity, is a key financial expenditure for an insurer. In terms of money outgo, an insurer is indifferent to having ten claims of 100 when compared to one claim of 1,000. Nonetheless, it is common for insurers to study how often claims arise, known as the frequency of claims. The frequency is important for expenses, but it also influences contractual parameters (such as deductibles and policy limits that are described later) that are written on a per occurrence basis, is routinely monitored by insurance regulators, and can be a key driver in the overall indemnification obligation of the insurer. We shall consider the frequency and severity as the two main claim variables that we wish to understand, model, and manage. To illustrate, in 2010 there were 1,110 policyholders in the property fund who experienced a total of 1,377 claims. Table 1.1 shows the distribution. Almost two-thirds (0.637) of the policyholders did not have any claims and an additional 18.8% had only one claim. The remaining 17.5% (=1 - 0.637 - 0.188) had more than one claim; the policyholder with the highest number recorded 239 claims. The average number of claims for this sample was 1.24 (=1377/1110). Table 1.1: 2010 Claims Frequency Distribution Type Number 0 1 2 3 4 5 6 7 8 9 or more Sum Count 707 209 86 40 18 12 9 4 6 19 1,110 Claims 0 209 172 120 72 60 54 28 48 617 1,377 Proportion 0.637 0.188 0.077 0.036 0.016 0.011 0.008 0.004 0.005 0.017 1.000 R Code for Frequency Table Insample &lt;- read.csv(&quot;Insample.csv&quot;, header=T, na.strings=c(&quot;.&quot;), stringsAsFactors=FALSE) Insample2010 &lt;- subset(Insample, Year==2010) table(Insample2010$Freq) For the severity distribution, a common approach is to examine the distribution of the sample of 1,377 claims. However, another common approach is to examine the distribution of the average claims of those policyholders with claims. In our 2010 sample, there were 403 (=1110-707) such policyholders. For 209 of these policyholders with one claim, the average claim equals the only claim they experienced. For the policyholder with highest frequency, the average claim is an average over 239 separately reported claim events. This average is also known as the pure premium or loss cost. Table 1.2 summarizes the sample distribution of average severities from the 403 policyholders who made a claim; it shows that the average claim amount was 56,330 (all amounts are in U.S. Dollars). However, the average gives only a limited look at the distribution. More information can be gleaned from the summary statistics which show a very large claim in the amount of 12,920,000. Figure 1.2 provides further information about the distribution of sample claims, showing a distribution that is dominated by this single large claim so that the histogram is not very helpful. Even when removing the large claim, you will find a distribution that is skewed to the right. A generally accepted technique is to work with claims in logarithmic units especially for graphical purposes; the corresponding figure in the right-hand panel is much easier to interpret. Table 1.2: 2010 Average Severity Distribution Minimum First Quartile Median Mean Third Quartile Maximum 167 2,226 4,951 56,330 11,900 12,920,000 Figure 1.2: Distribution of Positive Average Severities R Code for Severity Distribution Table and Figures Insample &lt;- read.csv(&quot;Data/PropertyFundInsample.csv&quot;, header=T, na.strings=c(&quot;.&quot;), stringsAsFactors=FALSE) Insample2010 &lt;- subset(Insample, Year==2010) InsamplePos2010 &lt;- subset(Insample2010, yAvg&gt;0) # Table summary(InsamplePos2010$yAvg) length(InsamplePos2010$yAvg) # Figures par(mfrow=c(1, 2)) hist(InsamplePos2010$yAvg, main=&quot;&quot;, xlab=&quot;Average Claims&quot;) hist(log(InsamplePos2010$yAvg), main=&quot;&quot;, xlab=&quot;Logarithmic Average Claims&quot;) 1.3.2 Fund Rating Variables Developing models to represent and manage the two outcome variables, frequency and severity, is the focus of the early chapters of this text. However, when actuaries and other financial analysts use those models, they do so in the context of external variables. In general statistical terminology, one might call these explanatory or predictor variables; there are many other names in statistics, economics, psychology, and other disciplines. Because of our insurance focus, we call them rating variables as they will be useful in setting insurance rates and premiums. We earlier considered observations from a sample of 1,110 policyholders which may seem like a lot. However, as we will see in our forthcoming applications, because of the preponderance of zeros and the skewed nature of claims, actuaries typically yearn for more data. One common approach that we adopt here is to examine outcomes from multiple years, thus increasing the sample size. We will discuss the strengths and limitations of this strategy later but, at this juncture, we just wish to show the reader how it works. Specifically, Table 1.3 shows that we now consider policies over five years of data, 2006, …, 2010, inclusive. The data begins in 2006 because there was a shift in claim coding in 2005 so that comparisons with earlier years are not helpful. To mitigate the effect of open claims, we consider policy years prior to 2011. An open claim means that not all of the obligations for the claim are known at the time of the analysis; for some claims, such an injury to a person in an auto accident or in the workplace, it can take years before costs are fully known. Table 1.3: Claims Summary by Policyholder Year Average Frequency Average Severity Average Coverage Number of Policyholders 2006 0.951 9,695 32,498,186 1,154 2007 1.167 6,544 35,275,949 1,138 2008 0.974 5,311 37,267,485 1,125 2009 1.219 4,572 40,355,382 1,112 2010 1.241 20,452 41,242,070 1,110 R Code for Claims Summary by Policyholder Insample &lt;- read.csv(&quot;Data/PropertyFundInsample.csv&quot;, header=T, na.strings=c(&quot;.&quot;), stringsAsFactors=FALSE) library(doBy) T1A &lt;- summaryBy(Freq ~ Year, data = Insample, FUN = function(x) { c(m = mean(x), num=length(x)) } ) T1B &lt;- summaryBy(yAvg ~ Year, data = Insample, FUN = function(x) { c(m = mean(x), num=length(x)) } ) T1C &lt;- summaryBy(BCcov ~ Year, data = Insample, FUN = function(x) { c(m = mean(x), num=length(x)) } ) Table1In &lt;- cbind(T1A[1],T1A[2],T1B[2],T1C[2],T1A[3]) names(Table1In) &lt;- c(&quot;Year&quot;, &quot;Average Frequency&quot;,&quot;Average Severity&quot;, &quot;Average&quot;,&quot;Number of Policyholders&quot;) Table1In Table 1.3 shows that the average claim varies over time, especially with the high 2010 value (that we saw was due to a single large claim)1. The total number of policyholders is steadily declining and, conversely, the coverage is steadily increasing. The coverage variable is the amount of coverage of the property and contents. Roughly, you can think of it as the maximum possible payout of the insurer. For our immediate purposes, the coverage is our first rating variable. Other things being equal, we would expect that policyholders with larger coverage will have larger claims. We will make this vague idea much more precise as we proceed, and also justify this expectation with data. For a different look at the 2006-2010 data, Table 1.4 summarizes the distribution of our two outcomes, frequency and claims amount. In each case, the average exceeds the median, suggesting that the two distributions are right-skewed. In addition, the table summarizes our continuous rating variables, coverage and deductible amount. The table also suggests that these variables also have right-skewed distributions. Table 1.4: Summary of Claim Frequency and Severity, Deductibles, and Coverages Minimum Median Average Maximum Claim Frequency 0 0 1.109 263 Claim Severity 0 0 9,292 12,922,218 Deductible 500 1,000 3,365 100,000 Coverage (000’s) 8.937 11,354 37,281 2,444,797 R Code for Summary of Claim Frequency and Severity, Deductibles, and Coverages Insample &lt;- read.csv(&quot;Data/PropertyFundInsample.csv&quot;, header=T, na.strings=c(&quot;.&quot;), stringsAsFactors=FALSE) t1&lt;- summaryBy(Insample$Freq ~ 1, data = Insample, FUN = function(x) { c(ma=min(x), m1=median(x),m=mean(x),mb=max(x)) } ) names(t1) &lt;- c(&quot;Minimum&quot;, &quot;Median&quot;,&quot;Average&quot;, &quot;Maximum&quot;) t2 &lt;- summaryBy(Insample$yAvg ~ 1, data = Insample, FUN = function(x) { c(ma=min(x), m1=median(x), m=mean(x),mb=max(x)) } ) names(t2) &lt;- c(&quot;Minimum&quot;, &quot;Median&quot;,&quot;Average&quot;, &quot;Maximum&quot;) t3 &lt;- summaryBy(Deduct ~ 1, data = Insample, FUN = function(x) { c(ma=min(x), m1=median(x), m=mean(x),mb=max(x)) } ) names(t3) &lt;- c(&quot;Minimum&quot;, &quot;Median&quot;,&quot;Average&quot;, &quot;Maximum&quot;) t4 &lt;- summaryBy(BCcov/1000 ~ 1, data = Insample, FUN = function(x) { c(ma=min(x), m1=median(x), m=mean(x),mb=max(x)) } ) names(t4) &lt;- c(&quot;Minimum&quot;, &quot;Median&quot;,&quot;Average&quot;, &quot;Maximum&quot;) Table2 &lt;- rbind(t1,t2,t3,t4) Table2a &lt;- round(Table2,3) Rowlable &lt;- rbind(&quot;Claim Frequency&quot;,&quot;Claim Severity&quot;,&quot;Deductible&quot;,&quot;Coverage (000&#39;s)&quot;) Table2aa &lt;- cbind(Rowlable,as.matrix(Table2a)) Table2aa The following display describes the rating variables considered in this chapter. Hopefully, these are variables that you think might naturally be related to claims outcomes. You can learn more about them in Frees, Lee, and Yang (2016). To handle the skewness, we henceforth focus on logarithmic transformations of coverage and deductibles. Description of Rating Variables \\[{\\small \\begin{matrix} \\begin{array}{ l | l} \\hline Variable &amp; Description \\\\ \\hline \\text{EntityType} &amp; \\text{Categorical variable that is one of six types: (Village, City,} \\\\ &amp; ~~~~ \\text{County, Misc, School, or Town)} \\\\ \\text{LnCoverage} &amp; \\text{Total building and content coverage, in logarithmic millions of dollars}\\\\ \\text{LnDeduct} &amp; \\text{Deductible, in logarithmic dollars} \\\\ \\text{AlarmCredit} &amp; \\text{Categorical variable that is one of four types: (0, 5, 10, or 15)} \\\\ &amp; ~~~~ \\text{for automatic smoke alarms in main rooms} \\\\ \\text{NoClaimCredit} &amp; \\text{Binary variable to indicate no claims in the past two years} \\\\ \\text{Fire5 } &amp; \\text{Binary variable to indicate the fire class is below 5} \\\\ &amp; ~~~~ \\text{(The range of fire class is 0 to 10)} \\\\ \\hline \\end{array} \\end{matrix}}\\] To get a sense of the relationship between the non-continuous rating variables and claims, Table 1.5 relates the claims outcomes to these categorical variables. Table 1.5 suggests substantial variation in the claim frequency and average severity of the claims by entity type. It also demonstrates higher frequency and severity for the \\({\\tt Fire5}\\) variable and the reverse for the \\({\\tt NoClaimCredit}\\) variable. The relationship for the \\({\\tt Fire5}\\) variable is counter-intuitive in that one would expect lower claim amounts for those policyholders in areas with better public protection (when the protection code is five or less). Naturally, there are other variables that influence this relationship. We will see that these background variables are accounted for in the subsequent multivariate regression analysis, which yields an intuitive, appealing (negative) sign for the \\({\\tt Fire5}\\) variable. Table 1.5: Claims Summary by Entity Type, Fire Class, and No Claim Credit Variable Number of Policies Claim Frequency Average Severity EntityType Village 1,341 0.452 10,645 City 793 1.941 16,924 County 328 4.899 15,453 Misc 609 0.186 43,036 School 1,597 1.434 64,346 Town 971 0.103 19,831 Fire Fire5=0 2,508 0.502 13,935 Fire5=1 3,131 1.596 41,421 No Claims Credit NoClaimCredit=0 3,786 1.501 31,365 NoClaimCredit=1 1,853 0.310 30,499 Total 5,639 1.109 31,206 R Code for Claims Summary by Entity Type, Fire Class, and No Claim Credit ByVarSumm&lt;-function(datasub){ tempA &lt;- summaryBy(Freq ~ 1 , data = datasub, FUN = function(x) { c(m = mean(x), num=length(x)) } ) datasub1 &lt;- subset(datasub, yAvg&gt;0) tempB &lt;- summaryBy(yAvg ~ 1, data = datasub1,FUN = function(x) { c(m = mean(x)) } ) tempC &lt;- merge(tempA,tempB,all.x=T)[c(2,1,3)] tempC1 &lt;- as.matrix(tempC) return(tempC1) } datasub &lt;- subset(Insample, TypeVillage == 1); t1 &lt;- ByVarSumm(datasub) datasub &lt;- subset(Insample, TypeCity == 1); t2 &lt;- ByVarSumm(datasub) datasub &lt;- subset(Insample, TypeCounty == 1); t3 &lt;- ByVarSumm(datasub) datasub &lt;- subset(Insample, TypeMisc == 1); t4 &lt;- ByVarSumm(datasub) datasub &lt;- subset(Insample, TypeSchool == 1); t5 &lt;- ByVarSumm(datasub) datasub &lt;- subset(Insample, TypeTown == 1); t6 &lt;- ByVarSumm(datasub) datasub &lt;- subset(Insample, Fire5 == 0); t7 &lt;- ByVarSumm(datasub) datasub &lt;- subset(Insample, Fire5 == 1); t8 &lt;- ByVarSumm(datasub) datasub &lt;- subset(Insample, Insample$NoClaimCredit == 0); t9 &lt;- ByVarSumm(datasub) datasub &lt;- subset(Insample, Insample$NoClaimCredit == 1); t10 &lt;- ByVarSumm(datasub) t11 &lt;- ByVarSumm(Insample) Tablea &lt;- rbind(t1,t2,t3,t4,t5,t6,t7,t8,t9,t10,t11) Tableaa &lt;- round(Tablea,3) Rowlable &lt;- rbind(&quot;Village&quot;,&quot;City&quot;,&quot;County&quot;,&quot;Misc&quot;,&quot;School&quot;, &quot;Town&quot;,&quot;Fire5--No&quot;,&quot;Fire5--Yes&quot;,&quot;NoClaimCredit--No&quot;, &quot;NoClaimCredit--Yes&quot;,&quot;Total&quot;) Table4 &lt;- cbind(Rowlable,as.matrix(Tableaa)) Table4 Table 1.6 shows the claims experience by alarm credit. It underscores the difficulty of examining variables individually. For example, when looking at the experience for all entities, we see that policyholders with no alarm credit have on average lower frequency and severity than policyholders with the highest (15%, with 24/7 monitoring by a fire station or security company) alarm credit. In particular, when we look at the entity type School, the frequency is 0.422 and the severity 25,523 for no alarm credit, whereas for the highest alarm level it is 2.008 and 85,140. This may simply imply that entities with more claims are the ones that are likely to have an alarm system. Summary tables do not examine multivariate effects; for example, Table 1.5 ignores the effect of size (as we measure through coverage amounts) that affect claims. Table 1.6: Claims Summary by Entity Type and Alarm Credit (AC) Category Entity Type AC0 Claim Frequency AC0 Avg. Severity AC0 Num. Policies AC5 Claim Frequency AC5 Avg. Severity AC5 Num. Policies Village 0.326 11,078 829 0.278 8,086 54 City 0.893 7,576 244 2.077 4,150 13 County 2.140 16,013 50 - - 1 Misc 0.117 15,122 386 0.278 13,064 18 School 0.422 25,523 294 0.410 14,575 122 Town 0.083 25,257 808 0.194 3,937 31 Total 0.318 15,118 2,611 0.431 10,762 239 Claims Summary by Entity Type and Alarm Credit (AC) Category Entity Type AC10 Claim Frequency AC10 Avg. Severity AC10 Num. Policies AC15 Claim Frequency AC15 Avg. Severity AC15 Num. Policies Village 0.500 8,792 50 0.725 10,544 408 City 1.258 8,625 31 2.485 20,470 505 County 2.125 11,688 8 5.513 15,476 269 Misc 0.077 3,923 26 0.341 87,021 179 School 0.488 11,597 168 2.008 85,140 1,013 Town 0.091 2,338 44 0.261 9,490 88 Total 0.517 10,194 327 2.093 41,458 2,462 R Code for Claims Summary by Entity Type and Alarm Credit Category #Claims Summary by Entity Type and Alarm Credit ByVarSumm&lt;-function(datasub){ tempA &lt;- summaryBy(Freq ~ AC00 , data = datasub, FUN = function(x) { c(m = mean(x), num=length(x)) } ) datasub1 &lt;- subset(datasub, yAvg&gt;0) if(nrow(datasub1)==0) { n&lt;-nrow(datasub) return(c(0,0,n)) } else { tempB &lt;- summaryBy(yAvg ~ AC00, data = datasub1, FUN = function(x) { c(m = mean(x)) } ) tempC &lt;- merge(tempA,tempB,all.x=T)[c(2,4,3)] tempC1 &lt;- as.matrix(tempC) return(tempC1) } } AlarmC &lt;- 1*(Insample$AC00==1) + 2*(Insample$AC05==1)+ 3*(Insample$AC10==1)+ 4*(Insample$AC15==1) ByVarCredit&lt;-function(ACnum){ datasub &lt;- subset(Insample, TypeVillage == 1 &amp; AlarmC == ACnum); t1 &lt;- ByVarSumm(datasub) datasub &lt;- subset(Insample, TypeCity == 1 &amp; AlarmC == ACnum); t2 &lt;- ByVarSumm(datasub) datasub &lt;- subset(Insample, TypeCounty == 1 &amp; AlarmC == ACnum); t3 &lt;- ByVarSumm(datasub) datasub &lt;- subset(Insample, TypeMisc == 1 &amp; AlarmC == ACnum); t4 &lt;- ByVarSumm(datasub) datasub &lt;- subset(Insample, TypeSchool == 1 &amp; AlarmC == ACnum); t5 &lt;- ByVarSumm(datasub) datasub &lt;- subset(Insample, TypeTown == 1 &amp; AlarmC ==ACnum); t6 &lt;- ByVarSumm(datasub) datasub &lt;- subset(Insample, AlarmC == ACnum); t7 &lt;- ByVarSumm(datasub) Tablea &lt;- rbind(t1,t2,t3,t4,t5,t6,t7) Tableaa &lt;- round(Tablea,3) Rowlable &lt;- rbind(&quot;Village&quot;,&quot;City&quot;,&quot;County&quot;,&quot;Misc&quot;,&quot;School&quot;, &quot;Town&quot;,&quot;Total&quot;) Table4 &lt;- cbind(Rowlable,as.matrix(Tableaa)) } Table4a &lt;- ByVarCredit(1) #Claims Summary by Entity Type and Alarm Credit==00 Table4b &lt;- ByVarCredit(2) #Claims Summary by Entity Type and Alarm Credit==05 Table4c &lt;- ByVarCredit(3) #Claims Summary by Entity Type and Alarm Credit==10 Table4d &lt;- ByVarCredit(4) #Claims Summary by Entity Type and Alarm Credit==15 1.3.3 Fund Operations We have now seen the Fund’s two outcome variables: a count variable for the number of claims, and a continuous variable for the claims amount. We have also introduced a continuous rating variable (coverage); a discrete quantitative variable (logarithmic deductibles); two binary rating variables (no claims credit and fire class); and two categorical rating variables (entity type and alarm credit). Subsequent chapters will explain how to analyze and model the distribution of these variables and their relationships. Before getting into these technical details, let us first think about where we want to go. General insurance company functional areas are described in Section 1.2; let us now think about how these areas might apply in the context of the property fund. Initiating Insurance Because this is a government sponsored fund, we do not have to worry about selecting good or avoiding poor risks; the fund is not allowed to deny a coverage application from a qualified local government entity. If we do not have to underwrite, what about how much to charge? We might look at the most recent experience in 2010, where the total fund claims were approximately 28.16 million USD (\\(=1377 \\text{ claims} \\times 20452 \\text{ average severity}\\)). Dividing that among 1,110 policyholders, that suggests a rate of 24,370 ( \\(\\approx\\) 28,160,000/1110). However, 2010 was a bad year; using the same method, our premium would be much lower based on 2009 data. This swing in premiums would defeat the primary purpose of the fund, to allow for a steady charge that local property managers could utilize in their budgets. Having a single price for all policyholders is nice but hardly seems fair. For example, Table 1.5 suggests that Schools have much higher claims than other entities and so should pay more. However, simply doing the calculation on an entity by entity basis is not right either. For example, we saw in Table 1.6 that had we used this strategy, entities with a 15% alarm credit (for good behavior, having top alarm systems) would actually wind up paying more. So, we have the data for thinking about the appropriate rates to charge but will need to dig deeper into the analysis. We will explore this topic further in Chapter 7 on premium calculation fundamentals. Selecting appropriate risks is introduced in Chapter 8 on risk classification. Renewing Insurance Although property insurance is typically a one-year contract, Table 1.3 suggests that policyholders tend to renew; this is typical of general insurance. For renewing policyholders, in addition to their rating variables we have their claims history and this claims history can be a good predictor of future claims. For example, Table 1.5 shows that policyholders without a claim in the last two years had much lower claim frequencies than those with at least one accident (0.310 compared to 1.501); a lower predicted frequency typically results in a lower premium. This is why it is common for insurers to use variables such as \\({\\tt NoClaimCredit}\\) in their rating. We will explore this topic further in Chapter 9 on experience rating. Claims Management Of course, the main story line of the 2010 experience was the large claim of over 12 million USD, nearly half the claims for that year. Are there ways that this could have been prevented or mitigated? Are their ways for the fund to purchase protection against such large unusual events? Another unusual feature of the 2010 experience noted earlier was the very large frequency of claims (239) for one policyholder. Given that there were only 1,377 claims that year, this means that a single policyholder had 17.4 % of the claims. This also suggests opportunities for managing claims, the subject of Chapter 10. Loss Reserving In our case study, we look only at the one year outcomes of closed claims (the opposite of open). However, like many lines of insurance, obligations from insured events to buildings such as fire, hail, and the like, are not known immediately and may develop over time. Other lines of business, including those where there are injuries to people, take much longer to develop. Chapter 11 introduces this concern and loss reserving, the discipline of determining how much the insurance company should retain to meet its obligations. Show Quiz Solution 1.4 Further Resources and Contributors Contributor Edward W. (Jed) Frees, University of Wisconsin-Madison, is the principal author of the initial version of this chapter. Email: jfrees@bus.wisc.edu for chapter comments and suggested improvements. Chapter reviewers include: Yair Babad, Chunsheng Ban, Aaron Bruhn, Gordon Enderle, Hirokazu (Iwahiro) Iwasawa, Bell Ouelega. This book introduces loss data analytic tools that are most relevant to actuaries and other financial risk analysts. We have also introduced you to many new insurance terms; more terms can be found at the NAIC Glossary (2018). Here are a few reference cited in the chapter. Bibliography "],
["C-Frequency-Modeling.html", "Chapter 2 Modelización de la frecuencia 2.1 Distribuciones de frecuencias 2.2 Distribuciones de frecuencias elementales 2.3 La clase (a, b, 0) 2.4 Estimación de las distribuciones de frecuencias 2.5 Otras Distribuciones de Frecuencias 2.6 Distribuciones Mixtas 2.7 Bondad del Ajuste 2.8 Ejercicios 2.9 Recursos adicionales y autores", " Chapter 2 Modelización de la frecuencia Resumen del capítulo. Uno de los objetivos primordiales de las aseguradoras es estimar la magnitud de las pérdidas agregadas que debe soportar en virtud de sus contratos de seguro. Las pérdidas agregadas se ven afectadas tanto por la frecuencia de los eventos asegurados como por la cuantía del evento asegurado. Descomponer las pérdidas agregadas en estos dos componentes, cada uno de los cuales requiere una gran atención, es fundamental para el análisis y tarificación. En este capítulo se examinan las distribuciones de frecuencia, las medidas resumen y las técnicas de estimación de los parámetros. En la Sección 2.1, presentamos la terminología y discutimos las razones por las que estudiamos la frecuencia y la cuantía por separado. Los fundamentos de las distribuciones y medidas de frecuencia se presentan en la Sección 2.2 junto con tres de las principales distribuciones: binomial, Poisson, y binomial negativa. Estas tres distribuciones son miembros de lo que se conoce como la clase de distribuciones (a,b,0), una característica distintiva e identificadora que permite un cálculo eficiente de las probabilidades, que se discute con más detalle en la Sección 2.3. Cuando se ajusta una distribución a un conjunto de datos, es necesario estimar los valores de los parámetros y en la Sección 2.4, se explica el procedimiento para la estimación por máxima verosimilitud. En el caso de los datos de seguros, la observación de 0, que indica la ocurrencia de cero de un evento concreto, es frecuente y puede merecer una atención adicional. Según el tipo de datos, y explicado con más detalle en la Sección 2.5, puede ser imposible tener un cero del suceso estudiado, o la probabilidad de cero puede ser de tal magnitud que el ajuste directo llevaría a estimaciones inadecuadas. Las técnicas de truncamiento o modificación del cero permiten un mejor ajuste de la distribución. Cabe señalar que nuestra cartera de seguros podría estar compuesta por diferentes subgrupos, cada uno con su propio conjunto de características individuales, la Sección 2.6 introduce las distribuciones mixtas y la metodología para permitir esta heterogeneidad dentro de una cartera. La Sección 2.7 describe la bondad de ajuste que mide la razonabilidad de las estimaciones de los parámetros. Los ejercicios se presentan en la Sección 2.8 and la Sección 2.9.1 concluye el capítulo con el código R para los gráficos mostrados en la Sección 2.4. 2.1 Distribuciones de frecuencias En esta sección se aprende a analizar la importancia de la modelización de las frecuencias en términos contractuales, de comportamiento, bases de datos y razones administrativas/regulatorias. 2.1.1 Cómo la frecuencia incrementa la información sobre la cuantía 2.1.1.1 Terminología básica En este capítulo, pérdida, también llamada daño económico, denota la cantidad sufrida por el asegurado. Denominamos siniestro para indicar la indemnización cuando ocurre un evento asegurado, por lo tanto, la cantidad que paga el asegurador. Aunque algunos textos utilizan pérdida y siniestro indistintamente, hacemos aquí una distinción para remarcar cómo las disposiciones contractuales de los seguros, tales como las deducciones y los límites, afectan a la cuantía de la reclamación derivada de una pérdida. La frecuencia representa la frecuencia con la que ocurre un evento asegurado, normalmente dentro de un contrato de póliza. Aquí nos centramos en las variables aleatorias de recuento que representan el número de siniestros, es decir, la frecuencia con la que se produce un evento. La cuantía indica la cantidad, o tamaño, de cada pago de un evento asegurado. En futuros capítulos, se examina el modelo agregado, que combina modelos de frecuencia con modelos de cuantía o severidad. 2.1.1.2 La importancia de la Frecuencia Recordemos en el Capítulo 1 que fijar el precio de un producto de seguro puede ser un problema complejo. En la fabricación, el coste de un producto es (relativamente) conocido. En otras áreas de servicios financieros, se dispone de precios de mercado. En los seguros, podemos generalizar la fijación de precios de la siguiente manera: empezar con un coste esperado. Añadir “márgenes” para tener en cuenta el riesgo del producto, los gastos incurridos en el mantenimiento del producto y una asignación de beneficios/superávit para el asegurador. Ese coste esperado para el seguro puede definirse como el número esperado de siniestros por la cantidad esperada por siniestro, es decir, la frecuencia por cuantía esperada. Centrarse en el recuento de siniestros permite al asegurador considerar aquellos factores que afectan directamente a la ocurrencia de una pérdida, generando así potencialmente un siniestro. El proceso de la frecuencia puede entonces modelizarse. 2.1.1.3 Por qué Examinar la Información de la Frecuencia Las aseguradoras y otros interesados, incluidas las organizaciones gubernamentales, tienen diferentes motivos para generar y mantener bases de datos de frecuencias. Contractual. En los contratos de seguro, es común que se enumeren e invoquen deducibles y límites de póliza particulares para cada ocurrencia de un evento asegurado. En consecuencia, los datos de recuento de siniestros generados indicarían el número de siniestros que cumplen esos criterios, ofreciendo una medida única de la frecuencia de los mismos. Por otra parte, los modelos de pérdidas totales aseguradas tendrían que contabilizar los deducibles y los límites de la póliza para cada evento asegurado. Conducta. Al considerar los factores que influyen en la frecuencia de las pérdidas, se debería tener en cuenta el comportamiento de riesgo y de su reducción por parte de los individuos y las empresas. Las variables explicativas (de tarificación) pueden tener diferentes efectos en los modelos de la frecuencia de un evento en contraste con el tamaño del mismo. En los seguros de salud, la decisión de utilizar los servicios sanitarios por parte de los individuos, y de reducir al mínimo su utilización mediante medidas de prevención y salud, está relacionada principalmente con sus características personales. El coste por usuario viene determinado por esas características personales, el estado de salud del asegurado, los posibles tratamientos y las decisiones tomadas por el proveedor de atención médica (como el médico) y el paciente. Si bien hay una superposición de esos factores y la forma en que afectan a los costes totales de la atención sanitaria, nos podemos centrar por separado en los factores que afectan la frecuencia de las visitas a los servicios sanitarios y la cuantía de los costes de la atención médica. En productos de seguros a particulares, el historial de siniestralidad es un importante factor de suscripción. Es común utilizar un indicador de si el asegurado tuvo o no un siniestro dentro de un determinado período de tiempo antes del contrato. Además, el número de siniestros incurridos por el asegurado en períodos anteriores tiene capacidad predictiva. En el seguro del hogar, al modelizar la frecuencia de pérdidas potenciales, el asegurador podría considerar las medidas de prevención de pérdidas que el propietario ha adoptado, como los sistemas de alarma o de seguridad visibles. Por otra parte, al modelizar la cuantía de las pérdidas, el asegurador examinaría los factores que afectan a los costes de reparación y sustitución. Bases de datos. Las aseguradoras pueden mantener bases de datos separadas que ayudan a desarrollar modelos separados de frecuencia y cuantía. Por ejemplo, un archivo de titulares de pólizas se genera cuando se suscribe una póliza. En este archivo se registra mucha información de suscripción sobre el asegurado o los asegurados, como la edad, el sexo y la información previa sobre siniestralidad; información sobre la póliza como la cobertura, los deducibles y las limitaciones, así como la existencia de reclamaciones de seguro. Un archivo separado, conocido como el archivo de “siniestros”, registra los detalles de la reclamación contra el asegurador, incluyendo la cantidad. (También puede haber un archivo de “pagos” que registra el proceso de los pagos, aunque no nos ocuparemos de eso aquí). Este proceso de recogida de información podría luego extenderse a la modelización por parte de los asegurados como procesos separados de la frecuencia y la cuantía. Regulación y Administración. El seguro es una industria altamente regulada y supervisada, dada su importancia en la provisión de seguridad financiera a los individuos y empresas que se enfrentan a los riesgos. Como parte de sus obligaciones los reguladores exigen habitualmente que se informe sobre el número de reclamaciones y las cantidades. Esto puede deberse a que puede haber definiciones alternativas de “cuantía”, por ejemplo, lo pagado frente a lo incurrido, y hay menos posibilidades de error al informar del número de reclamaciones. Esta vigilancia continua ayuda a garantizar la estabilidad financiera de estas compañías de seguros. 2.2 Distribuciones de frecuencias elementales En esta sección, aprenderás a: Determinar los valores que resumen una distribución como la función de distribución y de supervivencia, así como los momentos como la media y la varianza Definir y calcular las funciones generadoras de momentos y de probabilidades Describir y comprender las relaciones entre tres importantes distribuciones: binomial, Poisson y binomial negativa En esta sección, presentaremos las distribuciones que se utilizan frecuentemente en la práctica actuarial para modelizar los datos de recuento. La variable aleatoria del número de siniestros se denota con \\(N\\); por su propia naturaleza toma sólo valores enteros no negativos. Por lo tanto, las distribuciones que se muestran a continuación son todas distribuciones discretas con soporte el conjunto de números enteros no negativos \\(\\{0, 1, \\ldots \\}\\). 2.2.1 Fundamentos Dado que \\(N\\) es una variable aleatoria discreta que toma valores en \\(\\{0, 1, \\ldots \\}\\), la descripción completa más natural de su distribución es a través de la especificación de las probabilidades con las que asume cada uno de los valores enteros no negativos. Esto nos lleva al concepto de la función de masa de probabilidad (pmf, según sus siglas en inglés) de \\(N\\), denotada como \\(p_N(\\cdot)\\) y definida de la siguiente manera: \\[\\begin{equation} p_N(k)=\\Pr(N=k), \\quad \\hbox{for } k=0,1,\\ldots \\end{equation}\\] Cabe señalar que hay descripciones completas, o caracterizaciones, alternativas de la distribución de \\(N\\); por ejemplo, una de ellas es la función de distribución de \\(N\\) denotada por \\(F_N(\\cdot)\\) y definida a continuación: \\[\\begin{equation} F_N(x):=\\begin{cases} \\sum\\limits_{k=0}^{\\lfloor x \\rfloor } \\Pr(N=k), &amp;x\\geq 0;\\\\ 0, &amp; \\hbox{en otro caso}. \\end{cases} \\end{equation}\\] En lo anterior, \\(\\lfloor \\cdot \\rfloor\\) indica la función entero; \\(\\lfloor x \\rfloor\\) indica el mayor entero menor o igual a \\(x\\). Cabe señalar que la función de supervivencia de \\(N\\), denotada como \\(S_N(\\cdot)\\), se define como la complementaria de \\(F_N(\\cdot)\\), i.e. \\(S_N(\\cdot):=1-F_N(\\cdot)\\). Claramente, esta última es otra caracterización de la distribución de \\(N\\). A menudo se está interesado en cuantificar un aspecto concreto de la distribución y no su descripción completa. Esto es particularmente útil cuando se comparan distribuciones. La posición central de la distribución es uno de esos aspectos, y hay muchas medidas diferentes que se utilizan frecuentemente para cuantificarlo. De éstas, la media es la más popular; la media de \\(N\\), denotada por \\(\\mu_N\\),2 se define como \\[\\begin{equation} \\mu_N=\\sum_{k=0}^\\infty k~p_N(k). \\end{equation}\\] Cabe señalar que \\(\\mu_N\\) es el valor esperado de la variable aleatoria \\(N\\), i.e. \\(\\mu_N=\\mathrm{E}[N]\\). Esto nos lleva a una clase general de medidas, los momentos de la distribución; el momento \\(r\\)-ésimo de \\(N\\), para \\(r&gt; 0\\), se define como \\(\\mathrm{E}{[N^r]}\\) y se denota \\(\\mu_N&#39;(r)\\). Por lo tanto, para \\(r&gt;0\\), tenemos \\[\\begin{equation} \\mu_N&#39;(r)= \\mathrm{E}{[N^r]}= \\sum_{k=0}^\\infty k^r~p_N(k). \\end{equation}\\] Nótese que \\(\\mu_N&#39;(\\cdot)\\) es una función no decreciente bien definida que toma los valores en \\([0,\\infty]\\), como \\(\\Pr(N\\in\\{0, 1, \\ldots \\})=1\\); también, nótese que \\(\\mu_N=\\mu_N&#39;(1)\\). A partir de aquí, cuando nos refiramos a un momento estará implícito que es finito a menos que se mencione lo contrario. Otro aspecto fundamental de una distribución es su dispersión, y de las diversas medidas de dispersión estudiadas en la literatura, la desviación estándar es la más popular. Para definirla, primero definimos la varianza de \\(N\\), denotada por \\(\\mathrm{Var}[N]\\), como \\(\\mathrm{Var}[N]:=\\mathrm{E}{[(N-\\mu_N)^2]}\\) cuando \\(\\mu_N\\) es finita. Por las propiedades básicas del valor esperado de una variable aleatoria, vemos que \\(\\mathrm{Var}[N]:=\\mathrm{E}[N^2]-[\\mathrm{E}(N)]^2\\). La desviación estándar de \\(N\\), denotada por \\(\\sigma_N\\), se define como la raíz cuadrada de \\(\\mathrm{Var}~N\\). Nótese que esta última queda bien definida como \\(\\mathrm{Var}[N]\\), por su definición de promedio de la desviación respecto a la media al cuadrado, y es no negativa; \\(\\mathrm{Var}[N]\\) se denota como \\(\\sigma_N^2\\). Obsérvese que estas dos medidas toman valores en \\([0,\\infty]\\). 2.2.2 Funciones Generadoras de Momentos y de Probabilidad Ahora presentaremos dos funciones generadoras que son útiles cuando se trabaja con variables de recuento. Recordemos que para una variable aleatoria discreta, la la función generadora de momentos (mgf, según sus siglas en inglés) de \\(N\\), denotada como \\(M_N(\\cdot)\\), se define como \\[ M_N(t) = \\mathrm{E}~{[e^{tN}]} = \\sum^{\\infty}_{k=0} ~e^{tk}~ p_N(k), \\quad t\\in \\mathbb{R}. \\] Obsérvese que mientras \\(M_N(\\cdot)\\) está bien definida ya que es el valor esperado de una variable aleatoria no negativa (\\(e^{tN}\\)), aunque puede tomar el valor \\(\\infty\\). Nótese que para una variable aleatoria de recuento, \\(M_N(\\cdot)\\) tiene un valor finito en \\((-\\infty,0]\\) con \\(M_N(0)=1\\). El siguiente teorema, cuya demostración se encuentra en (Billingsley 2008) (pages 285-6), justifica su nombre. Theorem 2.1 Consideremos que \\(N\\) es una variable aleatoria de recuento tal que \\(\\mathrm{E}~{[e^{t^\\ast N}]}\\) es finita para algún \\(t^\\ast&gt;0\\). Se tiene lo siguiente: Todos los momentos de \\(N\\) son finitos, i.e. \\[ \\mathrm{E}{[N^r]}&lt;\\infty, \\quad r \\gt 0. \\] La mgf se puede usar para generar sus momentos de la siguiente forma: \\[ \\left.\\frac{{\\rm d}^m}{{\\rm d}t^m} M_N(t)\\right\\vert_{t=0}=\\mathrm{E}{N^m}, \\quad m\\geq 1. \\] La mgf \\(M_N(\\cdot)\\) caracteriza la distribución; en otras palabras, especifica de manera única la distribución. Otro motivo por el que la mgf es muy útil como herramienta es que, para dos variables aleatorias independientes \\(X\\) e \\(Y\\), con sus mgfs que existen alrededor de \\(0\\), la mgf de \\(X+Y\\) es el producto de sus respectivas mgfs. Una función generadora relacionada con la mgf es la función generadora de probabilidad (pgf, según sus siglas en inglés), y es una herramienta útil para las variables aleatorias que toman valores en los números enteros no negativos. Para una variable aleatoria \\(N\\), por \\(P_N(\\cdot)\\) denotamos su pgf y se define como:3 \\[\\begin{equation} P_N(s):=\\mathrm{E}~{[s^N]}, \\quad s\\geq 0. \\end{equation}\\] Es sencillo ver que si la mgf \\(M_N(\\cdot)\\) existe en \\((-\\infty,t^\\ast)\\) entonces \\[ P_N(s)=M_N(\\log(s)), \\quad s&lt;e^{t^\\ast}. \\] Además, si la pgf existe en el intervalo \\([0,s^\\ast)\\) con \\(s^\\ast&gt;1\\), entonces la mgf \\(M_N(\\cdot)\\) existe en \\((-\\infty,\\log(s^\\ast))\\), y especifica la distribución de \\(N\\) de forma única por el Teorema 2.1. El siguiente resultado para pgf es análogo al Teorema 2.1, y en concreto motiva su nombre. Theorem 2.2 Suponer que \\(N\\) es una variable aleatoria de tal manera que \\(\\mathrm{E}~{(s^{\\ast})^N}\\) es finita para algún \\(s^\\ast&gt;1\\). Se tiene lo siguiente: Todos los momentos de \\(N\\) son finitos, i.e. \\[ \\mathrm{E}~{N^r}&lt;\\infty, \\quad r\\geq 0. \\] La pmf de \\(N\\) se puede derivar de la pgf de la siguiente forma: \\[ p_N(m)=\\begin{cases} P_N(0), &amp;m=0;\\cr &amp;\\cr \\left(\\frac{1}{m!}\\right) \\left.\\frac{{\\rm d}^m}{{\\rm d}s^m} P_N(s)\\right\\vert_{s=0}\\;, &amp;m\\geq 1.\\cr \\end{cases} \\] Los momentos factoriales de \\(N\\) se pueden derivar de la siguiente manera: \\[ \\left.\\frac{{\\rm d}^m}{{\\rm d}s^m} P_N(s)\\right\\vert_{s=1}=\\mathrm{E}~{\\prod\\limits_{i=0}^{m-1} (N-i)}, \\quad m\\geq 1. \\] La pgf \\(P_N(\\cdot)\\) caracteriza la distribución; en otras palabras, especifica de manera única la distribución. 2.2.3 Distribuciones de Frecuencias Importantes En esta subsección estudiaremos tres importantes distribuciones de frecuencia utilizadas en estadística, que son las distribuciones binomial, Poisson y binomial negativa. En lo siguiente, un riesgo denota una unidad cubierta por el seguro. Un riesgo puede ser un individuo, un edificio, una empresa o algún otro aspecto para el que se proporciona cobertura de seguro. Para contextualizar, imaginemos un conjunto de datos de seguros que contenga el número de siniestros por riesgo o que esté estratificado de alguna otra manera. Las distribuciones mencionadas anteriormente resultan ser también las que más se utilizan en el ámbito asegurador por diferentes razones, algunas de las cuales se mencionan a continuación. Estas distribuciones pueden motivarse a partir de experimentos aleatorios que son buenas aproximaciones a los procesos de la vida real de los que surgen muchos datos de seguros. Por lo tanto, no es sorprendente que, en conjunto, ofrezcan un ajuste razonable a muchos conjuntos de datos de interés en seguros. La idoneidad de una distribución concreta para el conjunto de datos puede determinarse utilizando metodologías estadísticas estándar, como se discute más adelante en este capítulo. Proporcionan una base suficientemente rica para generar otras distribuciones que se ajustan aún mejor o se adaptan bien a situaciones más reales de interés para nosotros. Las tres distribuciones son de un parámetro o dos parámetros. En el ajuste a los datos al parámetro se le asigna un valor concreto. El conjunto de estas distribuciones puede ampliarse hasta sus envolventes convexas tratando el/los parámetro(s) como una variable aleatoria (o vector) con su propia distribución de probabilidad, con este conjunto más amplio de distribuciones que ofrece una mayor flexibilidad. Un ejemplo sencillo que se aborda mejor con esta ampliación es una cartera de siniestros generada por asegurados pertenecientes a muchas clases de riesgo diferentes. En los datos de seguros se puede observar un número desproporcionado de ceros, es decir, de cero siniestros por riesgo. Al ajustarse a los datos, la distribución de frecuencias en su especificación estándar a menudo no tiene en cuenta suficientemente este hecho. Sin embargo, la modificación natural de las tres distribuciones anteriores se adapta bien a este fenómeno para ofrecer un mejor ajuste. En el seguro nos interesa el total de los siniestros pagados, cuya distribución resulta de la combinación de la distribución de frecuencia ajustada con una distribución de severidad. Estas tres distribuciones tienen propiedades que facilitan trabajar con la distribución de severidad agregada resultante. 2.2.3.1 Distribución Binomial Empezamos con la distribución binomial que se genera a partir de una secuencia finita de experimentos idénticos e independientes con resultados dicotómicos. El más clásico de estos experimentos es el del lanzamiento de una moneda (trucada o no trucada) con el resultado de cara o cruz. Así, si \\(N\\) denota el número de caras en una secuencia de \\(m\\) experimentos independientes del lanzamiento de una moneda idéntica cuya probabilidad de obtener cara es \\(q\\), entonces la distribución de \\(N\\) se denomina distribución binomial con parámetros \\((m,q)\\), con \\(m\\) un entero positivo y \\(q\\in[0,1]\\). Nótese que cuando \\(q=0\\) (resp., \\(q=1\\)) entonces la distribución es degenerada con \\(N=0\\) (resp., \\(N=m\\)) con probabilidad \\(1\\). De forma clara, cuando \\(q\\in(0,1)\\) su suporte es igual a \\(\\{0,1,\\ldots,m\\}\\) con pmf dada por4 \\[\\begin{equation*} p_k:= \\binom{m}{k} q^k (1-q)^{m-k}, \\quad k=0,\\ldots,m. \\end{equation*}\\] donde \\[\\binom{m}{k} = \\frac{m!}{k!(m-k)!}\\] La razón de su nombre es que la pmf toma valores entre los valores que surgen de la expansión binomial \\((q +(1-q))^m\\). Esta característica nos permite obtener la siguiente expresión para la pgf de la distribución binomial: \\[ P_N(z):= \\sum_{k=0}^m z^k \\binom{m}{k} q^k (1-q)^{m-k} = \\sum_{k=0}^m \\binom{m}{k} (zq)^k (1-q)^{m-k} = (qz+(1-q))^m = (1+q(z-1))^m. \\] Nótese que la expresión anterior para la pgf nos confirma que la distribución binomial es la convolución m-ésima de la distribución de Bernoulli, que a su vez es una distribución binomial con \\(m=1\\) y pgf \\((1+q(z-1))\\). Además, cabe señalar que la mgf de la distribución binomial viene dada por \\((1+q(e^t-1))^m\\). Los momentos centrales de la distribución binomial se pueden encontrar de diferentes maneras. Para enfatizar la propiedad de que se trata de una convulsión \\(m\\)-ésima de la distribución de Bernoulli, derivamos a continuación los momentos que se basan en esta propiedad. Empezamos observando que la distribución de Bernoulli con parámetro \\(q\\) asigna la probabilidad de \\(q\\) y \\(1-q\\) a \\(1\\) y \\(0\\), respectivamente. Así que su media es igual a \\(q\\) (\\(=0\\times (1-q) + 1\\times q\\)); nótese que su segundo momento ordinario es igual a su media como \\(N^2=N\\) con probabilidad \\(1\\). Usando estas dos características vemos que la varianza es igual a \\(q(1-q)\\). Pasando a la distribución binomial con parámetros \\(m\\) y \\(q\\), usando el hecho de que es la convolución \\(m\\)-ésima de la distribución de Bernoulli, escribimos \\(N\\) como la suma de \\(N_1,\\ldots,N_m\\), donde \\(N_i\\) son variables de Bernoulli iid. Ahora a partir de los momentos de la Bernoulli y la linealidad de la esperanza, vemos que \\[ \\mathrm{E}[{N}]=\\mathrm{E}[{\\sum_{i=1}^m N_i}] = \\sum_{i=1}^m ~\\mathrm{E}[N_i] = mq. \\] Además, dado que la varianza de la suma de variables aleatorias independientes es la suma de sus varianzas, vemos que \\[ \\mathrm{Var}[{N}]=\\mathrm{Var}~\\left({\\sum_{i=1}^m N_i}\\right)=\\sum_{i=1}^m \\mathrm{Var}[{N_i}] = mq(1-q). \\] En los ejercicios se proponen formas alternativas de derivar los momentos anteriores. Es importante remarcar, especialmente desde el punto de vista de las aplicaciones, que la media es mayor que la varianza a menos que \\(q=0\\). 2.2.3.2 Distribución de Poisson Después de la distribución binomial, la distribución de Poisson (llamada así por el polímata francés Simeon Denis Poisson) es probablemente la más conocida de las distribuciones discretas. En parte se debe a que surge de forma natural como la distribución de recuento de las ocurrencias aleatorias de un tipo de evento en un determinado período de tiempo, si la tasa de ocurrencia de los eventos es constante. También surge como el límite asintótico de la distribución binomial con \\(m\\rightarrow \\infty\\) y \\(mq\\rightarrow \\lambda\\). La distribución de Poisson se parametriza con un único parámetro normalmente denotado por \\(\\lambda\\) que toma valores en \\((0,\\infty)\\). Su pmf viene dada por \\[ p_k = \\frac{e^{-\\lambda}\\lambda^k}{k!}, k=0,1,\\ldots \\] Es fácil comprobar que la expresión anterior es una pmf ya que los términos son claramente no-negativos, y a partir de la expansión infinita de la serie de Taylor de \\(e^\\lambda\\) se obtiene que suman uno. De forma genérica, podemos derivar su pgf, \\(P(\\cdot)\\), como sigue: \\[ P_N(z)= \\sum_{k=0}^\\infty p_k z^k = \\sum_{k=0}^\\infty \\frac{e^{-\\lambda}\\lambda^kz^k}{k!} = e^{-\\lambda} e^{\\lambda z} = e^{\\lambda(z-1)}, \\forall z\\in\\mathbb{R}. \\] De aquí, derivamos su mgf como sigue: \\[ M_N(t)=P_N(e^t)=e^{\\lambda(e^t-1)}, t\\in \\mathbb{R}. \\] Para obtener su media, observamos que para la distribución de Poisson \\[ kp_k=\\begin{cases} 0, &amp;k=0;\\cr \\lambda~p_{k-1}, &amp;k\\geq1. \\end{cases} \\] se puede comprobar fácilmente. En particular, lo anterior implica que \\[ \\mathrm{E}[{N}]=\\sum_{k\\geq 0} k~p_k =\\lambda\\sum_{k\\geq 1} p_{k-1} = \\lambda\\sum_{j\\geq 0} p_{j} =\\lambda. \\] De hecho, de manera más general, utilizando una generalización de lo anterior o el Teorema 2.2, vemos que \\[ \\mathrm{E}{\\prod\\limits_{i=0}^{m-1} (N-i)}=\\left.\\frac{{\\rm d}^m}{{\\rm d}s^m} P_N(s)\\right\\vert_{s=1}=\\lambda^m, \\quad m\\geq 1. \\] En concreto, lo anterior implica que \\[ \\mathrm{Var}[{N}]=\\mathrm{E}[{N^2}]-[\\mathrm{E}({N})]^2 = \\mathrm{E}~[N(N-1)]+\\mathrm{E}[N]-(\\mathrm{E}[{N]})^2=\\lambda^2+\\lambda-\\lambda^2=\\lambda. \\] Nótese que, curiosamente, para la distribución de Poisson \\(\\mathrm{Var}[N]=\\mathrm{E}[N]\\). 2.2.3.3 Distribución Binomial Negativa La tercera distribución importante de recuento es la distribución binomial negativa. Recordemos que la distribución binomial surge como la distribución del número de éxitos en la repetición independiente de \\(m\\) veces de un experimento con resultados binarios o dicotómicos. Si por el contrario, consideramos el número de éxitos hasta que observamos el \\(r\\)-ésimo fallo en repeticiones independientes de un experimento con resultados binarios, entonces su distribución es una distribución binomial negativa. Un caso particular, cuando \\(r=1\\), es la distribución geométrica. Sin embargo, cuando \\(r\\) no es un número entero, el experimento aleatorio anterior no sería aplicable. A partir de aquí, permitiremos que el parámetro \\(r\\) sea cualquier número real positivo, para luego motivar la distribución de manera más general. Para explicar su nombre, recordemos la serie binomial, i.e. \\[ (1+x)^s= 1 + s x + \\frac{s(s-1)}{2!}x^2 + \\ldots..., \\quad s\\in\\mathbb{R}; \\vert x \\vert&lt;1. \\] Si definimos \\(\\binom{s}{k}\\), el coeficiente binomial generalizado, por \\[ \\binom{s}{k}=\\frac{s(s-1)\\cdots(s-k+1)}{k!}, \\] tenemos, entonces, que \\[ (1+x)^s= \\sum_{k=0}^{\\infty} \\binom{s}{k} x^k, \\quad s\\in\\mathbb{R}; \\vert x \\vert&lt;1. \\] Si fijamos \\(s=-r\\), entonces observamos que lo anterior genera \\[ (1-x)^{-r}= 1 + r x + \\frac{(r+1)r}{2!}x^2 + \\ldots...= \\sum_{k=0}^\\infty \\binom{r+k-1}{k} x^k, \\quad r\\in\\mathbb{R}; \\vert x \\vert&lt;1. \\] Lo anterior implica que si definimos \\(p_k\\) como \\[ p_k = \\binom{k+r-1}{k} \\left(\\frac{1}{1+\\beta}\\right)^r \\left(\\frac{\\beta}{1+\\beta}\\right)^k, \\quad k=0,1,\\ldots \\] para \\(r&gt;0\\) y \\(\\beta\\geq0\\), entonces queda definida una pmf válida. Esta distribución que se ha definido se denomina la distribución negativa binomial con parámetros \\((r,\\beta)\\) con \\(r&gt;0\\) y \\(\\beta\\geq 0\\). Además, la serie binomial también implica que la pgf de la distribución venga dada por \\[ \\begin{aligned} P_N(z) &amp;= (1-\\beta(z-1))^{-r}, \\quad \\vert z \\vert \\lt 1+\\frac{1}{\\beta}, \\beta\\geq0. \\end{aligned} \\] Lo anterior implica que la mgf venga dada por \\[ \\begin{aligned} M_N(t) &amp;= (1-\\beta(e^t-1))^{-r}, \\quad t \\lt \\log\\left(1+\\frac{1}{\\beta}\\right), \\beta\\geq0. \\end{aligned} \\] Derivamos sus momentos utilizando el Teorema 2.1 como sigue: \\[\\begin{eqnarray*} \\mathrm{E}[N]&amp;=&amp;M&#39;(0)= \\left. r\\beta e^t (1-\\beta(e^t-1))^{-r-1}\\right\\vert_{t=0}=r\\beta;\\\\ \\mathrm{E}[N^2]&amp;=&amp;M&#39;&#39;(0)= \\left.\\left[ r\\beta e^t (1-\\beta(e^t-1))^{-r-1} + r(r+1)\\beta^2 e^{2t} (1-\\beta(e^t-1))^{-r-2}\\right]\\right\\vert_{t=0}\\\\ &amp;=&amp;r\\beta(1+\\beta)+r^2\\beta^2;\\\\ \\hbox{y }\\mathrm{Var}[N]&amp;=&amp;\\mathrm{E}{[N^2]}-(\\mathrm{E}[{N}])^2=r\\beta(1+\\beta)+r^2\\beta^2-r^2\\beta^2=r\\beta(1+\\beta) \\end{eqnarray*}\\] Observamos que cuando \\(\\beta&gt;0\\), tenemos \\(\\mathrm{Var}[N] &gt;\\mathrm{E}[N]\\). En otras palabras, esta distribución es sobredispersa (en relación a la Poisson); de manera similar, cuando \\(q&gt;0\\) la distribución binomial se dice que es infradispersa (en relación a la Poisson). Finalmente, observamos que la distribución de Poisson también surge como límite de distribuciones binomiales negativas. Para establecer esto, fijamos \\(\\beta_r\\) de tal forma que cuando \\(r\\) tienda a infinito \\(r\\beta_r\\) tiende a \\(\\lambda&gt;0\\). Entonces, podemos ver que las mgfs de las distribuciones binomiales negativas con parámetros \\((r,\\beta_r)\\) satisfacen \\[ \\lim_{r\\rightarrow 0} (1-\\beta_r(e^t-1))^{-r}=\\exp\\{\\lambda(e^t-1)\\}, \\] con el lado derecho de la ecuación anterior siendo la mgf de la distribución de Poisson con parámetro \\(\\lambda\\).5 2.3 La clase (a, b, 0) En esta sección, se aprende a: Definir la clase (a,b,0) de distribuciones de frecuencia Discutir la importancia de la relación recursiva que sustenta esta clase de distribuciones Identificar las condiciones en las que esta clase general se reduce a cada una de las distribuciones binomial, Poisson y binomial negativa En la sección anterior estudiamos tres distribuciones, en concreto, la binomial, la Poisson y la binomial negativa. En el caso de la Poisson, para obtener su media usamos el hecho que \\[ kp_k=\\lambda p_{k-1}, \\quad k\\geq 1, \\] lo que se puede expresar de forma equivalente como \\[ \\frac{p_k}{p_{k-1}}=\\frac{\\lambda}{k}, \\quad k\\geq 1. \\] Curiosamente, se puede mostrar de forma similar que para la distribución binomial \\[ \\frac{p_k}{p_{k-1}}=\\frac{-q}{1-q}+\\left(\\frac{(m+1)q}{1-q}\\right)\\frac{1}{k}, \\quad k=1,\\ldots,m, \\] y para la distribución binomial negativa \\[ \\frac{p_k}{p_{k-1}}=\\frac{\\beta}{1+\\beta}+\\left(\\frac{(r-1)\\beta}{1+\\beta}\\right)\\frac{1}{k}, \\quad k\\geq 1. \\] Las tres relaciones previas son de la forma \\[\\begin{equation} \\frac{p_k}{p_{k-1}}=a+\\frac{b}{k}, \\quad k\\geq 1; \\tag{2.1} \\end{equation}\\] esto plantea la cuestión de si hay otras distribuciones que satisfagan esta relación de recurrencia aparentemente general. Nótese que la relación de la izquierda, el cociente entre dos probabilidades, es no negativa. Para empezar, permitamos \\(a&lt;0\\). En este caso, como \\(k\\rightarrow \\infty\\), \\((a+b/k)\\rightarrow a&lt;0\\). De esto se deduce que si \\(a&lt;0\\) entonces \\(b\\) debería satisfacer \\(b=-ka\\), para \\(k\\geq 1\\). Cualquier par \\((a,b)\\) puede escribirse como \\[ \\left(\\frac{-q}{1-q},\\frac{(m+1)q}{1-q}\\right), \\quad q\\in(0,1), m\\geq 1; \\] nótese que en el caso \\(a&lt;0\\) con \\(a+b=0\\) produce la degenerada de una distribución de \\(0\\) que es la distribución binomial con \\(q=0\\) y un arbitrario \\(m\\geq 1\\). En el caso de \\(a=0\\), de nuevo por la no negatividad de la proporción \\(p_k/p_{k-1}\\), tenemos \\(b\\geq 0\\). Si \\(b=0\\) la distribución es degenerada en \\(0\\), que es una binomial con \\(q=0\\) o una distribución de Poisson con \\(\\lambda=0\\) o una distribución binomial negativa con \\(\\beta=0\\). Si \\(b&gt;0\\), entonces de forma clara esta distribución es una distribución de Poisson con una media (i.e. \\(\\lambda\\)) igual a \\(b\\), como se muestra al principio de esta sección. En el caso de \\(a&gt;0\\), de nuevo por la no negatividad de la proporción \\(p_k/p_{k-1}\\), tenemos \\(a+b/k\\geq 0\\) para todo \\(k\\geq 1\\). La más estricta de estas es la desigualdad \\(a+b\\geq 0\\). Nótese que \\(a+b=0\\) de nuevo resulta en una degenerada en \\(0\\); excluyendo este caso tenemos \\(a+b&gt;0\\) o equivalentemente \\(b=(r-1)a\\) con \\(r&gt;0\\). Después de un poco de álgebra, fácilmente se obtiene la siguiente expresión para \\(p_k\\): \\[ p_k = \\binom{k+r-1}{k} p_0 a^k, \\quad k=1,2,\\ldots. \\] La serie anterior converge a \\(a&lt;1\\) cuando \\(r&gt;0\\), con la suma dada por \\(p_0*((1-a)^{(-r)}-1)\\). Por lo tanto, al igualar este último a \\(1-p_0\\) obtenemos \\(p_0=(1-a)^{(r)}\\). Así, en este caso el par \\((a,b)\\) es de la forma \\((a,(r-1)a)\\), para \\(r&gt;0\\) y \\(0&lt;a&lt;1\\); ya que una parametrización equivalente es \\((\\beta/(1+\\beta),(r-1)\\beta/(1+\\beta))\\), para \\(r&gt;0\\) y \\(\\beta&gt;0\\), vemos de lo anterior que estas distribuciones son distribuciones binomiales negativas. A partir del desarrollo anterior vemos que no sólo la recurrencia (2.1) une estas tres distribuciones, sino que también las caracteriza. Por esta razón, estas tres distribuciones se denominan de forma genérica en la literatura actuarial como clase (a,b,0) de distribuciones, con \\(0\\) haciendo referencia al punto inicial de la recurrencia. Nótese que el valor de \\(p_0\\) está implícito en \\((a,b)\\) ya que las probabilidades tienen que sumar uno. Por supuesto, (2.1) como relación de recurrencia para \\(p_k\\), hace que el cálculo de la pmf sea eficiente al eliminar las redundancias. Más adelante veremos que lo hace incluso en el caso de distribuciones compuestas con la distribución de frecuencias perteneciente a la clase \\((a,b,0)\\) - esta característica es la razón más importante para justificar el estudio de estas tres distribuciones desde este punto de vista. Ejemplo 2.3.1. Una distribución de probabilidad discreta tiene las siguientes propiedades \\[ \\begin{aligned} p_k&amp;=c\\left( 1+\\frac{2}{k}\\right) p_{k-1} \\:\\:\\: k=1,2,3,\\ldots\\\\ p_1&amp;= \\frac{9}{256} \\end{aligned} \\] Determinar el valor esperado de esta variable aleatoria discreta. Mostrar Solución de Ejemplo Solución: Dado que la pmf satisface la relación de recurrencia \\((a,b,0)\\) sabemos que la distribución subyacente es una entre las distribuciones binomial, Poisson y binomial negativa. Puesto que la relación de los parámetros (i.e. \\(b/a\\)) es igual a \\(2\\), sabemos que es binomial negativa y que \\(r=3\\). Además, ya que para la binomial negativa \\(p_1=r(1+\\beta)^{-(r+1)}\\beta\\), tenemos \\[ \\begin{aligned} &amp;&amp;\\frac{9}{256}=&amp;3\\frac{\\beta}{(1+\\beta)^4}\\\\ \\implies &amp;&amp;\\frac{3}{(1+3)^4}=&amp;\\frac{\\beta}{(1+\\beta)^4}\\\\ \\implies &amp;&amp;\\beta=&amp;3. \\end{aligned} \\] Por último, dado que la media de la binomial negativa es \\(r\\beta\\), tenemos que la media de esta distribución es igual a \\(9\\). 2.4 Estimación de las distribuciones de frecuencias En esta sección, se aprende a: Definir la verosimilitud para una muestra de observaciones de una distribución discreta Definir el estimador de máxima verosimilitud para una muestra aleatoria de observaciones de una distribución discreta Calcular el estimador de máxima verosimilitud para las distribuciones binomial, Poisson y binomial negativa 2.4.1 Estimación de los parámetros En la sección 2.2 se introdujeron tres distribuciones muy importantes para la modelización de varios tipos de datos de recuento derivados de los seguros. Supongamos ahora que tenemos un conjunto de datos de recuento a los que queremos ajustar una distribución, y hemos determinado que una de las distribuciones \\((a,b,0)\\) es más apropiada que las otras. Dado que cada una de ellas forma una clase de distribuciones si permitimos que su(s) parámetro(s) tome(n) cualquier valor permisible, queda la tarea de determinar el mejor valor del(los) parámetro(s) para los datos en cuestión. Éste es un problema estadístico de estimación puntual, y el paradigma de inferencia estadística de máxima verosimilitud suele producir estimadores eficientes en los problemas de inferencia paramétrica. En esta sección describiremos este paradigma y derivaremos los estimadores de máxima verosimilitud. Supongamos que observamos las variables aleatorias independientes e idénticamente distribuidas, iid, \\(X_1,X_2,\\ldots,X_n\\) de una distribución con pmf \\(p_\\theta\\), donde \\(\\theta\\) es un parámetro y un valor desconocido en el espacio del parámetro \\(\\Theta\\subseteq \\mathbb{R}^d\\). Por ejemplo, en el caso de la distribución de Poisson \\[ p_\\theta(x)=e^{-\\theta}\\frac{\\theta^x}{x!}, \\quad x=0,1,\\ldots, \\] con \\(\\theta=(0,\\infty)\\). En el caso de la distribución binomial, tenemos \\[ p_\\theta(x)=\\binom{m}{x} q^x(1-q)^{m-x}, \\quad x=0,1,\\ldots,m, \\] con \\(\\theta:=(m,q)\\in \\{0,1,2,\\ldots\\}\\times[0,1]\\). Supongamos que las observaciones son \\(x_1,\\ldots,x_n\\), valores observados de la muestra aleatoria \\(X_1,X_2,\\ldots,X_n\\) presentada anteriormente. En este caso, la probabilidad de observar esta muestra a partir de \\(p_\\theta\\) es igual a \\[ \\prod_{i=1}^n p_\\theta(x_i). \\] Lo anterior, denotado por \\(L(\\theta)\\), visto como una función de \\(\\theta\\) se denomina la verosimilitud. Nótese que eliminamos su dependencia de los datos, para enfatizar que lo estamos viendo como una función del parámetro. Por ejemplo, en el caso de la distribución de Poisson tenemos \\[ L(\\lambda)=e^{-n\\lambda} \\lambda^{\\sum_{i=1}^n x_i} \\left(\\prod_{i=1}^n x_i!\\right)^{-1}; \\] en el caso de la distribución binomial tenemos \\[ L(m,q)=\\left(\\prod_{i=1}^n \\binom{m}{x_i}\\right) q^{\\sum_{i=1}^n x_i} (1-q)^{nm-\\sum_{i=1}^n x_i} . \\] El estimador máximo verosímil (MLE, según sus siglas en inglés) para \\(\\theta\\) es un maximizador de la verosimilitud; en cierto sentido, el MLE elige el conjunto de valores de los parámetros que mejor explican las observaciones observadas. Consideremos una muestra de tamaño \\(3\\) de una distribución de Bernoulli (binomial con \\(m=1\\)) con valores de \\(0,1,0\\). En este caso se comprueba fácilmente que la verosimilitud es igual a \\[ L(q)=q(1-q)^2, \\] y el gráfico de la verosimilitud se muestra en la Figura 2.1. Como se muestra en el gráfico, el valor máximo de la verosimilitud es igual a \\(4/27\\) y se alcanza en \\(q=1/3\\), y por lo tanto el estimador máximo verosímil para \\(q\\) es \\(1/3\\) para la muestra considerada. En este caso se puede recurrir al álgebra para mostrar que \\[ q(1-q)^2=\\left(q-\\frac{1}{3}\\right)^2\\left(q-\\frac{4}{3}\\right)+\\frac{4}{27}, \\] y concluir que el máximo es igual a \\(4/27\\), y se alcanza en \\(q=1/3\\) (usando el hecho de que el primer término es no positivo en el intervalo \\([0,1]\\)). Pero como es evidente, esta forma de derivar el mle utilizando el álgebra no es generalizada. Normalmente, se recurre al cálculo para derivar el mle - obsérvese que para algunas verosimilitudes uno puede tener que recurrir a otros métodos de optimización, especialmente cuando la verosimilitud tiene muchos extremos locales. Se acostumbra a maximizar de forma equivalente el logaritmo de la verosimilitud6 \\(L(\\cdot)\\), denotado por \\(l(\\cdot)\\), y mirar el conjunto de ceros de su primera derivada7 \\(l&#39;(\\cdot)\\). En el caso de la verosimilitud anterior, \\(l(q)=\\log(q)+2\\log(1-q)\\), y \\[ l&#39;(q):=\\frac{\\rm d}{{\\rm d}q}l(q)=\\frac{1}{q}-\\frac{2}{1-q}. \\] El único cero de \\(l&#39;(\\cdot)\\) iguala a \\(1/3\\), y dado que \\(l&#39;&#39;(\\cdot)\\) es negativa, tenemos que \\(1/3\\) es el único maximizador de la verosimilitud y por tanto su estimador máximo verosímil. Figure 2.1: Verosimilitud para \\((0,1,0)\\) de una muestra de \\(3\\) de una Bernoulli 2.4.2 MLE de las distribuciones de frecuencias A continuación derivamos el estimador de máxima verosimilitud, MLE, para los tres miembros de la clase \\((a,b,0)\\). Empezamos resumiendo la discusión anterior. En el escenario de observar las variables aleatorias iid, independientes e idénticamente distribuidas, \\(X_1,X_2,\\ldots,X_n\\) de una distribución con pmf \\(p_\\theta\\), donde \\(\\theta\\) toma un valor desconocido en \\(\\Theta\\subseteq \\mathbb{R}^d\\), la verosimilitud \\(L(\\cdot)\\), una función en \\(\\Theta\\) se define como \\[ L(\\theta):=\\prod_{i=1}^n p_\\theta(x_i), \\] donde \\(x_1,\\ldots,x_n\\) son los valores observados. El MLE de \\(\\theta\\), denotado como \\(\\hat{\\theta}_{\\rm MLE}\\), es una función que asigna las observaciones a un elemento del conjunto de maximizadores de \\(L(\\cdot)\\), concretamente \\[ \\{\\theta \\vert L(\\theta)=\\max_{\\eta\\in\\Theta}L(\\eta)\\}. \\] Nótese que el conjunto anterior es una función de las observaciones, aunque esta dependencia no se muestra explícitamente. En el caso de las tres distribuciones que estudiaremos, y de forma bastante general, el conjunto anterior es un conjunto unitario (singleton) con una probabilidad que tiende a uno (con un tamaño de muestra creciente). En otras palabras, para muchas distribuciones de uso común y cuando el tamaño de la muestra es grande, el estimador verosímil se define de forma única con una alta probabilidad. A continuación, asumiremos que hemos observado \\(n\\) variables aleatorias iid \\(X_1,X_2,\\ldots,X_n\\) de la distribución considerada, aunque el valor del parámetro es desconocido. Además, \\(x_1,x_2,\\ldots,x_n\\) denotará los valores observados. Cabe señalar en el caso de los datos de recuento, y de los datos de distribuciones discretas en general, que la verosimilitud puede representarse alternativamente como \\[ L(\\theta):=\\prod_{k\\geq 0} \\left(p_\\theta(k)\\right)^{m_k}, \\] donde \\[ m_k:= \\left\\vert \\{i\\vert x_i=k, 1\\leq i \\leq n\\} \\right\\vert=\\sum_{i= 1}^n I(x_i=k), \\quad k\\geq 0. \\] Obsérvese que esta transformación conserva todos los datos, compilándolos de manera racionalizada. Para un \\(n\\) grande, lleva a la compresión de los datos en el sentido de suficiencia. A continuación, presentamos las expresiones para el MLE también en términos de \\(\\{m_k\\}_{k\\geq 1}\\). MLE – Distribución de Poisson: En este caso, como se ha señalado anteriormente, la verosimilitud viene dada por \\[ L(\\lambda)=\\left(\\prod_{i=1}^n x_i!\\right)^{-1}e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n x_i}, \\] que implica \\[ l(\\lambda)= -\\sum_{i=1}^n \\log(x_i!) -n\\lambda +\\log(\\lambda) \\cdot \\sum_{i=1}^n x_i, \\] y \\[ l&#39;(\\lambda)= -n +\\frac{1}{\\lambda}\\sum_{i=1}^n x_i. \\] En la evaluación de \\(l&#39;&#39;(\\lambda)\\), cuando \\(\\sum_{i=1}^n x_i&gt;0\\), \\(l&#39;&#39;&lt; 0\\). Por consiguiente, el máximo se alcanza en la media de la muestra, \\(\\overline{x}\\), que se presenta a continuación. Cuando \\(\\sum_{i=1}^n x_i=0\\), la verosimilitud es una función decreciente y, por lo tanto, el máximo se alcanza en el menor valor posible del parámetro; esto da como resultado que el estimador máximo verosímil sea cero. Por lo tanto, tenemos \\[ \\overline{x} = \\hat{\\lambda}_{\\rm MLE} = \\frac{1}{n}\\sum_{i=1}^n x_i. \\] Nótese que la media muestral puede calcularse también como \\[ \\frac{1}{n} \\sum_{k\\geq 1} km_k. \\] Cabe mencionar que en el caso de la Poisson, la distribución exacta de \\(\\hat{\\lambda}_{\\rm MLE}\\) está disponible en forma cerrada - es una Poisson a escala - cuando la distribución subyacente es una Poisson. Esto es así porque la suma de variables aleatorias independientes de Poisson es también una Poisson. Por supuesto, para muestras de gran tamaño se puede utilizar el Teorema Central del Límite (CLT, según sus siglas en inglés) ordinario para derivar una aproximación normal. Nótese que esta última aproximación es válida si la distribución subyacente es una distribución con un segundo momento finito. MLE – Distribución Binomial: A diferencia del caso de la distribución de Poisson, el espacio de parámetros en el caso de la binomial es bidimensional. Por lo tanto, el problema de optimización es un poco más difícil. Podemos comenzar observando que la verosimilitud viene dada por \\[ L(m,q)= \\left(\\prod_{i=1}^n \\binom{m}{x_i}\\right) q^{\\sum_{i=1}^n x_i} (1-q)^{nm-\\sum_{i=1}^n x_i}, \\] y el logaritmo de la verosimilitud por \\[ l(m,q)= \\sum_{i=1}^n \\log\\left(\\binom{m}{x_i}\\right) + \\left({\\sum_{i=1}^n x_i}\\right)\\log(q)+ \\left({nm-\\sum_{i=1}^n x_i}\\right)\\log(1-q). \\] Nótese que como \\(m\\) sólo toma valores enteros no negativos, no podemos usar cálculo multivariante para encontrar los valores óptimos. Sin embargo, podemos usar el cálculo para una sola variable para mostrar que \\[\\begin{equation} \\hat{q}_{\\rm MLE}\\times \\hat{m}_{\\rm MLE}= \\frac{1}{n}\\sum_{i=1}^n X_i. \\tag{2.2} \\end{equation}\\] En este sentido, observamos que para un valor fijado de \\(m\\), \\[ \\frac{\\delta}{\\delta q} l(m,q) = \\left({\\sum_{i=1}^n x_i}\\right)\\frac{1}{q}- \\left({nm-\\sum_{i=1}^n x_i}\\right)\\frac{1}{1-q}, \\] y que \\[ \\frac{\\delta^2}{\\delta q^2} l(m,q) = -\\left[\\left({\\sum_{i=1}^n x_i}\\right)\\frac{1}{q^2} + \\left({nm-\\sum_{i=1}^n x_i}\\right)\\frac{1}{(1-q)^2}\\right]\\leq 0. \\] Lo anterior implica que para un valor concreto de \\(m\\), el valor máximo de \\(q\\) satisface \\[ mq=\\frac{1}{n}\\sum_{i=1}^n X_i, \\] y por lo tanto establecemos la ecuación (2.2). Lo anterior reduce la tarea a la búsqueda de \\(\\hat{m}_{\\rm MLE}\\), que es miembro del conjunto de los maximizadores de \\[\\begin{equation} L\\left(m,\\frac{1}{nm}\\sum_{i=1}^n x_i\\right). \\tag{2.3} \\end{equation}\\] Nótese que la verosimilitud sería cero para valores de \\(m\\) menores a \\(\\max\\limits_{1\\leq i \\leq n}x_i\\), y por tanto \\[ \\hat{m}_{\\rm MLE}\\geq \\max_{1\\leq i \\leq n}x_i. \\] Para especificar un algoritmo para calcular \\(\\hat{m}_{\\rm MLE}\\), primero señalamos que para algunos conjuntos de datos \\(\\hat{m}_{\\rm MLE}\\) podría ser igual a \\(\\infty\\), lo que indicaría que una distribución de Poisson se ajustaría mejor que una distribución binomial. Esto es así, ya que la distribución binomial con los parámetros \\((m,\\overline{x}/m)\\) se aproxima a la distribución de Poisson con el parámetro \\(\\overline{x}\\) con \\(m\\) tendiendo a infinito. El hecho de que algunos conjuntos de datos prefieran una distribución de Poisson no debería ser sorprendente ya que desde este punto de vista el conjunto de la distribución de Poisson está en el límite del conjunto de las distribuciones binomiales. Curiosamente, en (Olkin, Petkau, and Zidek 1981) muestran que si la media de la muestra es menor o igual a la varianza de la muestra entonces \\(\\hat{m}_{\\rm MLE}=\\infty\\); de lo contrario, existe un \\(m\\) finito que maximiza la ecuación (2.3). En la siguiente Figura 2.2 se muestra el gráfico de \\(L\\left(m,\\frac{1}{nm}\\sum_{i=1}^n x_i\\right)\\) para tres muestras diferentes de tamaño \\(5\\); sólo difieren en el valor del máximo de la muestra. La primera muestra de \\((2,2,2,4,5)\\) tiene una relación entre la media de la muestra y la varianza de la muestra mayor a \\(1\\) (\\(1,875\\)), la segunda muestra de \\((2,2,2,4,6)\\) tiene la relación igual a \\(1,25\\) que está más cerca de \\(1\\), y la tercera muestra de \\((2,2,2,4,7)\\) tiene una relación menor a \\(1\\) (\\(0,885\\)). Para las tres muestras, como se muestra en la Figura 2.2, \\(\\hat{m}_{\\rm MLE}\\) es igual a \\(7\\), \\(18\\) and \\(\\infty\\), respectivamente. Nótese que el valor en el límite de \\(L\\left(m,\\frac{1}{nm}\\sum_{i=1}^n x_i\\right)\\) cuando \\(m\\) tiende a infinito es igual a \\[\\begin{equation} \\left(\\prod_{i=1}^n x_i! \\right)^{-1} \\exp\\left\\{-\\sum_{i=1}^n x_i\\right\\} \\overline{x}^{n\\overline{x}}. \\tag{2.4} \\end{equation}\\] También, se debe señalar que la Figura 2.2 muestra que el MLE de \\(m\\) es no robusto, i.e., pequeños cambios en el conjunto de datos pueden causar grandes cambios en el estimador. La discusión anterior sugiere el siguiente algoritmo sencillo: Paso 1. Si la media de la muestra es menor o igual a la varianza de la muestra, \\(\\hat{m}_{MLE}=\\infty\\). La distribución sugerida por MLE es una distribución de Poisson con \\(\\hat{\\lambda}=\\overline{x}\\). Paso 2. Si la media de la muestra es mayor que la varianza de la muestra, entonces calcula \\(L(m,\\overline{x}/m)\\) para valores de \\(m\\) mayores o iguales al máximo de la muestra hasta que \\(L(m,\\overline{x}/m)\\) se acerque al valor de la verosimilitud de Poisson dada en (2.4). El valor de \\(m\\) que corresponde al valor máximo de \\(L(m,\\overline{x}/m)\\) entre los calculados es igual a \\(\\hat{m}_{MLE}\\). Obsérvese que si la distribución subyacente es la distribución binomial con parámetros \\((m,q)\\) (con \\(q&gt;0\\)) entonces \\(\\hat{m}_{MLE}\\) será igual a \\(m\\) para los tamaños de muestra grandes. Además, \\(\\hat{q}_{MLE}\\) tendrá una distribución asintóticamente normal y convergerá con probabilidad uno a \\(q\\). Figure 2.2: Gráfico de \\(L(m,\\overline{x}/m)\\) de la distribución binomial MLE – Distribución Binomial Negativa: El caso de la distribución binomial negativa es similar al de la distribución binomial en el sentido de que tenemos dos parámetros y los MLE no existen en una forma cerrada. Una diferencia entre ellas es que, a diferencia del parámetro de la binomial \\(m\\) que toma valores enteros positivos, el parámetro \\(r\\) de la binomial negativa puede tomar cualquier valor real positivo. Esto hace que el problema de optimización sea un poco más complejo. Comencemos señalando que la verosimilitud puede expresarse de la siguiente forma: \\[ L(r,\\beta)=\\left(\\prod_{i=1}^n \\binom{r+x_i-1}{x_i}\\right) (1+\\beta)^{-n(r+\\overline{x})} \\beta^{n\\overline{x}}. \\] Lo anterior implica que la log-verosimilitud viene dada por \\[ l(r,\\beta)=\\sum_{i=1}^n \\log\\binom{r+x_i-1}{x_i} -n(r+\\overline{x}) \\log(1+\\beta) +n\\overline{x}\\log\\beta, \\] Y por tanto \\[ \\frac{\\delta}{\\delta\\beta} l(r,\\beta) = -\\frac{n(r+\\overline{x})}{1+\\beta} + \\frac{n\\overline{x}}{\\beta}. \\] Igualando la ecuación a cero, tenemos \\[ \\hat{r}_{MLE}\\times \\hat{\\beta}_{MLE} = \\overline{x}. \\] Lo anterior reduce el problema de optimización bidimensional a un problema unidimensional- se necesita maximizar \\[ l(r,\\overline{x}/r)=\\sum_{i=1}^n \\log\\binom{r+x_i-1}{x_i} -n(r+\\overline{x}) \\log(1+\\overline{x}/r) +n\\overline{x}\\log(\\overline{x}/r), \\] con respecto a \\(r\\), siendo el maximizador de \\(r\\) su MLE y \\(\\hat{\\beta}_{MLE}=\\overline{x}/\\hat{r}_{MLE}\\). En (Levin, Reeds, and others 1977) se muestra que si la varianza muestral es mayor que la media muestral, entonces existe un único \\(r&gt;0\\) que maximiza \\(l(r,\\overline{x}/r)\\) y por lo tanto un único MLE para \\(r\\) y \\(\\beta\\). Además, muestran que si \\(\\hat{\\sigma}^2\\leq \\overline{x}\\), entonces la verosimilitud de la binomial negativa estará dominada por la verosimilitud de la Poisson con \\(\\hat{\\lambda}=\\overline{x}\\). En otras palabras, una distribución de Poisson ofrece un mejor ajuste a los datos. La garantía en el caso de \\(\\hat{\\sigma}^2&gt;\\hat{\\mu}\\) nos permite usar un algoritmo para maximizar \\(l(r,\\overline{x}/r)\\). Mediante un método alternativo de calcular la verosimilitud, observamos que \\[ l(r,\\overline{x}/r)=\\sum_{i=1}^n \\sum_{j=1}^{x_i}\\log(r-1+j) - \\sum_{i=1}^n\\log(x_i!) - n(r+\\overline{x}) \\log(r+\\overline{x}) + nr\\log(r) + n\\overline{x}\\log(\\overline{x}), \\] lo que genera \\[ \\left(\\frac{1}{n}\\right)\\frac{\\delta}{\\delta r}l(r,\\overline{x}/r)=\\left(\\frac{1}{n}\\right)\\sum_{i=1}^n \\sum_{j=1}^{x_i}\\frac{1}{r-1+j} - \\log(r+\\overline{x}) + \\log(r). \\] Observamos que, en las expresiones anteriores para los términos que implican un doble sumatorio, el sumatorio interno es igual a cero si \\(x_i=0\\). El estimador máximo verosímil de \\(r\\) es una raíz de la última expresión y podemos usar un algoritmo de búsqueda de raíces para calcularla. Además, tenemos \\[ \\left(\\frac{1}{n}\\right)\\frac{\\delta^2}{\\delta r^2}l(r,\\overline{x}/r)=\\frac{\\overline{x}}{r(r+\\overline{x})}-\\left(\\frac{1}{n}\\right)\\sum_{i=1}^n \\sum_{j=1}^{x_i}\\frac{1}{(r-1+j)^2}. \\] Un algoritmo iterativo de búsqueda de raíces simple y de rápida convergencia es el método de Newton, que se cree que los Babilonios ya utilizaban para calcular raíces cuadradas. Con este método, se selecciona una aproximación inicial para la raíz y se generan sucesivamente nuevas aproximaciones para la raíz hasta la convergencia. Aplicando el método de Newton a nuestro problema se obtiene el siguiente algoritmo: Paso i. Elegir una solución aproximada, denominada \\(r_0\\). Fijar \\(k\\) igual a \\(0\\). Paso ii. Definir \\(r_{k+1}\\) como \\[ r_{k+1}:= r_k - \\frac{\\left(\\frac{1}{n}\\right)\\sum_{i=1}^n \\sum_{j=1}^{x_i}\\frac{1}{r_k-1+j} - \\log(r_k+\\overline{x}) + \\log(r_k)}{\\frac{\\overline{x}}{r_k(r_k+\\overline{x})}-\\left(\\frac{1}{n}\\right)\\sum_{i=1}^n \\sum_{j=1}^{x_i}\\frac{1}{(r_k-1+j)^2}} \\] Paso iii. Si \\(r_{k+1}\\sim r_k\\), entonces establece \\(r_{k+1}\\) como estimador máximo verosímil; en otro caso, incrementa \\(k\\) por \\(1\\) y repite Paso ii. Por ejemplo, simulamos una muestra de \\(5\\) observaciones de \\(41, 49, 40, 27, 23\\) de la binomial negativa con los parámetros \\(r=10\\) y \\(\\beta=5\\). Escogiendo el valor inicial de \\(r\\) de tal manera que \\[ r\\beta=\\hat{\\mu} \\quad \\hbox{and} \\quad r\\beta(1+\\beta)=\\hat{\\sigma}^2 \\] donde \\(\\hat{\\mu}\\) representa la media estimada y \\(\\hat{\\sigma}^2\\) es la varianza estimada. Esto nos conduce a un valor inicial de \\(r\\) de \\(23,14286\\). Las iteraciones de \\(r\\) del método de Newton son \\[ 21,39627, 21,60287, 21,60647, 21,60647; \\] la rápida convergencia anterior es frecuente con el método de Newton. Por lo tanto, en este ejemplo, \\(\\hat{r}_{MLE}\\sim21,60647\\) y \\(\\hat{\\beta}_{MLE}=8,3308\\). Implementación R del Método de Newton - MLE binomial negativa para \\(r\\) Mostrar Código R Newton&lt;-function(x,abserr){ mu&lt;-mean(x); sigma2&lt;-mean(x^2)-mu^2; r&lt;-mu^2/(sigma2-mu); b&lt;-TRUE; iter&lt;-0; while (b) { tr&lt;-r; m1&lt;-mean(c(x[x==0],sapply(x[x&gt;0],function(z){sum(1/(tr:(tr-1+z)))}))); m2&lt;-mean(c(x[x==0],sapply(x[x&gt;0],function(z){sum(1/(tr:(tr-1+z))^2)}))); r&lt;-tr-(m1-log(1+mu/tr))/(mu/(tr*(tr+mu))-m2); b&lt;-!(abs(tr-r)&lt;abserr); iter&lt;-iter+1; } c(r,iter) } Para concluir nuestra discusión sobre MLE para la clase de distribuciones \\((a,b,0)\\), en la Figura 2.3 siguiente representamos gráficamente el valor máximo de la verosimilitud de Poisson, \\(L(m,\\overline{x}/m)\\) para la binomial, y \\(L(r,\\overline{x}/r)\\) para la binomial negativa, para las tres muestras de tamaño \\(5\\) dadas en Tabla 2.1. Los datos se construyeron de tal forma que cubrieran las tres ordenaciones entre la media y varianza muestrales. Como se muestra en la Figura 2.3, y demostrado por la teoría, si \\(\\hat{\\mu}&lt;\\hat{\\sigma}^2\\) entonces la binomial negativa dará un mayor valor del máximo de verosimilitud; si \\(\\hat{\\mu}=\\hat{\\sigma}^2\\) la Poisson dará el mayor valor de la verosimilitud; y finalmente en el caso que \\(\\hat{\\mu}&gt;\\hat{\\sigma}^2\\) la binomial dará un mejor ajuste que las otras. Así que, antes de ajustar los datos con una distribución de frecuencias \\((a,b,0)\\), es mejor empezar por examinar el orden entre \\(\\hat{\\mu}\\) y \\(\\hat{\\sigma}^2\\). Cabe volver a enfatizar que la Poisson está en el límite de las distribuciones binomial negativa y binomial. Por lo tanto en el caso que \\(\\hat{\\mu}\\geq\\hat{\\sigma}^2\\) (\\(\\hat{\\mu}\\leq\\hat{\\sigma}^2\\), resp.) la Poisson dará un mejor ajuste que la binomial negativa (binomial, resp.), que también se indicará con \\(\\hat{r}=\\infty\\) (\\(\\hat{m}=\\infty\\), resp.). \\[\\begin{matrix} \\begin{array}{c|c|c} \\hline \\text{Datos} &amp; \\text{Media }(\\hat{\\mu}) &amp; \\text{Varianza }(\\hat{\\sigma}^2) \\\\ \\hline (2,3,6,8,9) &amp; 5,60 &amp; 7,44 \\\\ (2,5,6,8,9) &amp; 6 &amp; 6\\\\ (4,7,8,10,11) &amp; 8 &amp; 6\\\\\\hline \\end{array} \\end{matrix}\\] Tabla 2.1 : Tres Muestras de Tamaño \\(5\\) Figure 2.3: Gráfico de las Verosimilitudes Parcialmente Maximizadas \\((a,b,0)\\) 2.5 Otras Distribuciones de Frecuencias En esta sección, se aprende a: Definir la clase de distribuciones de frecuencia (a,b,1) y discutir la importancia de la relación recursiva que sustenta esta clase de distribuciones Interpretar las versiones truncadas y modificadas en cero de las distribuciones binomiales, Poisson y binomial negativa Calcular las probabilidades usando la relación recursiva En las secciones anteriores hemos examinado tres distribuciones con soporte definido en el conjunto de números enteros no negativos, que se adaptan bien a muchas aplicaciones de seguros. Además, al permitir frecuentemente que los parámetros sean una función de variables explicativas conocidas (por el asegurador) como la edad, el sexo, la ubicación geográfica (territorio), etc., estas distribuciones nos permiten explicar las probabilidades de siniestro en términos de estas variables. El ámbito de la estadística que analiza estos modelos se conoce como análisis de regresión - es un tópico importante de interés actuarial que no se tratará en este libro; ver (Edward W Frees 2009). Es evidente que existen infinitas otras distribuciones de recuento, y lo que es más importante, las distribuciones anteriores por sí mismas no satisfacen todas las necesidades prácticas. En concreto, una característica de algunos datos en seguros es que la proporción de ceros puede ser muy diferente en la relación a la proporción de otros valores para que puedan ser explicados por las distribuciones anteriores. A continuación, se modifican las distribuciones previas para permitir una probabilidad arbitraria para el recuento de ceros, independientemente de la asignación relativa de probabilidades para los otros valores. Otra característica de un conjunto de datos que está compuesto por subconjuntos homogéneos es que, aunque las distribuciones anteriores pueden proporcionar buenos ajustes a cada subconjunto, pueden no hacerlo para la totalidad del conjunto de datos. Posteriormente, se amplían de forma natural las distribuciones \\((a,b,0)\\) para poder cubrir, en particular, estos conjuntos de datos. 2.5.1 Modificación o Truncamiento en Cero Supongamos que analizamos pólizas del seguro de automóvil que aparecen en una base de datos de siniestros de automóvil ocurridos en un determinado período. Si se estudia el número de siniestros que estas pólizas han tenido durante este período, entonces obviamente la distribución tiene que asignar una probabilidad de cero a la variable de recuento que asume el valor cero. En otras palabras, al restringir la atención a los datos de recuento en las pólizas de la base de datos de siniestros, en cierto modo hemos truncado en cero los datos de recuento de todas las pólizas. En productos de seguros a particulares (como en el caso de los automóviles), los asegurados pueden no querer informar del primer siniestro por temor a que aumente el precio del seguro en el futuro - este comportamiento inflará la proporción de recuentos de cero. Ejemplos como estos últimos modifican la proporción de ceros. Es interesante mencionar que las modificaciones naturales de las tres distribuciones anteriores son capaces de proporcionar buenos ajustes a los conjuntos de datos cero modificados/truncados que se generan en el seguro. Como se presenta a continuación, se modifica la probabilidad que se le asigna al valor cero en la clase \\((a,b,0)\\) manteniendo las probabilidades relativas asignadas a los valores no nulos - modificación en cero. Nótese que como la clase de distribuciones \\((a,b,0)\\) satisface la recurrencia (2.1), el mantenimiento de las probabilidades relativas de los valores no nulos implica que la recurrencia (2.1) se satisface para \\(k\\geq 2\\). Esto nos lleva a la definición de la siguiente clase de distribuciones. Definición. Una distribución de recuento es un miembro de la clase \\((a, b, 1)\\) si para las constantes \\(a\\) y \\(b\\) las probabilidades \\(p_k\\) satisfacen \\[\\begin{equation} \\frac{p_k}{p_{k-1}}=a+\\frac{b}{k},\\quad k\\geq 2. \\tag{2.5} \\end{equation}\\] Nótese que como la recursión empieza en \\(p_1\\), y no en \\(p_0\\), nos referimos a esta superclase de distribuciones \\((a,b,0)\\) como (a,b,1). Para entender esta clase, recordemos que cada par de valores válidos para \\(a\\) y \\(b\\) de la clase \\((a,b,0)\\) corresponde a un único vector de probabilidades \\(\\{p_k\\}_{k\\geq 0}\\). Si ahora observamos el vector de probabilidades \\(\\{\\tilde{p}_k\\}_{k\\geq 0}\\) dado por \\[ \\tilde{p}_k= \\frac{1-\\tilde{p}_0}{1-p_0}\\cdot p_k, \\quad k\\geq 1, \\] donde \\(\\tilde{p}_0\\in[0,1)\\) se elige arbitrariamente, entonces como las probabilidades relativas de valores positivos de acuerdo con \\(\\{p_k\\}_{k\\geq 0}\\) y \\(\\{\\tilde{p}_k\\}_{k\\geq 0}\\) son las mismas, tenemos que \\(\\{\\tilde{p}_k\\}_{k\\geq 0}\\) satisface la recurrencia (2.5). Esto, en particular, muestra que la clase de distribuciones \\((a,b,1)\\) es estrictamente más amplia que la \\((a,b,0)\\). Previamente, hemos establecido un par de valores para \\(a\\) y \\(b\\) que llevaron a una distribución válida de \\((a,b,0)\\), y luego miramos las distribuciones \\((a,b,1)\\) que correspondían a esta distribución \\((a,b,0)\\). Ahora argumentaremos que la clase \\((a,b,1)\\) admite un conjunto mayor de distribuciones permitidas para \\(a\\) y \\(b\\) que la clase \\((a,b,0)\\). Recordemos de la Sección 2.3 que en el caso de \\(a&lt;0\\) no se utiliza el hecho de que la recurrencia (2.1) empieza en \\(k=1\\), y por lo tanto el conjunto de pares \\((a,b)\\) con \\(a&lt;0\\) que son admisibles para la clase \\((a,b,0)\\) es idéntico al que es admisible para la clase \\((a,b,1)\\). La misma conclusión se puede extraer fácilmente para los pares con \\(a=0\\). En el caso que \\(a&gt;0\\), en lugar de la restricción \\(a+b&gt;0\\) para la clase \\((a,b,0)\\), tenemos ahora la restricción más débil de \\(a+b/2&gt;0\\) para la clase \\((a,b,1)\\). Con la parametrización \\(b=(r-1)a\\) utilizada en la Sección 2.3, en lugar de \\(r&gt;0\\) tenemos ahora la restricción más débil de \\(r&gt;-1\\). En particular, vemos que mientras que al modificar el cero en una distribución \\((a,b,0)\\) conduce a una distribución de la clase \\((a,b,1)\\), está conclusión no se cumple en la dirección contraria. La modificación en cero de una distribución de recuento \\(F\\) tal que asigna una probabilidad cero al valor cero se llama un truncamiento en cero de \\(F\\). De este modo, la versión truncada en cero de las probabilidades \\(\\{p_k\\}_{k\\geq 0}\\) viene dada por \\[ \\tilde{p}_k=\\begin{cases} 0, &amp; k=0;\\\\ \\frac{p_k}{1-p_0}, &amp; k\\geq 1. \\end{cases} \\] En concreto, tenemos que una modificación en cero de una distribución de recuento \\(\\{p_k^T\\}_{k\\geq 0}\\), denotada por \\(\\{p^M_k\\}_{k\\geq 0}\\), puede escribirse como una combinación convexa de la distribución degenerada en \\(0\\) y el truncamiento en cero de \\(\\{p_k\\}_{k\\geq 0}\\), denotado por \\(\\{p^T_k\\}_{k\\geq 0}\\). De este modo tenemos \\[ p^M_k= p^M_0 \\cdot \\delta_{0}(k) + (1-p^M_0) \\cdot p^T_k, \\quad k\\geq 0. \\] Ejemplo 2.5.1. Poisson Cero Modificada/Truncada. Considerar una distribución de Poisson con parámetro \\(\\lambda=2\\). Calcular \\(p_k, k=0,1,2,3\\), para la usual (sin modificar), truncada y una versión modificada con \\((p_0^M=0,6)\\). Mostrar Solución de Ejemplo Solución. Para la distribución de Poisson como miembro de la clase ((\\(a,b\\),0), tenemos \\(a=0\\) y \\(b=\\lambda=2\\). Por lo tanto, podemos usar para cada tipo la recursión \\(p_k = \\lambda p_{k-1}/k= 2 p_{k-1}/k\\), después de determinar las probabilidades iniciales. El cálculo de probabilidades para \\(k\\leq 3\\) se muestra en Tabla 2.2. \\[\\begin{matrix} \\begin{array}{c|c|c|c} \\hline k &amp; p_k &amp; p_k^T &amp; p_k^M\\\\\\hline 0 &amp; p_0=e^{-\\lambda}=0,135335 &amp; 0 &amp; 0,6\\\\\\hline 1 &amp; p_1=p_0(0+\\frac{\\lambda}{1})=0,27067 &amp; \\frac{p_1}{1-p_0}=0,313035 &amp; \\frac{1-p_0^M}{1-p_0}~p_1=0,125214\\\\\\hline 2 &amp; p_2=p_1\\left( \\frac{\\lambda}{2}\\right)=0,27067 &amp; p_2^T=p_1^T\\left(\\frac{\\lambda}{2}\\right)=0,313035 &amp; p_2^M=p_1^M\\left(\\frac{\\lambda}{2}\\right)=0,125214\\\\\\hline 3 &amp; p_3=p_2\\left(\\frac{\\lambda}{3}\\right)=0,180447 &amp; p_3^T=p_2^T\\left(\\frac{\\lambda}{3}\\right)=0,208690 &amp; p_3^M=p_2^M\\left(\\frac{\\lambda}{3}\\right)=0,083476\\\\\\hline \\end{array} \\end{matrix}\\] Tabla 2.2 : Cálculo de probabilidades para \\(k\\leq 3\\) 2.6 Distribuciones Mixtas En esta sección, se aprende a: Definir una distribución mixta cuando el componente de mixtura se basa en un número finito de subgrupos Calcular las probabilidades de la distribución mixta a partir de las proporciones de la mixtura y el conocimiento de la distribución de cada subgrupo Definir una distribución mixta cuando el componente de mixtura es continuo En muchas aplicaciones la población subyacente consiste en subgrupos definidos de forma natural con cierta homogeneidad dentro de cada subgrupo. En estos casos es conveniente modelizar los subgrupos individuales y, de manera fundamentada, modelizar el conjunto de la población. Como veremos más adelante, más allá del atractivo del enfoque, también se amplía el abanico de aplicaciones que pueden cubrirse mediante las distribuciones paramétricas estándar. Supongamos que \\(k\\) denota el número de subgrupos definidos en una población, y \\(F_i\\) denota la distribución de una observación extraída del subgrupo \\(i\\)-ésimo. Si dejamos que \\(\\alpha_i\\) denote la proporción de la población en el subgrupo \\(i\\)-ésimo, con \\(\\sum_{i=1}^k \\alpha_i=1\\), entonces la distribución de una observación elegida al azar de la población, denotada por \\(F\\), viene dada por \\[\\begin{equation} F(x)=\\sum_{i=1}^k \\alpha_i \\cdot F_i(x). \\tag{2.6} \\end{equation}\\] La expresión anterior puede considerarse una aplicación directa de la Ley de Probabilidad Total. Como ejemplo, consideremos una población de conductores dividida en dos subgrupos, los que tienen como máximo \\(5\\) años de experiencia de conducción y los que tienen más de \\(5\\) años de experiencia. Supongamos que \\(\\alpha\\) denota la proporción de conductores con menos de \\(5\\) años de experiencia, y \\(F_{\\leq 5}\\) y \\(F_{&gt; 5}\\) denotan la distribución del número de siniestros en un año para un conductor de cada grupo, respectivamente. Entonces la distribución del número de siniestros de un conductor seleccionado al azar viene dada por \\[ \\alpha\\cdot F_{\\leq 5}(x) + (1-\\alpha)F_{&gt; 5}(x). \\] Una definición alternativa de una distribución mixta es la siguiente. Supongamos que \\(N_i\\) es una variable aleatoria con distribución \\(F_i\\), \\(i=1,\\ldots, k\\). Sea \\(I\\) una variable aleatoria que toma valores \\(1,2,\\ldots,k\\) con probabilidades \\(\\alpha_1,\\ldots,\\alpha_k\\), respectivamente. Entonces, la variable aleatoria \\(N_I\\) tiene una distribución dada por la ecuación (2.6)8. En (2.6) vemos que la función de distribución es una combinación convexa de las funciones de distribución que la componen. Este resultado se extiende fácilmente a la función de densidad, la función de supervivencia, los momentos ordinarios y el valor esperado, ya que todos ellos son aplicaciones lineales de la función de distribución. Observamos que esto no es cierto en el caso de los momentos centrales como la varianza, y de las medidas condicionales como la función de tasa de riesgo (hazard rate). En el caso de la varianza se ve fácilmente como \\[\\begin{equation} \\mathrm{Var}{[N_I]}=\\mathrm{E}[{\\mathrm{Var}[{N_I\\vert I}]]} + \\mathrm{Var}[{\\mathrm{E}[{N_I|I}}]]=\\sum_{i=1}^k \\alpha_i \\mathrm{Var}[{N_i}] + \\mathrm{Var}[{\\mathrm{E}[{N_I|I}}]] . \\tag{2.7} \\end{equation}\\] El Apéndice 16 proporciona información adicional sobre esta importante expresión. Ejemplo 2.6.1. Pregunta de Examen Actuarial. En una determinada ciudad el número de resfriados comunes que un individuo tendrá en un año sigue una distribución de Poisson que depende de la edad del individuo y su condición de fumador. La distribución de la población y el número medio de resfriados son los siguientes: \\[\\begin{matrix} \\begin{array}{l|c|c} \\hline &amp; \\text{Proporción de población} &amp; \\text{Número medio de resfriados}\\\\\\hline \\text{Niños} &amp; 0,3 &amp; 3\\\\ \\text{Adultos No-fumadores} &amp; 0,6 &amp; 1\\\\ \\text{Adultos Fumadores} &amp; 0,1 &amp; 4\\\\\\hline \\end{array} \\end{matrix}\\] Tabla 2.3 : La distribución de la población y el número medio de resfriados Calcular la probabilidad de que una persona seleccionada al azar tenga 3 resfriados comunes en un año. Calcular la probabilidad condicionada de que una persona con exactamente 3 resfriados comunes en un año sea un fumador adulto. Mostrar Solución de Ejemplo Solución. Utilizando la Ley de Probabilidad Total, podemos escribir la probabilidad requerida como \\(\\Pr(N_I=3)\\), con \\(I\\) que denota el grupo del individuo seleccionado al azar con \\(1,2\\) y \\(3\\) que significan los grupos Niños, Adulto No Fumador, y Adulto Fumador, respectivamente. Ahora, por el condicionamiento, tenemos \\[ \\Pr(N_I=3)=0,3\\cdot\\Pr(N_1=3)+0,6\\cdot\\Pr(N_2=3)+0,1\\cdot\\Pr(N_3=3), \\] con \\(N_1,N_2\\) y \\(N_3\\) que siguen una distribución de Poisson de media \\(3,1\\), y \\(4\\), respectivamente. Utilizando lo anterior, obtenemos \\(\\Pr(N_I=3)\\sim0,1235\\) La probabilidad condicionada del evento A dado el evento B, \\(\\Pr(A\\vert B) = \\frac{\\Pr(A,B)}{\\Pr(B)}\\). La probabilidad condicionada requerida en este problema puede escribirse como \\(\\Pr(I=3\\vert N_I=3)\\), que es igual a \\[ \\Pr(I=3\\vert N_I=3)=\\frac{\\Pr(I=3,N_3=3)}{\\Pr(N_I=3)}\\sim\\frac{0,1 \\times 0,1954}{0,1235}\\sim 0,1581. \\] En el ejemplo previo, el número de subgrupos \\(k\\) era igual a tres. En general, \\(k\\) puede ser cualquier número natural, pero cuando \\(k\\) es grande es parsimonioso desde el punto de vista de la modelización tomar el siguiente enfoque de infinitamente muchos subgrupos. Para justificar este enfoque, supongamos que el subgrupo \\(i\\)-ésimo sea tal que su distribución componente \\(F_i\\) viene dada por \\(G_{\\tilde{\\theta_i}}\\), donde \\(G_\\cdot\\) es una familia paramétrica de distribuciones con espacio paramétrico \\(\\Theta\\subseteq \\mathbb{R}^d\\). Con este supuesto, la función de distribución \\(F\\) de una observación extraída aleatoriamente de la población viene dada por \\[ F(x)=\\sum_{i=1}^k \\alpha_i G_{\\tilde{\\theta_i}}(x),\\quad \\forall x\\in\\mathbb{R}. \\] que puede escribirse alternativamente como \\[ F(x)=\\mathrm{E}[{G_{\\tilde{\\vartheta}}(x)}],\\quad \\forall x\\in\\mathbb{R}, \\] donde \\(\\tilde{\\vartheta}\\) toma valores \\(\\tilde{\\theta_i}\\) con probabilidad \\(\\alpha_i\\), para \\(i=1,\\ldots,k\\). Esto muestra que cuando \\(k\\) es grande, se puede modelizar lo anterior tratando \\(\\tilde{\\vartheta}\\) como una variable aleatoria continua. Para ilustrar este enfoque, supongamos que tenemos una población de conductores con la distribución de siniestros de un conductor individual que se distribuye como una Poisson. Cada persona tiene su propio (personal) número esperado de siniestros \\(\\lambda\\) - valores más pequeños para los buenos conductores, y valores más grandes para el resto. Hay una distribución de \\(\\lambda\\) en la población; una opción común y conveniente para la modelización de esta distribución es una distribución gamma con parámetros \\((\\alpha, \\theta)\\). Con estas características resulta que la distribución resultante de \\(N\\), los siniestros de un conductor elegido aleatoriamente, es una binomial negativa con parámetros \\((r=\\alpha,\\beta=\\theta)\\). Esto puede mostrarse de muchas maneras, pero una forma sencilla es la siguiente: \\[\\begin{align*} \\Pr(N=k)&amp;= \\int_0^\\infty \\frac{e^{-\\lambda}\\lambda^k}{k!} \\frac{\\lambda^{\\alpha-1}e^{-\\lambda/\\theta}}{\\Gamma{(\\alpha)}\\theta^{\\alpha}} {\\rm d}\\lambda = \\frac{1}{k!\\Gamma(\\alpha)\\theta^\\alpha}\\int_0^\\infty \\lambda^{\\alpha+k-1}e^{-\\lambda(1+1/\\theta)}{\\rm d}\\lambda=\\frac{\\Gamma{(\\alpha+k)}}{k!\\Gamma(\\alpha)\\theta^\\alpha(1+1/\\theta)^{\\alpha+k}} \\\\ &amp;=\\binom{\\alpha+k-1}{k}\\left(\\frac{1}{1+\\theta}\\right)^\\alpha\\left(\\frac{\\theta}{1+\\theta}\\right)^k, \\quad k=0,1,\\ldots \\end{align*}\\] Obsérvese que la derivación previa utiliza implícitamente lo siguiente: \\[ f_{N\\vert\\Lambda=\\lambda}(N=k)=\\frac{e^{-\\lambda}\\lambda^k}{k!}, \\quad k\\geq 0; \\quad \\hbox{y} \\quad f_{\\Lambda}(\\lambda)= \\frac{\\lambda^{\\alpha-1}e^{-\\lambda/\\theta}}{\\Gamma{(\\alpha)}\\theta^{\\alpha}}, \\quad \\lambda&gt;0. \\] Cabe mencionar que al considerar las mixturas de una clase paramétrica de distribuciones se incrementa la riqueza de la clase. Esta expansión de las distribuciones da como resultado que la clase de mixtura pueda adaptarse bien a más aplicaciones que la clase paramétrica inicial. La modelización de mixturas es una técnica de modelización muy importante en las aplicaciones de seguros, y en los capítulos posteriores se tratarán más aspectos de esta técnica de modelización. Ejemplo 2.6.2. Supongamos que \\(N|\\Lambda \\sim\\) Poisson\\((\\Lambda)\\) y que \\(\\Lambda \\sim\\) gamma con media de 1 y varianza de 2. Determinar la probabilidad que \\(N=1\\). Mostrar Solución de Ejemplo Solución. Para una distribución gamma con parámetros \\((\\alpha, \\theta)\\), tenemos que la media es \\(\\alpha \\theta\\) y la varianza es \\(\\alpha \\theta^2\\). En base a estas expresiones tenemos que \\[ \\begin{aligned} \\alpha &amp;= \\frac{1}{2} \\text{ y } \\theta =2. \\end{aligned} \\] Ahora, se puede utilizar directamente el resultado anterior para concluir que \\(N\\) se distribuye como una binomial negativa con \\(r = \\alpha = \\frac{1}{2}\\) y \\(\\beta= \\theta =2\\). Por lo tanto, \\[ \\begin{aligned} \\Pr(N=1) &amp;= \\binom{1+r-1}{1}(\\frac{1}{(1+\\beta)^r})\\left(\\frac{\\beta}{1+\\beta}\\right)^1 \\\\ &amp;= \\binom{1+\\frac{1}{2}-1}{1}{\\frac{1}{(1+2)^{1/2}}}\\left(\\frac{2}{1+2}\\right)^1\\\\ &amp;= \\frac{1}{3^{3/2}} = 0,19245 . \\end{aligned} \\] 2.7 Bondad del Ajuste En esta sección, se aprende a: Calcular un estadístico de bondad del ajuste para comparar una distribución discreta hipotética con una muestra de observaciones discretas Comparar el estadístico con una distribución de referencia para evaluar la adecuación del ajuste Previamente se han analizado tres distribuciones de frecuencias elementales, junto con sus extensiones mediante la modificación/truncamiento en cero y mostrando las mixturas de estas distribuciones. Ahora bien, estas clases siguen siendo paramétricas y, por tanto, por su propia naturaleza, un pequeño subconjunto de la clase de todas las distribuciones de frecuencia posibles (i.e. el conjunto de distribuciones para números enteros no negativos.) Por lo tanto, aunque hemos mostrado métodos para estimar los parámetros desconocidos, la distribución ajustada no será una buena representación de la distribución subyacente si ésta está lejos de la clase de distribución utilizada en la modelización. De hecho, se puede demostrar que el estimador máximo verosímil convergerá a un valor de tal forma que la distribución correspondiente será una proyección Kullback-Leibler de la distribución subyacente en la clase de distribuciones utilizada para la modelización. A continuación presentamos un método de contraste - el estadístico chi-cuadrado de Pearson - para comprobar la bondad del ajuste de la distribución ajustada. Para más detalles sobre el contraste chi-cuadrado de Pearson, a un nivel introductorio de estadística matemática, remitimos al lector a la Sección 9.1 de (Hogg, Tanis, and Zimmerman 2015). En \\(1993\\), una cartera de \\(n=7.483\\) pólizas de seguro de automóvil de una importante compañía de seguros de Singapur tenía la distribución de accidentes de automóvil por asegurado como se indica en Tabla 2.4. \\[\\begin{matrix} \\begin{array}{c|c|c|c|c|c|c} \\hline \\text{Número }(k) &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; \\text{Total}\\\\ \\hline \\text{No. de Pólizas con }k\\text{ accidentes }(m_k) &amp; 6.996 &amp; 455 &amp; 28 &amp; 4 &amp; 0 &amp; 7483\\\\ \\hline \\end{array} \\end{matrix}\\] Tabla 2.4 : Datos de Accidentes de Automóvil en Singapur Si se ajusta una distribución de Poisson, entonces el MLE para \\(\\lambda\\), la media de la Poisson, es la media muestral que es igual a \\[ \\overline{N} = \\frac{0\\cdot 6996 + 1 \\cdot 455 + 2 \\cdot 28 + 3 \\cdot 4 + 4 \\cdot 0}{7483} = 0,06989. \\] Ahora si se usa la Poisson (\\(\\hat{\\lambda}_{MLE}\\)) como la distribución ajustada, entonces una comparación tabular de los valores ajustados y los valores observados se muestra en la Tabla 2.5 siguiente, donde \\(\\hat{p}_k\\) representa las probabilidades estimadas mediante la distribución de Poisson ajustada. \\[\\begin{matrix} \\begin{array}{c|c|c} \\hline \\text{Número} &amp; \\text{Observado} &amp; \\text{Ajustado}\\\\ (k) &amp; (m_k) &amp; \\text{Usando Poisson }(n\\hat{p}_k)\\\\ \\hline 0 &amp; 6.996 &amp; 6.977,86 \\\\ 1 &amp; 455 &amp; 487,70 \\\\ 2 &amp; 28 &amp; 17,04 \\\\ 3 &amp; 4 &amp; 0,40 \\\\ \\geq4 &amp; 0 &amp; 0,01\\\\ \\hline \\text{Total} &amp; 7.483 &amp; 7.483,00\\\\ \\hline \\end{array} \\end{matrix}\\] Tabla 2.5 : Comparación entre valores observados y ajustados: Datos de automóviles de Singapur Mientras que el ajuste parece razonable, una comparación tabular no es suficiente como contraste estadístico de la hipótesis de que la distribución subyacente es efectivamente la Poisson. El estadístico de chi-cuadrado de Pearson es una medida de bondad del ajuste que puede utilizarse para este propósito. Para explicar este estadístico, supongamos que un conjunto de datos de tamaño \\(n\\) se agrupa en \\(k\\) celdas, siendo \\(m_k/n\\) y \\(\\hat{p}_k\\), para \\(k=1\\ldots,K\\), las probabilidades observadas y estimadas de que una observación pertenezca a la celda \\(k\\)-ésima, respectivamente. El estadístico del contraste chi-cuadrado de Pearson viene dado por \\[ \\sum_{k=1}^K\\frac{\\left( m_k-n\\widehat{p}_k \\right) ^{2}}{n\\widehat{p}_k}. \\] La justificación del estadístico anterior se deriva del hecho que \\[ \\sum_{k=1}^K\\frac{\\left( m_k-n{p}_k \\right) ^{2}}{n{p}_k} \\] tiene como límite una distribución chi-cuadrado con \\(K-1\\) grados de libertad si \\(p_k\\), \\(k=1,\\ldots,K\\) son las probabilidades verdaderas de cada celda. Ahora supongamos que sólo los datos resumidos representados por \\(m_k\\), \\(k=1,\\ldots,K\\) están disponibles. Además, si las \\(p_k\\) son funciones de \\(s\\) parámetros, sustituyendo las \\(p_k\\) por cualquier probabilidad estimada eficientemente \\(\\widehat{p}_k\\), el estadístico sigue teniendo una distribución chi-cuadrado como límite pero con \\(K-1-s\\) grados de libertad. Estas estimaciones eficientes pueden obtenerse, por ejemplo, usando el método MLE (con una verosimilitud multinomial) o estimando los \\(s\\) parámetros que minimizan el estadístico chi-cuadrado de Pearson previo. Por ejemplo, el código R que se muestra a continuación realiza una estimación de \\(\\lambda\\) en base a esto último y se obtiene un estimador de \\(0,06623153\\), cercano pero diferente del MLE de \\(\\lambda\\) usando la totalidad de los datos: m&lt;-c(6996,455,28,4,0); op&lt;-m/sum(m); g&lt;-function(lam){sum((op-c(dpois(0:3,lam),1-ppois(3,lam)))^2)}; optim(sum(op*(0:4)),g,method=&quot;Brent&quot;,lower=0,upper=10)$par Cuando se usa la totalidad de los datos para estimar las probabilidades, la distribución asintótica está entre las distribuciones chi-cuadrado con parámetros \\(K-1\\) y \\(K-1-s\\). En la práctica, normalmente no se considera este matiz y se asume que la chi-cuadrado límite tiene \\(K-1-s\\) grados de libertad. Curiosamente, esta forma de actuar funciona bastante bien en el caso de la distribución de Poisson. Para los datos de autos de Singapur el estadístico chi-cuadrado de Pearson es igual a \\(41,98\\) utilizando el conjunto de datos MLE para \\({\\lambda}\\). Usando la distribución límite de chi-cuadrado con \\(5-1-1=3\\) grados de libertad, vemos que el valor de \\(41,98\\) está muy lejos en la cola (el percentil \\(99\\) está por debajo de \\(12\\)). Por lo tanto, podemos concluir que la distribución de Poisson proporciona un ajuste inadecuado para los datos. Anteriormente, en la tabla resumen previa hemos considerado que las celdas vienen dadas. En la práctica, una pregunta relevante es cómo definir las celdas para que la distribución chi-cuadrado sea una buena aproximación a la distribución de muestra finita del estadístico. Una regla empírica es definir las celdas de tal manera que el \\(80%\\) de las celdas, si no todas, tengan al menos valores esperados mayores a \\(5\\). Además, puesto que un mayor número de celdas proporciona una mayor potencia del contraste, una simple regla empírica es por tanto maximizar el número de celdas de tal forma que cada celda tenga al menos 5 observaciones. 2.8 Ejercicios Ejercicios Teóricos Ejercicio 2.1. Derivar una expresión para \\(p_N(\\cdot)\\) en términos de \\(F_N(\\cdot)\\) y \\(S_N(\\cdot)\\). Ejercicio 2.2. Una medida del centro de localización debe ser equivariable con respecto a los desplazamientos, o transformaciones de localización. En otras palabras, si \\(N_1\\) y \\(N_2\\) son dos variables aleatorias tales que \\(N_1+c\\) tiene la misma distribución que \\(N_2\\), para una constante \\(c\\), entonces la diferencia entre las medidas del centro de localización de \\(N_2\\) y \\(N_1\\) debe ser igual a \\(c\\). Mostrar que la media satisface esta propiedad. Ejercicio 2.3. Las medidas de dispersión deben ser invariables con respecto a desplazamientos y escala equi-variables. Demuestre que la desviación estándar satisface estas propiedades haciendo lo siguiente: Mostrar que para una variable aleatoria \\(N\\), su desviación estándar es igual a la de \\(N+c\\), para cualquier constante \\(c\\). Mostrar que para una variable aleatoria \\(N\\), su desviación estándar es igual a \\(1/c\\) por \\(cN\\), para cualquier constante positiva \\(c\\). Ejercicio 2.4. Supongamos que \\(N\\) es una variable aleatoria con función masa de probabilidad dada por \\[ p_N(k):= \\begin{cases} \\left(\\frac{6}{\\pi^2}\\right)\\left(\\frac{1}{k^{2}}\\right), &amp; k\\geq 1;\\\\ 0, &amp;\\hbox{en otro caso}. \\end{cases} \\] Demostrar que la media de \\(N\\) es \\(\\infty\\). Ejercicio 2.5. Supongamos que \\(N\\) es una variable aleatoria con segundo momento finito. Demostrar que la función \\(\\psi(\\cdot)\\) definida por \\[ \\psi(x):=\\mathrm{E}{(N-x)^2}. \\quad x\\in\\mathbb{R} \\] se minimiza en \\(\\mu_N\\) sin realizar cálculos. También, proporcionar una demostración de este resultado mediante derivadas. Concluir que el valor mínimo es igual a la varianza de \\(N\\). Ejercicio 2.6. Derivar los dos primeros momentos centrales de las distribuciones \\((a,b,0)\\) utilizando los métodos mencionados a continuación: Para la distribución binomial, derivar los momentos usando sólo su pmf, luego su mgf, y luego su pgf. Para la distribución Poisson, derivar los momentos usando sólo su mgf. Para la distribución binomial negativa, derivar los momentos usando sólo su pmf, y luego su pgf. Ejercicio 2.7. Supongamos que \\(N_1\\) y \\(N_2\\) son dos variables aleatorias independientes de Poisson con medias \\(\\lambda_1\\) y \\(\\lambda_2\\), respectivamente. Identificar la distribución condicionada de \\(N_1\\) dado \\(N_1+N_2\\). Ejercicio 2.8. (No unicidad de MLE) Considerar la siguiente familia paramétrica de densidades indexadas por el parámetro \\(p\\) que toma valores en \\([0,1]\\): \\[ f_p(x)=p\\cdot\\phi(x+2)+(1-p)\\cdot\\phi(x-2), \\quad x\\in\\mathbb{R}, \\] donde \\(\\phi(\\cdot)\\) representa la densidad normal estándar. Mostrar que para todos los \\(p\\in[0,1]\\), la \\(f_p(\\cdot)\\) previa es una función de densidad válida. Encontrar una expresión en \\(p\\) para la media y la varianza de \\(f_p(\\cdot)\\). Supongamos una muestra de tamaño uno que consiste en \\(x\\). Mostrar que cuando \\(x\\) es igual a \\(0\\), el conjunto de estimadores máximo verosímiles para \\(p\\) es igual a \\([0,1]\\); también mostrar que el MLE es único en otro caso. Ejercicio 2.9. Representar gráficamente la región del plano que corresponde a los valores de \\((a,b)\\) que dan lugar a distribuciones \\((a,b,0)\\) válidas. Hacer lo mismo para las distribuciones \\((a,b,1)\\). Ejercicio 2.10. (Complejidad computacional) Para la clase de distribuciones \\((a,b,0)\\), contabilizar el número de operaciones matemáticas básicas (suma, resta, multiplicación, división) necesarias para calcular las \\(n\\) probabilidades \\(p_0\\ldots p_{n-1}\\) utilizando la relación de recurrencia. Para la distribución binomial negativa con \\(r\\) no entero, contabilizar el número de estas operaciones. ¿Qué es lo que observas? Ejercicio 2.11. (** **) Utilizando el desarrollo de la Sección 2.3 mostrar de forma rigurosa que no sólo la recurrencia (2.1) une las distribuciones binomiales, Poisson y binomial negativa, sino que también las caracteriza. Ejercicios con Enfoque Práctico Ejercicio 2.12. Pregunta de Examen Actuarial. Se conoce: \\(p_k\\) denota la probabilidad que el número de siniestros sea igual a \\(k\\) para \\(k=0,1,2,\\ldots\\) \\(\\frac{p_n}{p_m}=\\frac{m!}{n!}, m\\ge 0, n\\ge 0\\) Usando la distribución correspondiente del número de siniestros cero-modificada con \\(p_0^M=0,1\\), calcular \\(p_1^M\\). Ejercicio 2.13. Pregunta de Examen Actuarial. Durante un período de un año, el número de accidentes por día se distribuyó de la siguiente manera: \\[ \\begin{matrix} \\begin{array}{c|c|c|c|c|c|c} \\hline \\text{No. de Accidentes} &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\\\ \\hline \\text{No. de Días} &amp; 209 &amp; 111 &amp; 33 &amp; 7 &amp; 5 &amp; 2\\\\ \\hline \\end{array} \\end{matrix} \\] Se utiliza un contraste chi-cuadrado para medir el ajuste de una distribución de Poisson con una media de 0,60. El número mínimo esperado de observaciones en cualquier grupo debe ser 5. El número máximo de grupos debe utilizarse. Determinar el valor del estadístico chi-cuadrado. Ejercicio 2.14. Una distribución de probabilidad discreta tiene las siguientes propiedades \\[ \\begin{aligned} \\Pr(N=k) = \\left( \\frac{3k+9}{8k}\\right) \\Pr(N=k-1), \\quad k=1,2,3,\\ldots \\end{aligned} \\] Determinar el valor de \\(\\Pr(N=3)\\). (Resp: 0,1609) Ejercicios Adicionales Aquí se encuentra un conjunto de ejercicios que guían al lector a través de algunos de los fundamentos teóricos de Loss Data Analytics. Cada tutorial se basa en una o más preguntas de los exámenes actuariales profesionales - normalmente el examen C de la Society of Actuaries. Tutoriales Guiados de Distribución de Frecuencias 2.9 Recursos adicionales y autores El Capítulo del Apéndice 15 ofrece una introducción general a la teoría de máxima verosimilitud en relación con la estimación de los parámetros de una familia paramétrica. El Capítulo del Apéndice 17 proporciona ejemplos más específicos y expande algunos de los conceptos. Autoría N.D. Shyamalkumar, The University of Iowa, y Krupa Viswanathan, Temple University, son los autores principales de la versión inicial de este capítulo. Email: shyamal-kumar@uiowa.edu para comentarios del capítulo y sugerencias de mejora. Revisores del Capítulo incluyen: Paul Johnson, Hirokazu (Iwahiro) Iwasawa, Rajesh Sahasrabuddhe, Michelle Xia. Traducción al español: Ramon Alemany y Miguel Santolino (Universitat de Barcelona). 2.9.1 TS 2.A. Código R para Gráficos Código para Figura 2.3: Mostrar Código R likbinm&lt;-function(m){ # verosimilitud binomial maximizada con respecto a p prod((dbinom(x,m,mean(x)/m))) } liknbinm&lt;-function(r){ # verosimilitud binomial negativa maximizada con respecto a beta prod(dnbinom(x,r,1-mean(x)/(mean(x)+r))) } # Datos Matriciales; Tres muestras, una en cada Columna; # Primera Muestra tiene Var&lt;Mean # Segunda Muestra tiene Var=Mean # Tercera Muestra tiene Var&gt;Mean X&lt;-cbind(c(2,5,6,8,9)+2,c(2,5,6,8,9),c(2,3,6,8,9)); # Se utiliza para crear las etiquetas en la matriz z ord_char&lt;-c(&quot;&lt;&quot;,&quot;=&quot;,&quot;&gt;&quot;); # Matrices vacías; Y&lt;-matrix(1,ncol=2,nrow=0); Z&lt;-matrix(1,ncol=2,nrow=0); for (i in (1:3)) { # Trabaja con los datos de la i-ésima muestra x&lt;-X[,i]; # Verosimilitud Binomial # Intervalo de n valores cubriendo la MLE n&lt;-(9:100); # Evaluación de la verosimilitud en varios valores de n ll&lt;-sapply(n,likbinm); # Encontrando la MLE de n n[ll==max(ll[!is.na(ll)])] # Almacenamiento de los datos y las etiquetas Y&lt;-rbind(Y,cbind(n,ll)); Z&lt;-rbind(Z,cbind(rep(paste(&quot;$\\\\hat{\\\\sigma}^2&quot;,ord_char[i],&quot;\\\\hat{\\\\mu}$&quot;),length(n)),rep(&quot;Binomial - $L(m,\\\\overline{x}/m)$&quot;,length(n)))); # Verosimilitud Binomial Negativa # Intervalo de valores de r r&lt;-(1:100); # Evaluación de la verosimilitud en varios valores de r ll&lt;-sapply(r,liknbinm); # Encontrando la MLE de r ll[is.na(ll)]=0; r[ll==max(ll[!is.na(ll)])]; # Almacenamiento de los datos y las etiquetas Y&lt;-rbind(Y,cbind(r,ll)); Z&lt;-rbind(Z,cbind(rep(paste(&quot;$\\\\hat{\\\\sigma}^2&quot;,ord_char[i],&quot;\\\\hat{\\\\mu}$&quot;),length(r)),rep(&quot;Neg.Binomial - $L(r,\\\\overline{x}/r)$&quot;,length(r)))); # Verosimilitud de Poisson # Almacenamiento de los datos y las etiquetas # En el caso de la Poisson la MLE es la media muestral Y&lt;-rbind(Y,cbind(r,rep(prod(dpois(x,mean(x))),length(r)))); Z&lt;-rbind(Z,cbind(rep(paste(&quot;$\\\\hat{\\\\sigma}^2&quot;,ord_char[i],&quot;\\\\hat{\\\\mu}$&quot;),length(r)),rep(&quot;Poisson - $L(\\\\overline{x})$&quot;,length(r)))); } # Asignación de Nombres a las Columnas colnames(Y)&lt;-c(&quot;x&quot;,&quot;lik&quot;); colnames(Z)&lt;-c(&quot;dataset&quot;,&quot;Distribution&quot;); # Creación de un Dataframe para usar ggplot dy&lt;-cbind(data.frame(Y),data.frame(Z)); library(tikzDevice); library(ggplot2); options(tikzMetricPackages = c(&quot;\\\\usepackage[utf8]{inputenc}&quot;,&quot;\\\\usepackage[T1]{fontenc}&quot;, &quot;\\\\usetikzlibrary{calc}&quot;, &quot;\\\\usepackage{amssymb}&quot;,&quot;\\\\usepackage{amsmath}&quot;,&quot;\\\\usepackage[active]{preview}&quot;)) tikz(file = &quot;plot_test_2.tex&quot;, width = 6.25, height = 6.25); ggplot(data=dy,aes(x=x,y=lik,col=Distribution)) + geom_point(size=0.25) + facet_grid(dataset~.)+ labs(x=&quot;m/r&quot;,y=&quot;Verosimilitud&quot;,title=&quot;&quot;); dev.off(); Código para Figura 2.2: Mostrar Código de R likm&lt;-function(m){ prod((dbinom(x,m,mean(x)/m))) } x&lt;-c(2,2,2,4,5); n&lt;-(5:100); # Cálculo de la verosimilitud ll&lt;-sapply(n,likm); # Calculando MLE n[ll==max(ll)] # Almacenamiento de la curva de verosimilitud y&lt;-cbind(n,ll); # Segundo conjunto de datos x&lt;-c(2,2,2,4,6); ll&lt;-sapply(n,likm); n[ll==max(ll)] y&lt;-cbind(y,ll); # Tercer conjunto de datos x&lt;-c(2,2,2,4,7); ll&lt;-sapply(n,likm); n[ll==max(ll)] y&lt;-cbind(y,ll); colnames(y)&lt;-c(&quot;m&quot;,&quot;$\\\\tilde{x}=(2,2,2,4,5)$&quot;,&quot;$\\\\tilde{x}=(2,2,2,4,6)$&quot;,&quot;$\\\\tilde{x}=(2,2,2,4,7)$&quot;); dy&lt;-data.frame(y); library(tikzDevice); library(ggplot2); options(tikzMetricPackages = c(&quot;\\\\usepackage[utf8]{inputenc}&quot;,&quot;\\\\usepackage[T1]{fontenc}&quot;, &quot;\\\\usetikzlibrary{calc}&quot;, &quot;\\\\usepackage{amssymb}&quot;,&quot;\\\\usepackage{amsmath}&quot;,&quot;\\\\usepackage[active]{preview}&quot;)) tikz(file = &quot;plot_test.tex&quot;, width = 6.25, height = 3.125); ggplot(dy) + geom_point(aes(x=m, y=(X..tilde.x...2.2.2.4.5..),shape=&quot;$\\\\tilde{x}=(2,2,2,4,5):\\\\hat{m}=7$&quot;),size=0.75) + geom_point(aes(x=m, y=(X..tilde.x...2.2.2.4.6..),shape=&quot;$\\\\tilde{x}=(2,2,2,4,6):\\\\hat{m}=18$&quot;),size=0.75) + geom_point(aes(x=m, y=(X..tilde.x...2.2.2.4.7..),shape=&quot;$\\\\tilde{x}=(2,2,2,4,7):\\\\hat{m}=\\\\infty$&quot;),size=0.75) + geom_point(aes(x=c(7),y=dy$X..tilde.x...2.2.2.4.5..[3],colour=&quot;$\\\\hat{m}$&quot;,shape=&quot;$\\\\tilde{x}=(2,2,2,4,5):\\\\hat{m}=7$&quot;),size=0.75)+ geom_point(aes(x=c(18),y=dy$X..tilde.x...2.2.2.4.6..[14],colour=&quot;$\\\\hat{m}$&quot;,shape=&quot;$\\\\tilde{x}=(2,2,2,4,6):\\\\hat{m}=18$&quot;),size=0.75)+ labs(x=&quot;m&quot;,y=&quot;$L(m,\\\\overline{x}/m)$&quot;,title=&quot;MLE para $m$: No-Robustez de MLE &quot;); dev.off(); Bibliography "],
["C-Severity.html", "Chapter 3 Modelización de la severidad de las pérdidas 3.1 Cantidades distribucionales básicas 3.2 Distribuciones continuas para modelizar la severidad de las pérdidas 3.3 Métodos para crear distribuciones nuevas 3.4 Modificaciones de cobertura 3.5 Estimación por máxima verosimilitud 3.6 Recursos y contribuciones adicionales", " Chapter 3 Modelización de la severidad de las pérdidas Vista previa del capítulo. El enfoque tradicional para la modelización de la distribución de las pérdidas agregadas comienza ajustando por separado una distribución para la frecuencia al número de pérdidas y una distribución para la severidad al tamaño de las pérdidas. La distribución de pérdidas agregades estimada combina la distribución para la frecuencia y la distribución para la severidad de las pérdidas por convolución. En el Capítulo 2 han sido utilizadas distribuciones discretas, frecuentemente referenciades como distribuciones para el recuento o distribuciones para la frecuencia, para describir el número de eventos, como por ejemplo el número de accidentes del conductor o número de siniestros del asegurado. Tiempos de vida, valores de activos, pérdidas y tamaños de siniestros son frecuentemente modelizados como variables aleatorias continuas y como tales son modelizadas usando distribuciones continuas, frecuentemente referenciades como distribuciones de perdidas o de severidad. Una distribución mixta es una combinación ponderada de distribuciones más simples que es usada para modelitzar un fenómeno investigado en una población heterogénea, como modelitzar más de un tipo de siniestro en el seguro de responsabilidad civil (siniestros pequeños pero frecuentes y siniestros grandes pero relativamente raros). En este capítulo se explora el uso de distribuciones continuas y mixtas para modelitzar el tamaño aleatorio de las pérdidas. Se presentan atributos clave que caracterizan modelos continuos y que además son un medio para crear nuevas distribuciones a partir de otras existentes. También se explora el efecto de modificaciones de cobertura, que cambian las condiciones que desencadenan el pago, como por ejemplo la aplicación de franquicias, límites, o ajustes por inflación, a la distribución de las cantidades de pérdidas individuales. Las distribuciones de frecuencias del Capítulo 2 seran combinadas con las ideas de este capítulo para describir las pérdidas agregadas del conjunto de la cartera en el Capítulo 5. 3.1 Cantidades distribucionales básicas En esta sección, se muestra la definición de algunas cantidades distribucionales básicas: momentos, percentiles, y funciones generadoras. 3.1.1 Momentos Sea \\(X\\) una variable aleatoria continua con función de densidad de probabilidad \\(f_{X}\\left( x \\right)\\). El k-ésimo momento ordinario de \\(X\\), denotado como \\(\\mu_{k}^{\\prime}\\), es el valor esperado de la k-esima potencia de \\(X\\), siempre que esta exista. El primer momento ordinario \\(\\mu_{1}^{\\prime}\\) es la media de \\(X\\) frecuentemente denotada como \\(\\mu\\). La fórmula para \\(\\mu_{k}^{\\prime}\\) viene dada por \\[ \\mu_{k}^{\\prime} = \\mathrm{E}\\left( X^{k} \\right) = \\int_{0}^{\\infty}{x^{k}f_{X}\\left( x \\right)dx } . \\] El soporte de la variable aleatoria \\(X\\) se asume que es no negativo dado que los fenómenos actuariales son raramente negativos. Una simple integración por partes demuestra que los momentos ordinarios para variables no negativas pueden también calcularse usando \\[ \\mu_{k}^{\\prime} = \\int_{0}^{\\infty}{k~x^{k-1}\\left[1- F_{X}(x) \\right]dx }, \\] que está basado en la función de supervivencia, denotada como \\(S_X(x) = 1-F_{X}(x)\\). Esta fórmula es particularment útil cuando \\(k=1\\). El k-ésimo momento central de \\(X\\), denotado como \\(\\mu_{k}\\), es el valor esperado de la potencia k-ésima de la desviación de \\(X\\) respecto de su media \\(\\mu\\). La fórmula para \\(\\mu_{k}\\) viene dada por \\[ \\mu_{k} = \\mathrm{E}\\left\\lbrack {(X - \\mu)}^{k} \\right\\rbrack = \\int_{0}^{\\infty}{\\left( x - \\mu \\right)^{k}f_{X}\\left( x \\right) dx }. \\] El segundo momento central \\(\\mu_{2}\\) define la varianza de \\(X\\), denotada por \\(\\sigma^{2}\\). La raíz cuadrada de la varianza es la desviación estándar \\(\\sigma\\). Desde una perspectiva clásica, otras caracterizaciones de la forma de una distribución incluyen su grado de simetria así como su apuntamiento en comparación con la distribución normal. La ratio del tercer momento central sobre el cubo de la desviación estándar \\(\\left( \\mu_{3} / \\sigma^{3} \\right)\\) define el coeficiente de asimetría que es una medida de simetría. Un coeficiente positivo de asimetria indica que la distribución es asimétrica por la derecha (asimetria positiva). La ratio del cuarto momento central sobre la cuarta potencia de la desviación estándar \\(\\left(\\mu_{4} / \\sigma^{4} \\right)\\) define el coeficiente de curtosis. La distribución normal tiene un coeficiente de curtosis de 3. Una distribución con un coeficiente de curtosis mayor que 3 tiene colas más pesadas y un mayor pico que la normal, mientras que distribuciones con un coeficiente de curtosis menor que 3 tienen colas más ligeras y son más planas. En la Sección 10.2 se describen las colas de las distribuciones desde una perspectiva actuarial y aseguradora. Ejemplo 3.1.1. Pregunta de un examen actuarial. Asumimos que la v.a. \\(X\\) tiene una distribución gamma con media 8 y asimetría 1. Determina la varianza de \\(X\\). (Hint: La distribución gamma es tratada en la Sección 3.2.1.) Mostrar Solución de Ejemplo Solución. La función de densidad de probabilidad de \\(X\\) viene dada por \\[ f_{X}\\left( x \\right) = \\frac{\\left( x / \\theta \\right)^{\\alpha}}{x ~\\Gamma\\left( \\alpha \\right)} e^{- x / \\theta} \\] para \\(x &gt; 0\\). Para \\(\\alpha&gt;0\\), el k-ésimo momento ordinário es \\[ \\mu_{k}^{\\prime} = \\mathrm{E}\\left( X^{k} \\right) = \\int_{0}^{\\infty}{\\frac{1}{\\Gamma\\left( \\alpha \\right)\\theta^{\\alpha}}x^{k + \\alpha - 1}e^{- x / \\theta} dx} = \\frac{\\Gamma\\left( k + \\alpha \\right)}{\\Gamma\\left( \\alpha \\right)}\\theta^{k} \\] Dado que \\(\\Gamma\\left( r + 1 \\right) = r\\Gamma\\left( r \\right)\\) y \\(\\Gamma\\left( 1 \\right) = 1\\), then \\(\\mu_{1}^{\\prime} = \\mathrm{E}\\left( X \\right) = \\alpha\\theta\\), \\(\\mu_{2}^{\\prime} = \\mathrm{E}\\left( X^{2} \\right) = \\left( \\alpha + 1 \\right)\\alpha\\theta^{2}\\), \\(\\mu_{3}^{\\prime} = \\mathrm{E}\\left( X^{3} \\right) = \\left( \\alpha + 2 \\right)\\left( \\alpha + 1 \\right)\\alpha\\theta^{3}\\), y \\(\\mathrm{Var}\\left( X \\right) = (\\alpha + 1)\\alpha\\theta^2 - (\\alpha\\theta)^2 = \\alpha\\theta^{2}\\). \\[ \\text{Skewness} = \\frac{\\mathrm{E}\\left\\lbrack {(X - \\mu_{1}^{\\prime})}^{3} \\right\\rbrack}{{\\mathrm{Var}\\left( X \\right)}^{3/2}} = \\frac{\\mu_{3}^{\\prime} - 3\\mu_{2}^{\\prime}\\mu_{1}^{\\prime} + 2{\\mu_{1}^{\\prime}}^{3}}{{\\mathrm{Var}\\left( X \\right)}^{3/2}} \\\\ = \\frac{\\left( \\alpha + 2 \\right)\\left( \\alpha + 1 \\right)\\alpha\\theta^{3} - 3\\left( \\alpha + 1 \\right)\\alpha^{2}\\theta^{3} + 2\\alpha^{3}\\theta^{3}}{\\left( \\alpha\\theta^{2} \\right)^{3/2}} = \\frac{2}{\\alpha^{1/2}} = 1. \\] Por lo tanto, \\(\\alpha = 4\\). Dado que \\(\\mathrm{E}\\left( X \\right) = \\alpha\\theta = 8\\), entonces \\(\\theta = 2\\) y finalmente, \\(\\mathrm{Var}\\left( X \\right) = \\alpha\\theta^{2} = 16\\). 3.1.2 Cuantiles Los cuantiles también pueden ser usados para describir las características de la distribución de \\(X\\). Cuando la distribución de \\(X\\) es continua, para una fracción concreta \\(0 \\leq p \\leq 1\\) el correspondiente cuantil es la solución a la ecuación \\[ F_{X}\\left( \\pi_{p} \\right) = p . \\] Por ejemplo, el punto medio de una distribución, \\(\\pi_{0.5}\\), es la mediana. Un percentil es un tipo de cuantil; un \\(100p\\) percentil es el número tal que \\(100 \\times p\\) porciento de los datos están por debajo de él. Ejemplo 3.1.1. Pregunta de un examen actuarial. Sea \\(X\\) una variable aleatoria continua con función de densidad \\(f_{X}\\left( x \\right) = \\theta e^{- \\theta x}\\), para \\(x &gt; 0\\) y 0 en caso contrario. Si la mediana de la distribución es \\(\\frac{1}{3}\\), encuentra \\(\\theta\\). Mostrar Solución de Ejemplo Solución. La función de distribución es \\(F_{X}\\left( x \\right) = 1 - e^{- \\theta x}\\). Por tanto, \\(F_{X}\\left( \\pi_{0,5} \\right) = 1 - e^{- \\theta\\pi_{0.5}} = 0.5\\). Como \\(\\pi_{0,5} = \\frac{1}{3}\\), tenemos que \\(F_X\\left(\\frac{1}{3}\\right) = 1 - e^{-\\theta / 3} = 0,5\\) y \\(\\theta = 3 \\ln 2\\). En la Sección 4.1.1.3 se extiende la definición de cuantil para incluir las distribuciones que son discretas, continuas, o una combiación híbrida. 3.1.3 Función generatriz de momentos La función generatriz de momentos, denotada por \\(M_{X}(t)\\) caracteriza unícovamente la distribución de \\(X\\). Mientras que es posible que dos distribuciones diferentes tengan los mismos momentos y sigan siendo diferentes, esto no ocurre con la función generatriz de momentos. Es decir, si dos variables aleatorias tienen la misma función generatriz de momentos, entonces tienen la misma distribución. La función generatriz de momentos viene dada por \\[ M_{X}(t) = \\mathrm{E}\\left( e^{tX} \\right) = \\int_{0}^{\\infty}{e^{\\text{tx}}f_{X}\\left( x \\right) dx } \\] para todo \\(t\\) para el que exista el valor esperado. La función generatriz de momentos es una función real para la que la k-ésima derivada en cero es igual al k-ésimo momento ordinario de \\(X\\). En símbolos, esto es \\[ \\left.\\frac{d^k}{dt^k} M_{X}(t)\\right|_{t=0} = \\mathrm{E}\\left( X^{k} \\right) . \\] Ejemplo 3.1.3. Pregunta de un examen actuarial. La variable aleatoria \\(X\\) tiene una distribución exponencial con media \\(\\frac{1}{b}\\). Se determina que \\(M_{X}\\left( - b^{2} \\right) = 0,2\\). Encuentra \\(b\\). (Hint: La exponencial es un caso especial de la distribución gamma que es tratada en la Sección 3.2.1.) Mostrar Solución de Ejemplo Solución. Dado que \\(X\\) sigue una distribución exponencial con media \\(\\frac{1}{b}\\), tenemos que \\[ M_{X}(t) = \\mathrm{E}\\left( e^{tX} \\right) = \\int_{0}^{\\infty}{e^{\\text{tx}}be^{- bx} dx} = \\int_{0}^{\\infty}{be^{- x\\left( b - t \\right)} dx} = \\frac{b}{\\left( b - t \\right)}. \\] Entonces, \\[ M_{X}\\left( - b^{2} \\right) = \\frac{b}{\\left( b + b^{2} \\right)} = \\frac{1}{\\left( 1 + b \\right)} = 0,2. \\] Por tanto, \\(b = 4\\). Ejemplo 3.1.4. Pregunta de examen actuarial. Sea \\(X_{1}, \\ldots, X_{n}\\) variables aleatorias independientes, donde \\(X_i\\) sigue una distribución gamma con parámetros \\(\\alpha_{i}\\) y \\(\\theta\\). Encuentra la distribución de \\(S = \\sum_{i = 1}^{n}X_{i}\\), la media \\(\\mathrm{E}(S)\\) y la varianza \\(\\mathrm{Var}(S)\\). Mostrar Solución de Ejemplo Solución. La función generatriz de momentos de \\(S\\) es \\[ M_{S}(t) = \\text{E}\\left( e^{\\text{tS}} \\right) = \\mathrm{E}\\left( e^{t\\sum_{i = 1}^{n}X_{i}} \\right) = \\mathrm{E}\\left( \\prod_{i = 1}^{n}e^{tX_{i}} \\right) . \\] Teniendo en cuenta que son independientes, obtenemos \\[ M_{S}(t) = \\prod_{i = 1}^{n}{\\mathrm{E}\\left( e^{tX_{i}} \\right) = \\prod_{i = 1}^{n}{M_{X_{i}}(t)}} . \\] La función generatriz de momentos de una distribución gamma \\(X_i\\) es \\(M_{X_i}(t) = (1-\\theta)^{\\alpha_i}\\). . Entonces, \\[ M_{S}(t) = \\prod_{i = 1}^{n}\\left( 1 - \\theta t \\right)^{- \\alpha_{i}} = \\left( 1 - \\theta t \\right)^{- \\sum_{i = 1}^{n}\\alpha_{i}} . \\] Esto indica que la distribución de \\(S\\) es gamma con parámetros \\(\\sum_{i = 1}^{n}\\alpha_{i}\\) y \\(\\theta\\). Esta es una demostración de cómo puede usarse la propiedad de unicidad de la función generatriz de momentos para determinar la distribución de probabilidad de una variable aleatoria. Podemos encontrar la media y varianza a partir de las propiedades de la distribución gamma. Alternativamente, determinando la primera y segunda derivadas de \\(M_{S}(t)\\) en cero, se demuestra que \\(\\mathrm{E}\\left( S \\right) = \\left. \\ \\frac{\\partial M_{S}(t)}{\\partial t} \\right|_{t = 0} = \\alpha\\theta\\) donde \\(\\alpha = \\sum_{i = 1}^{n}\\alpha_{i}\\), y \\[ \\mathrm{E}\\left( S^{2} \\right) = \\left. \\ \\frac{\\partial^{2}M_{S}(t)}{\\partial t^{2}} \\right|_{t = 0} = \\left( \\alpha + 1 \\right)\\alpha\\theta^{2}. \\] Por lo tanto, \\(\\mathrm{Var}\\left( S \\right) = \\alpha\\theta^{2}\\). También se puede usar la función generatriz de momentos para calcular la función generatriz de probabilidad \\[ P_{X}(z) = \\mathrm{E}\\left( z^{X} \\right) = M_{X}\\left( \\ln z \\right) . \\] Tal y como se introdujo en la Sección 2.2.2, la función generatriz de probabilidad es más útil para v.a.s discretas. 3.2 Distribuciones continuas para modelizar la severidad de las pérdidas En esta sección, se presentará la definición y aplicación de cuatro distribuciones fundamentales para la severidad: gamma, Pareto, Weibull, y distribución beta generalitzada de segundo tipo. 3.2.1 Distribución gamma El enfoque tradicional para la modelización de las pérdidas consiste en ajustar de forma separada modelos para la frecuencia y la severidad. Cuando la frecuencia y la severidad se modelizan por separado es común para los actuarios usar la distribución de Poisson (introducida en la Sección 2.2.3.2) para la frecuencia de siniestros y la distribucíon gamma para la severidad. Un enfoque alternativo para modelitzar las pérdidas que ha ganado popularidad recientemente es crear un único modelo para la prima pura (coste medio de los siniestros) que será descrito en el Capítulo Chapter 4. Se dice que la variable continua \\(X\\) tiene una distribución gamma con parámetro de forma \\(\\alpha\\) y parámetro de escala \\(\\theta\\) si su función de densidad de probabilidad viene dada por \\[ f_{X}\\left( x \\right) = \\frac{\\left( x/ \\theta \\right)^{\\alpha}}{x~ \\Gamma\\left( \\alpha \\right)}\\exp \\left( -x/ \\theta \\right) \\ \\ \\ \\text{for } x &gt; 0 . \\] Nótese que \\(\\alpha &gt; 0,\\ \\theta &gt; 0\\). Los dos paneles de la Figura 3.1 muestran los efectos de los parámetros de escala y forma en la función de densidad de la gamma. Figure 3.1: Densidades Gamma. El panel de la izquierda corresponde a forma=2 y un parámetro de escala variable. El panel de la derecha corresponde a escala=100 y parámetro de forma variable. Código R para gráficos de densidad gamma par(mfrow=c(1, 2), mar = c(4, 4, .1, .1)) # Densidades gamma con escala variable scaleparam &lt;- seq(100, 250, by = 50) shapeparam &lt;- 2:5 x &lt;- seq(0, 1000, by = 1) fgamma &lt;- dgamma(x, shape = 2, scale = scaleparam[1]) plot(x, fgamma, type = &quot;l&quot;, ylab = &quot;Densidad gamma&quot;) for(k in 2:length(scaleparam)){ fgamma &lt;- dgamma(x,shape = 2, scale = scaleparam[k]) lines(x,fgamma, col = k) } legend(&quot;topright&quot;, c(&quot;scale=100&quot;, &quot;scale=150&quot;, &quot;scale=200&quot;, &quot;scale=250&quot;), lty=1, col = 1:4) # Densidades gamma con forma variable fgamma &lt;- dgamma(x, shape = shapeparam[1], scale = 100) plot(x, fgamma, type = &quot;l&quot;, ylab = &quot;Densidad gamma&quot;) for(k in 2:length(shapeparam)){ fgamma &lt;- dgamma(x,shape = shapeparam[k], scale = 100) lines(x,fgamma, col = k) } legend(&quot;topright&quot;, c(&quot;shape=2&quot;, &quot;shape=3&quot;, &quot;shape=4&quot;, &quot;shape=5&quot;), lty=1, col = 1:4) Cuando \\(\\alpha = 1\\) la gamma se reduce a una distribución exponencial y cuando \\(\\alpha = \\frac{n}{2}\\) y \\(\\theta = 2\\) la gamma se reduce a una distribucióin chi-cuadrado con \\(n\\) grados de libertad. Tal y como veremos en la Sección 15.4, la distribución chi-cuadrado es ampliamente utilitzada en el contraste estadístico de hipótesis. La función de distribución de un modelo gamma es la función incompleta gamma, denotada por \\(\\Gamma\\left(\\alpha; \\frac{x}{\\theta} \\right)\\), y definida como \\[ F_{X}\\left( x \\right) = \\Gamma\\left( \\alpha; \\frac{x}{\\theta} \\right) = \\frac{1}{\\Gamma\\left( \\alpha \\right)}\\int_{0}^{x /\\theta}t^{\\alpha - 1}e^{- t}~dt \\] \\(\\alpha &gt; 0,\\ \\theta &gt; 0\\). Para un entero \\(\\alpha\\), puede expresarse como \\(\\Gamma\\left( \\alpha; \\frac{x}{\\theta} \\right) = 1 - e^{-x/\\theta}\\sum_{k = 0}^{\\alpha-1}\\frac{(x/\\theta)^k}{k!}\\). El momento \\(k\\)-ésimo de una variable aleatoria con distribución gamma para cualquier \\(k\\) positivo viene dada por \\[ \\mathrm{E}\\left( X^{k} \\right) = \\theta^{k} \\frac{\\Gamma\\left( \\alpha + k \\right)}{\\Gamma\\left( \\alpha \\right)} . \\] La media y varianza vienen dadas por \\(\\mathrm{E}\\left( X \\right) = \\alpha\\theta\\) y \\(\\mathrm{Var}\\left( X \\right) = \\alpha\\theta^{2}\\), respectivamente. Dado que todos los momentos existen para cualquier \\(k\\) positivo, la distribución gamma se considera una distribución de cola ligera, que puede no ser adecuada para modelitzar activos con riesgo dado que no proporciona una valoración realista de la versimilitud de pérdidas severas. 3.2.2 Distribución Pareto La distribución Pareto, denominada así por el economista italiano Vilfredo Pareto (1843-1923), tiene muchas aplicacions económicas y financieras. Es una distribución con asimetria positiva y con cola pesada que la hace adecuada para modelitzar ingresos, siniestros en seguros con alto riesgo y la severidad de grandes pérdidas en seguros. La función de supervivencia de una distribución de Pareto que decrece lentamente a cero fue por primera vez utilizada para describir la distribución de ingresos en los que un pequeño porcentaje de la población tiene una gran proporción de la riqueza total. Para siniestros extermos en seguros, la cola de la distribución de la severidad (pérdidas por encima de un determinado umbral) pueden modelizarse usando una distribución Pareto Generalizada. Se dice que la variable continua \\(X\\) tiene una distribución de Pareto con parámetro de forma \\(\\alpha\\) y parámetro de escala \\(\\theta\\) si su pdf viene dada por \\[ f_{X}\\left( x \\right) = \\frac{\\alpha\\theta^{\\alpha}}{\\left( x + \\theta \\right)^{\\alpha + 1}} \\ \\ \\ x &gt; 0,\\ \\alpha &gt; 0,\\ \\theta &gt; 0. \\] Los dos paneles de la Figura 3.2 muestran los efectos de los parámetros de escala y forma en la función de densidad Pareto. Figure 3.2: Densidades Pareto. El panel de la izquierda corresponde a escala=2000 y forma variable. El panel de la derecha corresponde a forma=3 y escala variable Código R para los gráficos de la densidad Pareto library(VGAM) par(mfrow=c(1, 2), mar = c(4, 4, .1, .1)) # Densidades Pareto con forma variable x &lt;- seq(1, 3000, by = 1) scaleparam &lt;- seq(2000, 3500, 500) shapeparam &lt;- 1:4 # variando el parámetro de forma plot(x, dparetoII(x, loc=0, shape = shapeparam[1], scale = 2000), ylim=c(0,0.002),type = &quot;l&quot;, ylab = &quot;Pareto density&quot;) for(k in 2:length(shapeparam)){ lines(x, dparetoII(x, loc=0, shape = shapeparam[k], scale = 2000), col = k) } legend(&quot;topright&quot;, c(expression(alpha~&#39;=1&#39;), expression(alpha~&#39;=2&#39;), expression(alpha~&#39;=3&#39;), expression(alpha~&#39;=4&#39;)), lty=1, col = 1:4) # Densidades de Pareto con escala variable plot(x, dparetoII(x, loc=0, shape = 3, scale = scaleparam[1]), type = &quot;l&quot;, ylab = &quot;Pareto density&quot;) for(k in 2:length(scaleparam)){ lines(x, dparetoII(x, loc=0, shape = 3, scale = scaleparam[k]), col = k) } legend(&quot;topright&quot;, c(expression(theta~&#39;=2000&#39;), expression(theta~&#39;=2500&#39;), expression(theta~&#39;=3000&#39;), expression(theta~&#39;=3500&#39;)), lty=1, col = 1:4) La función de distribución de una Pareto viene dada por \\[ F_{X}\\left( x \\right) = 1 - \\left( \\frac{\\theta}{x + \\theta} \\right)^{\\alpha} \\ \\ \\ x &gt; 0,\\ \\alpha &gt; 0,\\ \\theta &gt; 0. \\] Se puede ver fácilmente que la función de riesgo de la distribución de Pareto es una función decreciente en \\(x\\), otro indicador de que es una distribución de cola pesada. Cuando la función de riesgo decrece con el tiempo la población fallece a una tasa decreciente dando como resultado una cola más pesada para la distribución. La función de riesgo revela información sobre la distribución de la cola y es frecuentemente usada para modelizar distribuciones en análisis de la supervivencia. La función de riesgo se define como la posibilidad instantánea de que el evento de interés ocurra dentro de un marco temporal muy pequeño. El momento \\(k\\)-ésimo de una variable aleatoria con una distribución de Pareto existe si y solo si \\(\\alpha &gt; k\\). Si \\(k\\) es un entero positivo entonces \\[ \\mathrm{E}\\left( X^{k} \\right) = \\frac{\\theta^{k}~ k!}{\\left( \\alpha - 1 \\right)\\cdots\\left( \\alpha - k \\right)} \\ \\ \\ \\alpha &gt; k. \\] La media y varianza vienen dadas por \\[\\mathrm{E}\\left( X \\right) = \\frac{\\theta}{\\alpha - 1} \\ \\ \\ \\text{for } \\alpha &gt; 1\\] y \\[\\mathrm{Var}\\left( X \\right) = \\frac{\\alpha\\theta^{2}}{\\left( \\alpha - 1 \\right)^{2}\\left( \\alpha - 2 \\right)} \\ \\ \\ \\text{for } \\alpha &gt; 2,\\]respectivamente. Ejemplo 3.2.1. El tamaño de los siniestros en una cartera de asegurados sigue una distribución de Pareto con media y varianza iguales a 40 y 1800 respectivamente. Encuentra Los parámetros de forma y escala. El percentil 95 de la distribución. Mostrar Solución de Ejemplo Solución. a. Dado que \\(X\\sim Pa(\\alpha,\\theta)\\), se tiene que \\(\\mathrm{E}\\left( X \\right) = \\frac{\\theta}{\\alpha - 1} = 40\\) y \\(\\mathrm{Var}\\left( X \\right) = \\frac{\\alpha\\theta^{2}}{\\left( \\alpha - 1 \\right)^{2}\\left( \\alpha - 2 \\right)} = 1800\\). Dividiendo el cuadrado de la primera ecuación por la segunda obtenemos \\(\\frac{\\alpha - 2}{\\alpha} = \\frac{40^{2}}{1800}\\). Por tanto, \\(\\alpha = 18,02\\) y \\(\\theta = 680,72\\). b. El percentil 95, \\(\\pi_{0,95}\\), satisface la ecuación \\[ F_{X}\\left( \\pi_{0,95} \\right) = 1 - \\left( \\frac{680,72}{\\pi_{0,95} + 680,72} \\right)^{18,02} = 0,95. \\] Por tanto, \\(\\pi_{0,95} = 122,96\\). 3.2.3 Distribución Weibull La distribución Weibull, denominada así por el físico sueco Waloddi Weibull (1887-1979) es ampliamente utilizada en fiabilidad, análisis de tiempos de vida, predicciones del tiempo y siniestros en seguros generales. Datos truncados aparecen frecuentemente en estudios de seguros. La distribución Weibull ha sido utilizada para modelizar el acuerdo de exceso de pérdida en el seguro del automóvil así como el tiempo entre la llegada de dos terremotos. Se dice que la variable continua \\(X\\) sigue una distribución Weibull con parámetro de forma \\(\\alpha\\) y parámetro de escala \\(\\theta\\) si su función de densidad de probabilidad viene dada por \\[ f_{X}\\left( x \\right) = \\frac{\\alpha}{\\theta}\\left( \\frac{x}{\\theta} \\right)^{\\alpha - 1} \\exp \\left(- \\left( \\frac{x}{\\theta} \\right)^{\\alpha}\\right) \\ \\ \\ x &gt; 0,\\ \\alpha &gt; 0,\\ \\theta &gt; 0. \\] Los dos paneles de la Figura 3.3 muestran los efectos de los parámetros de escala y forma de la función de densidad de una Weibull. Figure 3.3: Densidades Weibull. El panel de la izquierda corresponde a forma=3 y escala variable. El panel de la derecha corresponde a escala=100 y forma variable. Código R para los gráficos de la densidad Weibull par(mfrow=c(1, 2), mar = c(4, 4, .1, .1)) # Densidad Weibull con escala variable z&lt;- seq(0,400,by=1) scaleparam &lt;- seq(50,200,50) shapeparam &lt;- seq(1.5,3,0.5) plot(z, dweibull(z, shape = 3, scale = scaleparam[1]), type = &quot;l&quot;, ylab = &quot;Densidad Weibull&quot;) for(k in 2:length(scaleparam)){ lines(z,dweibull(z,shape = 3, scale = scaleparam[k]), col = k)} legend(&quot;topright&quot;, c(&quot;scale=50&quot;, &quot;scale=100&quot;, &quot;scale=150&quot;, &quot;scale=200&quot;), lty=1, col = 1:4) # Densidad Weibull con forma variable plot(z, dweibull(z, shape = shapeparam[1], scale = 100), ylim=c(0,0.012), type = &quot;l&quot;, ylab = &quot;Densidad Weibull &quot;) for(k in 2:length(shapeparam)){ lines(z,dweibull(z,shape = shapeparam[k], scale = 100), col = k)} legend(&quot;topright&quot;, c(&quot;shape=1.5&quot;, &quot;shape=2&quot;, &quot;shape=2.5&quot;, &quot;shape=3&quot;), lty=1, col = 1:4) La función de distribución de una Weibull viene dada por \\[ F_{X}\\left( x \\right) = 1 - e^{- \\left( x / \\theta \\right)^{\\alpha}} \\ \\ \\ x &gt; 0,\\ \\alpha &gt; 0,\\ \\theta &gt; 0. \\] Se puede ver fácilmente que el parámetro de forma \\(\\alpha\\) describe la forma de la función de riesgo de una distribución Weibull. La función de riesgo es una función decreciente cuando \\(\\alpha &lt; 1\\) (distribución de cola pesada), constante cuando \\(\\alpha = 1\\) y creciente cuando \\(\\alpha &gt; 1\\) (distribución de cola ligera). Este comportamiento de la función de riesgo hace que la distribución de Weibull sea adecuada para una gran variedad de fenómenos como la predicción del tiempo, ingeniería eléctrica e industrial, modelización actuarial y análisis del riesgo financiero. El momento \\(k\\)-ésimo de una variable aleatoria con distribución Weibull viene dado por \\[ \\mathrm{E}\\left( X^{k} \\right) = \\theta^{k}~\\Gamma\\left( 1 + \\frac{k}{\\alpha} \\right) . \\] La media y la varianza vienen dades por \\[ \\mathrm{E}\\left( X \\right) = \\theta~\\Gamma\\left( 1 + \\frac{1}{\\alpha} \\right) \\] y \\[ \\mathrm{Var}(X)= \\theta^{2}\\left( \\Gamma\\left( 1 + \\frac{2}{\\alpha} \\right) - \\left\\lbrack \\Gamma\\left( 1 + \\frac{1}{\\alpha} \\right) \\right\\rbrack ^{2}\\right), \\] respectivamente. Ejemplo 3.2.2. Se asume que la distribución de probabilidad del tiempo de vida de pacientes con SIDA (en meses) desde el momento del diagnóstico sigue una distribución de Weibull con parámetro de forma 1,2 y parámetro de escala 33,33. Determina la probabilidad de que una persona de esta población elegida al azar sobreviva al menos 12 meses, Se selecciona una muestra de 10 pacientes de esta población. Cuál es la probabilidad de que como máximo dos mueran al cabo de un año del diagnóstico. Encuentra el percentil 99 de la distribución de los tiempos de vida. Mostrar Solución de Ejemplo Solución. a. Sea \\(X\\) el tiempo de vida de los pacientes con SIDA (en meses) con distribución Weibull de parámetros \\(\\left(1,2,\\ 33,33 \\right)\\). Tenemos, \\[ \\Pr \\left( X \\geq 12 \\right) = S_{X} \\left( 12 \\right) = e^{- \\left( \\frac{12}{33,33} \\right)^{1,2}} = 0,746. \\] b. Sea \\(Y\\) el número de pacientes que mueren al cabo de un año del diagnóstico. Entonces, \\(Y\\sim Bin\\left( 10,\\ 0,254 \\right)\\) y \\(\\Pr\\left( Y \\leq 2 \\right) = 0,514.\\) c. Sea \\(\\pi_{0,99}\\) el percentil 99 de esta distribución. Entonces, \\[ S_{X}\\left( \\pi_{0,99} \\right) = \\exp\\left\\{- \\left( \\frac{\\pi_{0,99}}{33,33} \\right)^{1,2}\\right\\} = 0,01. \\] Resolviendo para \\(\\pi_{0,99}\\), obtenemos \\(\\pi_{0,99} = 118,99\\). 3.2.4 Distribución Beta Generalizada de segundo tipo La Distribución Beta Generalizada de segundo tipo (GB2) fue introducida por Venter (1983) en el contexto de la modelización de las pérdidas en seguros y por McDonald (1984) como una distribución para los ingresos y la riqueza. Es una distribución de cuatro parámetros muy flexible que puede modelizar distribuciones con asimetria tanto positiva como negativa. Se dice que la variable \\(X\\) tiene una distribución GB2 con parámetros \\(\\sigma\\), \\(\\theta\\), \\(\\alpha_1\\) y \\(\\alpha_2\\) si su función de densidad de probabilidad viene dada por \\[\\begin{equation} f_{X}\\left( x \\right) = \\frac{(x/\\theta)^{\\alpha_2/\\sigma}}{x \\sigma~\\mathrm{B}\\left( \\alpha_1,\\alpha_2\\right)\\left\\lbrack 1 + \\left( x/\\theta \\right)^{1/\\sigma} \\right\\rbrack^{\\alpha_1 + \\alpha_2}} \\ \\ \\ \\text{for } x &gt; 0, \\tag{3.1} \\end{equation}\\] \\(\\sigma,\\theta,\\alpha_1,\\alpha_2 &gt; 0\\), y donde la función beta es \\(\\mathrm{B}\\left( \\alpha_1,\\alpha_2 \\right)\\) definida como \\[ \\mathrm{B}\\left( \\alpha_1,\\alpha_2\\right) = \\int_{0}^{1}{t^{\\alpha_1 - 1}\\left( 1 - t \\right)^{\\alpha_2 - 1}}~ dt. \\] La GB2 proporciona una modelo para datos con cola pesada así como ligera. Incluye a las distribuciones exponencial, gamma, Weibull, Burr, Lomax, F, chi-cuadrado, Rayleigh, lognormal y log-logistic como casos especiales o límite. Por ejemplo, estableciendo estos valores para los parámetros \\(\\sigma = \\alpha_1 = \\alpha_2 = 1\\), la GB2 se reduce a la distribución log-logistic. Cuando \\(\\sigma = 1\\) y \\(\\alpha_2 \\rightarrow \\infty\\), se reduce a la distribución gamma y cuando \\(\\alpha = 1\\) y \\(\\alpha_2 \\rightarrow \\infty\\), se reduce a la distribución Weibull. Una variable aleatoria GB2 puede ser definida como sigue. Se asume que \\(G_1\\) y \\(G_2\\) son variables aleatorias independientes donde \\(G_i\\) tiene una distribución gamma con parámetros \\(\\alpha_i\\) y parámetro de escala igual a 1. Entonces, puede demostrarse que la variable aleatoria \\(X = \\theta \\left(\\frac{G_1}{G_2}\\right)^{\\sigma}\\) sigue una distribución GB2 con pdf resumida en la ecuación (3.1). Este resultado teórico tiene diverses implicaciones. Por ejemplo, cuando los momentos existen, puede demostrarse que el momento \\(k\\)-ésimo de la variable aleatoria con distribución GB2 viene dado por \\[ \\mathrm{E}\\left( X^{k} \\right) = \\frac{\\theta^{k}~\\mathrm{B}\\left( \\alpha_1 +k \\sigma,\\alpha_2 - k \\sigma \\right)}{\\mathrm{B}\\left( \\alpha_1,\\alpha_2 \\right)}, \\ \\ \\ k &gt; 0. \\] Anteriormente la GB2 también había sido aplicada a datos de ingresos y más recientemente ha sido utilitzada para modelitzar datos de siniestros de cola larga (en la Sección 10.2 se describen diferentes interpretaciones del concepto “cola larga”). GB2 fue usada para modelizar diferentes tipos de siniestros en el seguro del automóvil, severidad de las pérdidas causades por el fuego así como datos de sinietros en seguros médicos. 3.3 Métodos para crear distribuciones nuevas En esta sección se mostrara como: Entender las conexiones entre distribuciones Proporcionar ideas sobre cuando una distribución es preferible en comparación con otras alternativas Proporcionar los fundamentos para la creación de nuevas distribuciones 3.3.1 Funciones de variables aleatorias y sus distribuciones En la Sección 3.2 se han descrito algunas distribuciones fundamentales conocidas. En esta sección se describe la forma de crear nuevas distribuciones de probabilidad paramétricas a partir de otras existentes. Concretamente, sea \\(X\\) una variable aleatoria continua con función de densidad de probabilidad conocida \\(f_{X}(x)\\) y función de distribución \\(F_{X}(x)\\). Se desea conocer la distribución de \\(Y = g\\left( X \\right)\\), donde \\(g(X)\\) es una transformación uno-a-uno que define una nueva variable aleatoria \\(Y\\). Es esta sección se aplica las siguientes técnicas para crear nuevas familias de distribuciones: (a) multiplicación por una constante (b) elevación a una potencia, (c) exponenciación y (d) mixtura. 3.3.2 Multiplicación por una constante Si los datos de siniestros muestran cambios a lo largo del tiempo entonces esta transformación puede ser útil para ajustar el efecto de la inflación. Si el nivel de la inflación es positivo entonces los costes de los siniestros están aumentando, y si es negativo los costes están decreciendo. Para realizar el ajuste por inflación multiplicamos el coste \\(X\\) por 1+ tasa de inflación (inflación negativa es deflacción). Para tener en cuenta el impacto de los tipos de cambio en los costes de los siniestros también usamos una transformación para aplicar la conversión de una moneda base a otra. Se considera la transformación \\(Y = cX\\), donde \\(c &gt; 0\\), entonces, la función de distribución de \\(Y\\) viene dada por \\[ F_{Y}\\left( y \\right) = \\Pr\\left( Y \\leq y \\right) = \\Pr\\left( cX \\leq y \\right) = \\Pr\\left( X \\leq \\frac{y}{c} \\right) = F_{X}\\left( \\frac{y}{c} \\right). \\] Por lo tanto, la función de densidad de probabilidad que se desea determinar \\(f_{Y}(y)\\) puede expresarse como \\[ f_{Y}\\left( y \\right) = \\frac{1}{c}f_{X}\\left( \\frac{y}{c} \\right). \\] Se asume que \\(X\\) pertenece a un cierto conjunto de distribuciones paramétricas y se define la versión reescalada \\(Y\\ = \\ cX\\), \\(c\\ &gt; \\ 0\\). Si \\(Y\\) está en el mismo conjunto de distribuciones entonces se dice que la distribución es una distribución escala. Cuando un miembro de una distribución escala se multiplica por una constante \\(c\\) (\\(c &gt; 0\\)), el parámetro de escala de esa distribución escala cumple dos condiciones: El parámetro se transforma multiplicando por \\(c\\); El resto de parámetros no se ven afectados. Ejemplo 3.3.1. Pregunta de un examen actuarial. Las pérdidas agregadas de Eiffel Auto Insurance se denotan en Euros y siguen una distribución lognormal con \\(\\mu = 8\\) y \\(\\sigma = 2\\). Dado que 1 euro \\(=\\) 1,3 dólares, encuentra el conjunto de parámetros lognormales que describen la distribución de pérdidas de Eiffel en dólares. Mostrar Solución de Ejemplo Solución. Sean \\(X\\) e \\(Y\\) las pérdidas agregadas de Eiffel Auto Insurance en euros y dólares respectivamente. Dado que \\(Y = 1.3X\\), tenemos, \\[ F_{Y}\\left( y \\right) = \\Pr\\left( Y \\leq y \\right) = \\Pr\\left( 1.3X \\leq y \\right) = \\Pr\\left( X \\leq \\frac{y}{1,3} \\right) = F_{X}\\left( \\frac{y}{1.3} \\right). \\] \\(X\\) sigue una distribución lognormal con parámetros \\(\\mu = 8\\) y \\(\\sigma = 2\\). La función de densidad de probabilidad de \\(X\\) viene dada por \\[ f_{X}\\left( x \\right) = \\frac{1}{x \\sigma \\sqrt{2\\pi}}\\exp \\left\\{- \\frac{1}{2}\\left( \\frac{\\ln x - \\mu}{\\sigma} \\right)^{2}\\right\\} \\ \\ \\ \\text{para } x &gt; 0. \\] Dado que \\(\\left| \\frac{dx}{dy} \\right| = \\frac{1}{1,3}\\), la función de densidad de probabilidad de interés \\(f_{Y}(y)\\) es \\[ f_{Y}\\left( y \\right) = \\frac{1}{1,3}f_{X}\\left( \\frac{y}{1,3} \\right) \\\\ = \\frac{1}{1,3}\\frac{1,3}{y \\sigma \\sqrt{2\\pi}}\\exp \\left\\{- \\frac{1}{2}\\left( \\frac{\\ln\\left( y/1.3 \\right) - \\mu}{\\sigma} \\right)^{2}\\right\\} \\\\ = \\frac{1}{y \\sigma\\sqrt{2\\pi}}\\exp \\left\\{- \\frac{1}{2}\\left( \\frac{\\ln y - \\left( \\ln 1,3 + \\mu \\right)}{\\sigma} \\right)^{2}\\right\\}. \\] Entonces \\(Y\\) sigue una distribución lognormal con parámetros \\(\\ln 1,3 + \\mu = 8,26\\) y \\(\\sigma = 2,00\\). Si se establece que \\(\\mu = ln(m)\\) entonces resulta fácil ver que \\(m\\)=\\(e^{\\mu}\\) es el parámetro de escala que fue multiplicado por 1,3 mientras que \\(\\sigma\\) es el parámetro de forma que no se ha visto alterado. Ejemplo 3.3.2. Pregunta de un examen actuarial. Demuestra que la distribución gamma es una distribución escala. Mostrar Solución de Ejemplo Solución. Sea \\(X\\sim Ga(\\alpha,\\theta)\\) e \\(Y = cX\\). Dado que \\(\\left| \\frac{dx}{dy} \\right| = \\frac{1}{c}\\), entonces \\[ f_{Y}\\left( y \\right) = \\frac{1}{c}f_{X}\\left( \\frac{y}{c} \\right) = \\frac{\\left( \\frac{y}{c\\theta} \\right)^{\\alpha}}{y~\\Gamma\\left( \\alpha \\right)}\\exp \\left( - \\frac{y}{c\\theta} \\right) . \\] Se puede ver que \\(Y\\sim Ga(\\alpha,c\\theta)\\) lo cual indica que la gamma es una distribución escala y \\(\\theta\\) es un parámetro de escala. Usando el mismo enfoque podemos demostrar que otras distribuciones introducidas en la Sección 3.2 son también distribuciones escala. En la modelización actuarial, trabajar con una distribución escala es muy conveniente porque permite incorporar el efecto de la inflación y adaptar los cambios en la modeda correspondiente. 3.3.3 Elevación a una potencia En la Sección 3.2.3 se ha tratado la fexibilidad de la distribución de Weibull para el ajuste de datos de fiabilidad. Teniendo en cuenta los orígenes de la distribución de Weibull, se reconoce que la Weibull es una transformación basada en la potencia de la distribución exponencial. Esta se una aplicación de otro tipo de transformación que implica elevar una variable aleatoria a una potencia. Si se considera la transformación \\(Y = X^{\\tau}\\), donde \\(\\tau &gt; 0\\), entonces la función de distribución de \\(Y\\) viene dada por \\[ F_{Y}\\left( y \\right) = \\Pr\\left( Y \\leq y \\right) = \\Pr\\left( X^{\\tau} \\leq y \\right) = \\Pr\\left( X \\leq y^{1/ \\tau} \\right) = F_{X}\\left( y^{1/ \\tau} \\right). \\] Por lo tanto, la función de densidad de probabilidad de interés \\(f_{Y}(y)\\) puede expresarse como \\[ f_{Y}(y) = \\frac{1}{\\tau} y^{1/ \\tau - 1} f_{X}\\left( y^{1/ \\tau} \\right). \\] Por otro lado, si \\(\\tau &lt; 0\\), la función de distribución de \\(Y\\) viene dada por \\[ F_{Y}\\left( y \\right) = \\Pr\\left( Y \\leq y \\right) = \\Pr\\left( X^{\\tau} \\leq y \\right) = \\Pr\\left( X \\geq y^{1/ \\tau} \\right) = 1 - F_{X}\\left( y^{1/ \\tau} \\right), \\] y \\[ f_{Y}(y) = \\left| \\frac{1}{\\tau} \\right|{y^{1/ \\tau - 1}f}_{X}\\left( y^{1/ \\tau} \\right). \\] Ejemplo 3.3.3. Se asume que \\(X\\) sigue una distribución exponencial con media \\(\\theta\\) y se considera la variable transformada \\(Y = X^{\\tau}\\). Demuestra que \\(Y\\) sigue una distribución de Weibull cuando \\(\\tau\\) es positiva y determina los parámetros de la distribución de Weibull. Mostrar Solución de Ejemplo Solución. Dado que \\(X\\) sigue una distribución exponencial con media \\(\\theta\\), tenemos \\[ f_{X}(x) = \\frac{1}{\\theta}e^{- x/ \\theta} \\ \\ \\ \\, x &gt; 0. \\] Resolviendo para x se obtiene \\(x = y^{1/\\tau}\\). Tomando derivadas, tenemos \\[ \\left| \\frac{dx}{dy} \\right| = \\frac{1}{\\tau}{y^{\\frac{1}{\\tau}-1}}. \\] Así tenemos, \\[ f_{Y}\\left( y \\right) = \\frac{1}{\\tau}{y^{\\frac{1}{\\tau} - 1}f}_{X}\\left( y^{\\frac{1}{\\tau}} \\right) \\\\ = \\frac{1}{\\tau \\theta }y^{\\frac{1}{\\tau} - 1}e^{- \\frac{y^{\\frac{1}{\\tau}}}{\\theta}} = \\frac{\\alpha}{\\beta}\\left( \\frac{y}{\\beta} \\right)^{\\alpha - 1}e^{- \\left( y/ \\beta \\right)^{\\alpha}}. \\] donde \\(\\alpha = \\frac{1}{\\tau}\\) y \\(\\beta = \\theta^{\\tau}\\). Entonces, \\(Y\\) sigue una distribución de Weibull con parámetro de forma \\(\\alpha\\) y parámetro de escala \\(\\beta\\). 3.3.4 Exponenciación La distribución normal es un modelo muy popular para un gran número de aplicaciones y cuando el tamaño muestral es grande, puede servir como una distribucion aproximada para otros modelos. Si una variable aleatoria \\(X\\) tiene una distribución normal con media \\(\\mu\\) y varianza \\(\\sigma^{2}\\), entonces \\(Y = e^{X}\\) tiene una distribución lognormal con parámetros \\(\\mu\\) y \\(\\sigma^{2}\\). La variable aleatoria lognormal está acotada en cero por abajo, tiene asimetria positiva y tiene una larga cola por la derecha. La distribución lognormal es frecuentemente utilizada para describir la distribución de activos financieros como los precios de las acciones. También es usada para ajustar cuantías de siniestros en los seguros del automóvil y de salud. Este es un ejemplo de otro tipo de transformación que implica exponenciación. En general, consideramos la transformación \\(Y = e^{X}\\). Entonces, la función de distribución de \\(Y\\) viene dada por \\[F_{Y}\\left( y \\right) = \\Pr\\left( Y \\leq y \\right) = \\Pr\\left( e^{X} \\leq y \\right) = \\Pr\\left( X \\leq \\ln y \\right) = F_{X}\\left( \\ln y \\right).\\] Tomando derivadas, vemos que la función de densidad de probabilidad de interés \\(f_{Y}(y)\\) puede expresarse como \\[ f_{Y}(y) = \\frac{1}{y}f_{X}\\left( \\ln y \\right). \\] Como un caso especial e importante, se asume que \\(X\\) tiene distribución normal con media \\(\\mu\\) y varianza \\(\\sigma^2\\). Entonces, la distribución de \\(Y = e^X\\) es \\[ f_{Y}(y) = \\frac{1}{y}f_{X}\\left( \\ln y \\right) = \\frac{1}{y\\sqrt{2 \\pi}} \\exp \\left\\{-\\frac{1}{2}\\left(\\frac{ \\ln y - \\mu}{\\sigma}\\right)^2\\right\\}. \\] A esta distribución se la conoce como la distribución lognormal. Ejemplo 3.3.4. Pregunta de examen actuarial. Se asume que \\(X\\) tiene una distribución uniforme en el intervalo \\((0,\\ c)\\) y definimos \\(Y = e^{X}\\). Determina la distribución de \\(Y\\). Mostrar Solución de Ejemplo Solución. En primer lugar, se considera la cdf de \\(Y\\), \\[ F_{Y}\\left( y \\right) = \\Pr\\left( Y \\leq y \\right) = \\Pr\\left( e^{X} \\leq y \\right) = \\Pr\\left( X \\leq \\ln y \\right) = F_{X}\\left( \\ln y \\right). \\] Tomando derivadas, se tiene, \\[ f_{Y}\\left( y \\right) = \\frac{1}{y}f_{X}\\left(\\ln y \\right) = \\frac{1}{cy} . \\] Dado que \\(0 &lt; x &lt; c\\), entonces \\(1 &lt; y &lt; e^{c}\\). 3.3.5 Mixturas finitas Las distribuciones mixtas representan una forma útil de modelizar datos que provienen de una población heterogénea. Esta población de origen puede considerarse dividida en múltiples subpoblaciones con diferentes distribuciones. 3.3.5.1 Mixtura de dos variables Si el fenómeno subyacente es diverso y puede ser ciertamente descrito como dos fenómenos que representan dos subpoblaciones con diferentes modelos, es posible construir la variable aleatoria de mixtura de dos variables \\(X\\). Sean las variables aleatorias \\(X_{1}\\) y \\(X_{2}\\), con funciones de densidad de probabilidad \\(f_{X_{1}}\\left( x \\right)\\) y \\(f_{X_{2}}\\left( x \\right)\\) respectivamente, la función de densidad de probabilidad de \\(X\\) es la media ponderada de la componente de la funcion de densidad de probabilidad \\(f_{X_{1}}\\left( x \\right)\\) y \\(f_{X_{2}}\\left( x \\right)\\). Las funciones de densidad de probabilidad y de distribución de \\(X\\) vienen dadas por \\[f_{X}\\left( x \\right) = af_{X_{1}}\\left( x \\right) + \\left( 1 - a \\right)f_{X_{2}}\\left( x \\right),\\] y \\[F_{X}\\left( x \\right) = aF_{X_{1}}\\left( x \\right) + \\left( 1 - a \\right)F_{X_{2}}\\left( x \\right),\\] para \\(0 &lt; a &lt;1\\), donde los parámetros de mixtura \\(a\\) y \\((1 - a)\\) representan las proporciones de las observaciones de los datos que caen en cada una de las dos subpoblaciones repectivamente. Esta media ponderada puede ser aplicada a un buen número distribuciones relacionadas con cuantías. El momento k-ésimo y la función generatriz de momentos de \\(X\\) vienen dadas por \\(\\mathrm{E}\\left( X^{k} \\right) = a\\mathrm{E}\\left( X_{1}^{K} \\right) + \\left( 1 - a \\right)\\mathrm{E}\\left( X_{2}^{k} \\right)\\), y \\[M_{X}(t) = aM_{X_{1}}(t) + \\left( 1 - a \\right)M_{X_{2}}(t),\\] respectivamente. Ejemplo 3.3.5. Pregunta del examen actuarial. En un conjunto de pólizas de seguros se distinguen dos tipos. 25% de las pólizas son de Tipo 1 y 75% de Tipo 2. Para una póliza de Tipo 1, la cuantía de pérdida por año sigue una distribución exponencial con media 200, y para las pólizas de Tipo 2, la cuantía de perdidas por año sigue una distribución de Pareto con parámetros \\(\\alpha=3\\) y \\(\\theta=200\\). Para una póliza seleccionada al azar de la población total que incluye los dos tipos de pólizas, encuentra la probabilidad de que la pérdida anual sea inferior a 100, y determina la perdida media. Mostrar Solución de Ejemplo Solución. Los dos tipos de pérdidas son las variables aleatorias \\(X_1\\) y \\(X_2\\). \\(X_1\\) digue una distribución exponencial con media 100, por lo tanto \\(F_{X_1}\\left(100\\right)=1-e^{-\\frac{100}{200}}=0,393\\). \\(X_2\\) sigue una distribución de Pareto con parámetros \\(\\alpha=3\\) y \\(\\theta=200\\), por lo tanto \\(F_{X_1}\\left(100\\right)=1-\\left(\\frac{200}{100+200}\\right)^3=0,704\\). Por lo tanto, \\(F_X\\left(100\\right)=\\left(0,25\\times0,393\\right)+\\left(0,75\\times0,704\\right)=0,626\\). La pérdida media viene dada por \\[\\mathrm{E}\\left(X\\right)=0,25\\mathrm{E}\\left(X_1\\right)+0,75\\mathrm{E}\\left(X_2\\right)=\\left(0,25\\times200\\right)+\\left(0,75\\times100\\right)=125\\]. 3.3.5.2 Mixtura de k variables En el caso de las distribuciones mixtas finitas, la variable aleatoria de interés \\(X\\) tiene una probabilidad \\(p_{i}\\) de provenir de una subpoblación homogénea \\(i\\), donde \\(i = 1,2,\\ldots,k\\) y \\(k\\) es el número inicialment especificado de subpoblaciones en la mixtura. El parámetro de mixtura \\(p_{i}\\) representa la proporción de observaciones de la subpoblación \\(i\\). Se considera la variable aleatoria \\(X\\) que es generada por \\(k\\) subpoblaciones diferentes, donde la subpoblación \\(i\\) es modelizada con la distribución continua \\(f_{X_{i}}\\left( x \\right)\\). La distribución de probabilidad de \\(X\\) viene dada por \\[f_{X}\\left( x \\right) = \\sum_{i = 1}^{k}{p_{i}f_{X_{i}}\\left( x \\right)},\\] donde \\(0 &lt; p_{i} &lt; 1\\) y \\(\\sum_{i = 1}^{k} p_{i} = 1\\). Este modelo es frecuentemente referenciado como mixtura finita o mixtura de \\(k\\) variables. La función de distribución, momento \\(r\\)-ésimo y funciones generatrices de momentos de la mixtura de \\(k\\) variables vienen dadas por \\[F_{X}\\left( x \\right) = \\sum_{i = 1}^{k}{p_{i}F_{X_{i}}\\left( x \\right)},\\] \\[\\mathrm{E}\\left( X^{r} \\right) = \\sum_{i = 1}^{k}{p_{i}\\mathrm{E}\\left( X_{i}^{r} \\right)}, \\text{and}\\] \\[M_{X}(t) = \\sum_{i = 1}^{k}{p_{i}M_{X_{i}}(t)},\\] respectivamente. Ejemplo 3.3.6. Pregunta de un examen actuarial. \\(Y_{1}\\) es una mixtura de \\(X_{1}\\) y \\(X_{2}\\) con ponderaciones de mixtura \\(a\\) y \\((1 - a)\\). \\(Y_{2}\\) es una mixtura de \\(X_{3}\\) y \\(X_{4}\\) con ponderaciones de mixtura \\(b\\) y \\((1 - b)\\). \\(Z\\) es una mixtura de \\(Y_{1}\\) y \\(Y_{2}\\) con ponderaciones de mixtura \\(c\\) y \\((1 - c)\\). Demuestra que \\(Z\\) es una mixtura de \\(X_{1}\\), \\(X_{2}\\), \\(X_{3}\\) y \\(X_{4}\\), y determina las ponderaciones de mixtura. Mostrar Solución de Ejemplo Solución. Aplicando la fórmula para una distribución mixta, obtenemos \\[f_{Y_{1}}\\left( x \\right) = af_{X_{1}}\\left( x \\right) + \\left( 1 - a \\right)f_{X_{2}}\\left( x \\right)\\] \\[f_{Y_{2}}\\left( x \\right) = bf_{X_{3}}\\left( x \\right) + \\left( 1 - b \\right)f_{X_{4}}\\left( x \\right)\\] \\[f_{Z}\\left( x \\right) = cf_{Y_{1}}\\left( x \\right) + \\left( 1 - c \\right)f_{Y_{2}}\\left( x \\right)\\] Sustituyendo las dos primeras ecuaciones en la tercera, obtenemos \\[f_{Z}\\left( x \\right) = c\\left\\lbrack af_{X_{1}}\\left( x \\right) + \\left( 1 - a \\right)f_{X_{2}}\\left( x \\right) \\right\\rbrack + \\left( 1 - c \\right)\\left\\lbrack bf_{X_{3}}\\left( x \\right) + \\left( 1 - b \\right)f_{X_{4}}\\left( x \\right) \\right\\rbrack\\] \\[= caf_{X_{1}}\\left( x \\right) + c\\left( 1 - a \\right)f_{X_{2}}\\left( x \\right) + \\left( 1 - c \\right)bf_{X_{3}}\\left( x \\right) + (1 - c)\\left( 1 - b \\right)f_{X_{4}}\\left( x \\right)\\]. Entonces, \\(Z\\) es una mixtura de \\(X_{1}\\), \\(X_{2}\\), \\(X_{3}\\) y \\(X_{4}\\), con pesos de mixtura \\(\\text{ca}\\), \\(c\\left( 1 - a \\right)\\), \\(\\left( 1 - c \\right)b\\) y \\((1 - c)\\left( 1 - b \\right)\\), respectivamente. Se puede ver fácilmente que las ponderaciones de mixtura suman uno. 3.3.6 Mixturas continuas Una mixtura con un gran número de subpoblaciones (\\(k\\) tiende a infinito) es frecuentemente denominada mixtura continua. En una mixtura continua, las subpoblaciones no se distinguen a través de un parámetro de mixtura discreto sino por una variable continua \\(\\Theta\\), donde \\(\\Theta\\) juega el papel de \\(p_{i}\\) en la mixtura finita. Se considera la variable aleatoria \\(X\\) con una distribución que depende de un parametro \\(\\Theta\\), donde \\(\\Theta\\) es a su vez una variable aleatoria continua. Esta descrición da lugar al siguiente modelo para \\(X\\) \\[ f_{X}\\left( x \\right) = \\int_{-\\infty}^{\\infty}{f_{X}\\left(x \\left| \\theta \\right. \\right)g_{\\Theta}( \\theta )} d \\theta , \\] donde \\(f_{X}\\left( x | \\theta \\right)\\) es la distribución condicional de \\(X\\) en un valor concreto de \\(\\Theta=\\theta\\) y \\(g_{\\Theta}\\left( \\theta \\right)\\) es la declaración realitzada sobre la probabilidad en relación con el parámetro \\(\\theta\\) desconocido. En un contexto Bayesiano (descrito en la Sección 4.4), se le conoce como la distribución a priori de \\(\\Theta\\) (la información a priori u opinión experta que se va a utilitzar en el análisis). La función de distribución, momento \\(k\\)-ésimo y función generatriz de momentos de la mixtura continua vienen dadas por \\[ F_{X}\\left( x \\right) = \\int_{-\\infty}^{\\infty}{F_{X}\\left(x \\left| \\theta \\right. \\right) g_{\\Theta}(\\theta)} d \\theta, \\] \\[ \\mathrm{E}\\left( X^{k} \\right) = \\int_{-\\infty}^{\\infty}{\\mathrm{E}\\left( X^{k}\\left| \\theta \\right. \\right)g_{\\Theta}(\\theta)}d \\theta, \\] \\[ M_{X}(t) = \\mathrm{E}\\left( e^{t X} \\right) = \\int_{-\\infty}^{\\infty}{\\mathrm{E}\\left( e^{ tx}\\left| \\theta \\right. \\right)g_{\\Theta}(\\theta)}d \\theta, \\] respectivamente. El momento \\(k\\)-ésimo de la distribución mixta puede ser igualmente expresado como \\[ \\mathrm{E}\\left( X^{k} \\right) = \\int_{-\\infty}^{\\infty}{\\mathrm{E}\\left( X^{k}\\left| \\theta \\right. \\right)g_{\\Theta}(\\theta)}d\\theta ~=~ \\mathrm{E}\\left\\lbrack \\mathrm{E}\\left( X^{k}\\left| \\Theta \\right. \\right) \\right\\rbrack . \\] Usando la ley de las esperanzas iteradas (ver Apéndice Capítulo 16), se puede definir la media y varianza de \\(X\\) como \\[ \\mathrm{E}\\left( X \\right) = \\mathrm{E}\\left\\lbrack \\mathrm{E}\\left( X\\left| \\Theta \\right. \\right) \\right\\rbrack \\] y \\[ \\mathrm{Var}\\left( X \\right) = \\mathrm{E}\\left\\lbrack \\mathrm{Var}\\left( X\\left| \\Theta \\right. \\right) \\right\\rbrack + \\mathrm{Var}\\left\\lbrack \\mathrm{E}\\left( X\\left| \\Theta \\right. \\right) \\right\\rbrack . \\] Ejemplo 3.3.7. Pregunta del examen actuarial. \\(X\\) tiene una distribución normal con media \\(\\Lambda\\) y varianza 1. \\(\\Lambda\\) tiene una distribución normal con media 1 y varianza 1. Determina la media y varianza de \\(X\\). Mostrar Solución de Ejemplo Solución. X es una mixtura continua con media \\[ \\mathrm{E}\\left(X\\right)=\\mathrm{E}\\left[\\mathrm{E}\\left(X\\middle|\\Lambda\\right)\\right]=\\mathrm{E}\\left(\\Lambda\\right)=1 \\text{ and } \\mathrm{V}\\left(X\\right)=\\mathrm{V}\\left[\\mathrm{E}\\left(X\\middle|\\Lambda\\right)\\right]+\\mathrm{E}\\left[\\mathrm{V}\\left(X\\middle|\\Lambda\\right)\\right]=\\mathrm{V}\\left(\\Lambda\\right)+\\mathrm{E}\\left(1\\right)=1+1=2. \\] Ejemplo 3.3.8. Pregunta del examen actuarial. Las cuantías de los siniestros, \\(X\\), son uniformes en el intervalo \\(\\left(\\Theta,\\Theta+10\\right)\\) para cada asegurado. \\(\\Theta\\) varía según el asegurado de acuerdo a una distribución exponencial con media 5. Determina la distribución incondicional, media y varianza de \\(X\\). Mostrar Solución de Ejemplo Solución. La distribución condicional de \\(X\\) es \\(f_{X}\\left( \\left. \\ x \\right|\\theta \\right) = \\frac{1}{10}\\) para \\(\\theta &lt; x &lt; \\theta + 10\\). La distribución a priori de \\(\\theta\\) es \\(g_{\\Theta}(\\theta) = \\frac{1}{5}e^{- \\frac{\\theta}{5}}\\) para \\(0 &lt; \\theta &lt; \\infty\\). La media y varianza condicionales de \\(X\\) vienen dadas por \\[ \\mathrm{E}\\left( \\left. \\ X \\right|\\theta \\right) = \\frac{\\theta + \\theta + 10}{2} = \\theta + 5 \\] y \\[ \\mathrm{Var}\\left( \\left. \\ X \\right|\\theta \\right) = \\frac{\\left\\lbrack \\left( \\theta + 10 \\right) - \\theta \\right\\rbrack^{2}}{12} = \\frac{100}{12}, \\] respectivamente. Por lo tanto, la media y varianza incondicionales de \\(X\\) vienen dadas por \\[ \\mathrm{E}\\left( X \\right) = \\mathrm{E}\\left\\lbrack \\mathrm{E}\\left( X\\left| \\Theta \\right. \\right) \\right\\rbrack = \\mathrm{E}\\left( \\Theta + 5 \\right) = \\mathrm{E}\\left( \\Theta \\right) + 5 = 5 + 5 = 10, \\] y \\[ \\mathrm{Var}\\left( X \\right) = \\mathrm{E}\\left\\lbrack V\\left( X\\left| \\Theta \\right. \\right) \\right\\rbrack + \\mathrm{Var}\\left\\lbrack \\mathrm{E}\\left( X\\left| \\Theta \\right. \\right) \\right\\rbrack \\\\ = \\mathrm{E}\\left( \\frac{100}{12} \\right) + \\mathrm{Var}\\left( \\Theta + 5 \\right) = 8.33 + \\mathrm{Var}\\left( \\Theta \\right) = 33,33. \\] La distribucíon incondicional de \\(X\\) es \\[ f_{X}\\left( x \\right) = \\int f_{X}\\left( x |\\theta \\right) ~g_{\\Theta}(\\theta) d \\theta . \\] \\[ f_{X}\\left( x \\right) = \\left\\{ \\begin{matrix} \\int_{0}^{x}{\\frac{1}{50}e^{- \\frac{\\theta}{5}}d\\theta = \\frac{1}{10}\\left( 1 - e^{- \\frac{x}{5}} \\right)} &amp; 0 \\leq x \\leq 10, \\\\ \\int_{x - 10}^{x}{\\frac{1}{50}e^{- \\frac{\\theta}{5}} d\\theta} = \\frac{1}{10}\\left( e^{- \\frac{\\left( x - 10 \\right)}{5}} - e^{- \\frac{x}{5}} \\right) &amp; 10 &lt; x &lt; \\infty. \\\\ \\end{matrix} \\right.\\ \\] 3.4 Modificaciones de cobertura En esta sección se evalúa el impacto de las modificaciones de cobertura: a) franquicias, b) límites en la póliza, c) coseguro e inflación en los costes del asegurador. 3.4.1 Franquicias En una póliza con franquícia ordinaria, el asegurado (tomador) acepta cubrir una cantidad fija de un siniestro antes de que el asegurador comience a pagar. Este gasto fijo pagado de su bolsillo se llama franquícia y suele denotarse por \\(d\\). Si la cuantía del siniestro excede \\(d\\) entonces el asegurador es responsable de cubrir el coste X menos la franquicia \\(d\\). Dependiendo del acuerdo, la franquícia puede aplicarse a cada pérdida asegurada o al total de las pérdidas durante un determinado periodo (mes, año, etc.) Las franquicias eliminan un gran número de pequeños siniestros, reduce el coste de gestionar y processar estos siniestros, reduce las primas para el tomador y reduce el riesgo moral. El riesgo moral ocurre cuando el asegurado asume más riesgos, aumentando las posibilidades de pérdidas debido a peligros frente a los que está asegurado, al saber que el asegurador se hará cargo de los costes (e.g. un asegurado con seguro frente a colisiones puede estar alentado a conducir temerariamente). Cuanto mayor sea la franquícia, el asegurado pagará primas más bajas por su póliza. Sea \\(X\\) la pérdida incurrida para el asegurado e \\(Y\\) la cantidad del siniestro pagada por el asegurador. En relación con el beneficio pagado al tomador, se distinguen dos variables: el pago por pérdida y el pago por pago. La variable pago por pérdida, denotada por \\(Y^{L}\\) o \\((X-d)_+\\) está censurada por la izquierda porque los valores de \\(X\\) que son inferiores a \\(d\\) no son ignorados pero se igualan a cero. Esta variable incluye pérdidas para las que se realiza un pago así como pérdidas inferiores a la franquícia y por lo tanto se define como \\[ Y^{L} = \\left( X - d \\right)_{+} = \\left\\{ \\begin{array}{cc} 0 &amp; X &lt; d, \\\\ X - d &amp; X &gt; d \\end{array} \\right. . \\] \\(Y^{L}\\) es frecuentemente denominada como una variable censurada por la izquierda y desplazada porque los valores por debajo de \\(d\\) no son ignorados y todas las pérdidas se ven desplazadas un valor \\(d\\). Por otra parte, la variable pago por pago, denotada por \\(Y^{P}\\), está solo definida cuando existe un pago. Concretamente, \\(Y^P\\) es igual a \\(X-d\\) cuando \\(\\{X &gt;d\\}\\), denotado como \\(Y^P = X-d ||X&gt;d\\). Otra forma frecuentemente utilizada para expresarla es \\[ Y^{P} = \\left\\{ \\begin{matrix} \\text{No definido} &amp; X \\le d \\\\ X - d &amp; X &gt; d \\end{matrix} . \\right. \\] Por lo tanto, \\(Y^{P}\\) es frecuentemente referenciada como una variable truncada por la izquierda y desplazada o variable exceso de pérdida porque los siniestros inferiores a \\(d\\) no son reportados y los valores por encima de \\(d\\) se ven desplazados en \\(d\\) unidades. Incluso cuando la distribución de \\(X\\) es continua, la distribución de \\(Y^{L}\\) es una combinación híbrida de una componente discreta y otra continua. La parte discreta de la distribución está concentrada en \\(Y = 0\\) (cuando \\(X \\leq d\\)) y la parte continua se extiende sobre el intervalo \\(Y &gt; 0\\) (cuando \\(X &gt; d\\)). Para la parte discreta, la probabilidad de que no existan pagos es la probabiidad de que las pérdidas caigan por debajo de la franquícia; que es, \\[\\Pr\\left( Y^{L} = 0 \\right) = \\Pr\\left( X \\leq d \\right) = F_{X}\\left( d \\right).\\] Usando la transformación \\(Y^{L} = X - d\\) para la parte continua de la distribución, se puede determinar la función de densidad de probabilidad de \\(Y^{L}\\) que viene dada por \\[f_{Y^{L}}\\left( y \\right) = \\left\\{ \\begin{matrix} F_{X}\\left( d \\right) &amp; y = 0, \\\\ f_{X}\\left( y + d \\right) &amp; y &gt; 0 \\end{matrix} \\right. \\] Se puede ver que la variable pago por pago es la variable pago por pérdida condicionado a que la pérdida exceda la franquicia; es decir, \\(Y^{P} = \\left. \\ Y^{L} \\right|X &gt; d\\). Por lo tanto, la función de densidad de probabilidad de \\(Y^{P}\\) viene dada por \\[f_{Y^{P}}\\left( y \\right) = \\frac{f_{X}\\left( y + d \\right)}{1 - F_{X}\\left( d \\right)},\\] para \\(y &gt; 0\\). De acuerdo con esto, las funciones de distribución de \\(Y^{L}\\) y \\(Y^{P}\\) vienen dadas por \\[F_{Y^{L}}\\left( y \\right) = \\left\\{ \\begin{matrix} F_{X}\\left( d \\right) &amp; y = 0, \\\\ F_{X}\\left( y + d \\right) &amp; y &gt; 0. \\\\ \\end{matrix} \\right.\\ \\] y \\[F_{Y^{P}}\\left( y \\right) = \\frac{F_{X}\\left( y + d \\right) - F_{X}\\left( d \\right)}{1 - F_{X}\\left( d \\right)},\\] para \\(y &gt; 0\\), respectivamente. Los momentos ordinarios de \\(Y^{L}\\) y \\(Y^{P}\\) se pueden determinar directamente usando la función de densidad de probabilidad de \\(X\\) como sigue \\[\\mathrm{E}\\left\\lbrack \\left( Y^{L} \\right)^{k} \\right\\rbrack = \\int_{d}^{\\infty}\\left( x - d \\right)^{k}f_{X}\\left( x \\right)dx ,\\] y \\[ \\mathrm{E}\\left\\lbrack \\left( Y^{P} \\right)^{k} \\right\\rbrack = \\frac{\\int_{d}^{\\infty}\\left( x - d \\right)^{k}f_{X}\\left( x \\right) dx }{{1 - F}_{X}\\left( d \\right)} = \\frac{\\mathrm{E}\\left\\lbrack \\left( Y^{L} \\right)^{k} \\right\\rbrack}{{1 - F}_{X}\\left( d \\right)}, \\] respectivamente. Para \\(k=1\\), se puede usar la función de supervivencia para calcular \\(\\mathrm{E}(Y^L)\\) como \\[ \\mathrm{E}(Y^L) = \\int_d^{\\infty} [1-F_X(x)] ~dx . \\] Esto puede ser facilmente demostrado si se considera la definición inicial de \\(\\mathrm{E}(Y^L)\\) y se integra por partes. Se ha visto que la franquicia \\(d\\) impuesta en una póliza de seguros es la cantidad de pérdida que ha de ser pagada del bolsillo del asegurado antes de que el asegurador realice ningún pago. La franquicia \\(d\\) impuesta en una póliza de seguros reduce la prima. La ratio de eliminación de pérdida (LER) es el porcentaje de decrecimiento en el pago esperado del asegurador como resultado de imponer una franquícia. LER se define como \\[LER = \\frac{\\mathrm{E}\\left( X \\right) - \\mathrm{E}\\left( Y^{L} \\right)}{\\mathrm{E}\\left( X \\right)}.\\] Un tipo de franquícia no tan frecuente es la franquícia pura. La franquicia pura se aplica a la póliza de igual manera que la franquícia ordinaria excepto que cuando la pérdida excede la franquícia \\(d\\), la totalidad de la pérdida es cubierta por el asegurador. Las variables pago por pérdida y pago por pago en este caso se definen como \\[Y^{L} = \\left\\{ \\begin{matrix} 0 &amp; X \\leq d, \\\\ X &amp; X &gt; d, \\\\ \\end{matrix} \\right.\\ \\] y \\[Y^{P} = \\left\\{ \\begin{matrix} \\text{No definido} &amp; X \\leq d, \\\\ X &amp; X &gt; d, \\\\ \\end{matrix} \\right.\\ \\] respectivamente. Ejemplo 3.4.1. Pregunta del examen actuarial. Se asume que la distribución para la severidad de los siniestros es exponencial con media 1000. Una compañía de seguros pagará la cantidad de cada siniestro en exceso de una franquicia de 100. Calcula la varianza de la cantidad pagada por la compañía aseguradora por un siniestro, incluyendo la posibilidad de que la cantidad pagada sea 0. Mostrar Solución de Ejemplo Solution. Sea \\(Y^{L}\\) la cantidad pagada por la compañía aseguradora por un siniestro. \\[Y^{L} = \\left( X - 100 \\right)_{+} = \\left\\{ \\begin{matrix} 0 &amp; X \\leq 100, \\\\ X - 100 &amp; X &gt; 100. \\\\ \\end{matrix} \\right.\\ \\] El primer y segundo momento de \\(Y^{L}\\) son \\[E\\left( Y^{L} \\right) = \\int_{100}^{\\infty}\\left( x - 100 \\right)f_{X}\\left( x \\right)dx \\\\ = {\\int_{100}^{\\infty}{S_{X}\\left( x \\right)}dx = 1000e}^{- \\frac{100}{1000}},\\] y \\[E\\left\\lbrack \\left( Y^{L} \\right)^{2} \\right\\rbrack = \\int_{100}^{\\infty}\\left( x - 100 \\right)^{2}f_{X}\\left( x \\right)dx \\\\\\\\ = 2 \\times 1000^{2}e^{- \\frac{100}{1000}}.\\] Por lo tanto, \\[\\mathrm{Var}\\left( Y^{L} \\right) = \\left( 2 \\times 1000^{2}e^{- \\frac{100}{1000}} \\right) - \\left( {1000e}^{- \\frac{100}{1000}} \\right)^{2} = 990,944.\\] Otra forma más simple para llegar a la solución consiste en usar la relación entre \\(X\\) e \\(Y^{P}\\). Si \\(X\\) tiene distribución exponencial con media 1000, entonces \\(Y^{P}\\) tiene también distribución exponencial con la misma media, debido a la propiedad de falta de memoria de la distribución exponencial. Por lo tanto, \\(E\\left( Y^{P} \\right)\\)=1000 y \\[E\\left\\lbrack \\left( Y^{P} \\right)^{2} \\right\\rbrack = 2 \\times 1000^{2}.\\] Usando la relación entre \\(Y^{L}\\) y \\(Y^{P}\\) determinamos \\[E\\left( Y^{L} \\right) = \\ E\\left( Y^{P} \\right)S_{X}\\left( 100 \\right){= 1000e}^{- \\frac{100}{1000}}\\] \\[E\\left\\lbrack \\left( Y^{L} \\right)^{2} \\right\\rbrack = E\\left\\lbrack \\left( Y^{P} \\right)^{2} \\right\\rbrack S_{X}\\left( 100 \\right) = 2 \\times 1000^{2}e^{- \\frac{100}{1000}}.\\] La relación entre \\(X\\) e \\(Y^P\\) se puede usar también al trabajar con las distribuciones uniforme y Pareto. Puede demostrarse facilmente que si \\(X\\) es uniforme en el intervalo \\(\\left(0,\\theta\\right)\\) entonces \\(Y^P\\) es uniforme en el intervalo \\(\\left(0,\\theta-d\\right)\\) y si \\(X\\) es Pareto con parámetros \\(\\alpha\\) y \\(\\theta\\) entonces \\(Y^P\\) es Pareto con parámetros \\(\\alpha\\) y \\(\\theta+d\\). Ejemplo 3.4.2. Pregunta del examen actuarial. Para un seguro: Las pérdidas tienen la función de densidad \\[f_{X}\\left( x \\right) = \\left\\{ \\begin{matrix} 0,02x &amp; 0 &lt; x &lt; 10, \\\\ 0 &amp; \\text{en otros casos.} \\\\ \\end{matrix} \\right. \\] El seguro tiene una franquicia ordinaria por pérdida de 4. \\(Y^{P}\\) es la variable aleatoria pago por pago. Calcula \\(\\mathrm{E}\\left( Y^{P} \\right)\\). Mostrar Solución de Ejemplo Solución. Se define \\(Y^P\\) como sigue \\[Y^{P} = \\left\\{ \\begin{matrix} \\text{Indefinido} &amp; X \\leq 4, \\\\ X - 4 &amp; X &gt; 4. \\\\ \\end{matrix} \\right.\\ \\] Por lo tanto, \\(E\\left( Y^{P} \\right) = \\frac{\\int_{4}^{10}\\left( x - 4 \\right)0,02xdx}{{1 - F}_{X}\\left( 4 \\right)} = \\frac{2,88}{0,84} = 3,43\\). Nótese que se divide por \\(S_X(4)=1-F_X(4)\\), dado que ese es el rango en el que la variable \\(Y^P\\) está definida. Ejemplo 3.4.3. Pregunta del examen actuarial. Se proporcionan los siguientes datos: Las pérdidas siguen una distribución exponencial con la misma media en todos los años. . La ratio de eliminación de pérdida este año es 70%. La franquicia ordinaria para el año siguiente es 4/3 de la franquicia actual. Calcula la ratio de eliminación de pérdida para el siguiente año. Mostrar Solución de Ejemplo Solución. Sean las pérdidas \\(X\\sim Exp(\\theta)\\) y la franquícia para el año próximo \\(d&#39; = \\frac{4}{3}d\\), la franquícia del año actual. La LER para el año actual es \\[\\frac{E\\left( X \\right) - E\\left( Y^{L} \\right)}{E\\left( X \\right)} = \\frac{\\theta - \\theta e^{- d / \\theta}}{\\theta} = 1 - e^{- d / \\theta} = 0,7.\\] Entonces, \\(e^{- d / \\theta} = 0,3\\). La LER para el año próximo es \\[\\begin{align*} &amp;\\frac{\\theta - \\theta \\exp(- \\frac{d&#39;}{\\theta})}{\\theta}=\\frac{\\theta - \\theta \\exp(- \\frac{\\left( \\frac{4}{3}d \\right)}{\\theta})}{\\theta} \\\\ &amp;= 1 - \\exp\\left(- \\frac{ \\frac{4}{3} d }{\\theta}\\right) = 1 - \\left( e^{-d /\\theta} \\right)^{4/3} = 1 - {0,3}^{4/3} = 0.8 . \\end{align*}\\] 3.4.2 Límites de la póliza Cuando existe un límite en la póliza, el asegurador es responsable de cubrir la pérdida real \\(X\\) hasta el límite de cobertura. Este límite de cobertura fijado se llama límite de la póliza y se denota frecuentemente como \\(u\\). Si la pérdida excede el límite de la póliza, la diferencia \\(X - u\\) ha de ser pagada por el tomador. Mientras que un límite más alto para la póliza implica una compensación más alta para el asegurado, también se asocia a una prima mayor. Sea \\(X\\) la pérdida incurrida por el asegurado e \\(Y\\) la cantidad pagada por el asegurador. La variable \\(Y\\) conocida como variable pérdida limitada se denota por \\(X \\land u\\). Es una variable censurada por la derecha porque los valores por encima de \\(u\\) se igualan a \\(u\\). La variable aleatoria pérdida limitada \\(Y\\) se define como \\[ Y = X \\land u = \\left\\{ \\begin{matrix} X &amp; X \\leq u, \\\\ u &amp; X &gt; u. \\\\ \\end{matrix} \\right.\\ \\] Se puede ver que la distinción entre \\(Y^{L}\\) e \\(Y^{P}\\) no es necesaria en el supuesto de una póliza limitada dado que el asegurador siempre hará un pago. Usando las definiciones de \\(\\left(X-d\\right)_+ \\text{ y } \\left(X\\land d\\right)\\), se puede ver facilmente que el pago esperado sin modificaciones de cobertura, \\(X\\), es igual a la suma de los pagos esperados con una franquicia \\(d\\) y un límite \\(d\\). Es decir, \\({X=\\left(X-d\\right)}_++ \\left(X\\land d\\right)\\). Cuando una pérdida está sujeta a una franquicia \\(d\\) y un límite \\(u\\), la variable pago por pérdida \\(Y^L\\) se define como \\[ Y^{L} = \\left\\{ \\begin{matrix} 0 &amp; X \\leq d, \\\\ X - d &amp; d &lt; X \\leq u, \\\\ u - d &amp; X &gt; u. \\\\ \\end{matrix} \\right.\\ \\] Por tanto, \\(Y^L\\) puede expresarse como \\(Y^L=\\left(X\\land u\\right)-\\left(X\\land d\\right)\\). Aún cuando la distribución de \\(X\\) sea continua, la distribución de \\(Y\\) es una combinación híbrida de un componente discreto y uno continuo. La parte discreta de la distribución está concentrada en \\(Y = u\\) (cuando \\(X &gt; u\\)), mientras que la parte continua se extiende en el intervalo \\(Y &lt; u\\) (cuando \\(X \\leq u\\)). Para la parte discreta, la probabilidad de que la compensación pagada sea \\(u\\), es la probabilidad de que la pérdida exceda el límite de la póliza \\(u\\); es decir, \\[\\Pr \\left( Y = u \\right) = \\Pr \\left( X &gt; u \\right) = {1 - F}_{X}\\left( u \\right).\\] Para la parte continua de la distribución \\(Y = X\\), por lo tanto la función de densidad de probabilidad de \\(Y\\) viene dada por \\[f_{Y}\\left( y \\right) = \\left\\{ \\begin{matrix} f_{X}\\left( y \\right) &amp; 0 &lt; y &lt; u, \\\\ 1 - F_{X}\\left( u \\right) &amp; y = u. \\\\ \\end{matrix} \\right.\\ \\] De acuerdo con esto, la función de distribución de \\(Y\\) viene dada por \\[F_{Y}\\left( y \\right) = \\left\\{ \\begin{matrix} F_{X}\\left( x \\right) &amp; 0 &lt; y &lt; u, \\\\ 1 &amp; y \\geq u. \\\\ \\end{matrix} \\right.\\ \\] Los momentos ordinarios de \\(Y\\) pueden determinarse directamente usando la función de densidad de probabilidad de \\(X\\) como sigue \\[ \\mathrm{E}\\left( Y^{k} \\right) = \\mathrm{E}\\left\\lbrack \\left( X \\land u \\right)^{k} \\right\\rbrack = \\int_{0}^{u}x^{k}f_{X}\\left( x \\right)dx + \\int_{u}^{\\infty}{u^{k}f_{X}\\left( x \\right)} dx \\\\ = \\int_{0}^{u}x^{k}f_{X}\\left( x \\right)dx + u^{k}\\left\\lbrack {1 - F}_{X}\\left( u \\right) \\right\\rbrack . \\] For \\(k=1\\), we can use the survival function to calculate \\(\\mathrm{E}\\left( Y \\right)\\) as follows \\[ \\mathrm{E}\\left( Y \\right) = \\mathrm{E}\\left( X \\land u \\right) = \\int_{0}^{u} [1-F_{X}(x) ]dx . \\] Esto puede ser demostrado facilmente si se considera la distribución inicial de \\(\\mathrm{E}\\left( Y \\right)\\) y se hace una integración por partes. Ejemplo 3.4.4. Pregunta del examen actuarial. A través de una póliza de seguro colectivo, un asegurador se compromete a pagar el 100% de las facturas médicas incurridas durante el año por los empleados de una pequeña compañía, hasta una cantidad total máxima de un millón de dólares. La cantidad total de facturas incurridas, \\(X\\), tiene función de densiad de probabilidad \\[f_{X}\\left( x \\right) = \\left\\{ \\begin{matrix} \\frac{x\\left( 4 - x \\right)}{9} &amp; 0 &lt; x &lt; 3, \\\\ 0 &amp; \\text{en otros casos.} \\\\ \\end{matrix} \\right.\\ \\] donde \\(x\\) se mide en millones. Calcula la cantidad total, en millones de dólares, que en términos esperados el asegurador pagará por esta póliza. Mostrar Solución de Ejemplo Solución. Se define la cantidad total que el asegurador paga por las facturas como \\[Y = X \\land 1 = \\left\\{ \\begin{matrix} X &amp; X \\leq 1, \\\\ 1 &amp; X &gt; 1. \\\\ \\end{matrix} \\right.\\ \\] Por lo tanto \\(\\mathrm{E}\\left( Y \\right) = \\mathrm{E}\\left( X \\land 1 \\right) = \\int_{0}^{1}\\frac{x^{2}(4 - x)}{9}dx + 1 * \\int_{1}^{3}\\frac{x\\left( 4 - x \\right)}{9}dx = 0,935\\). 3.4.3 Coseguro e inflación Tal y como hemos visto en la Sección 3.4.1 la cantidad de pérdida retenida por el tomador está limitada por el nivel de la franquicia \\(d\\). La pérdida retenida también puede ser un porcentaje del importe de los siniestros. El porcentaje \\(\\alpha\\), a menudo denominado factor de coseguro, es el porcentaje del siniestro que la compañía ha de cubrir. Si la póliza está sujeta a una franquicia ordinaria y a un límite de la póliza, el coseguro se refiere al porcentaje del siniestro que el asegurador ha de cubrir, después de imponer la franquicia ordinaria y el límite de la póliza. La variable pago por pérdida, \\(Y^{L}\\), se define como \\[ Y^{L} = \\left\\{ \\begin{matrix} 0 &amp; X \\leq d, \\\\ \\alpha\\left( X - d \\right) &amp; d &lt; X \\leq u, \\\\ \\alpha\\left( u - d \\right) &amp; X &gt; u. \\\\ \\end{matrix} \\right.\\ \\] El límite de la póliza (la cantidad máxima pagada por el asegurador) en este caso es \\(\\alpha\\left( u - d \\right)\\), mientras que \\(u\\) es la pérdida máxima cubierta. Hemos visto en la Sección 3.4.2 que cuando una pérdida está sujeta a una franquicia \\(d\\) y a un límite \\(u\\) la variable por pérdida \\(Y^L\\) puede expresarse como \\(Y^L=\\left(X\\land u\\right)-\\left(X\\land d\\right)\\). Con coseguro, se tiene que \\(Y^L\\) puede expresarse como \\(Y^L=\\alpha\\left[(X\\land u)-(X\\land d)\\right]\\). El momento \\(k\\)-ésimo de \\(Y^{L}\\) viene dado por \\[ \\mathrm{E}\\left\\lbrack \\left( Y^{L} \\right)^{k} \\right\\rbrack = \\int_{d}^{u}\\left\\lbrack \\alpha\\left( x - d \\right) \\right\\rbrack^{k}f_{X}\\left( x \\right)dx + \\left\\lbrack \\alpha\\left( u - d \\right) \\right\\rbrack^{k} [1-F_{X}\\left( u \\right)] . \\] Un factor de incremento \\(\\left( 1 + r \\right)\\) se puede aplicar a \\(X\\) dando como resultado una variable aleatoria de pérdida ajustada por inflación \\(\\left( 1 + r \\right)X\\) (los valores de d y u preespecificados se mantienen inalterables). La variable por pérdida resultante se puede expresar como \\[Y^{L} = \\left\\{ \\begin{matrix} 0 &amp; X \\leq \\frac{d}{1 + r}, \\\\ \\alpha\\left\\lbrack \\left( 1 + r \\right)X - d \\right\\rbrack &amp; \\frac{d}{1 + r} &lt; X \\leq \\frac{u}{1 + r}, \\\\ \\alpha\\left( u - d \\right) &amp; X &gt; \\frac{u}{1 + r}. \\\\ \\end{matrix} \\right.\\ \\] Los momentos primero y segundo de \\(Y^{L}\\) se pueden expresar como \\[\\mathrm{E}\\left( Y^{L} \\right) = \\alpha\\left( 1 + r \\right)\\left\\lbrack \\mathrm{E}\\left( X \\land \\frac{u}{1 + r} \\right) - \\mathrm{E}\\left( X \\land \\frac{d}{1 + r} \\right) \\right\\rbrack,\\] y \\[\\mathrm{E}\\left\\lbrack \\left( Y^{L} \\right)^{2} \\right\\rbrack = \\alpha^{2}\\left( 1 + r \\right)^{2} \\left\\{ \\mathrm{E}\\left\\lbrack \\left( X \\land \\frac{u}{1 + r} \\right)^{2} \\right\\rbrack - \\mathrm{E}\\left\\lbrack \\left( X \\land \\frac{d}{1 + r} \\right)^{2} \\right\\rbrack \\right. \\\\ \\left. \\ \\ \\ \\ \\ - 2\\left( \\frac{d}{1 + r} \\right)\\left\\lbrack \\mathrm{E}\\left( X \\land \\frac{u}{1 + r} \\right) - \\mathrm{E}\\left( X \\land \\frac{d}{1 + r} \\right) \\right\\rbrack \\right\\} ,\\] respectivamente. Las fórmulas proporcionadas para los momentos primero y segundo de \\(Y^{L}\\) son generales. Bajo cobertura total, \\(\\alpha = 1\\), \\(r = 0\\), \\(u = \\infty\\), \\(d = 0\\) y \\(\\mathrm{E}\\left( Y^{L} \\right)\\) se reduce a \\(\\mathrm{E}\\left( X \\right)\\). Si solo se impone una franquicia ordinaria, \\(\\alpha = 1\\), \\(r = 0\\), \\(u = \\infty\\) y \\(\\mathrm{E}\\left( Y^{L} \\right)\\) se reduce a \\(\\mathrm{E}\\left( X \\right) - \\mathrm{E}\\left( X \\land d \\right)\\). Si solo se impone un límite en la póliza \\(\\alpha = 1\\), \\(r = 0\\), \\(d = 0\\) y \\(\\mathrm{E}\\left( Y^{L} \\right)\\) se reduce a \\(\\mathrm{E}\\left( X \\land u \\right)\\). Ejemplo 3.4.5. Pregunta del examen actuarial. La variable aleatoria ground up loss para una póliza de seguro de salud en 2006 se modeliza con X, una distribución exponencial de media 1000. Una póliza de seguros paga las pérdidas por encima de una franquicia ordinaria de 100, con un máximo pago anual de 500. La variable aleatoria ground up loss se espera que sea 5% mayor en 2007, pero el seguro en 2007 tiene la misma franquícia y máximo pago como en 2006. Encuentra el porcentaje de incremento en el coste esperado por pago desde 2006 a 2007. Mostrar Solución de Ejemplo Solución. Definimos la cantidad por pérdida \\(Y^L\\) en ambos años como \\[Y_{2006}^{L} = \\left\\{ \\begin{matrix} 0 &amp; X \\leq 100, \\\\ X - 100 &amp; 100 &lt; X \\leq 600, \\\\ 500 &amp; X &gt; 600. \\\\ \\end{matrix} \\right.\\ \\] \\[Y_{2007}^{L} = \\left\\{ \\begin{matrix} 0 &amp; X \\leq 95,24, \\\\ 1.05X - 100 &amp; 95,24 &lt; X \\leq 571,43, \\\\ 500 &amp; X &gt; 571,43. \\\\ \\end{matrix} \\right.\\ \\] Por lo tanto, \\[E\\left( Y_{2006}^{L} \\right) = E\\left( X \\land 600 \\right) - E\\left( X \\land 100 \\right) = 1000\\left( {1 - e}^{- \\frac{600}{1000}} \\right) - 1000\\left( {1 - e}^{- \\frac{100}{1000}} \\right)\\] \\[= 356,026\\]. \\[E\\left( Y_{2007}^{L} \\right) = 1,05\\left\\lbrack E\\left( X \\land 571,43 \\right) - E\\left( X \\land 95,24 \\right) \\right\\rbrack\\] \\[ = 1,05\\left\\lbrack 1000\\left( {1 - e}^{- \\frac{571,43}{1000}} \\right) - 1000\\left( {1 - e}^{- \\frac{95,24}{1000}} \\right) \\right\\rbrack \\] \\[=361,659\\]. \\(E\\left( Y_{2006}^{P} \\right) = \\frac{356,026}{e^{- \\frac{100}{1000}}} = 393,469\\). \\(E\\left( Y_{2007}^{P} \\right) = \\frac{361,659}{e^{- \\frac{95,24}{1000}}} = 397,797\\). Dado que \\(\\frac{E\\left( Y_{2007}^{P} \\right)}{E\\left( Y_{2006}^{P} \\right)} -1 = 0,011,\\) hay un incremento del 1,1% desde 2006 a 2007. Debido al límite de la póliza, el coste por evento por pago creció solo un 1,1% entre 2006 y 2007 aunque las ground up losses aumentaron un 5% entre los dos años. 3.4.4 Reaseguro En la Sección 3.4.1 se introdujo la franquicia en la póliza, que es un acuerdo contractual bajo el cual un asegurado transfiere parte del riesgo al asegurador que garantiza su cobertura a cambio del pago de una prima. En base a esta póliza, el asegurado ha de pagar todos los costes hasta el valor de la franquicia, y el asegurador solo paga la cantidad por encima de la franquicia (si la supera). Ahora se introduce el conceptoreaseguro, un mecanismo de seguro para las compañías aseguradoras. El reaseguro es un acuerdo contractual bajo el cual un asegurador transfiere la cobertura de parte de los riesgos subyacentes asegurados a otro asegurador (al que nos referimos como el reasegurador) a cambio de una prima de reaseguro. Aunque el reaseguro implica una relación entre tres partes: el asegurado original, el asegurador (a veces denominado cedente) y el reasegurador, el acuerdo de reaseguro solo implica al asegurador primario y al reasegurador. No existe relación contractual entre el asegurado original y el reasegurador. Aunque existen diferentes tipos de contratos de reaseguro, una forma común es la cobertura de exceso de pérdida. En estos contratos, el asegurador primario ha de hacer todos los pagos requeridos al asegurado hasta que el total de pagos del asegurador primario alcanza el valor de la franquicia fijada en el reaseguro. El reasegurador es entonces solo responsable del pago de cuantías por encima de la franquícia de reaseguro. La cantidad máxima retenida por el asegurador primario en el acuerdo de reaseguro (la franquícia de reaseguro) se denomina retención. Los acuerdos de reaseguro permiten a los aseguradores con recursos financieros limitados incrementar su capacidad de suscribir pólizas y cumplir con los requerimientos realizados por los clientes para cobertures de seguro mayores al tiempo que reducen el impacto de pérdidas potenciales y protegen la compañía aseguradora frente a pérdidas castastróficas. El reasseguro también permite al asegurador primario beneficiarse de las habilidades de suscripción, la experiencia y la gestión compleja y competente de los archivos de reclamaciones de las compañías de reaseguro más grandes. Ejemplo 3.4.6. Pregunta del examen actuarial. Las pérdidas que se derivan de una determinada cartera tienen una distribución de Pareto de dos parámetros con \\(\\alpha=5\\) y \\(\\theta=3.600\\). Se ha firmado un acuerdo de reaseguro, bajo el cual (a) el reasegurador acepta un 15% de las pérdidas hasta \\(u=5.000\\) y todas las cantidades en exceso de 5.000 y (b) el asegurador paga el resto de pérdidas. Expresa las variables aleatorias para los pagos del reasegurador y asegurador en función de \\(X\\), las pérdidas de la cartera. Calcula la cantidad media pagada por el asegurador por un único siniestro. Asumiendo que el límite superior es \\(u = \\infty\\), calcula un límite superior para la desviación estándar de la cantidad pagada por un único siniestro por el asegurador (reteniendo el 15% de copago). Mostrar Solución de Ejemplo Solución. La porción del reasegurador es \\[ Y_{reasegurador} = \\left\\{ \\begin{array}{cc} 0,15 X &amp; X &lt; 5000, \\\\ 0,15(5000) + X-5000 &amp; X \\ge 5000 \\end{array} \\right. . \\] Y la porción del asegurador es \\[ Y_{asegurador} = \\left\\{ \\begin{array}{cc} 0,85 X &amp; X &lt; 5000, \\\\ 0,85(5000) &amp; X \\ge 5000 \\end{array} \\right. = 0,85(X \\wedge 5000). \\] b) Usando las tablas para el valor esperado limitado de una distribución de Pareto, tenemos \\[ \\mathrm{E}~Y_{asegurador} = 0,85~\\mathrm{E}~(X \\wedge 5000)= 0,85~\\frac{\\theta}{\\alpha-1}\\left[ 1- \\left(\\frac{\\theta}{5000+\\theta}\\right)^{\\alpha-1} \\right] \\\\ = 0,85~\\frac{3600}{5-1}\\left[ 1- \\left(\\frac{3600}{5000+3600}\\right)^{5-1}\\right] = 741,5103. \\] c) Para el primer momento de la variable no limitada, tenemos \\[ \\mathrm{E}~Y_{asegurador}(u=\\infty) = 0,85~\\mathrm{E}~X = 0,85~\\frac{\\theta}{\\alpha-1} = 0,85~\\frac{3600}{5-1} = 765. \\] Para el segundo momento de la variable no limitada, usamos la tabla de distribuciones para obtener \\[ \\mathrm{E}~Y_{asegurador}(u=\\infty)^2 = 0,85^2~\\mathrm{E}~X^2 = 0,85^2~\\frac{\\theta^2 \\Gamma(2+1)\\Gamma(\\alpha-2)}{\\Gamma(\\alpha)} \\\\ = 0,85^2~\\frac{3600^2 *2*2}{24} = 1560600. \\] Por tanto, la varianza es \\(1560600-765^2 =975375.\\) Alternativamente, se puede usar la fórmula \\[ 0,85^2~\\mathrm{Var}~X = 0,85^2~\\frac{\\alpha \\theta^2}{(\\alpha-1)^2(\\alpha-2)} \\\\ = 0,85^2~\\frac{5(3600^2)}{(5-1)^2(5-2)} = 975375. \\] Tomando raíces cuadradas, la desviación estándar es \\(\\sqrt{975375} \\approx 987,6108\\). En la Sección 3.4.4 se proporcionaran más detalles sobre el reaseguro. 3.5 Estimación por máxima verosimilitud En esta sección, se describirá cómo: Definir la verosimilitud para una muestra de observaciones de una distribución continua Definir el estimador de máxima verosimilitud para una muestra aleatoria de observaciones de una distribución continua Estimar distribuciones paramétricas basándose en datos agrupados, censurados y truncados 3.5.1 Estimadores de máxima verosimilitud para datos completos Hasta este punto, este capítulo se ha centrado en distribuciones paramétricas que son frecuentemente usadas en aplicacions en el mundo asegurador. No obstante, para ser útiles en el trabajo aplicado, estas distribuciones deben usar valores “realistas” para los parámetros, y para ello es necesario volver a los datos. Fundamentalmente, asumimos que el analista dispone de una muestra aleatoria \\(X_1, \\ldots, X_n\\) de una distribución con función de distribución \\(F_X\\) (por simplicidad, a veces se omite el subíndice \\(X\\)). Como es común, se usa el vector \\(\\boldsymbol \\theta\\) para denotar el conjunto de parámetros de \\(F\\). Este esquema básico de la muestra es revisado en la Sección Appendix 15.1. Aunque sea básico, este esquema de muestreo proporciona los fundamentos para entender esquemas más complejos que son regularmente usados en la práctica, y por lo tanto es importante dominar los conceptos básicos. Antes de obtener valores aleatorios de una distribución, se consideran los resultados potenciales resumidos por una variable aleatoria \\(X_i\\) (aquí, \\(i\\) es 1, 2, …, \\(n\\)). Después de obtener el valor aleatorio, se observa \\(x_i\\). En relación con la notación, se usa letras romanas mayúsculas para variables aleatorias y minúscules para las realizaciones. Ya se ha presentado este planteamiento en la Sección 2.4, donde se ha usado \\(\\Pr(X_1 =x_1, \\ldots, X_n=x_n)\\) para cuantificar la “verosimilitud” de extraer una muestra \\(\\{x_1, \\ldots, x_n\\}\\). Con datos continuos, se usa la función de densidad de probabilidad conjunta (pdf) en lugar de probabilidades conjuntas. Asumiendo independencia, la pdf conjunta puede ser expressada como el producto de pdfs. Por lo tanto, se define la verosimilitud como \\[\\begin{equation} L(\\boldsymbol \\theta) = \\prod_{i=1}^n f(x_i) . \\tag{3.2} CREO QUE ESTO ES UN LABEL Y DE DEBERIA SALIR \\end{equation}\\] A partir de esta notación, es necesario destacar que se considera esta función una función de los parámetros en \\(\\boldsymbol \\theta\\), con los datos \\(\\{x_1, \\ldots, x_n\\}\\) fijos. El estimador de máxima verosimilitud es aquel valor de los parámetros en \\(\\boldsymbol \\theta\\) que maximiza \\(L(\\boldsymbol \\theta)\\). De cálculo, se sabe que maximizar una función produce el mismo resultado que maximizar el logaritmo de la función (esto es debido a que el logaritmo es una función monótona convexa). Dado que obtenemos los mismos resultados, para facilitar las consideraciones computacionales, es común considerar la verosimilitud logarítmica, denotada como \\[\\begin{equation} l(\\boldsymbol \\theta) = \\ln L(\\boldsymbol \\theta) = \\sum_{i=1}^n \\ln f(x_i) . (\\#eq:Verosimilitud logarítmica) \\end{equation}\\] Ejemplo 3.5.1. Pregunta del examen actuarial. Se proporcionan las siguientes cinco observaciones: 521, 658, 702, 819, 1217. Se usa una Pareto de un único parámetro con función de distribución: \\[ F(x) = 1- \\left(\\frac{500}{x}\\right)^{\\alpha}, ~~~~ x&gt;500 . \\] Con \\(n=5\\), el logaritmo de la función de verosimilitud es \\[ l(\\alpha|\\mathbf{x} ) = \\sum_{i=1}^5 \\ln f(x_i;\\alpha ) = 5 \\alpha \\ln 500 + 5 \\ln \\alpha -(\\alpha+1) \\sum_{i=1}^5 \\ln x_i. \\] La Figura 3.4 muestra la verosimilitud logarítmica como función del parámetro \\(\\alpha\\). Figure 3.4: Verosimilitud logarítmica para una Pareto de un parámetro Se puede determinar el valor máximo del logaritmo de la verosimilitud tomando derivadas e igualándolas a cero. De esto resulta \\[ \\frac{ \\partial}{\\partial \\alpha } l(\\alpha |\\mathbf{x}) = 5 \\ln 500 + 5 / \\alpha - \\sum_{i=1}^5 \\ln x_i =_{set} 0 \\Rightarrow \\hat{\\alpha}_{MLE} = \\frac{5}{\\sum_{i=1}^5 \\ln x_i - 5 \\ln 500 } = 2,453 . \\] Naturalmente, hay muchos problemas en los que no es práctico realizar un cálculo manual para la optimización. Afortunadamente hay muchas rutinas estadísticas disponibles como la función optim de R. Código de R para la optimización c1 &lt;- log(521)+log(658)+log(702)+log(819)+log(1217) nloglike &lt;- function(alpha){-(5*alpha*log(500)+5*log(alpha)-(alpha+1)*c1)} MLE &lt;- optim(par=1, fn=nloglike)$par Este código confirma el resultado del cálculo manual en el que el estimador máximo verosímil es \\(\\alpha_{MLE} =\\) 2.453125. Se presentan algunos ejemplos adicionales para ilustrar cómo los actuarios ajustan modelos de distribución paramétricos a una base de datos de siniestros usando máxima verosimilitud. Ejemmplo 3.5.2. Pregunta de examen actuarial. Se considera una muestra aleatoria de cuantías de siniestros: 8.000 10.000 12.000 15.000. Se asume que la cuantía de los siniestros sigue una distribución inversa exponencial, con parámetro \\(\\theta\\). Calcula el estimador máximo verosímil de \\(\\theta\\). Mostrar Solución de Ejemplo Solución. La función de densidad de probabilidad es \\[f_{X}\\left( x \\right) = \\frac{\\theta e^{- \\frac{\\theta}{x}}}{x^{2}}, \\] donde \\(x &gt; 0\\). La función de verosimilitud, \\(L\\left( \\theta \\right)\\), puede ser vista como la probabilidad de los datos observados, expresada en función de los parámetros del modelo \\(\\theta\\) \\[L\\left( \\theta \\right) = \\prod_{i = 1}^{4}{f_{X_{i}}\\left( x_{i} \\right)} = \\frac{\\theta^{4}e^{- \\theta\\sum_{i = 1}^{4}\\frac{1}{x_{i}}}}{\\prod_{i = 1}^{4}x_{i}^{2}}.\\] El logaritmo de la función de verosimilitud, \\(\\ln L \\left( \\theta \\right)\\), es la suma de los logarítmos individuales. \\[\\ln L \\left( \\theta \\right) = 4 \\ln \\theta - \\theta\\sum_{i = 1}^{4}\\frac{1}{x_{i}} - 2\\sum_{i = 1}^{4}\\ln x_{i} .\\] \\[ \\frac{d \\ln L \\left( \\theta \\right)}{d \\theta} = \\frac{4}{\\theta} - \\sum_{i = 1}^{4}\\frac{1}{x_{i}}. \\] El estimador máximo verosímil de \\(\\theta\\), denotado como \\(\\hat{\\theta}\\), es la solución para la ecuación \\[\\frac{4}{\\hat{\\theta}} - \\sum_{i = 1}^{4}{\\frac{1}{x_{i}} = 0}.\\] Por tanto, \\(\\hat{\\theta} = \\frac{4}{\\sum_{i = 1}^{4}\\frac{1}{x_{i}}} = 10.667\\) La segunda derivada de \\(\\ln L \\left( \\theta \\right)\\) viene dada por \\[\\frac{d^{2}\\ln L\\left( \\theta \\right)}{d\\theta^{2}} = \\frac{- 4}{\\theta^{2}}.\\] Evaluando la segunda derivada del logaritmo de la función de verosimilitud en \\(\\hat{\\theta} = 10.667\\) da un valor negativo, lo cual indica que \\(\\hat{\\theta}\\) es el valor que maximiza el logaritmo de la función de verosimilitud. Ejemplo 3.5.3. Pregunta del examen actuarial. Una muestra aleatoria de tamaño 6 proviene de una distribución lognormal con parámetros \\(\\mu\\) y \\(\\sigma\\). Los valores de la muestra son 200, 3.000, 8.000, 60.000, 60.000, 160.000. Calcula el estimador máximo verosímil de \\(\\mu\\) y \\(\\sigma\\). Mostrar Solución de Ejemplo Solución. La función de densidad de probabilidad es \\[f_{X}\\left( x \\right) = \\frac{1}{x \\sigma \\sqrt{2\\pi}}\\exp - \\frac{1}{2}\\left( \\frac{\\ln x - \\mu}{\\sigma} \\right)^{2},\\] donde \\(x &gt; 0\\). La función de verosimilitud, \\(L\\left( \\mu,\\sigma \\right)\\), es el producto de la pdf para cada punto. \\[L\\left( \\mu,\\sigma \\right) = \\prod_{i = 1}^{6}{f_{X_{i}}\\left( x_{i} \\right)} = \\frac{1}{\\sigma^{6}\\left( 2\\pi \\right)^{3}\\prod_{i = 1}^{6}x_{i}}exp - \\frac{1}{2}\\sum_{i = 1}^{6}\\left( \\frac{\\ln x_{i} - \\mu}{\\sigma} \\right)^{2}.\\] El logaritmo de la función de verosimilitud, \\(\\ln L \\left( \\mu,\\sigma \\right)\\), es la suma de los logaritmos individuales. \\[\\ln \\left( \\mu,\\sigma \\right) = - 6 \\ln \\sigma - 3 \\ln \\left( 2\\pi \\right) - \\sum_{i = 1}^{6}\\ln x_{i} - \\frac{1}{2}\\sum_{i = 1}^{6}\\left( \\frac{\\ln x_{i} - \\mu}{\\sigma} \\right)^{2}.\\] Las primeras derivadas parciales son \\[\\frac{\\partial \\ln L\\left( \\mu,\\sigma \\right)}{\\partial\\mu} = \\frac{1}{\\sigma^{2}}\\sum_{i = 1}^{6}\\left( \\ln x_{i} - \\mu \\right).\\] \\[\\frac{\\partial \\ln L\\left( \\mu,\\sigma \\right)}{\\partial\\sigma} = \\frac{- 6}{\\sigma} + \\frac{1}{\\sigma^{3}}\\sum_{i = 1}^{6}\\left( \\ln x_{i} - \\mu \\right)^{2}.\\] Los estimadores máximo verosímiles de \\(\\mu\\) y \\(\\sigma\\), denotados como \\(\\hat{\\mu}\\) y \\(\\hat{\\sigma}\\), son las soluciones de las ecuaciones \\[\\frac{1}{{\\hat{\\sigma}}^{2}}\\sum_{i = 1}^{6}\\left( \\ln x_{i} - \\hat{\\mu} \\right) = 0.\\] \\[\\frac{- 6}{\\hat{\\sigma}} + \\frac{1}{{\\hat{\\sigma}}^{3}}\\sum_{i = 1}^{6}\\left( \\ln x_{i} - \\hat{\\mu} \\right)^{2} = 0.\\] Esto resulta en las estimaciones \\[\\hat{\\mu} = \\frac{\\sum_{i = 1}^{6}{\\ln x_{i}}}{6} = 9,38 \\ \\ \\ \\text{y} \\ \\ \\ {\\hat{\\sigma}}^{2} = \\frac{\\sum_{i = 1}^{6}\\left( \\ln x_{i} - \\hat{\\mu} \\right)^{2}}{6} = 5,12 . \\]. Las segundas derivadas parciales son \\[ \\frac{\\partial^{2}\\ln L\\left( \\mu,\\sigma \\right)}{\\partial\\mu^{2}} = \\frac{- 6}{\\sigma^{2}}, \\ \\ \\ \\ \\frac{\\partial^{2}\\ln L\\left( \\mu,\\sigma \\right)}{\\partial\\mu\\partial\\sigma} = \\frac{- 2}{\\sigma^{3}}\\sum_{i = 1}^{6}\\left( \\ln x_{i} - \\mu \\right) \\] y \\[ \\frac{\\partial^{2}\\ln L\\left( \\mu,\\sigma \\right)}{\\partial\\sigma^{2}} = \\frac{6}{\\sigma^{2}} - \\frac{3}{\\sigma^{4}}\\sum_{i = 1}^{6}\\left( \\ln x_{i} - \\mu \\right)^{2} \\]. Dos cuestiones que vendrían a continuación tienen que ver con las propiedades para muestras grandes que el lector puede haber visto en cursos anteriores. El Capítulo del Apéndice 17 revisa la definición de función de verosimilitud, introduce sus propiedades, revisa los estimadores máximo verosímiles, extiende sus propiedades para muestras grandes al caso en el que hay múltiples parámetros en el modelo, y revisa la inferencia estadística basada en los estimadores máximo verosímiles. En las soluciones de estos ejemplos se derivan las varianzas asintóticas de los estimadores máximo verosímiles de los parámetros del modelo. Se usa el método delta para derivar las varianzas asintóticas de las funciones de estos parámetros. Ejemplo 3.5.2 - Continuación. Se refiere al Ejemplo 3.5.2. Aproxima la varianza del estimador máximo verosímil. Determina un intervalo de confianza para \\(\\theta\\) al 95%. Determina un intervalo de confianza del 95% para \\(\\Pr \\left( X \\leq 9.000 \\right).\\) Mostrar Solución de Ejemplo Solución. a. Tomando el recíproco de la esperanza negativa de la segunda derivada de \\(\\ln L \\left( \\theta \\right)\\), se obtiene una estimación de la varianza de \\(\\hat{\\theta}\\), \\(\\widehat{Var}\\left( \\hat{\\theta} \\right) = \\left. \\ \\left\\lbrack E\\left( \\frac{d^{2}\\ln L \\left( \\theta \\right)}{d\\theta^{2}} \\right) \\right\\rbrack^{- 1} \\right|_{\\theta = \\hat{\\theta}} = \\frac{{\\hat{\\theta}}^{2}}{4} = 28.446.222\\). Nótese que dado que el tamaño de la muestra \\(n \\rightarrow \\infty\\), la distribución del estimador máximo verosímil \\(\\hat{\\theta}\\) converge a una distribución normal con media \\(\\theta\\) y varianza \\(\\hat{V}\\left( \\hat{\\theta} \\right)\\). El intervalo de confianza aproximado en este ejemplo se basa en el supuesto de normalidad, a pesar del pequeño tamaño muestral, solo con fines ilustrativos. b. El intervalo de confianza al 95% para \\(\\theta\\) viene dado por \\[ 10.667 \\pm 1,96\\sqrt{28.446.222} = \\left( 213,34,\\ 21.120,66 \\right). \\] c. La función de distribución de \\(X\\) es \\(F\\left( x \\right) = 1 - e^{- \\frac{x}{\\theta}}\\). Entonces, el estimador máximo verosímil de \\(g_{\\Theta}(\\theta) = F\\left( 9.000 \\right)\\) es \\[g\\left( \\hat{\\theta} \\right) = 1 - e^{- \\frac{9.000}{10.667}} = 0,57.\\] Se usa el método delta para aproximar la varianza de \\(g\\left( \\hat{\\theta} \\right)\\). \\[\\frac{\\text{dg}\\left( \\theta \\right)}{d \\theta} = {- \\frac{9.000}{\\theta^{2}}e}^{- \\frac{9.000}{\\theta}}.\\] \\(\\widehat{Var}\\left\\lbrack g\\left( \\hat{\\theta} \\right) \\right\\rbrack = \\left( - {\\frac{9.000}{{\\hat{\\theta}}^{2}}e}^{- \\frac{9.000}{\\hat{\\theta}}} \\right)^{2}\\hat{V}\\left( \\hat{\\theta} \\right) = 0,0329\\). El intervalo de confianza al 95% para \\(F\\left( 9.000 \\right)\\) viene dado por \\[0,57 \\pm 1,96\\sqrt{0,0329} = \\left( 0,214,\\ 0,926 \\right).\\] Ejemplo 3.5.3 - Continuación. Se refiere al Ejemplo 3.5.3. Estima la matriz de covarianzas del estimador máximo verosímil. Determina intervalos de confianza aproximados al 95% para \\(\\mu\\) y \\(\\sigma\\). Determina un intervalo de confianza aproximado al 95% para la media de la distribución lognormal. Mostrar Solución de Ejemplo a. Para obtener la matriz de covarianzas del mle es necesario encontrar esperanzas de las segundas derivadas. Dado que la variable aleatoria \\(X\\) sigue una distribución lognormal con parámetros \\(\\mu\\) y \\(\\sigma\\), entonces \\(\\text{lnX}\\) se distribuye como una normal con media \\(\\mu\\) y varianza \\(\\sigma^{2}\\). \\(\\mathrm{E}\\left( \\frac{\\partial^{2}\\text{lnL}\\left( \\mu,\\sigma \\right)}{\\partial\\mu^{2}} \\right) = \\mathrm{E}\\left( \\frac{- 6}{\\sigma^{2}} \\right) = \\frac{- 6}{\\sigma^{2}}\\), \\(\\mathrm{E}\\left( \\frac{\\partial^{2}\\text{lnL}\\left( \\mu,\\sigma \\right)}{\\partial\\mu\\partial\\sigma} \\right) = \\frac{- 2}{\\sigma^{3}}\\sum_{i = 1}^{6}{\\mathrm{E}\\left( \\ln x_{i} - \\mu \\right)} = \\frac{- 2}{\\sigma^{3}}\\sum_{i = 1}^{6}\\left\\lbrack \\mathrm{E}\\left( \\ln x_{i} \\right) - \\mu \\right\\rbrack\\)=\\(\\frac{- 2}{\\sigma^{3}}\\sum_{i = 1}^{6}\\left( \\mu - \\mu \\right) = 0\\), y \\(\\mathrm{E}\\left( \\frac{\\partial^{2}\\text{lnL}\\left( \\mu,\\sigma \\right)}{\\partial\\sigma^{2}} \\right) = \\frac{6}{\\sigma^{2}} - \\frac{3}{\\sigma^{4}}\\sum_{i = 1}^{6}{\\mathrm{E}\\left( \\ln x_{i} - \\mu \\right)}^{2} = \\frac{6}{\\sigma^{2}} - \\frac{3}{\\sigma^{4}}\\sum_{i = 1}^{6}{\\mathrm{V}\\left( \\ln x_{i} \\right) = \\frac{6}{\\sigma^{2}} - \\frac{3}{\\sigma^{4}}\\sum_{i = 1}^{6}{\\sigma^{2} = \\frac{- 12}{\\sigma^{2}}}}\\). Usando el negativo de estas esperanzas se obtiene la matriz de información de Fisher \\[\\begin{bmatrix} \\frac{6}{\\sigma^{2}} &amp; 0 \\\\ 0 &amp; \\frac{12}{\\sigma^{2}} \\\\ \\end{bmatrix}.\\] La matriz de covarianzas, \\(\\Sigma\\), es la inversa de la matriz de información de Fisher \\[\\Sigma = \\begin{bmatrix} \\frac{\\sigma^{2}}{6} &amp; 0 \\\\ 0 &amp; \\frac{\\sigma^{2}}{12} \\\\ \\end{bmatrix}.\\] La matriz estimada viene dada por \\[\\hat{\\Sigma} = \\begin{bmatrix} 0,8533 &amp; 0 \\\\ 0 &amp; 0,4267 \\\\ \\end{bmatrix}.\\] b. El intervalo de confianza al 95% para \\(\\mu\\) viene dado por \\(9,38 \\pm 1,96\\sqrt{0,8533} = \\left( 7,57,\\ 11,19 \\right)\\). El intervalo de confianza al 95% para \\(\\sigma^{2}\\) viene dado por \\(5,12 \\pm 1,96\\sqrt{0,4267} = \\left( 3,84,\\ 6,40 \\right)\\). c. La media de X es \\(\\exp\\left( \\mu + \\frac{\\sigma^{2}}{2} \\right)\\). Entonces, el estimador máximo verosímil de \\[g\\left( \\mu,\\sigma \\right) = \\exp\\left( \\mu + \\frac{\\sigma^{2}}{2} \\right)\\] es \\[g\\left( \\hat{\\mu},\\hat{\\sigma} \\right) = \\exp\\left( \\hat{\\mu} + \\frac{{\\hat{\\sigma}}^{2}}{2} \\right) = 153.277.\\] Se usa el método delta para aproximar la varianza del mle \\(g\\left( \\hat{\\mu},\\hat{\\sigma} \\right)\\). \\(\\frac{\\partial g\\left( \\mu,\\sigma \\right)}{\\partial\\mu} = exp\\left( \\mu + \\frac{\\sigma^{2}}{2} \\right)\\) y \\(\\frac{\\partial g\\left( \\mu,\\sigma \\right)}{\\partial\\sigma} = \\sigma exp\\left( \\mu + \\frac{\\sigma^{2}}{2} \\right)\\). Usando el método delta, la varianza aproximada de \\(g\\left( \\hat{\\mu},\\hat{\\sigma} \\right)\\) viene dada por \\[\\left. \\ \\hat{V}\\left( g\\left( \\hat{\\mu},\\hat{\\sigma} \\right) \\right) = \\begin{bmatrix} \\frac{\\partial g\\left( \\mu,\\sigma \\right)}{\\partial\\mu} &amp; \\frac{\\partial g\\left( \\mu,\\sigma \\right)}{\\partial\\sigma} \\\\ \\end{bmatrix}\\Sigma\\begin{bmatrix} \\frac{\\partial g\\left( \\mu,\\sigma \\right)}{\\partial\\mu} \\\\ \\frac{\\partial g\\left( \\mu,\\sigma \\right)}{\\partial\\sigma} \\\\ \\end{bmatrix} \\right|_{\\mu = \\hat{\\mu},\\sigma = \\hat{\\sigma}}\\] \\[= \\begin{bmatrix} 153.277 &amp; 346.826 \\\\ \\end{bmatrix}\\begin{bmatrix} 0,8533 &amp; 0 \\\\ 0 &amp; 0,4267 \\\\ \\end{bmatrix}\\begin{bmatrix} 153.277 \\\\ 346.826 \\\\ \\end{bmatrix} =\\]71.374.380.000 El intervalo de confianza al 95% para \\(\\exp\\left( \\mu + \\frac{\\sigma^{2}}{2} \\right)\\) viene dado por \\(153.277 \\pm 1,96\\sqrt{71.374.380.000} = \\left( - 370.356,\\ 676.910 \\right)\\). Dado que la media de la distribución lognormal no puede ser negativa, se debería reemplazar el límite inferior negativo en el intervalo anterior por cero. Ejemplo 3.5.4. Fondo de propiedad de Wisconsin. Para ver cómo los estimadores máximo verosímiles se aplican a datos reales, volvemos a los 2010 datos de siniestros introducidos en la Sección 1.3. El siguiente fragmento de código muestra cómo ajustar un modelo exponencial, gamma, Pareto, lognormal y GB2. Por consistencia, el código emplea el paquete VGAM de R. El acrónimo viene de Vector Generalized Linear and Additive Models; como sugiere el nombre, este paquete puede hacer mucho más que ajustar estos modelos, aunque esto es suficiente para los propósitos requeridos en este caso. La única excepción es la densidad GB2 que no es muy utilizada fuera del mundo asegurador; en cualquier caso, puede programarse esta densidad y calcular los estimadores máximo verosímiles usando el optimizador general optim. Mostrar Solución de Ejemplo library(VGAM) claim_lev &lt;- read.csv(&quot;Data/CLAIMLEVEL.csv&quot;, header = TRUE) claim_data &lt;- subset(claim_lev, Year == 2010); # Inferencia usando una distribución GB2 – más complicado # La función de verosimilitud de una distribución GB2 (negativo para optimización) lik_gb2 &lt;- function (param) { a_1 &lt;- param[1] a_2 &lt;- param[2] mu &lt;- param[3] sigma &lt;- param[4] yt &lt;- (log(claim_data$Claim) - mu) / sigma logexpyt &lt;- ifelse(yt &gt; 23, yt, log(1 + exp(yt))) logdens &lt;- a_1 * yt - log(sigma) - log(beta(a_1,a_2)) - (a_1+a_2) * logexpyt - log(claim_data$Claim) return(-sum(logdens)) } # &quot;optim&quot; es una función general utilizada con propósito de minimizar gb2_bop &lt;- optim(c(1, 1, 0, 1), lik_gb2, method = c(&quot;L-BFGS-B&quot;), lower = c(0.01, 0.01, -500, 0.01), upper = c(500, 500, 500, 500), hessian = TRUE) # Gráfico no paramétrico plot(density(log(claim_data$Claim)), main = &quot;&quot;, xlab = &quot;Gastos logarítmicos&quot;, ylim = c(0 ,0.37)) x &lt;- seq(0, 15, by = 0.01) #Exponencial fit.exp &lt;- vglm(Claim ~ 1, exponential, data = claim_data) theta = 1 / exp(coef(fit.exp)) fexp_ex &lt;- dgamma(exp(x), scale = exp(-coef(fit.exp)), shape = 1) * exp(x) lines(x, fexp_ex, col = &quot;red&quot;, lty =2) # Inferencia asumiendo una distribución gamma fit.gamma &lt;- vglm(Claim ~ 1, family = gamma2, data = claim_data) theta &lt;- exp(coef(fit.gamma)[1]) / exp(coef(fit.gamma)[2]) # theta = mu / alpha alpha &lt;- exp(coef(fit.gamma)[2]) fgamma_ex &lt;- dgamma(exp(x), shape = alpha, scale = theta) * exp(x) lines(x, fgamma_ex, col = &quot;blue&quot;, lty =3) #Pareto fit.pareto &lt;- vglm(Claim ~ 1, paretoII, loc = 0, data = claim_data) fpareto_ex &lt;- dparetoII(exp(x), loc = 0, shape = exp(coef(fit.pareto)[2]), scale = exp(coef(fit.pareto)[1])) * exp(x) lines(x, fpareto_ex, col = &quot;purple&quot;) # Lognormal fit.LN &lt;- vglm(Claim ~ 1, family = lognormal, data = claim_data) flnorm_ex &lt;- dlnorm(exp(x), mean = coef(fit.LN)[1], sd = exp(coef(fit.LN)[2])) * exp(x) lines(x, flnorm_ex, col = &quot;lightblue&quot;) # Densidad para GB II gb2_density &lt;- function (x) { a_1 &lt;- gb2_bop$par[1] a_2 &lt;- gb2_bop$par[2] mu &lt;- gb2_bop$par[3] sigma &lt;- gb2_bop$par[4] xt &lt;- (log(x) - mu) / sigma logexpxt &lt;- ifelse (xt &gt; 23, yt, log(1 + exp(xt))) logdens &lt;- a_1 * xt - log(sigma) - log(beta(a_1, a_2)) - (a_1+a_2) * logexpxt -log(x) exp(logdens) } fGB2_ex = gb2_density(exp(x)) * exp(x) lines(x, fGB2_ex, col=&quot;green&quot;) legend(&quot;topleft&quot;, c(&quot;log(Gastos)&quot;, &quot;Exponencial&quot;, &quot;Gamma&quot;, &quot;Pareto&quot;, &quot;Lognormal&quot;, &quot;GB2&quot;), cex=0.8, lty = c(4,2,3,1,1,1), #4 is &quot;longdash&quot; col = c(&quot;black&quot;,&quot;red&quot;,&quot;blue&quot;,&quot;purple&quot;,&quot;lightblue&quot;,&quot;green&quot;)) Figure 3.5: Comparaciones de densidad para el fondo de propiedad de Wisconsin Los resultados del ejercicio de ajuste se resumen en la Figura 3.5. Aquí, la curva negra de rayas largas es un histograma suavizado para los datos reales (que introduciremos en la Sección 4.1); las otras curvas son curvas paramétricas donde los parámetros se calculan vía máxima verosimilitud. Se aprecia un pobre ajuste en la línia de rayas rojas correspondiente al ajuste de la distribución exponencial y la línea de puntos azules correspondiente al ajuste de la distribución gamma. Los ajustes de las otras curvas, Pareto, lognormal y GB2, parecen proporcionar un ajuste razonablemente bueno a los datos reales. En el Capítulo 4 se describe en más detalle los principios para la selección de modelos. 3.5.2 Estimadores por máxima verosimilitud usando datos modificados En muchas aplicaciones, los actuarios y otros analistas desean estimar modelos paramétricos basados en datos individuales que no están limitados. En cualquier caso, hay también importantes aplicaciones en las que solo hay datos disponibles que están limitados o modificados. Esta sección introduce la estimación máximo verosímil para datos agrupados, censurados y truncados. Más adelante, se continuará con detalles adicionales en la Sección 4.3. 3.5.2.1 Estimadores por máxima verosimilitud para datos agrupados En la sección anterior se consideró la estimación máximo verosímil de modelos continuos a partir de datos (individuales) completos. Cada observación individual es guardada, y su contribución a la función de verosimilitud es la densidad en ese valor. En esta sección se considera el problema de obtener estimaciones máximo verosímiles de los parámetros a partir de datos agrupados. Las observaciones están solo disponibles en forma agrupada, y la contribución de cada observación a la función de verosimilitud es la probabilidad de caer en un grupo específico (intérvalo). Sea \\(n_{j}\\) el número de observaciones en el intervalo \\(\\left( \\left. \\ c_{j - 1},c_{j} \\right\\rbrack \\right.\\ \\) La función de verosimilitud para datos agrupados viene dada por \\[ L\\left( \\theta \\right) = \\prod_{j = 1}^{k}\\left\\lbrack F_X\\left( \\left. \\ c_{j} \\right|\\theta \\right) - F_X\\left( \\left. \\ c_{j - 1} \\right|\\theta \\right) \\right\\rbrack^{n_{j}}, \\] donde \\(c_{0}\\) es la observación más pequeña posible (a menudo establecida como cero) y \\(c_{k}\\) es la observación más grande posible (a menudo establecida como infinito). Ejemplo 3.5.5. Pregunta del examen actuarial. Para un grupo de pólizas, se sabe que las pérdidas siguen la función de distribución \\(F_X\\left( x \\right) = 1 - \\frac{\\theta}{x}\\), para \\(\\theta &lt; x &lt; \\infty.\\) Además, una muestra de 20 pérdidas toma los valores: \\[ {\\small \\begin{matrix}\\hline \\text{Intervalo} &amp; \\text{Número de pérdidas} \\\\ \\hline (\\theta, 10] &amp; 9 \\\\ (10, 25] &amp; 6 \\\\ (25, \\infty) &amp; 5 \\\\ \\hline \\end{matrix} } \\] Calcula la estimación máximo verosímil de \\(\\theta\\). Mostrar Solución de Ejemplo Solución. La contribución de cada una de las 9 observaciones en el primer intervalo a la función de verosimilitud es la probabilidad de que \\(X \\leq 10\\); es decir, \\(\\Pr\\left( X \\leq 10 \\right) = F_X\\left( 10 \\right)\\). De manera similar, las contribuciones de cada una de las 6 y 5 observationes en los intervalos segundo y tercero son \\(\\Pr\\left( 10 &lt; X \\leq 25 \\right) = F_X\\left( 25 \\right) - F_X(10)\\) y \\(P\\left( X &gt; 25 \\right) = 1 - F_X(25)\\), respectivamente. La función de verosimilitud viene dada por \\[ L\\left( \\theta \\right) = \\left\\lbrack F_X\\left( 10 \\right) \\right\\rbrack^{9}\\left\\lbrack F_X\\left( 25 \\right) - F_X(10) \\right\\rbrack^{6}\\left\\lbrack 1 - F_X(25) \\right\\rbrack^{5} \\] \\[ = {\\left( 1 - \\frac{\\theta}{10} \\right)}^{9}\\left( \\frac{\\theta}{10} - \\frac{\\theta}{25} \\right)^{6}\\left( \\frac{\\theta}{25} \\right)^{5} \\] \\[ = {\\left( \\frac{10 - \\theta}{10} \\right)}^{9}\\left( \\frac{15\\theta}{250} \\right)^{6}\\left( \\frac{\\theta}{25} \\right)^{5}. \\] Entonces, \\(\\ln L \\left( \\theta \\right) = 9\\ln \\left( 10 - \\theta \\right) + 6\\ln \\theta + 5\\ln \\theta - 9\\ln 10 + 6\\ln 15 - 6\\ln 250 - 5\\ln 25\\). \\[ \\frac{d \\ln L \\left( \\theta \\right)}{d \\theta} = \\frac{- 9}{\\left( 10 - \\theta \\right)} + \\frac{6}{\\theta} + \\frac{5}{\\theta}. \\] El estimador máximo verosímil, \\(\\hat{\\theta}\\), es la solución de la ecuación \\[ \\frac{- 9}{\\left( 10 - \\hat{\\theta} \\right)} + \\frac{11}{\\hat{\\theta}} = 0 \\] y \\(\\hat{\\theta} = 5,5\\). 3.5.2.2 Estimadores por máxima verosimilitud para datos censurados Otra posible característica distintiva de un mecanismo de recopilación de datos es la censura. Mientras que para algunos eventos de interés (pérdidas, siniestros, tiempos de vida, etc.) los datos completos pueden estar disponibles, para otros solo está disponible información parcial; todo lo que se sabe es que la observación excede un valor específico. La póliza limitada introducida en la Sección 3.4.2 es un ejemplo de censura por la derecha. Cualquier pérdida mayor o igual al límite de la póliza se iguala al límite. La contribución de la observación censurada a la función de verosimilitud es la probabilidad de que la variable aleatoria exceda el límite especificado. Nótese que las contribuciones tanto de las observaciones completas como censuradas comparten la función de supervivencia, para una observación completa esta función de supervivencia se multiplica por la función de riesgo, pero para una obseración censurada no. La función de verosimilitud para observaciones censuradas viene dada por \\[ L(\\theta) = \\left[ \\prod_{i=1}^r f_X(x_i) \\right] \\left[ S_X(u) \\right]^m , \\] donde \\(r\\) es el número de cuantías de pérdidas conocidas que están por debajo del límite \\(u\\) y \\(m\\) es el número de cuantías de pérdidas mayores que el límite \\(u\\). Ejemplo 3.5.6. Pregunta del examen actuarial. La variable aleatoria \\(X\\) tiene función de supervivencia: \\[ S_{X}\\left( x \\right) = \\frac{\\theta^{4}}{\\left( \\theta^{2} + x^{2} \\right)^{2}}. \\] Sean 2 y 4 dos valores observados de \\(X\\). Además, otro valor excede 4. Calcula el estimador máximo verosímil de \\(\\theta\\). Mostrar Solución de Ejemplo Solución. Las contribuciones de las dos observaciones 2 y 4 son \\(f_{X}\\left( 2 \\right)\\) y \\(f_{X}\\left( 4 \\right)\\) respectivamente. La contribución de la tercera observación, de la cual solo se sabe que excede 4 es \\(S_{X}\\left( 4 \\right)\\). La función de verosimilitud viene por tanto dada por \\[ L\\left( \\theta \\right) = f_{X}\\left( 2 \\right)f_{X}\\left( 4 \\right)S_{X}\\left( 4 \\right). \\] La función de densidad de probabilidad de \\(X\\) viene dada por \\[ f_{X}\\left( x \\right) = \\frac{4x\\theta^{4}}{\\left( \\theta^{2} + x^{2} \\right)^{3}}. \\] Por tanto, \\[ L\\left( \\theta \\right) = \\frac{8\\theta^{4}}{\\left( \\theta^{2} + 4 \\right)^{3}}\\frac{16\\theta^{4}}{\\left( \\theta^{2} + 16 \\right)^{3}}\\frac{\\theta^{4}}{\\left( \\theta^{2} + 16 \\right)^{2}} \\\\ = \\frac{128\\theta^{12}}{\\left( \\theta^{2} + 4 \\right)^{3}\\left( \\theta^{2} + 16 \\right)^{5}}, \\] Entonces, \\[ \\ln L\\left( \\theta \\right) = \\ln 128 + 12\\ln \\theta - 3\\ln \\left( \\theta^{2} + 4 \\right) - 5\\ln \\left( \\theta^{2} + 16 \\right) , \\] y \\(\\frac{d \\ln L\\left( \\theta \\right)}{d \\theta} = \\frac{12}{\\theta} - \\frac{6\\theta}{\\left( \\theta^{2} + 4 \\right)} - \\frac{10\\theta}{\\left( \\theta^{2} + 16 \\right)}\\). El estimador máximo verosímil, \\(\\hat{\\theta}\\), es la solución a la ecuación \\[ \\frac{12}{\\hat{\\theta}} - \\frac{6\\hat{\\theta}}{\\left( {\\hat{\\theta}}^{2} + 4 \\right)} - \\frac{10\\hat{\\theta}}{\\left( {\\hat{\\theta}}^{2} + 16 \\right)} = 0 \\] o \\[12\\left( {\\hat{\\theta}}^{2} + 4 \\right)\\left( {\\hat{\\theta}}^{2} + 16 \\right) - 6{\\hat{\\theta}}^{2}\\left( {\\hat{\\theta}}^{2} + 16 \\right) - 10{\\hat{\\theta}}^{2}\\left( {\\hat{\\theta}}^{2} + 4 \\right) = \\\\ - 4{\\hat{\\theta}}^{4} + 104{\\hat{\\theta}}^{2} + 768 = 0,\\] que permite obtener \\({\\hat{\\theta}}^{2} = 32\\) y \\(\\hat{\\theta} = 5,7\\). 3.5.2.3 Estimadores por máxima verosimilitud para datos truncados Esta sección se centra en la estimación máximo verosímil de la distribución continua de una variable aleatoria \\(X\\) cuando los datos estan incompletos debido a la existencia de truncamiento. Si los valores de \\(X\\) están truncados en \\(d\\), debe tenerse en cuenta que podria pasar desapercibida la existencia de estos valores si no superasen \\(d\\). La franquícia introducida en la póliza en la Sección 3.4.1 es un ejemplo de truncamiento por la izquierda. Cualquier pérdida menor o igual a la franquícia no se registra. La contribución a la función de verosimilitud de una observación \\(x\\) truncada en \\(d\\) será una probabilidad condicionada y \\(f_{X}\\left( x \\right)\\) será reemplazado por \\(\\frac{f_{X}\\left( x \\right)}{S_{X}\\left( d \\right)}\\). La función de verosimilitud para datos truncados viene dada por \\[ L(\\theta) = \\prod_{i=1}^k \\frac{f_X(x_i)}{S_X(d)} , \\] donde \\(k\\) es el número de cuantías de pérdidas mayores que la franquicia \\(d\\). Ejemplo 3.5.7. Pregunta del examen actuarial. Para una distribución de Pareto de un solo parámetro con \\(\\theta = 2\\), se aplica la estimación máximo verosímil para estimar el parámetro \\(\\alpha\\). Determina la media estimada de la distribución ground up loss en base a la estimación máximo verosímil de \\(\\alpha\\) para la siguiente base de datos: Franquicia ordinaria en la póliza de 5, máxima pérdida cubierta de 25 (límite de la póliza 20) 8 cuantías de seguro pagadas: 2, 4, 5, 5, 8, 10, 12, 15 2 límites de pago: 20, 20. Mostrar Solución de Ejemplo Solución. Las contribuciones de las diferentes observaciones pueden ser resumidas a continuación: Para la pérdida exacta: \\(f_{X}\\left( x \\right)\\) Para las observaciones censuradas: \\(S_{X}\\left( 25 \\right)\\). Para las observaciones truncadas: \\(\\frac{f_{X}\\left( x \\right)}{S_{X}\\left( 5 \\right)}\\). Dado que las ground up losses menores de 5 se omiten del conjunto de datos, la contribución de todas las observaciones debe estar condicionada a exceder 5. La función de verosimilitud resulta ser \\[ L\\left( \\alpha \\right) = \\frac{\\prod_{i = 1}^{8}{f_{X}\\left( x_{i} \\right)}}{\\left\\lbrack S_{X}\\left( 5 \\right) \\right\\rbrack^{8}}\\left\\lbrack \\frac{S_{X}\\left( 25 \\right)}{S_{X}\\left( 5 \\right)} \\right\\rbrack^{2}. \\] Para la Pareto de un parámetro las funciones densidad de probabilidad y distribución vienen dadas por \\[ f_{X}\\left( x \\right) = \\frac{\\alpha\\theta^{\\alpha}}{x^{\\alpha + 1}} \\ \\ \\text{and} \\ \\ F_{X}\\left( x \\right) = 1 - \\left( \\frac{\\theta}{x} \\right)^{\\alpha}, \\] para \\(x &gt; \\theta\\), respectivamente. Entonces, la función de verosimilitud y el logaritmo de la función de verosimilitud vienen dadas por \\[ L\\left( \\alpha \\right) = \\frac{\\alpha^{8}}{\\prod_{i = 1}^{8}x_{i}^{\\alpha + 1}}\\frac{5^{10\\alpha}}{25^{2\\alpha}}, \\] \\[ \\ln L \\left( \\alpha \\right) = 8\\ln\\alpha - \\left( \\alpha + 1 \\right)\\sum_{i = 1}^{8}{\\ln x_{i}} + 10\\alpha \\ln 5 - 2\\alpha \\ln 25. \\] \\(\\frac{d \\ln L \\left( \\alpha \\right)}{d \\theta} = \\frac{8}{\\alpha} - \\sum_{i = 1}^{8}{\\ln x_{i}} + 10\\ln 5 - 2\\ln 25\\). El estimador máximo verosímil, \\(\\hat{\\alpha}\\), es la solución de la ecuación \\[ \\frac{8}{\\hat{\\alpha}} - \\sum_{i = 1}^{8}{\\ln x_{i}} + 10\\ln 5 - 2\\ln 25 = 0, \\] que resulta en \\[ \\hat{\\alpha} = \\frac{8}{\\sum_{i = 1}^{8}{\\ln x_{i}} - 10\\ln 5 + 2\\ln 25} = \\frac{8}{(\\ln 7 + \\ln 9 + \\cdots + \\ln 20) - 10\\ln 5 + 2\\ln 25} = 0,785. \\] La media de la Pareto solo existe para \\(\\alpha &gt; 1\\). Dado que \\(\\hat{\\alpha} = 0,785 &lt; 1\\). Entonces, la media no existe. 3.6 Recursos y contribuciones adicionales ####Colaboradores {-} Zeinab Amin, The American University in Cairo, es el principal autor de este capítulo. Email: zeinabha@aucegypt.edu para comentarios sobre el capítulo y sugerencias de mejora. Numerosos comentarios de gran utilidad han sido proporcionados por Hirokazu (Iwahiro) Iwasawa, iwahiro@bb.mbn.or.jp . Otros revisores del capítulo son: Rob Erhardt, Jorge Yslas, Tatjana Miljkovic, y Samuel Kolins. Traducción al español: Ana Maria Pérez-Marín (Universitat de Barcelona) Ejercicios Se proporciona una lista de ejercicios que sirven de guía al lector sobre algunos de los fundamentos teóricos de ** Loss Data Analytics **. Cada tutorial se basa en una o más preguntas de los examenes para la profesión actuarial – típicamente el Examen C de la Sociedad de Actuarios. Severity Distribution Guided Tutorials Lecturas y referencias adicionales Notables contribuciones incluyen a: Cummins and Derrig (2012), Frees and Valdez (2008), Klugman, Panjer, and Willmot (2012), Kreer et al. (2015), McDonald (1984), McDonald and Xu (1995), Tevet (2016), and Venter (1983). Bibliography "],
["C-ModelSelection.html", "Chapter 4 Selección del modelo y estimación 4.1 Inferencia No Paramétrica 4.2 Selección del Modelo 4.3 Estimación utilizando Datos Modificados 4.4 Inferencia Bayesiana 4.5 Más Recursos y Colaboradores", " Chapter 4 Selección del modelo y estimación Vista Previa del Capítulo. En los Capítulos 2 y 3 se han descrito cómo ajustar los modelos paramétricos a datos que miden, respectivamente, la frecuencia y la severidad de los eventos analizados. Este capítulo se centra en la selección de los modelos. Inicialmente, para comparar modelos paramétricos alternativos, es útil describir los datos sin referencia a una distribución paramétrica específica. La Sección 4.1 describe en que consiste la estimación no paramétrica, cómo podemos usarla para comparar modelos paramétricos alternativos y cómo, a partir de la misma, pueden obtenerse valores iniciales que permitan implementar procedimientos paramétricos. El proceso de selección del modelo se resume en la Sección 4.2. Aunque la descripción se centra en el análisis de datos continuos, el mismo procedimiento puede usarse para datos discretos o datos que provienen de una combinación híbrida de datos discretos y continuos. La selección y la estimación del modelo son aspectos fundamentales de la modelización estadística. Para proporcionar una idea de cómo se pueden adaptar a esquemas de muestreo alternativos, la Sección 4.3 describe la estimación con datos agrupados, censurados y truncados (siguiendo la introducción de la Sección 3.5). Para ver cómo los procedimientos de selección y estimación se pueden adaptar a modelos alternativos, el capítulo se cierra con la Sección 4.4 sobre inferencia bayesiana, un procedimiento alternativo donde los parámetros (típicamente desconocidos) se tratan como variables aleatorias. 4.1 Inferencia No Paramétrica En esta sección se aprende a: Estimación de momentos, cuantiles y distribuciones sin referencia a una distribución paramétrica. Resumir los datos gráficamente sin referencia a una distribución paramétrica Determinar medidas que resuman las desviaciones de un ajuste paramétrico de un ajuste no paramétrico Use estimadores no paramétricos para aproximar los parámetros que se pueden usar para iniciar un procedimiento de estimación paramétrica 4.1.1 Estimación No Paramétrica En la Sección 2.2 para la frecuencia y en la Sección 3.1 para la severidad, aprendimos cómo describir una distribución mediante el cálculo de las medias, las varianzas, los cuantiles/percentiles, etc.. Para aproximar estas medidas de resumen utilizando un conjunto de datos, una estrategia es: asumir una forma paramétrica para una distribución, como una binomial negativa para la frecuencia o una distribución gamma para la severidad, estimar los parámetros de esa distribución, y luego usar la distribución con los parámetros estimados para calcular la medida de resumen deseada. Ésta es la aproximación paramétrica. Otra estrategia es estimar la medida de resumen deseada directamente a partir de las observaciones sin referencia a un modelo paramétrico. No es sorprendente que esto se conozca como aproximación no paramétrica Una forma de inferencia que no se basa en una modelo paramétrico. Comencemos por considerar el tipo más básico de esquema de muestreo y supongamos que las observaciones son realizaciones de un conjunto de variables aleatorias \\(X_1, \\ldots, X_n\\) que son iid independientes e idénticamente distribuidas generadas por una distribución poblacional desconocida \\(F(\\cdot)\\). Un modo equivalente de explicarlo es que \\(X_1, \\ldots, X_n\\), es una muestra aleatoria (con remplazamiento) de \\(F(\\cdot)\\). Para mostrar cómo funciona todo esto, a continuación se describen los estimadores no paramétricos de muchas medidas importantes que resumen una distribución. 4.1.1.1 Estimadores de Momentos En la Sección 2.2.2 aprendimos como definir momentos para la frecuencia y en la Sección 3.1.1 para la severidad. En particular, el \\(k\\)-ésimo momento, \\(\\mathrm{E~}[X^k] = \\mu^{\\prime}_k\\), resume muchos aspectos de la distribución para distintos valores de k. Aquí, \\(\\mu^{\\prime}_k\\) es comúnmente denominado el k-ésimo momento poblacional, para distinguirlo del k-ésimo momento muestral, \\[ \\frac{1}{n} \\sum_{i=1}^n X_i^k, \\] que es el estimador no paramétrico correspondiente. En las aplicaciones, \\(k\\) es normalmente un número entero positivo, aunque no es necesario que lo sea. Un caso particular importante es el primer momento donde k=1. En este caso, el símbolo principal (\\(\\prime\\)) y el subíndice \\(1\\) generalmente se eliminan y se usa \\(\\mu=\\mu^{\\prime}_1\\) para denotar la media de la población o, simplemente, la media. El estimador en la muestra correspondiente para \\(\\mu\\) se llama media muestral, denotada con una barra en la parte superior de la variable aleatoria: \\[ \\bar{X} =\\frac{1}{n} \\sum_{i=1}^n X_i. \\] Otro tipo de medida a modo de resumen que es de interés es el \\(k\\)-ésimo momento central, \\(\\mathrm{E~} [(X-\\mu)^k] = \\mu_k\\). Comúnmente, \\(\\mu^{\\prime}_k\\) se llama el \\(k\\)-ésimo momento ordinario para distinguirlo del momento central \\(\\mu_k\\). Un estimador no paramétrico, o muestral, de \\(\\mu_k\\) es \\[ \\frac{1}{n} \\sum_{i=1}^n \\left(X_i - \\bar{X}\\right)^k . \\] El segundo momento central (\\(k=2\\)) es un caso importante para el que generalmente asignamos un nuevo símbolo, \\(\\sigma^2=\\mathrm{E~} [(X-\\mu)^2]\\), conocido como la varianza. Las propiedades del estimador de momentos muestral de la varianza, \\(n^{-1}\\sum_{i=1}^n\\left (X_i-\\bar{X}\\right)^2\\), se han estudiado ampliamente y por lo tanto es natural que se hayan propuesto muchas variaciones. La variación más utilizada es aquella en la que el tamaño real de la muestra se reduce en uno, por lo que definimos \\[ s^2 = \\frac{1}{n-1} \\sum_{i=1}^n \\left(X_i - \\bar{X}\\right)^2. \\] Aquí, el estadístico \\(s^2\\) se conoce como varianza muestral. Dividir por n-1 en lugar de por n importa poco cuando se dispone de un tamaño de muestra n en miles, como es frecuente en las aplicaciones en seguros. De este modo, el estimador resultante es insesgado, en el sentido de que \\(\\mathrm{E ~} s^2=\\sigma^2\\), una propiedad deseable particularmente cuando se interpretan los resultados de un análisis. 4.1.1.2 Función de Distribución Empírica Hemos visto como calcular los estimadores no paramétricos del momento k-ésimo \\(\\mathrm{E ~} X^k\\). Del mismo modo, para cualquier función conocida \\(\\mathrm{g}(\\cdot)\\), podemos estimar \\(\\mathrm {E ~}\\mathrm{g}(X)\\) usando \\(n^{-1}\\sum_{i=1}^n\\mathrm{g}(X_i)\\). Ahora supongamos que fijamos un valor de x y consideramos la función \\(\\mathrm{g}(X)=I(X \\le x)\\). Aquí, la notación \\(I(\\cdot)\\) es la función del indicador; devuelve 1 si el evento \\((\\cdot)\\) es verdadero y 0 en caso contrario. Para esta elección de \\(\\mathrm{g}(\\cdot)\\), el valor esperado es \\(\\mathrm{E ~}I(X \\le x)=\\Pr(X \\le x)=F(x)\\), la función de distribución evaluada en un punto fijo x. Usando el principio analógico, definimos el estimador no paramétrico de la función de distribución \\[ \\begin{aligned} F_n(x) &amp;= \\frac{1}{n} \\sum_{i=1}^n I\\left(X_i \\le x\\right) \\\\ &amp;= \\frac{\\text{número de observaciones menores o iguales a } x}{n}. \\end{aligned} \\] Como el estimador no paramétrico \\(F_n(\\cdot)\\) se basa solo en observaciones y no asume una familia paramétrica para la distribución, también se conoce como función de distribución empírica. Ejemplo 4.1.1. Conjunto de Datos Ficticios. Como ilustración, considere un conjunto de datos ficticio o “Toy Dataset” de \\(n=10\\) observaciones. Determinar la función de distribución empírica. \\[ {\\small \\begin{array}{c|cccccccccc} \\hline i &amp;1&amp;2&amp;3&amp;4&amp;5&amp;6&amp;7&amp;8&amp;9&amp;10 \\\\ X_i&amp; 10 &amp;15 &amp;15 &amp;15 &amp;20 &amp;23 &amp;23 &amp;23 &amp;23 &amp;30\\\\ \\hline \\end{array} } \\] Mostrar la Solución del Ejemplo Debe verificar que la media de la muestra es \\(\\bar{X}=19,7\\) y que la varianza de la muestra es \\(s^2=34,45556\\). La función de distribución empírica correspondiente es \\[ \\begin{aligned} F_n(x) &amp;= \\left\\{ \\begin{array}{ll} 0 &amp; \\text{ for }\\ x&lt;10 \\\\ 0,1 &amp; \\text{ for }\\ 10 \\leq x&lt;15 \\\\ 0,4 &amp; \\text{ for }\\ 15 \\leq x&lt;20 \\\\ 0,5 &amp; \\text{ for }\\ 20 \\leq x&lt;23 \\\\ 0,9 &amp; \\text{ for }\\ 23 \\leq x&lt;30 \\\\ 1 &amp; \\text{ for }\\ x \\geq 30, \\end{array} \\right.\\end{aligned} \\] que se muestra en el siguiente gráfico en la Figura 4.1. Figure 4.1: Función de Distribución Empírica de un Ejemplo con Datos Ficticios Mostrar código R (xExample &lt;- c(10,rep(15,3),20,rep(23,4),30)) PercentilesxExample &lt;- ecdf(xExample) plot(PercentilesxExample, main=&quot;&quot;,xlab=&quot;x&quot;) 4.1.1.3 Cuartiles, Percentiles y Cuantiles Anteriormente ya hemos visto la mediana, que es el número tal que aproximadamente la mitad de un conjunto de datos está por debajo (o por encima). El primer cuartil es el número tal que aproximadamente el 25% de los datos está debajo de él y el tercer cuartil es el número tal que aproximadamente el 75% de los datos está debajo de él. Un \\(100p\\) percentil es el número tal que \\(100\\times p\\) por ciento de los datos están debajo de él. Para generalizar este concepto, se considera una función de distribución \\(F(\\cdot)\\), que puede o no ser continua, y sea \\(q\\) una fracción para la cual \\(0&lt;q&lt;1\\). Queremos definir un cuantil, digamos \\(q_F\\), para que sea un número tal que \\(F(q_F) \\approx q\\). Observe que cuando \\(q=0,5\\), \\(q_F\\) es la mediana; cuando \\(q=0,25\\), \\(q_F\\) es el primer cuartil, y así sucesivamente. Por lo tanto, un cuantil generaliza los conceptos de mediana, cuartiles y percentiles. Para ser precisos, para un determinado valor de \\(0&lt;q&lt;1\\), se define el \\(q\\)-ésimo cuantil \\(q_F\\) como cualquier número que satisfaga \\[\\begin{equation} F(q_F-) \\le q \\le F(q_F) \\tag{4.1} \\end{equation}\\] Aquí, la notación \\(F(x-)\\) significa evaluar la función \\(F(\\cdot)\\) como el límite por la izquierda. Para comprender mejor esta definición, veamos algunos casos especiales. Primero, considere el caso en el que \\(X\\) es una variable aleatoria continua para que la función de distribución \\(F(\\cdot)\\) no tenga puntos de salto, como se ilustra en la Figura 4.2. En esta figura, se muestran algunas fracciones, \\(q_1\\), \\(q_2\\) y \\(q_3\\) con sus cuantiles correspondientes \\(q_{F,1}\\), \\(q_{F,2}\\) y \\(q_{F,3}\\). En cada caso se puede ver que \\(F(q_F-)=F(q_F)\\), de modo que hay un cuantil único. Al igual que podemos encontrar una inversa de la función de distribución única para cualquier \\(0&lt;q&lt;1\\), podemos escribir \\(q_F=F^{-1}(q)\\). Figure 4.2: Caso de Cuantil Continuo La figura 4.3 muestra tres casos de funciones de distribución. El panel izquierdo corresponde al caso continuo recién discutido. El panel central muestra un punto de salto similar a los que ya vimos en la función de distribución empírica de la Figura 4.1. Para el valor de \\(q\\) que se muestra en este panel, todavía tenemos un valor único del cuantil \\(q_F\\). Aunque hay muchos valores de \\(q\\) tales que \\(F(q_F-) \\le q \\le F(q_F)\\), para un valor particular de \\(q\\), solo hay una solución para la ecuación (4.1). El panel de la derecha muestra una situación en la que el cuantil no puede determinarse de manera única para el \\(q\\) que se muestra, ya que hay un rango de \\(q_F\\) que satisfacen la ecuación (4.1). Figure 4.3: Tres Casos de Cuantiles Ejemplo 4.1.2. Conjunto de Datos Ficticios: Continuación. Se determinan los cuantiles correspondientes a los percentiles 20, 50 y 95. Mostrar la solución del Ejemplo Solución. Se considera la Figura 4.1. El caso de \\(q=0,20\\) corresponde al panel central, por lo que el percentil 20 es 15. El caso de \\(q=0,50\\) corresponde al panel derecho, por lo que la mediana es cualquier número entre 20 y 23, ambos inclusive. Muchos paquetes de software usan el promedio de 21,5 (por ejemplo, R, como se ve a continuación). Para el percentil 95, la solución es 30. Podemos ver en el gráfico que 30 también corresponde a los percentiles 99 y 99,99. quantile(xExample, probs=c(0.2, 0.5, 0.95), type=6) ## 20% 50% 95% ## 15.0 21.5 30.0 Al tomar un promedio ponderado entre las observaciones de datos, los cuantiles empíricos suavizados pueden asemejarse a los casos como el panel derecho en la Figura 4.3. El \\(q\\)-ésimo cuartil empírico suavizado se define como \\[ \\hat{\\pi}_q = (1-h) X_{(j)} + h X_{(j+1)} \\] donde \\(j=\\lfloor(n+1)q\\rfloor\\), \\(h=(n+1)q-j\\), y \\(X_{(1)}, \\ldots, X_{(n)}\\) son los valores ordenados (conocidos como los estadísticos de orden) correspondientes a \\(X_1, \\ldots, X_n\\). Cabe señalar que \\(\\hat{\\pi}_q\\) es simplemente una interpolación lineal entre \\(X_{(j)}\\) y \\(X_{(j+1)}\\). Ejemplo 4.1.3. Conjunto de Datos Ficticios: Continuación. Se determinan los percentiles 50-ésimo y 20-ésimo alisados. Mostrar la solución del Ejemplo Solución Se toma \\(n=10\\) y \\(q=0,5\\). De modo que, \\(j=\\lfloor(11)0,5 \\rfloor= \\lfloor 5,5 \\rfloor=5\\) y \\(h=(11)(0,5)-5=0,5\\). Por tanto, el 50-ésimo cuantil empírico alisado es \\[\\hat{\\pi}_{0,5} = (1-0,5) X_{(5)} + (0,5) X_{(6)} = 0,5 (20) + (0,5)(23) = 21,5.\\] Ahora se toma \\(n=10\\) y \\(q=0,2\\). En este caso, \\(j=\\lfloor(11)0,2\\rfloor=\\lfloor 2,2 \\rfloor=2\\) y \\(h=(11)(0,2)-2=0,2\\). Entonces, el 20-ésimo cuantil empírico alisado es \\[\\hat{\\pi}_{0,2} = (1-0,2) X_{(2)} + (0,2) X_{(3)} = 0,2 (15) + (0,8)(15) = 15.\\] 4.1.1.4 Estimadores de la Densidad Variable Discreta. Cuando la variable aleatoria es discreta, estimar la función de masa de probabilidad \\(f(x)=\\Pr(X = x)\\) es sencillo. Simplemente usamos el promedio del indicador \\(I(X_i = x)\\) en la muestra, definido como \\[f_n(x) = \\frac{1}{n} \\sum_{i=1}^n I(X_i = x).\\] Variable Continua Dentro de un Grupo. Para una variable aleatoria continua, se considera una formulación discretizada en la que el dominio de \\(F(\\cdot)\\) está dividido por las constantes \\(\\{c_0 &lt;c_1 &lt;\\cdots &lt;c_k\\}\\) en intervalos de la forma \\([c_{j-1}, c_j)\\), por \\(j = 1, \\ldots, k\\). Los datos observados se “agrupan” en función del intervalo en el que caen. Entonces, podríamos usar la definición básica de la función de masa de probabilidad empírica, o una variación como \\[f_n(x) = \\frac{n_j}{n \\times (c_j - c_{j-1})} \\ \\ \\ \\ \\ \\ c_{j-1} \\le x &lt; c_j,\\] donde \\(n_j\\) es el número de observaciones (\\(X_i\\)) que caen en el intervalo \\([c_{j-1}, c_j)\\). Variable Continua (no agrupada). Extendiendo esta noción a situaciones en las que observamos datos individuales, se debe tener en cuenta que siempre podemos crear agrupaciones arbitrarias y usar esta fórmula. Más formalmente, dada \\(b&gt;0\\) una constante positiva que toma un valor reducido y se conoce como ancho de banda (bandwidth), se define el estimador de la densidad como \\[\\begin{equation} f_n(x) = \\frac{1}{2nb} \\sum_{i=1}^n I(x-b &lt; X_i \\le x + b) \\tag{4.2} \\end{equation}\\] Mostrar un fragmento de Teoría La idea es que el estimador \\(f_n(x)\\) en la ecuación (4.2) es la media sobre \\(n\\) iid independientes e idénticamente distribuidas realizaciones de una variable aleatoria con media \\[ \\begin{aligned} \\mathrm{E~ } \\frac{1}{2b} I(x-b &lt; X \\le x + b) &amp;= \\frac{1}{2b}\\left(F(x+b)-F(x-b)\\right) \\\\ &amp;= \\frac{1}{2b} \\left( \\left\\{ F(x) + b F^{\\prime}(x) + b^2 C_1\\right\\} \\left\\{ F(x) - b F^{\\prime}(x) + b^2 C_2\\right\\} \\right) \\\\ &amp;= F^{\\prime}(x) + b \\frac{C_1-C_2}{2} \\rightarrow F^{\\prime}(x) = f(x), \\end{aligned} \\] como \\(b \\rightarrow 0\\). Esto es, \\(f_n(x)\\) es un estimador asintóticamente insesgado de \\(f(x)\\) (su esperanza se acerca al valor verdadero a medida que el tamaño de la muestra tiende a infinito). Este desarrollo supone cierta suavización de \\(F(\\cdot)\\), en particular, se deriva dos veces con respecto a \\(x\\), pero no hace suposiciones sobre la forma de la función de distribución \\(F\\). Debido a esto, se dice que el estimador de densidad \\(f_n\\) es no paramétrico. Más generalmente, se define el estimador núcleo (kernel) de la densidad de la función de pdf función de densidad de probabilidad en x como \\[\\begin{equation} f_n(x) = \\frac{1}{nb} \\sum_{i=1}^n w\\left(\\frac{x-X_i}{b}\\right) , \\tag{4.3} \\end{equation}\\] donde \\(w\\) es una función de densidad de probabilidad centrada en 0. Se tiene que tener en cuenta que la ecuación (4.2) simplemente se convierte en el estimador núcleo de la densidad donde \\(w(x) =\\frac{1}{2} I(-1 &lt;x \\le 1)\\), también conocido como núcleo uniforme. Otras opciones comunes para \\(w\\) se muestran en Table 4.1. \\[ {\\small \\begin{matrix} \\text{Table 4.1: Opciones más comunes como Núcleo del Estimador de la Densidad}\\\\ \\begin{array}{l|cc} \\hline \\text{Kernel} &amp; w(x) \\\\ \\hline \\text{Uniforme } &amp; \\frac{1}{2}I(-1 &lt; x \\le 1) \\\\ \\text{Triángulo} &amp; (1-|x|)\\times I(|x| \\le 1) \\\\ \\text{Epanechnikov} &amp; \\frac{3}{4}(1-x^2) \\times I(|x| \\le 1) \\\\ \\text{Gausiana} &amp; \\phi(x) \\\\ \\hline \\end{array}\\end{matrix} } \\] Siendo \\(\\phi(\\cdot)\\) la función de densidad normal estándar. Como veremos en el siguiente ejemplo, la elección del ancho de banda \\(b\\) viene dada por la existencia de un equilibrio entre sesgo-varianza, es decir, entre las coincidencias con las características locales de la distribución y la reducción de la dispersión. Ejemplo 4.1.4. Fondo Inmobiliario. La figura 4.4 muestra un histograma (con rectángulos grises sombreados) de los logaritmo de los costes de los siniestros en propiedades del año 2010. La curva gruesa (azul) representa la densidad estimada con el núcleo gaussiano, donde el ancho de banda se seleccionó automáticamente utilizando una regla ad-hoc basada en el tamaño de la muestra y la dispersión de los datos. Para este conjunto de datos, el ancho de banda resultó ser \\(b = 0,3255\\). A modo comparativo, la curva discontinua (roja) representa el estimador de la densidad con un ancho de banda igual a 0,1 y la curva verde, más suave, utiliza un ancho de banda de 1. Como se anticipó, el ancho de banda más pequeño (0,1) implica realizar promedios locales sobre menos datos para obtener una mejor idea del comportamiento local, pero al precio de una mayor dispersión. En contraste, el mayor ancho de banda (1) suaviza las fluctuaciones locales, produciendo una curva más suave que puede perder perturbaciones reales en el promedio local. Para aplicaciones actuariales, utilizamos principalmente el estimador núcleo de la densidad para obtener una impresión visual rápida de los datos. Desde esta perspectiva, simplemente puede usarse la regla ad-hoc predeterminada para la selección del ancho de banda, sabiendo que se tiene la capacidad de cambiarla dependiendo de la situación en cuestión. Figure 4.4: Histograma de los Logaritmo de los Costes de los Siniestros en Propiedades con Estimador Núcleo de la Densidad Superpuesto Mostrar código R #Comparación de Densidad hist(log(ClaimData$Claim), main=&quot;&quot;, ylim=c(0,.35),xlab=&quot;Log Costes&quot;, freq=FALSE, col=&quot;lightgray&quot;) lines(density(log(ClaimData$Claim)), col=&quot;blue&quot;,lwd=2.5) lines(density(log(ClaimData$Claim), bw=1), col=&quot;green&quot;) lines(density(log(ClaimData$Claim), bw=.1), col=&quot;red&quot;, lty=3) legend(&quot;topright&quot;, c(&quot;b=0.3255 (default)&quot;, &quot;b=0.1&quot;, &quot;b=1.0&quot;), lty=c(1,3,1), lwd=c(2.5,1,1), col=c(&quot;blue&quot;, &quot;red&quot;, &quot;green&quot;), cex=1) Los estimadores no paramétricos de la densidad, como el estimador núcleo, se usan habitualmente en la práctica. Este mismo concepto también se puede ampliar para dar versiones suavizadas de una función de distribución empírica. Dada la definición del estimador núcleo de la densidad, el estimador núcleo de la función de distribución se puede obtener como \\[ \\begin{aligned} \\hat{F}_n(x) = \\frac{1}{n} \\sum_{i=1}^n W\\left(\\frac{x-X_i}{b}\\right).\\end{aligned} \\] donde \\(W\\) es la función de distribución asociada con la densidad del núcleo \\(w\\). Para ilustrarlo, para el núcleo uniforme, tenemos \\(w(y) = \\frac{1}{2}I(-1 &lt; y \\le 1)\\), de modo que \\[ \\begin{aligned} W(y) = \\begin{cases} 0 &amp; y&lt;-1\\\\ \\frac{y+1}{2}&amp; -1 \\le y &lt; 1 \\\\ 1 &amp; y \\ge 1 \\\\ \\end{cases}\\end{aligned} . \\] Ejemplo 4.1.5. Pregunta de Examen Actuarial. Se estudian cinco individuos para estimar el tiempo desde el inicio de una enfermedad hasta la muerte. Los tiempos de muerte son: \\[ \\begin{array}{ccccc} 2 &amp; 3 &amp; 3 &amp; 3 &amp; 7 \\\\ \\end{array}. \\] Usando un núcleo triangular con ancho de banda \\(2\\), calcular la función de densidad estimada en 2,5. Mostrar la solución del Ejemplo Solución. Para la estimación núcleo de la densidad tenemos \\[f_n(x) = \\frac{1}{nb} \\sum_{i=1}^n w\\left(\\frac{x-X_i}{b}\\right),\\] donde \\(n=5\\), \\(b=2\\), y \\(x=2,5\\). Para un kernel triangular, \\(w(x) = (1-|x|)\\times I(|x| \\le 1)\\). Así, \\[ \\begin{array}{c|c|c} \\hline X_i &amp; \\frac{x-X_i}{b} &amp; w\\left(\\frac{x-X_i}{b} \\right) \\\\ \\hline 2 &amp; \\frac{2,5-2}{2}=\\frac{1}{4} &amp; (1-\\frac{1}{4})(1) = \\frac{3}{4} \\\\ \\hline 3 &amp; &amp; \\\\ 3 &amp; \\frac{2,5-3}{2}=\\frac{-1}{4} &amp; \\left(1-\\left| \\frac{-1}{4} \\right| \\right)(1) = \\frac{3}{4} \\\\ 3 &amp; &amp; \\\\ \\hline 7 &amp; \\frac{2,5-7}{2}=-2,25 &amp; (1-|-2,25|)(0) = 0\\\\ \\hline \\end{array} \\] Entonces la estimación núcleo de la densidad es \\[f_n(x) = \\frac{1}{5(2)}\\left( \\frac{3}{4} + (3) \\frac{3}{4} + 0 \\right) = \\frac{3}{10}\\] 4.1.1.5 Principio de Plug-in Una forma de crear un estimador no paramétrico es usar el principio de analogía o plug-in donde se reemplaza la cdf \\(F\\) desconocida por un estimador conocido como la cdf empírica \\(F_n\\). Por tanto, si estamos tratando de estimar \\(\\mathrm{E}~\\mathrm{g}(X)=\\mathrm{E}_F~\\mathrm{g}(X)\\) para una función genérica g, entonces se define un estimador noparamétrico como \\(\\mathrm{E}_{F_n}~\\mathrm{g}(X)=n^{-1}\\sum_{i=1}^n\\mathrm{g}(X_i)\\). Para ver su funcionamiento, como un caso particular de g consideramos la ratio de eliminación de pérdidas presentada en la Sección 3.4.1, \\[LER(d)=\\frac{\\mathrm{E~}(\\min(X,d) )}{\\mathrm{E~}(X)}\\] para un deducible fijo \\(d\\). Ejemplo. 4.1.11. Siniestros con Daños Corporales y Ratio de Eliminación de Pérdidas Utilizamos una muestra de 432 siniestros cerrados de automóvil ocurridos en Boston de Derrig, Ostaszewski, and Rempala (2001). Las pérdidas se registran para los pagos por daños corporales derivados en los accidentes de automóvil. Las pérdidas no están sujetas a deducibles, pero están sujetas a varios límites de póliza, también disponibles en los datos. Se obtiene que sólo 17 de 432 (\\(\\approx\\) 4%) estaban sujetas al límite en la póliza y, por ello, ignoraremos estos datos en esta ilustración. La pérdida promedio pagada es 6906. Figura 4.5 muestra otros aspectos de la distribución. En concreto, el panel izquierdo muestra la función de distribución empírica, el panel derecho proporciona un gráfico de la densidad no paramétrica. Figure 4.5: Siniestros por daños corporales. La figura de la izquierda proporciona la función de distribución empírica. La figura de la derecha presenta un gráfico de la densidad no paramétrica. El impacto de las pérdidas por lesiones corporales se puede mitigar mediante la imposición de límites o la compra de pólizas de reaseguro (consulte la Sección 10.3). Para cuantificar el impacto de estas herramientas de mitigación de riesgos, es común calcular el índice de eliminación de pérdida o loss elimination ratio (LER) como se introdujo en la Sección 3.4.1. La función de distribución no está disponible y se debe estimar de alguna manera. Usando el principio plug-in, un estimador no paramétrico se puede definir como \\[ LER_n(d) = \\frac{n^{-1} \\sum_{i=1}^n \\min(X_i,d)}{n^{-1} \\sum_{i=1}^n X_i} = \\frac{\\sum_{i=1}^n \\min(X_i,d)}{\\sum_{i=1}^n X_i} . \\] La figura 4.5 muestra el estimador \\(LER_n(d)\\) para varias opciones de d. Por ejemplo, si \\(d=14.000\\), resulta que \\(LER_n(14000)\\approx\\) 0.9768. Imponer un límite de 14.000 significa que esperamos retener 97.68 porcentaje de siniestros. Figure 4.6: LER para siniestros por daños corporales. La figura presenta el índice de eliminación de pérdidas (LER) en función del deducible d. 4.1.2 Herramientas para la Selección de Modelos y Diagnósticos En la sección anterior se introdujeron estimadores no paramétricos en los que no se asumía una forma paramétrica sobre las distribuciones subyacentes. Sin embargo, en muchas aplicaciones actuariales, los analistas buscan emplear un ajuste paramétrico de una distribución para facilitar la explicación y la capacidad de extenderla fácilmente a situaciones más complejas, como incluir variables explicativas en un entorno de regresión. Al ajustar una distribución paramétrica, un analista podría intentar usar una distribución gamma para representar un conjunto de datos de pérdida. Sin embargo, otro analista podría preferir usar una distribución de Pareto. ¿Cómo se sabe qué modelo seleccionar? Se pueden utilizar herramientas no paramétricas para corroborar la selección de modelos paramétricos. Esencialmente, el enfoque es calcular las medidas de resumen seleccionadas bajo un modelo paramétrico ajustado y compararlo con el valor correspondiente bajo el modelo no paramétrico. Como el no paramétrico no asume una distribución específica y es simplemente una función de los datos, se utiliza como punto de referencia para evaluar cómo de bien la distribución/modelo paramétrico representa los datos. Esta comparación puede alertar al analista de deficiencias en el modelo paramétrico y, a veces, señalar formas de mejorar la especificación paramétrica. Los procedimientos orientados a evaluar la validez de un modelo se conocen como diagnóstico del modelo. 4.1.2.1 Comparación Gráfica de Distribuciones Ya hemos visto la técnica de superponer gráficos para fines de comparación. Para reforzar la aplicación de esta técnica, la Figura @ref(fig: ComparisonCDFPDF) compara la distribución empírica con dos distribuciones paramétricas ajustadas. El gráfico izquierdo muestra las funciones de distribución de las distribuciones de siniestros. Los puntos que forman una curva “en forma de S” representan la función de distribución empírica en cada observación. La curva azul gruesa proporciona los valores correspondientes para la distribución gamma ajustada y el púrpura claro corresponde a la distribución de Pareto ajustada. Como la distribución de Pareto está mucho más cerca de la función de distribución empírica que la de la gamma, esto nos proporciona una evidencia de que la Pareto es el mejor modelo para este conjunto de datos. El gráfico derecho ofrece información similar para la función de densidad y proporciona un mensaje coherente. Basado (sólo) en estos gráficos, la distribución de Pareto es la opción preferida para el analista. Figure 4.7: Distribución paramétrica versus paramétrica ajustada y funciones de densidad. El gráfico de la izquierda compara las funciones de distribución, con los puntos correspondientes a la distribución empírica, la curva azul gruesa correspondiente a la gamma ajustada y la curva de color púrpura claro correspondiente al Pareto ajustado. El gráfico de la derecha compara estas tres distribuciones resumidas usando funciones de densidad de probabilidad. Otra forma de comparar la idoneidad de dos modelos ajustados es a partir del gráfico de probabilidad-probabilidad (\\(pp\\)). Un gráfico \\(pp\\) compara las probabilidades acumuladas en dos modelos. Para nuestro propósito, estos dos modelos son la función de distribución empírica no paramétrica y el modelo paramétrico ajustado. La Figura @ref(fig: PPPlot) muestra los gráficos \\(pp\\) para los datos del Fondo de la Propiedad. La gamma ajustada está a la izquierda y la Pareto ajustada está a la derecha, en comparación con la misma función de distribución empírica de los datos. La línea recta representa la igualdad entre las dos distribuciones que se comparan, por lo que son deseables los puntos cercanos a la línea. Como se vio en demostraciones anteriores, la Pareto está mucho más cerca de la distribución empírica que la gamma, lo que proporciona evidencia adicional de que la Pareto es el mejor modelo. Figure 4.8: Gráficos de Probabilidad-Probabilidad (\\(pp\\)). Los ejes horizontales representan la función de distribución empírica en cada observación. En el gráfico izquierdo, la función de distribución correspondiente a la gamma se muestra en el eje vertical. El gráfico de la derecha muestra la distribución de Pareto ajustada. Las líneas de \\(y=x\\) se superponen. Un gráfico \\(pp\\) es útil en parte porque no se requiere escala artificial, como con la superposición de densidades en la Figura @ref(fig: ComparisonCDFPDF), en la que cambiamos a la escala logarítmica para visualizar mejor los datos. El Capítulo 4 Suplemento técnico A.1 introduce una variación del diagrama \\(pp\\) conocido como curva de Lorenz; Ésta es una herramienta importante para evaluar la desigualdad de ingresos. Además, los gráficos \\(pp\\) están disponibles en entornos multivariantes en los que hay más de una variable disponible. Sin embargo, una limitación del gráfico \\(pp\\) es que, debido a que es un gráfico de funciones de distribución acumulativas, a veces puede resultar difícil detectar dónde una distribución paramétrica ajustada es deficiente. Como alternativa, se usa frecuentemente un gráfico cuantil-cuantil (\\(qq\\)), como se muestra en la Figura 4.9. El gráfico \\(qq\\) compara dos modelos ajustados a través de sus cuantiles. Al igual que con los gráficos \\(pp\\), comparamos el modelo no paramétrico con un modelo ajustado paramétrico. Los cuantiles se pueden evaluar en cada punto del conjunto de datos o en una cuadrícula (por ejemplo, en \\(0, 0,001, 0,002, \\ldots, 0,999, 1.000\\)), dependiendo de la aplicación. En la Figura 4.9, para cada punto en la cuadrícula mencionada, el eje horizontal muestra el cuantil empírico y el eje vertical muestra el correspondiente cuantil paramétrico ajustado (gamma para los dos gráficos superiores, Pareto para los dos inferiores). Los cuantiles se trazan en la escala original en los gráficos izquierdos y en la escala logarítmica en los gráficos derechos para permitirnos ver dónde una distribución ajustada es deficiente. La línea recta representa la igualdad entre la distribución empírica y la distribución ajustada. A partir de estos gráficos, nuevamente vemos que en general la Pareto se ajusta mejor que la gamma. Además, el gráfico inferior derecho sugiere que la distribución de Pareto muestra un buen ajuste con valores grandes, pero proporciona un peor ajuste para valores pequeños. Figure 4.9: Gráficos Cuantil-Cuantil (\\(qq\\)). Los ejes horizontales representan los cuantiles empíricos en cada observación. Los gráficos de la derecha están representados sobre una base logarítmica. El eje vertical contiene los cuantiles de las distribuciones ajustadas; los cuantiles gamma están en los gráficos superiores, los cuantiles de Pareto están en los gráficos inferiores. Ejemplo 4.1.6. Pregunta de Examen Actuarial. La siguiente figura muestra un gráfico \\(pp\\) de una distribución ajustada en comparación con una muestra. Comente las dos distribuciones con respecto a la cola izquierda, la cola derecha y las probabilidades medianas. Mostrar la solución del ejemplo Solución. La cola de la distribución ajustada es demasiado gruesa a la izquierda, demasiado delgada a la derecha, y la distribución ajustada tiene menos probabilidad alrededor de la mediana que la muestra. Para ver esto, recuerde que el gráfico \\(pp\\) representa gráficamente la distribución acumulada de dos distribuciones en sus ejes (empírica en el eje \\(x\\) y ajustada en el eje \\(y\\) en este caso). Para valores pequeños de \\(x\\), el modelo ajustado asigna una mayor probabilidad de estar por debajo de ese valor que el que se produjo en la muestra (es decir, \\(F(x)&gt;F_n(x)\\)). Esto indica que el modelo tiene una cola izquierda más pesada que los datos. Para valores grandes de \\(x\\), el modelo nuevamente asigna una mayor probabilidad de estar por debajo de ese valor y, por lo tanto, menos probabilidad de estar por encima de ese valor (es decir, \\(S(x)&lt;S_n(x)\\). Esto indica que el modelo tiene una cola derecha más fina que los datos. Además, a medida que avanzamos de 0,4 a 0,6 en el eje horizontal (mirando así el 20% medio de los datos), el gráfico \\(pp\\) aumenta aproximadamente de 0,3 a 0,4. Esto indica que el modelo asigna sólo alrededor del 10% de la probabilidad en este rango. 4.1.2.2 Comparación Estadística de Distribuciones Para seleccionar un modelo es útil realizar las representaciones gráficas previas. Sin embargo, para mostrar los resultados, puede ser necesario complementar los gráficos con estadísticos de selección que resumen la bondad de ajuste del modelo. La Tabla 4.2 proporciona tres estadísticos de bondad de ajuste de uso frecuente. En esta tabla, \\(F_n\\) es la distribución empírica, \\(F\\) es la distribución ajustada o hipotética, y \\(F_i=F(x_i)\\). \\[ {\\small \\begin{matrix} \\text{Tabla 4.2: Tres Estadísticos de Bondad de Ajuste } \\\\ \\begin{array}{l|cc} \\hline \\text{Estadístico} &amp; \\text{Definición} &amp; \\text{Expresión Computacional} \\\\ \\hline \\text{Kolmogorov-} &amp; \\max_x |F_n(x) - F(x)| &amp; \\max(D^+, D^-) \\text{ donde} \\\\ ~~~\\text{Smirnov} &amp;&amp; D^+ = \\max_{i=1, \\ldots, n} \\left|\\frac{i}{n} - F_i\\right| \\\\ &amp;&amp; D^- = \\max_{i=1, \\ldots, n} \\left| F_i - \\frac{i-1}{n} \\right| \\\\ \\text{Cramer-von Mises} &amp; n \\int (F_n(x) - F(x))^2 f(x) dx &amp; \\frac{1}{12n} + \\sum_{i=1}^n \\left(F_i - (2i-1)/n\\right)^2 \\\\ \\text{Anderson-Darling} &amp; n \\int \\frac{(F_n(x) - F(x))^2}{F(x)(1-F(x))} f(x) dx &amp; -n-\\frac{1}{n} \\sum_{i=1}^n (2i-1) \\log\\left(F_i(1-F_{n+1-i})\\right)^2 \\\\ \\hline \\end{array} \\\\ \\end{matrix} } \\] El estadístico de Kolmogorov-Smirnov es igual a la diferencia absoluta máxima entre la función de distribución ajustada y la función de distribución empírica. En lugar de comparar diferencias entre puntos individuales, el estadístico de Cramer-von Mises integra la diferencia entre las funciones de distribución empíricas y ajustadas en todo el rango de valores. El estadístico de Anderson-Darling también integra esta diferencia en el rango de valores, aunque ponderada por la inversa de la varianza. Por lo tanto, pone mayor énfasis en las colas de la distribución (es decir, cuando \\(F(x)\\) o \\(1-F(x)=S(x)\\) es pequeño). Ejemplo 4.1.7. Pregunta de Examen Actuarial (modificada). Una muestra de pagos de siniestros es: \\[ \\begin{array}{ccccc} 29 &amp; 64 &amp; 90 &amp; 135 &amp; 182 \\\\ \\end{array} \\] Comparar la distribución empírica de siniestros con una distribución exponencial con una media de \\(100\\) calculando el valor del estadístico de prueba de Kolmogorov-Smirnov. Mostrar solución del ejemplo Solución. Para una distribución exponencial con una media de \\(100\\), la función de distribución acumulada es \\(F(x)=1-e^{-x/100}\\). Así, \\[ \\begin{array}{ccccc} \\hline x &amp; F(x) &amp; F_n(x) &amp; F_n(x-) &amp; \\max(|F(x)-F_n(x)|,|F(x)-F_n(x-)|) \\\\ \\hline 29 &amp; 0,2517 &amp; 0,2 &amp; 0 &amp; \\max(0,0517, 0,2517) = 0,2517 \\\\ 64 &amp; 0,4727 &amp; 0,4 &amp; 0,2 &amp; \\max(0,0727, 0,2727) = 0,2727 \\\\ 90 &amp; 0,5934 &amp; 0,6 &amp; 0,4 &amp; \\max(0,0066, 0,1934) = 0,1934 \\\\ 135 &amp; 0,7408 &amp; 0,8 &amp; 0,6 &amp; \\max(0,0592, 0,1408) = 0,1408 \\\\ 182 &amp; 0,8380 &amp; 1 &amp; 0,8 &amp; \\max(0,1620, 0,0380) = 0,1620 \\\\ \\hline \\end{array} \\] El estadístico de la prueba de Kolmogorov-Smirnov es, por lo tanto, \\(KS = \\max(0,2517, 0,2727, 0,1934, 0,1408, 0,1620) = 0,2727\\). 4.1.3 Valores Iniciales Los métodos de momentos y basados en la coincidencia de percentiles son métodos de estimación no paramétricos que proporcionan alternativas a la máxima verosimilitud. Generalmente, la máxima verosimilitud es la técnica preferida porque emplea los datos de manera más eficiente. (Consulte el Capítulo 17 del Apéndice para obtener las definiciones precisas de eficiencia). Sin embargo, los métodos de momentos y coincidencia de percentiles son útiles porque son más fáciles de interpretar y, por lo tanto, permiten que el actuario o el analista explique los procedimientos a terceros. Además, el procedimiento de estimación numérica (por ejemplo, si se realiza en ‘R’) para la máxima verosimilitud es iterativo y requiere valores iniciales para comenzar el proceso recursivo. Aunque muchos problemas son robustos ante la elección de los valores iniciales, en algunas situaciones complejas, puede ser importante tener un valor inicial cercano al valor óptimo (desconocido). El método de los momentos y la coincidencia de percentiles son técnicas que pueden producir estimaciones deseables sin un elevado coste en términos computacionales y, por lo tanto, pueden usarse como un valor inicial para estimar los parámetros por máxima verosimilitud. 4.1.3.1 Método de Momentos Con el método de momentos, aproximamos los momentos de la distribución paramétrica utilizando los momentos empíricos (no paramétricos) descritos en la Sección 4.1.1.1. Entonces podemos obtener algebraicamente las estimaciones de los parámetros. *** Ejemplo 4.1.8. Fondo de Propiedad. Para el fondo inmobiliario de 2010, hay \\(n=1.377\\) siniestros individuales (en miles de dólares) con \\[m_1 = \\frac{1}{n} \\sum_{i=1}^n X_i = 26,62259 \\ \\ \\ \\ \\text{y} \\ \\ \\ \\ m_2 = \\frac{1}{n} \\sum_{i=1}^n X_i^2 = 136.154,6 .\\] Ajustar los parámetros de las distribuciones gamma y Pareto utilizando el método de los momentos. Mostrar solución del ejemplo Solución. Para ajustar una distribución gamma, tenemos \\(\\mu_1=\\alpha\\theta\\) y \\(\\mu_2^{\\prime}=\\alpha(\\alpha+1)\\theta^2\\). Al resolver ambas ecuaciones para obtener la estimación por el método de los momentos, mediante cálculos sencillos se muestra que \\[\\alpha = \\frac{\\mu_1^2}{\\mu_2^{\\prime}-\\mu_1^2} \\ \\ \\ \\text{y} \\ \\ \\ \\theta = \\frac{\\mu_2^{\\prime}-\\mu_1^2}{\\mu_1}.\\] Por lo tanto, los estimadores por el método de los momentos son \\[ \\begin{aligned} \\hat{\\alpha} &amp;= \\frac{26,62259^2}{136154,6-26,62259^2} = 0,005232809 \\\\ \\hat{\\theta} &amp;= \\frac{136154,6-26,62259^2}{26,62259} = 5.087,629. \\end{aligned} \\] A modo de comparación, los valores obtenidos por máxima verosimilitud son \\(\\hat{\\alpha}_{MLE}=0,2905959\\) y \\(\\hat{\\theta}_{MLE}=91,61378\\), por lo que hay grandes discrepancias entre las estimaciones obtenidas con los dos procedimientos. Esto es una indicación, como hemos visto antes, de que el modelo gamma no se ajusta bien. En contraste, ahora se asume una distribución de Pareto, de modo que \\(\\mu_1 = \\theta/(\\alpha -1)\\) y \\(\\mu_2^{\\prime} = 2\\theta^2/((\\alpha-1)(\\alpha-2) )\\). mediante cálculos sencillos se muestra que \\[\\alpha = 1+ \\frac{\\mu_2^{\\prime}}{\\mu_2^{\\prime}-\\mu_1^2} \\ \\ \\ \\ \\text{and} \\ \\ \\ \\ \\ \\theta = (\\alpha-1)\\mu_1.\\] Por lo tanto, los estimadores por el método de los momentos son \\[ \\begin{aligned} \\hat{\\alpha} &amp;= 1+ \\frac{136154,6}{136154,6-26,62259^2} = 2,005233 \\\\ \\hat{\\theta} &amp;= (2,005233-1) \\cdot 26,62259 = 26,7619 \\end{aligned} \\] Los valores estimados por máxima verosimilitud son \\(\\hat{\\alpha}_{MLE}=0,9990936\\) y \\(\\hat{\\theta}_{MLE}=2,2821147\\). Es interesante que \\(\\hat{\\alpha}_{MLE}&lt;1\\); para la distribución de Pareto, recuerde que \\(\\alpha&lt;1\\) significa que la media es infinita. Esto es otro indicio de que el conjunto de datos de siniestros de la propiedad tiene una distribución de cola larga y pesada. Como se sugiere en el ejemplo anterior, existe flexibilidad con el método de los momentos. Por ejemplo, podríamos haber igualado el segundo y el tercer momento en lugar del primero y el segundo, obteniendo diferentes estimadores. Además, no hay garantía de que exista una solución para cada problema. Adicionalmente, con datos censurados o truncados, hacer coincidir los momentos es solo posible para algunos problemas, y en general, es un escenario más complejo. Finalmente, para distribuciones donde los momentos no existen o son infinitos, el método de momentos no se puede aplicar. Como alternativa, se puede usar la técnica de coincidencia de percentiles. 4.1.3.2 Coincidencia de percentiles Bajo el método de coincidencia de percentiles, aproximamos los cuantiles o percentiles de la distribución paramétrica utilizando los cuantiles o percentiles empíricos (no paramétricos) descritos en la Sección 4.1.1.3. Ejemplo 4.1.9. Fondo de propiedad. Para el fondo inmobiliario de 2010, ilustramos la correspondencia en cuantiles. En concreto, la distribución de Pareto es intuitivamente sencilla debido a la expresión cerrada para los cuantiles. Recuerde que la función de distribución para la distribución de Pareto es \\[F(x) = 1 - \\left(\\frac{\\theta}{x+\\theta}\\right)^{\\alpha}.\\] Mediante sencillos cálculos se muestra que podemos expresar el cuantil como \\[F^{-1}(q) = \\theta \\left( (1-q)^{-1/\\alpha} -1 \\right).\\] for a fraction \\(q\\), \\(0&lt;q&lt;1\\). Determinar las estimaciones de los parámetros de la distribución de Pareto utilizando los cuantiles empíricos 25 y 95. Mostrar solución del ejemplo Solución. El percentil 25 (el primer cuartil) es \\(0,78853\\) y el percentil 95 es \\(50,98293\\) (ambos en miles de dólares). Con dos ecuaciones \\[0,78853 = \\theta \\left( 1- (1-0,25)^{-1/\\alpha} \\right) \\ \\ \\ \\ \\text{y} \\ \\ \\ \\ 50,98293 = \\theta \\left( 1- (1-0,95)^{-1/\\alpha} \\right)\\] y dos incógnitas, la solución es \\[\\hat{\\alpha} = 0,9412076 \\ \\ \\ \\ \\ \\text{y} \\ \\ \\ \\ \\hat{\\theta} = 2,205617 .\\] Observamos aquí que se requiere una rutina numérica para estas soluciones ya que no hay una solución analítica disponible. Además, recuerde que las estimaciones de máxima verosimilitud son \\(\\hat{\\alpha}_{MLE}=0,9990936\\) y \\(\\hat{\\theta}_{MLE} = 2,2821147\\), por lo que la coincidencia de percentiles proporciona una mejor aproximación para la distribución de Pareto que el método de los momentos. Ejemplo 4.1.10. Pregunta de Examen Actuarial. Te dan: Las pérdidas siguen una distribución loglogística con función de distribución acumulada: \\[F(x) = \\frac{\\left(x/\\theta\\right)^{\\gamma}}{1+\\left(x/\\theta\\right)^{\\gamma}}\\] La muestra de pérdidas es: \\[ \\begin{array}{ccccccccccc} 10 &amp;35 &amp;80 &amp;86 &amp;90 &amp;120 &amp;158 &amp;180 &amp;200 &amp;210 &amp;1500 \\\\ \\end{array} \\] Estimar \\(\\theta\\) mediante la coincidencia de percentiles, utilizando las estimaciones de percentiles empíricos suavizados del 40 y 80. Mostrar solución del ejemplo Solución. Con 11 observaciones, tenemos \\(j=\\lfloor(n+1)q\\rfloor = \\lfloor 12(0,4) \\rfloor = \\lfloor 4,8\\rfloor=4\\) y \\(h=(n+1)q-j = 12(0,4)-4=0,8\\). Por interpolación, la estimación del percentil 40 empírico suavizado es \\(\\hat{\\pi}_{0,4} = (1-h) X_{(j)} + h X_{(j+1)} = 0,2(86)+0,8(90)=89,2\\). Del mismo modo, para la estimación del percentil 80 empírico suavizado, tenemos \\(12(0,8)=9,6\\) entonces la estimación es \\(\\hat{\\pi}_{0,8} = 0,4(200)+0,6(210)=206\\). Usando la distribución acumulada loglogística, necesitamos resolver las siguientes dos ecuaciones para los parámetros \\(\\theta\\) y \\(\\gamma\\): \\[0,4=\\frac{(89,2/\\theta)^\\gamma}{1+(89,2/\\theta)^\\gamma} \\ \\ \\ \\text{y} \\ \\ \\ \\ 0,8=\\frac{(206/\\theta)^\\gamma}{1+(206+\\theta)^\\gamma}\\] Resolviendo para cada expresión entre paréntesis da \\(\\frac{2}{3}=(89,2/\\theta)^\\gamma\\) y \\(4=(206/\\theta)^\\gamma\\). Sustituyendo la razón de la segunda ecuación en la primera da \\(6=(206/89,2)^\\gamma \\Rightarrow \\gamma=\\frac{\\ln(6)}{\\ln(206/89,2)} = 2,1407\\). Entonces \\(4^{1/2,1407}=206/\\theta \\Rightarrow \\theta=107,8\\) Al igual que el método de los momentos, la coincidencia de percentiles es también muy sensible en el sentido de que muchos estimadores pueden basarse en coincidencias de percentiles; por ejemplo, un actuario puede basar la estimación en los percentiles 25 y 95, mientras que otro actuario utiliza los percentiles 20 y 80. En general, estos estimadores serán diferentes y no hay una razón convincente para preferir uno sobre el otro. Por otro lado, como con el método de los momentos, la coincidencia de percentiles es atractiva porque proporciona una técnica que se puede aplicar fácilmente en distintas situaciones y tiene una base intuitiva. Aunque la mayoría de las aplicaciones actuariales usan estimadores de máxima verosimilitud, puede ser conveniente utilizar enfoques alternativos como el método de momentos y la coincidencia de percentiles. 4.2 Selección del Modelo En esta sección, se aprende a: Describir el proceso iterativo de especificación y de selección de modelo. Esquematizar los pasos necesarios para seleccionar un modelo paramétrico. Describir los peligros de la selección del modelo basándose únicamente en datos en muestra en comparación con las ventajas de la validación del modelo fuera de muestra. En esta sección se subraya la idea de que la selección de modelos es un proceso iterativo en el que los modelos se (re)formulan cíclicamente y se prueban para determinar su idoneidad antes de usarlos para la inferencia. Después de una descripción general, describimos el proceso de selección del modelo basado en: un conjunto de datos en muestra o de entrenamiento, un conjunto de datos fuera de la muestra o de prueba, y un método que combina estos enfoques conocido como validación cruzada. 4.2.1 Selección del Modelo Iterativa En nuestro desarrollo examinamos los datos gráficamente, hipotetizamos la estructura de un modelo y comparamos los datos con un modelo candidato para formular un modelo mejorado. Box (1980) lo describe como un proceso iterativo el cual se muestra en la Figura 4.10. Figure 4.10: El proceso iterativo de especificación del modelo. Este proceso iterativo proporciona un mecanismo útil para estructurar el proceso de especificación de un modelo para representar un conjunto de datos. El primer paso, la etapa de formulación del modelo, se logra examinando los datos gráficamente y utilizando el conocimiento previo de las relaciones, como la teoría económica o la práctica de la industria. El segundo paso en el proceso iterativo consiste en el ajuste basado en los supuestos del modelo especificado. Estas suposiciones deben ser consistentes con los datos para hacer un uso válido del modelo. El tercer paso es el de comprobación de diagnóstico; los datos y el modelo deben ser coherentes entre sí antes de poder hacer inferencias adicionales. La verificación de diagnóstico es una parte importante de la formulación del modelo; puede revelar errores cometidos en pasos anteriores y proporcionar formas de corregir estos errores. El proceso iterativo también enfatiza las habilidades que se necesitan para que la analítica funcione. Primero, se necesita estar dispuesto a resumir la información numéricamente y representarla gráficamente. En segundo lugar, es importante desarrollar una comprensión de las propiedades del modelo. Debe comprenderse cómo se comporta un modelo probabilístico para hacer coincidir un conjunto de datos con él. Tercero, las propiedades teóricas del modelo también son importantes para inferir relaciones generales basadas en el comportamiento de los datos. 4.2.2 Selección de Modelo basada en un Conjunto de Datos de Entrenamiento Es común referirse a un conjunto de datos utilizado para el análisis como un conjunto de datos en muestra o de entrenamiento. Las técnicas disponibles para seleccionar un modelo dependen de si los resultados \\(X\\) son discretos, continuos o un híbrido de los dos, aunque los principios son los mismos. Gráfico y otras medidas de resumen básicas. Comenzar resumiendo los datos gráficamente y con estadísticos que no se basen en una forma paramétrica específica, como se describe en la Sección 4.1. En concreto, es necesario representar gráficamente tanto la distribución empírica como las funciones de densidad. Particularmente, para los datos de pérdidas que contienen muchos ceros y que pueden ser asimétricos, decidir la escala apropiada (por ejemplo, logarítmica) puede representar algunas dificultades. Para datos discretos, a menudo se prefieren las tablas. Determinar los momentos muestrales, como la media y la varianza, así como los cuantiles seleccionados, incluidos el mínimo, el máximo y la mediana. Para datos discretos, la moda (o el valor más frecuente) suele ser útil. Estos resúmenes, así como el conocimiento de la práctica profesional, permiten proponer uno o más modelos paramétricos candidatos. En general, se debe comenzar con los modelos paramétricos más simples (por ejemplo, la exponencial de un parámetro antes de una gamma de dos parámetros), introduciendo gradualmente más complejidad en el proceso de modelización. Evaluar el modelo paramétrico candidato numérica y gráficamente. Para los gráficos, se pueden utilizar las herramientas introducidas en la Sección 4.1.2 como los gráficos \\(pp\\) y \\(qq\\). Para las evaluaciones numéricas, examinar la importancia estadística de los parámetros e intentar eliminar los parámetros que no proporcionan información adicional. Pruebas de razón de verosimilitud. Para comparar ajustes del modelo, si un modelo es un subconjunto de otro, entonces se puede utilizar una prueba de razón de verosimilitud; el enfoque general para la prueba de razón de verosimilitud se describe en las Secciones 15.4.3 y 17.3.2. Estadísticos de bondad del ajuste. En general, los modelos no son subconjuntos unos de otros, por lo que los estadísticos generales de bondad del ajuste son útiles para comparar modelos. Los criterios de información son un tipo de estadístico de bondad de ajuste. Los ejemplos más utilizados son el Criterio de Información de Akaike (AIC) y el Criterio de Información Bayesiano (BIC) de Schwarz; se mencionan frecuentemente porque pueden generalizarse fácilmente a entornos multivariantes. La Sección 15.4.4 proporciona una descripción de estos estadísticos. Para seleccionar la distribución adecuada, los estadísticos que comparan un ajuste paramétrico con una alternativa no paramétrica, descritos en la Sección 4.1.2.2, son útiles para la comparación de modelos. Para datos discretos, generalmente se prefiere un estadístico de bondad de ajuste (como se describe en la Sección 2.7), ya que es más intuitivo y más simple de explicar. 4.2.3 Selección de Modelo basada en un Conjunto de Datos de Prueba Validación del modelo es el proceso de confirmar que el modelo propuesto es apropiado, especialmente a la luz de los propósitos de la investigación. Una limitación importante del proceso de selección de modelos basado solo en datos de muestra es que puede ser susceptible a indagación de datos (data-snooping), es decir, ajustar una gran cantidad de modelos a un solo conjunto de datos. Al analizar una gran cantidad de modelos, podemos sobreajustar los datos y subestimar la variación natural en nuestra representación. Seleccionar un modelo basado solo en datos de muestra tampoco es compatible con el objetivo de la inferencia predictiva. Particularmente, en aplicaciones actuariales nuestro objetivo es hacer declaraciones sobre la nueva experiencia en lugar de sobre el conjunto de datos disponible. Por ejemplo, utilizamos la experiencia de siniestros de un año para desarrollar un modelo que se pueda usar para fijar el precio de los contratos de seguro para el año siguiente. Como analogía, podemos pensar en el conjunto de datos de entrenamiento como experiencia de un año que se utiliza para predecir el comportamiento del conjunto de datos de prueba del próximo año. Podemos superar estas limitaciones utilizando una técnica a veces conocida como validación fuera de muestra. La situación ideal es tener disponibles dos conjuntos de datos, uno para entrenamiento o desarrollo del modelo y otro para prueba o validación del modelo. Inicialmente desarrollamos uno o varios modelos en el primer conjunto de datos que llamamos nuestros modelos candidatos. Luego, el rendimiento relativo de los modelos candidatos se puede medir en el segundo conjunto de datos. De esta manera, los datos utilizados para validar el modelo no se ven afectados por los procedimientos utilizados para formular el modelo. División aleatoria de los datos. Desafortunadamente, rara vez estarán disponibles dos conjuntos de datos para el investigador. Sin embargo, podemos implementar el proceso de validación dividiendo el conjunto de datos en submuestras de entrenamiento y prueba, respectivamente. La Figura 4.11 ilustra la división de los datos. Figure 4.11: Validación del modelo. Un conjunto de datos se divide aleatoriamente en dos submuestras. Diferentes proporciones se recomiendan para la asignación a las muestras de entrenamiento y prueba. Snee (1977) sugiere que la división de datos no se realice a menos que el tamaño de la muestra sea moderadamente grande. Las pautas de Picard and Berk (1990) muestran que cuanto mayor sea el número de parámetros a estimar, mayor será la proporción de observaciones necesarias para la submuestra de entrenamiento del modelo. Estadísticos de validación del modelo. Gran parte de la literatura que respalda el establecimiento de un proceso de validación del modelo se basa en modelos de regresión y clasificación que puede considerarse como un problema input-output (James et al. (2013)). Es decir, tenemos varias entradas \\(x_1,\\ldots,x_k\\) que están relacionadas con una salida \\(y\\) a través de una función como \\[y=\\mathrm{g}\\left(x_1,\\ldots,x_k\\right).\\] Se utiliza la muestra de entrenamiento para desarrollar una estimación de \\(\\mathrm{g}\\), digamos, \\(\\hat{\\mathrm{g}}\\), y luego se calibra la distancia entre los resultados observados y las predicciones usando un criterio de la forma \\[\\begin{equation} \\sum_i \\mathrm{d}(y_i,\\hat{\\mathrm{g}}\\left(x_{i1}, \\ldots, x_{ik}\\right) ) . \\tag{4.4} \\end{equation}\\] Aquí, la suma i se realiza sobre los datos de prueba. En muchas aplicaciones de regresión es común usar la distancia euclidiana al cuadrado de la forma \\(\\mathrm{d}(y_i,\\mathrm{g})=(y_i-\\mathrm{g})^2\\). En aplicaciones actuariales, la distancia euclidiana \\(\\mathrm{d}(y_i,\\mathrm{g})=|y_i-\\mathrm{g}|\\) a menudo se prefiere debido a la naturaleza asimétrica de los datos (valores extremos grandes de \\(y\\) pueden tener un gran impacto en la medida). El Capítulo 7 describe otra medida, el índice de Gini, que es útil en aplicaciones actuariales, particularmente cuando hay una gran proporción de ceros en los datos de siniestros (correspondientes a ningún siniestro). Selección de una distribución. Nuestro enfoque hasta ahora ha sido seleccionar una distribución para un conjunto de datos que pueda usarse para la modelización actuarial sin entradas adicionales \\(x_1,\\ldots,x_k\\). Incluso en este problema más fundamental, el enfoque de validación del modelo es adecuado. Si basamos toda la inferencia solo en datos de la muestra, entonces la tendencia es seleccionar modelos más complicados de lo necesario. Por ejemplo, se podría seleccionar una distribución con cuatro parámetros como la GB2, distribución beta generalizada de segundo tipo, cuando solo se necesita una Pareto con dos parámetros. Criterios de información como AIC criterio de información de Akaike y BIC criterio de información Bayesiano que incluyen penalizaciones a la complejidad del modelo y, por lo tanto, proporcionan cierta protección, con el uso de una muestra de prueba son la mejor garantía para lograr modelos parsimoniosos. Una cita a menudo atribuida a Albert Einstein, indica queremos “utilizar el modelo más simple (sencillo) posible pero no el más simple (simplón)”. 4.2.4 Selección del Modelo basada en Validación Cruzada Aunque la validación fuera de la muestra es el estándar más valioso en la modelización predictiva, no siempre es práctico hacerlo. La razón principal es que tenemos tamaños de muestra limitados y el criterio de selección de modelo fuera de muestra en la ecuación (4.4) depende de una división aleatoria de los datos. Lo anterior genera que diferentes analistas, incluso cuando utilizan el mismo conjunto de datos y el mismo enfoque para la modelización, puedan seleccionar diferentes modelos. Esto puede ocurrir en aplicaciones actuariales ya que se utilizan conjuntos de datos asimétricos en los que hay una elevada probabilidad de obtener algunos valores muy grandes y los valores grandes pueden tener un gran impacto en las estimaciones de los parámetros. Procedimiento de Validación Cruzada. Alternativamente, se puede utilizar validación cruzada, de la siguiente forma. -El procedimiento se inicia mediante el uso de un mecanismo aleatorio para dividir los datos en K subconjuntos denominados pliegues. Los analistas suelen utilizar de 5 a 10. -Después se utilizan las primeras K -1 submuestras para estimar los parámetros del modelo. Luego, se “predicen” los resultados para la submuestra K-ésima y se aplica una medida como las definidas en la ecuación (4.4) para describir el ajuste. -Ahora, se repite para cada una de las K submuestras, utilizando un estadístico acumulativo fuera de muestra para describir el ajuste. Repetir estos pasos para varios modelos candidatos y elegir el modelo con el estadístico acumulativo fuera de muestra más bajo. La validación cruzada se utiliza frecuentemente porque retiene la naturaliza predictiva del proceso de validación del modelo fuera de muestra pero, debido a la reutilización de los datos, es más estable que el procedimiento basado en muestras aleatorias. 4.3 Estimación utilizando Datos Modificados En esta sección, se aprende a: Describir datos agrupados, censurados y truncados. Estimar distribuciones paramétricas basadas en datos agrupados, censurados y truncados Estimar distribuciones no paramétricas basadas en datos agrupados, censurados y truncados 4.3.1 Estimación Paramétrica usando Datos Modificados La teoría básica y muchas aplicaciones se basan en observaciones individuales que son “completas” y “no modificadas”, como hemos visto en la sección anterior. La sección 3.5 introduce el concepto de observaciones que están “modificadas” debido a dos tipos comunes de limitaciones: censura y truncamiento. Por ejemplo, se suele pensar que un deducible o franquicia de seguros genera datos truncados (desde la izquierda) o los límites de la póliza genera datos censurados (desde la derecha). Este es el punto de vista del asegurador primario (el vendedor del seguro). Sin embargo, como veremos en el Capítulo 10, un reasegurador (un asegurador de una compañía de seguros) no puede observar reclamaciones menores a una cantidad, solo si existe la reclamación, un ejemplo de censura desde la izquierda. En esta sección se cubre toda la gama de alternativas. Específicamente, esta sección abordará los métodos de estimación paramétrica para tres alternativas a los datos individuales, completos y no modificados: datos censurados por intervalos disponibles solo en grupos, datos limitados o censurados, y datos que no pueden ser observados debido a truncamiento. 4.3.1.1 Estimación Paramétrica utilizando Datos Agrupados Considerar una muestra de tamaño \\(n\\) observada a partir de la distribución \\(F(\\cdot)\\), pero en grupos, de modo que solo conocemos el grupo en el que cayó cada observación, no el valor exacto. Esto se conoce como datos agrupados o censurados por intervalos. Por ejemplo, podemos estar viendo dos años consecutivos de registros anuales de empleados. Las personas empleadas en el primer año pero no en el segundo se han ido en algún momento durante el año. Con una fecha de salida exacta (datos individuales), podríamos calcular la cantidad de tiempo que estuvieron en la empresa. Sin la fecha de salida (datos agrupados), solo sabemos que partieron en algún momento durante un intervalo de un año. Formalizando esta idea, supongamos que hay \\(k\\) grupos o intervalos delimitados por límites \\(c_0&lt;c_1&lt;\\cdots&lt;c_k\\). Para cada observación solo se conoce el intervalo en el que cayó (por ejemplo, \\((c_{j-1},c_j)\\)), no el valor exacto. Por lo tanto, solo sabemos el número de observaciones en cada intervalo. Las constantes \\(\\{c_0&lt;c_1&lt;\\cdots&lt;c_k\\}\\) forman alguna partición del dominio de \\(F(\\cdot)\\). Entonces, la probabilidad de que una observación \\(X_i\\) caiga en el intervalo \\(j\\)-ésimo es \\[\\Pr\\left (X_i \\in (c_{j-1},c_j] \\right)=F(c_j)-F(c_{j-1}).\\] La función de masa de probabilidad correspondiente para una observación es \\[ \\begin{aligned} f(x) &amp;= \\begin{cases} F(c_1) - F(c_{0}) &amp; \\text{if }\\ x \\in (c_{0}, c_1]\\\\ \\vdots &amp; \\vdots \\\\ F(c_k) - F(c_{k-1}) &amp; \\text{if }\\ x \\in (c_{k-1}, c_k]\\\\ \\end{cases} \\\\ &amp;= \\prod_{j=1}^k \\left\\{F(c_j) - F(c_{j-1})\\right\\}^{I(x \\in (c_{j-1}, c_j])} \\end{aligned} \\] Ahora, se define \\(n_j\\) como el número de observaciones que caen en el intervalo \\(j\\)-ésimo, \\((c_{j-1}, c_j]\\). Por lo tanto, la función de verosimilitud (con respecto al(los) parámetro(s) \\(\\theta\\)) es \\[ \\begin{aligned} \\mathcal{L}(\\theta) = \\prod_{j=1}^n f(x_i) = \\prod_{j=1}^k \\left\\{F(c_j) - F(c_{j-1})\\right\\}^{n_j} \\end{aligned} \\] y el logaritmo de la función de verosimilitud es \\[ \\begin{aligned} L(\\theta) = \\ln \\mathcal{L}(\\theta) = \\ln \\prod_{j=1}^n f(x_i) = \\sum_{j=1}^k n_j \\ln \\left\\{F(c_j) - F(c_{j-1})\\right\\} \\end{aligned} \\] Entonces, maximizar la función de verosimilitud (o, de manera equivalente, maximizar el logaritmo de la función de verosimilitud) generará los estimadores por máxima verosimilitud para los datos agrupados. Ejemplo 4.3.1. Pregunta de Examen Actuarial. Te dan: Las pérdidas siguen una distribución exponencial con media \\(\\theta\\). Una muestra aleatoria de 20 pérdidas se distribuye de la siguiente manera: \\[ {\\small \\begin{array}{l|c} \\hline \\text{Rango de Pérdidas} &amp; \\text{Frecuencia} \\\\ \\hline [0,1000] &amp; 7 \\\\ (1000,2000] &amp; 6 \\\\ (2000,\\infty) &amp; 7 \\\\ \\hline \\end{array} } \\] Calcular la estimación máximo verosímil de \\(\\theta\\). Mostrar solución del ejemplo Solución. \\[ \\begin{aligned} \\mathcal{L}(\\theta) &amp;= F(1000)^7[F(2000)-F(1000)]^6[1-F(2000)]^7 \\\\ &amp;= (1-e^{-1000/\\theta})^7(e^{-1000/\\theta} - e^{-2000/\\theta})^6(e^{-2000/\\theta})^7 \\\\ &amp;= (1-p)^7(p-p^2)^6(p^2)^7 \\\\ &amp;= p^{20}(1-p)^{13} \\end{aligned} \\] donde \\(p=e^{-1000/\\theta}\\). Maximizar esta expresión con respecto a \\(p\\) es equivalente a maximizar la verosimilitud con respecto a \\(\\theta\\). El máximo ocurre en \\(p=\\frac{20}{33}\\) y entonces \\(\\hat{\\theta}=\\frac{-1000}{\\ln(20/33)}=1996,90\\). 4.3.1.2 Datos Censurados La censura ocurre cuando registramos solo un valor límite para una observación. La forma más común es censurar por la derecha, en la cual registramos el valor más pequeño entre el “verdadero” de la variable dependiente y una variable de censura. Usando notación, supongamos que \\(X\\) representa un resultado de interés, como la pérdida debido a un evento asegurado o el tiempo hasta un evento. La cuantía de censura se denota como \\(C_U\\). Como observaciones censuradas por la derecha, registramos \\(X_U^{\\ast}=\\min(X,C_U)=X\\wedge C_U\\). También registramos si se ha producido o no la censura. Supongamos que \\(\\delta_U=I(X \\leq C_U)\\) sea una variable binaria que es 0 si se produce la censura y 1 si no es así. Para el ejemplo que vimos en la Sección 3.4.2, \\(C_U\\) puede representar el límite superior de cobertura de una póliza de seguro (utilizamos \\(u\\) para el límite superior en esa sección). La pérdida puede exceder el valor \\(C_U\\), pero la aseguradora solo guarda \\(C_U\\) en sus registros como la cantidad pagada y no guarda el valor de la pérdida real \\(X\\). De manera similar, con la censura por la izquierda, registramos el valor más grande entre la variable de interés y la variable de censura. Si se usa \\(C_L\\) para representar la cantidad de censura, registramos \\(X_L^{\\ast}=\\max(X,C_L)\\) junto con el indicador de censura \\(\\delta_L=I(X\\geq C_L)\\). Como ejemplo, tenemos una breve introducción al reaseguro, seguro para aseguradores, en la Sección 3.4.4 y se verá más en el Capítulo 10. Supongamos que una reaseguradora cubrirá las pérdidas de la aseguradora mayores a \\(C_L\\); esto significa que el reasegurador es responsable del exceso de \\(X_L^{\\ast}\\) sobre \\(C_L\\). Usando notación, esto es \\(Y=X_L^{\\ast}-C_L\\). Para ver esto, primero considere el caso donde la pérdida del titular de la póliza \\(X&lt;C_L\\). Luego, el asegurador pagará el siniestro completo y \\(Y=C_L-C_L=0\\), sin pérdida para el reasegurador. Para el segundo caso, si la pérdida \\(X\\ge C_L\\), entonces \\(Y=X-C_L\\) representa las reclamaciones retenidas por el reasegurador. Dicho de otra manera, si ocurre una pérdida, el reasegurador registra la cuantía real si excede del límite \\(C_L\\) o, de lo contrario, solo registra que tuvo una pérdida de \\(0\\). 4.3.1.3 Datos Truncados Las observaciones censuradas se registran para su estudio, aunque de forma limitada. En contraste, los resultados truncados son un tipo de datos ausentes. Un resultado se trunca potencialmente cuando la disponibilidad de una observación depende del resultado. En el seguro, es común que las observaciones sean truncadas por la izquierda en \\(C_L\\) cuando la cantidad es \\[ \\begin{aligned} Y &amp;= \\left\\{ \\begin{array}{cl} \\text{nosotros no observamos }X &amp; X &lt; C_L \\\\ X &amp; X \\geq C_L \\end{array} \\right.\\end{aligned} . \\] En otras palabras, si \\(X\\) es menor que el umbral \\(C_L\\), entonces no se observa. Para un ejemplo que vimos en la Sección 3.4.1, \\(C_L\\) puede representar el deducible de una póliza de seguro (utilizamos \\(d\\) para el deducible en esa sección). Si la pérdida asegurada es menor que el deducible, entonces el asegurador no puede observar ni registrar la pérdida. Si la pérdida excede el deducible, el exceso de \\(X-C_L\\) es el siniestro que cubre la aseguradora. En la Sección 3.4.1, definimos la pérdida por pago como \\[ Y^{P} = \\left\\{ \\begin{matrix} \\text{Indefinido} &amp; X \\le d \\\\ X - d &amp; X &gt; d \\end{matrix} \\right. , \\] de modo que si una pérdida excede un deducible, registramos la cuantía en exceso \\(X-d\\). Esto es muy importante cuando se consideran las cuantías que pagará la aseguradora. Sin embargo, para propósitos de estimación de esta sección, importa poco si restamos una constante conocida como \\(C_L=d\\). Entonces, para nuestra variable truncada \\(Y\\), usamos la convención más simple y no restamos \\(d\\). De manera similar para datos truncados por la derecha, si \\(X\\) excede un umbral \\(C_U\\), entonces no se observa. En este caso, la cantidad es \\[ \\begin{aligned} Y &amp;= \\left\\{ \\begin{array}{cl} X &amp; X \\leq C_U \\\\ \\text{nosotros no observamos }X &amp; X &gt; C_U. \\end{array} \\right.\\end{aligned} \\] Los ejemplos clásicos de truncamiento por la derecha incluyen \\(X\\) como medida de distancia a una estrella. Cuando la distancia excede un cierto nivel \\(C_U\\), la estrella ya no es observable. La Figura 4.12 compara observaciones truncadas y censuradas. Los valores de \\(X\\) que son mayores que el límite “superior” \\(C_U\\) no se observan (truncados a la derecha), mientras que los valores de \\(X\\) que son menores que el límite “inferior” \\(C_L\\) se observan, pero se observan como \\(C_L\\) en lugar del valor real de \\(X\\) (censura a la izquierda). Figure 4.12: Censura y Truncamiento Mostrar ejemplo de estudio de mortalidad Ejemplo: estudio de mortalidad. Supongamos que se está realizando un estudio de dos años de mortalidad de sujetos de alto riesgo, comenzando el 1 de enero de 2010 y terminando el 1 de enero de 2012. Figura 4.13 representa gráficamente los seis tipos de sujetos reclutados. Para cada sujeto, el comienzo de la flecha representa que el sujeto fue reclutado y el final de la flecha representa el tiempo del evento. Por lo tanto, la flecha representa el tiempo de exposición. Figure 4.13: Cronología de varios sujetos en prueba en un estudio de mortalidad Tipo A: Censurado por la derecha. Este sujeto está vivo al principio y al final del estudio. Debido a que no se conoce el momento de la muerte al final del estudio, está censurado correctamente. La mayoría de los sujetos son de tipo A. Tipo B- Información completa está disponible para un sujeto tipo B. El sujeto está vivo al comienzo del estudio y la muerte ocurre dentro del período de observación. Tipo C: Censurado por la derecha y truncado a la izquierda. Un sujeto de tipo C está censurado por la derecha, ya que la muerte ocurre después del período de observación. Sin embargo, el sujeto ingresó después del inicio del estudio y se dice que tiene un tiempo de entrada retrasado. Debido a que el sujeto no habría sido observado si la muerte hubiera ocurrido antes de la entrada, se trunca a la izquierda. Tipo D: truncado por la izquierda. Un sujeto de tipo D también ha retrasado la entrada. Debido a que la muerte ocurre dentro del período de observación, este individuo no está censurado a la derecha. Tipo E: truncado por la izquierda. Un sujeto tipo E no está incluido en el estudio porque la muerte ocurre antes del período de observación. Tipo F: truncado por la derecha. Del mismo modo, un sujeto tipo F no está incluido porque el tiempo de entrada ocurre después del período de observación. Para resumir, para el resultado \\(X\\) y las constantes \\(C_L\\) y \\(C_U\\), Tipo de Limitación Variable Limitada Registro de Información Censura por drcha. \\(X_U^{\\ast}= \\min(X,C_U)\\) \\(\\delta_U= I(X \\leq C_U)\\) Censura por izda. \\(X_L^{\\ast}= \\max(X,C_L)\\) \\(\\delta_L= I(X \\geq C_L)\\) Censura por intervalo Truncamiento drcha. \\(X\\) observa \\(X\\) si \\(X \\leq C_U\\) Truncamiento izda. \\(X\\) observa \\(X\\) si \\(X \\geq C_L\\) 4.3.1.4 Estimación paramétrica utilizando datos censurados y truncados Para simplificar, asumimos valores de censura no aleatorios y una variable continua \\(X\\). Empezamos considerando el caso de datos censurados a la derecha donde registramos \\(X_U^{\\ast}=\\min(X,C_U)\\) y el indicador de censura \\(\\delta=I(X \\leq C_U)\\). Si la censura ocurre, de modo que \\(\\delta = 0\\), entonces \\(X\\geq C_U\\) y la probabilidad es \\(\\Pr(X \\geq C_U)=1-F(C_U)\\). Si la censura no ocurre, de modo que \\(\\delta=1\\), entonces \\(X&lt;C_U\\) y la verosimilitud es \\(f(x)\\). Resumiendo, tenemos la verosimilitud de una sola observación como \\[ \\begin{aligned} \\left\\{ \\begin{array}{ll} 1-F(C_U) &amp; \\text{if }\\delta=0 \\\\ f(x) &amp; \\text{if } \\delta = 1 \\end{array} \\right. = \\left\\{ f(x)\\right\\}^{\\delta} \\left\\{1-F(C_U)\\right\\}^{1-\\delta} . \\end{aligned} \\] La expresión de a la derecha nos permite presentar la verosimilitud de manera más compacta. Ahora, para una muestra iid de tamaño \\(n\\), la verosimilitud es \\[ \\mathcal{L} = \\prod_{i=1}^n \\left\\{ f(x_i)\\right\\}^{\\delta_i} \\left\\{1-F(C_{Ui})\\right\\}^{1-\\delta_i} = \\prod_{\\delta_i=1} f(x_i) \\prod_{\\delta_i=0} \\{1-F(C_{Ui})\\}, \\] con tiempos de censura potenciales \\(\\{C_{U1},\\ldots, C_{Un} \\}\\). Aquí, la notación “\\(\\prod_{\\delta_i=1}\\)” significa el producto de las observaciones sin censura, y de manera similar para “\\(\\prod_{\\delta_i=0}\\)”. Por otro lado, los datos truncados se tratan en inferencia de verosimilitud mediante probabilidades condicionadas. En concreto, ajustamos la contribución a la verosimilitud dividiendo por la probabilidad de que se haya observado la variable. En resumen, tenemos las siguientes contribuciones a la función de verosimilitud para seis tipos de resultados: \\[ {\\small \\begin{array}{lc} \\hline \\text{Resultado} &amp; \\text{Contribución en la Verosimilitud} \\\\ \\hline \\text{Valor exacto} &amp; f(x) \\\\ \\text{Censura por la derecha} &amp; 1-F(C_U) \\\\ \\text{Censura por la izquierda} &amp; F(C_L) \\\\ \\text{Truncamiento por la derecha} &amp; f(x)/F(C_U) \\\\ \\text{Truncamiento por la izquierda} &amp; f(x)/(1-F(C_L)) \\\\ \\text{Censura por intervalo } &amp; F(C_U)-F(C_L) \\\\ \\hline \\end{array} } \\] Para resultados conocidos y datos censurados, la verosimilitud es \\[\\mathcal{L}(\\theta) = \\prod_{E} f(x_i) \\prod_{R} \\{1-F(C_{Ui})\\} \\prod_{L} F(C_{Li}) \\prod_{I} (F(C_{Ui})-F(C_{Li})),\\] donde “\\(\\prod_{E}\\)” es el producto sobre las observaciones con valores Exactos (E), y de manera similar para los datos censurados por la Derecha (R), Izquierda (L) y en Intervalo (I). Para datos censurados por la derecha y truncados por la izquierda, la probabilidad es \\[\\mathcal{L} = \\prod_{E} \\frac{f(x_i)}{1-F(C_{Li})} \\prod_{R} \\frac{1-F(C_{Ui})}{1-F(C_{Li})},\\] y de manera similar para otras combinaciones. Para obtener más información, considere lo siguiente. Mostrar caso particular – Distribución Exponencial Caso especial: Distribución exponencial. Considere los datos que están censurados por la derecha y truncados por la izquierda, con variables aleatorias \\(X_i\\) que se distribuyen exponencialmente con media \\(\\theta\\). Con estas especificaciones, recuerde que \\(f(x) = \\theta^{-1} \\exp(-x/\\theta)\\) y \\(F(x) = 1-\\exp(-x/\\theta)\\). Para este caso particular, la log verosimilitud es \\[ \\begin{aligned} L(\\theta) &amp;= \\sum_{E} \\left\\{ \\ln f(x_i) - \\ln (1-F(C_{Li})) \\right\\} + \\sum_{R}\\left\\{ \\ln (1-F(C_{Ui}))- \\ln (1-\\mathrm{F}(C_{Li})) \\right\\}\\\\ &amp;= \\sum_{E} (-\\ln \\theta -(x_i-C_{Li})/\\theta ) -\\sum_{R} (C_{Ui}-C_{Li})/\\theta . \\end{aligned} \\] Para simplificar la notación, definimos \\(\\delta_i=I(X_i\\geq C_{Ui})\\) como una variable binaria que indica la censura a la derecha. Sea \\(X_i^{\\ast\\ast} = \\min(X_i,C_{Ui})-C_{Li}\\) la cantidad que la variable observada excede el límite inferior de truncamiento. Con esto, la log verosimilitud es \\[\\begin{equation} L(\\theta) = - \\sum_{i=1}^n ((1-\\delta_i) \\ln \\theta + \\frac{x_i^{\\ast \\ast}}{\\theta}). \\tag{4.5} \\end{equation}\\] Derivando con respecto al parámetro \\(\\theta\\) e igualando a cero se obtiene el estimador de máxima verosimilitud \\[\\widehat{\\theta} = \\frac{1}{n_u} \\sum_{i=1}^n x_i^{\\ast \\ast},\\] donde \\(n_u = \\sum_i (1-\\delta_i)\\) es el número de datos no censurados. Ejemplo 4.3.2. Pregunta de Examen Actuarial. Te dan: Una muestra de pérdidas es: 600 700 900 No hay información disponible sobre pérdidas de 500 o menos. Se supone que las pérdidas siguen una distribución exponencial con media \\(\\theta\\). Calcular el estimador de máxima verosimilitud de \\(\\theta\\). Mostrar solución del ejemplo Solución. Estas observaciones se truncan en 500. La contribución de cada observación a la función de verosimilitud es \\[\\frac{f(x)}{1-F(500)} = \\frac{\\theta^{-1}e^{-x/\\theta}}{e^{-500/\\theta}}\\] Entonces la función de verosimilitud es \\[\\mathcal{L}(\\theta)= \\frac{\\theta^{-1} e^{-600/\\theta} \\theta^{-1} e^{-700/\\theta} \\theta^{-1} e^{-900/\\theta}}{(e^{-500/\\theta})^3} = \\theta^{-3}e^{-700/\\theta}\\] El logaritmo de la verosimilitud es \\[L(\\theta) = \\ln\\mathcal{L}(\\theta) = -3\\ln \\theta - 700\\theta^{-1}\\] Maximizando esta expresión, estableciendo la derivada con respecto a \\(\\theta\\) igual a 0, tenemos \\[L&#39;(\\theta) = -3\\theta^{-1} + 700\\theta^{-2} = 0 \\ \\Rightarrow \\ \\hat{\\theta} = \\frac{700}{3} = 233,33\\] Ejemplo 4.3.3. Pregunta de Examen Actuarial. Se le proporciona la siguiente información sobre una muestra aleatoria: El tamaño de la muestra es igual a cinco. La muestra es de una distribución de Weibull con \\(\\tau = 2\\). Se sabe que dos de las observaciones de la muestra exceden 50, y las tres observaciones restantes son 20, 30 y 45. Calcule el estimador de máxima verosimilitud de \\(\\theta\\). Mostrar solución del ejemplo Solución. La función de verosimilitud es \\[ \\begin{aligned} \\mathcal{L}(\\theta) &amp;= f(20) f(30) f(45) [1-F(50)]^2 \\\\ &amp;= \\frac{2(20/\\theta)^2 e^{-(20/\\theta)^2}}{20} \\frac{2(30/\\theta)^2 e^{-(30/\\theta)^2}}{30} \\frac{2(45/\\theta)^2 e^{-(45/\\theta)^2}}{45}(e^{-(50/\\theta)^2})^2 \\\\ &amp;\\propto \\frac{1}{\\theta^6} e^{-8325/\\theta^2} \\end{aligned} \\] El logaritmo natural de la expresión anterior es \\(-6\\ln\\theta-\\frac{8325}{\\theta^2}\\). Maximizando esta expresión al fijar su derivada igual a 0, obtenemos \\[\\frac{-6}{\\theta} + \\frac{16650}{\\theta^3} = 0 \\ \\Rightarrow \\ \\hat{\\theta} = \\left(\\frac{16650}{6}\\right)^{\\frac{1}{2}} = 52,6783\\] 4.3.2 Estimación no Paramétrica Utilizando Datos Modificados Los estimadores no paramétricos proporcionan puntos de referencia útiles, por lo que es útil comprender los procedimientos de estimación para datos agrupados, censurados y truncados. 4.3.2.1 Datos Agrupados Como hemos visto en la Sección 4.3.1.1, las observaciones pueden agruparse (también denominadas censuradas por intervalos) en el sentido de que solo las observamos como pertenecientes a uno de los \\(k\\) intervalos de la forma \\((c_{j-1},c_j]\\), para \\(j=1,\\ldots,k\\). En los límites, la función de distribución empírica se define de la manera habitual: \\[ F_n(c_j) = \\frac{\\text{número de observaciones } \\le c_j}{n}. \\] Para otros valores de \\(x \\in (c_{j-1},c_j)\\), podemos estimar la función de distribución con el estimador ogive, que interpola linealmente entre \\(F_n(c_{j-1})\\) y \\(F_n(c_j)\\), es decir, los valores de los límites \\(F_n(c_{j-1})\\) y \\(F_n (c_j)\\) están conectados con una línea recta. Esto puede expresarse formalmente como \\[F_n(x) = \\frac{c_j-x}{c_j-c_{j-1}} F_n(c_{j-1}) + \\frac{x-c_{j-1}}{c_j-c_{j-1}} F_n(c_j) \\ \\ \\ \\text{para } c_{j-1} \\le x &lt; c_j\\] La densidad correspondiente es \\[f_n(x) = F^{\\prime}_n(x) = \\frac{F_n(c_j)-F_n(c_{j-1})}{c_j - c_{j-1}} \\ \\ \\ \\text{para } c_{j-1} \\le x &lt; c_j .\\] Ejemplo 4.3.4. Pregunta de Examen Actuarial. Se le proporciona la siguiente información sobre los cantidades reclamadas para 100 siniestros: \\[ {\\small \\begin{array}{r|c} \\hline \\text{Tamaño del Siniestro} &amp; \\text{Número de Siniestros } \\\\ \\hline 0 – 1.000 &amp; 16 \\\\ 1.000 – 3.000 &amp; 22 \\\\ 3.000 – 5.000 &amp; 25 \\\\ 5.000 – 10.000 &amp; 18 \\\\ 10.000 – 25.000 &amp; 10 \\\\ 25.000 – 50.000 &amp; 5 \\\\ 50.000 – 100.000 &amp; 3 \\\\ \\text{mayor } 100.000 &amp; 1 \\\\ \\hline \\end{array} } \\] Usando el estimador ogive, calcule la estimación de la probabilidad de que un siniestro elegido al azar esté entre 2000 y 6000. Mostrar solución del ejemplo Solución. En los límites, la función de distribución empírica se define de la manera habitual, por lo que tenemos \\[F_{100}(1000) = 0,16, \\ F_{100}(3000)=0,38, \\ F_{100}(5000)=0,63, \\ F_{100}(10000)=0,81.\\] Para otros tamaños del siniestro, el estimador ogive interpola linealmente entre estos valores: \\[F_{100}(2000) = 0,5F_{100}(1000) + 0,5F_{100}(3000) = 0,5(0,16)+0,5(0,38)=0,27\\] \\[F_{100}(6000)=0,8F_{100}(5000)+0,2F_{100}(10000) = 0,8(0,63)+0,2(0,81)=0,666\\] Por lo tanto, la probabilidad de que una reclamación esté entre 2000 y 6000 es \\(F_{100}(6000) - F_{100}(2000) = 0,666-0,27 = 0,396\\). 4.3.2.2 Función de Distribución Empírica Censurada por la Derecha Puede ser útil calibrar los estimadores paramétricos con métodos no paramétricos que no se basen en una forma paramétrica de la distribución. El estimador de límite de producto propuesto por (Kaplan and Meier 1958) es un estimador de la función de distribución bien conocido en presencia de censura. Motivación para el Estimador de Límite de Producto de Kaplan-Meier. Para explicar por qué el límite de producto funciona tan bien con observaciones censuradas, volvamos primero al caso “habitual” sin censura. Aquí, la función de distribución empírica \\(F_n(x)\\) es un estimador insesgado de la función de distribución \\(F(x)\\). Esto se debe a que \\(F_n(x)\\) es el promedio de las variables indicadoras, cada una de las cuales es insesgada, es decir, \\(\\mathrm{E~}I(X_i \\le x) = \\Pr(X_i \\le x) = F(x)\\). Ahora supongamos que la variable aleatoria está censurada por la derecha por una cantidad límite, por ejemplo, \\(C_U\\), de modo que registramos el menor de los dos, \\(X^* = \\min(X, C_U)\\). Para valores de \\(x\\) que son menores que \\(C_U\\), la variable indicadora todavía proporciona un estimador insesgado de la función de distribución antes de alcanzar el límite de censura. Es decir, \\(\\mathrm{E ~}I(X^* \\le x) = F(x)\\) porque \\(I(X^* \\le x) = I(X \\le x)\\) para \\(x&lt;C_U\\). Del mismo modo, \\(\\mathrm{E~}I(X^*&gt; x) = 1-F(x) = S(x)\\). En cambio, para \\(x&gt;C_U\\), \\(I(X^* \\le x)\\) en general no es un estimador insesgado de \\(F(x)\\). Como alternativa, consideremos dos variables aleatorias que tienen diferentes límites de censura. Por ejemplo, supongamos que observamos \\(X_1^* = \\min(X_1, 5)\\) y \\(X_2^* = \\min(X_2, 10)\\), donde \\(X_1\\) y \\(X_2\\) son extracciones independientes de la misma distribución. Para \\(x\\le 5\\), la función de distribución empírica \\(F_2(x)\\) es un estimador insesgado de \\(F(x)\\). Sin embargo, para \\(5&lt;x \\le 10\\), la primera observación no puede usarse para la función de distribución debido a la limitación de censura. En cambio, la estrategia desarrollada por (Kaplan and Meier 1958) es usar \\(S_2(5)\\) como estimador de \\(S(5)\\) y luego usar la segunda observación para estimar la función de supervivencia condicional a la supervivencia al tiempo 5, \\(\\Pr(X&gt;x|X&gt;5) = \\frac {S(x)}{S(5)}\\). Específicamente, para \\(5&lt;x \\le 10\\), el estimador de la función de supervivencia es \\[ \\hat{S}(x) = S_2(5) \\times I(X_2^* &gt; x ) . \\] Estimador del límite de producto de Kaplan-Meier. Ampliando esta idea, para cada observación \\(i\\), sea \\(u_i\\) el límite superior de censura (\\(= \\infty\\) si no hay censura). Por lo tanto, el valor registrado es \\(x_i\\) en el caso de no censura y \\(u_i\\) si hay censura. Supongamos que \\(t_{1}&lt;\\cdots&lt;t_{k}\\) sean \\(k\\) puntos distintos en los que se produce una pérdida sin censura, y que \\(s_j\\) sea el número de pérdidas sin censura \\(x_i\\)’s en \\(t_{j}\\). El conjunto de riesgo correspondiente es el número de observaciones que están activas (no censuradas) en un valor menor que \\(t_{j}\\), denotado como \\(R_j=\\sum_{i = 1}^n I(x_i \\geq t_{j})+\\sum_{i = 1}^n I(u_i \\geq t_{j})\\). Con esta notación, el estimador del límite de producto de la función de distribución es \\[\\begin{equation} \\hat{F}(x) = \\left\\{ \\begin{array}{ll} 0 &amp; x&lt;t_{1} \\\\ 1-\\prod_{j:t_{j} \\leq x}\\left( 1-\\frac{s_j}{R_{j}}\\right) &amp; x \\geq t_{1} \\end{array} \\right. .\\tag{4.6} \\end{equation}\\] Como de costumbre, la estimación correspondiente de la función de supervivencia es \\(\\hat{S}(x) = 1 - \\hat{F}(x)\\). Ejemplo 4.3.5. Pregunta de Examen Actuarial. La siguiente es una muestra de 10 pagos: \\[ \\begin{array}{cccccccccc} 4 &amp;4 &amp;5+ &amp;5+ &amp;5+ &amp;8 &amp;10+ &amp;10+ &amp;12 &amp;15 \\\\ \\end{array} \\] donde \\(+\\) indica que una pérdida ha excedido el límite de la póliza. Usando el estimador de límite de producto de Kaplan-Meier, calcule la probabilidad de que la pérdida en una póliza exceda 11, \\(\\hat{S}(11)\\). Mostrar solución del ejemplo Solución. Hay cuatro tiempos de eventos (observaciones no censuradas). Para cada tiempo \\(t_j\\), podemos calcular el número de eventos \\(s_j\\) y el conjunto de riesgo \\(R_j\\) de la siguiente manera: \\[ \\begin{array}{cccc} \\hline j &amp; t_j &amp; s_j &amp; R_j \\\\ \\hline 1 &amp; 4 &amp; 2 &amp; 10 \\\\ 2 &amp; 8 &amp; 1 &amp; 5 \\\\ 3 &amp; 12 &amp; 1 &amp; 2 \\\\ 4 &amp; 15 &amp; 1 &amp; 1 \\\\ \\hline \\end{array} \\] Asi, la estimación de Kaplan-Meier de \\(S(11)\\) es \\[ \\begin{aligned} \\hat{S}(11) &amp;= \\prod_{j:t_j\\leq 11} \\left( 1- \\frac{s_j}{R_j} \\right) = \\prod_{j=1}^{2} \\left( 1- \\frac{s_j}{R_j} \\right)\\\\ &amp;= \\left(1-\\frac{2}{10} \\right) \\left(1-\\frac{1}{5} \\right) = (0,8)(0,8)= 0,64. \\\\ \\end{aligned} \\] Ejemplo. 4.3.6. Siniestros con Daños Corporales. Consideramos nuevamente los datos de la aplicación de Derrig, Ostaszewski, and Rempala (2001) de siniestros por daños corporales en automóviles en Boston, que se presentaron en el Ejemplo 4.1.11. En ese ejemplo, omitimos los siniestros 17 que fueron censurados por los límites de la póliza. Ahora, incluimos el conjunto de datos completo y utilizamos el estimador del límite de producto de Kaplan-Meier para estimar la función de supervivencia. Esto se muestra en la Figura 4.14. Figure 4.14: Estimación de Kaplan-Meier de la función de supervivencia para siniestros por daños corporales Mostrar código R library(survival) # para Surv(), survfit() ## KM estimación KM0 &lt;- survfit(Surv(AmountPaid, UnCensored) ~ 1, type=&quot;kaplan-meier&quot;, data=BIData) plot(KM0, conf.int=FALSE, xlab=&quot;x&quot;,ylab=&quot;Supervivencia de Kaplan Meier &quot;) 4.3.2.3 Función de Distribución Empírica Censurada por la Derecha, Truncada por la Izquierda Además de la censura por la derecha, ahora ampliamos el marco para permitir datos truncados por la izquierda. Como antes, para cada observación \\(i\\), sea \\(u_i\\) el límite superior de censura (\\(= \\infty\\) si no hay censura). Además, sea \\(d_i\\) el límite inferior de truncamiento (0 si no hay truncamiento). Por lo tanto, el valor registrado (si es mayor que \\(d_i\\)) es \\(x_i\\) en el caso de no censura y \\(u_i\\) si hay censura. Supongamos que \\(t_{1} &lt;\\cdots &lt;t_{k}\\) son \\(k\\) puntos distintos en los que se produce un evento de interés, y que \\(s_j\\) son el número de eventos registrados \\(x_i\\)’s en el punto de tiempo \\(t_{j}\\). El conjunto de riesgos correspondiente es \\[R_j = \\sum_{i=1}^n I(x_i \\geq t_{j}) + \\sum_{i=1}^n I(u_i \\geq t_{j}) - \\sum_{i=1}^n I(d_i \\geq t_{j}).\\] Con esta nueva definición del conjunto de riesgos, el estimador del límite de producto de la función de distribución es como en la ecuación (4.6). Fórmula de Greenwood. (Greenwood 1926) obtuvo la fórmula para que la varianza estimada del estimador de límite de producto sea \\[\\widehat{Var}(\\hat{F}(x)) = (1-\\hat{F}(x))^{2} \\sum _{j:t_{j} \\leq x} \\dfrac{s_j}{R_{j}(R_{j}-s_j)}.\\] El método de R survfit utiliza un objeto de datos de supervivencia y crea un nuevo objeto que contiene la estimación de Kaplan-Meier de la función de supervivencia junto con los intervalos de confianza. El método de Kaplan-Meier (type = 'kaplan-meier') se usa por defecto para construir una estimación de la curva de supervivencia. La función de supervivencia discreta resultante tiene puntos de masa en los tiempos de evento observados (fechas de alta) \\(t_j\\), donde la probabilidad de supervivencia de un evento a esa duración se estima como el número de eventos observados en la duración \\(s_j\\) dividido por el número de sujetos expuestos o ‘en riesgo’ justo antes de la duración del evento \\(R_j\\). Dos tipos alternativos de estimación también están disponibles para el método survfit. La alternativa (type='fh2') maneja los empates, en esencia, al suponer que ocurren varios eventos con la misma duración en un orden arbitrario. Otra alternativa (type='fleming-harrington') usa el estimador de Nelson-Aalen (see (Aalen 1978)) en la estimación de la función de riesgo (hazard) acumulado para obtener una estimación de la función de supervivencia. El riesgo acumulado estimado \\(\\hat{H}(x)\\) comienza en cero y se incrementa en cada evento observado de duración \\(t_j\\) por el número de eventos \\(s_j\\) dividido por el número en riesgo \\(R_j\\). Con la misma notación anterior, el estimador de Nelson-Aalen de la función de distribución es \\[ \\begin{aligned} \\hat{F}_{NA}(x) &amp;= \\left\\{ \\begin{array}{ll} 0 &amp; x&lt;t_{1} \\\\ 1- \\exp \\left(-\\sum_{j:t_{j} \\leq x}\\frac{s_j}{R_j} \\right) &amp; x \\geq t_{1} \\end{array} \\right. .\\end{aligned} \\] Cabe tener en cuenta que la expresión anterior es el resultado del estimador de Nelson-Aalen de la función de riesgo acumulado \\[\\hat{H}(x) = \\sum_{j: t_j \\leq x}\\frac{s_j}{R_j}\\] y la relación entre la función de supervivencia y la función de riesgo acumulado es \\(\\hat{S}_{NA}(x) = e^{-\\hat{H}(x)}\\). Ejemplo 4.3.7. Pregunta de Examen Actuarial. Para la observación \\(i\\) de un estudio de supervivencia: \\(d_i\\) es el punto de truncamiento a la izquierda \\(x_i\\) es el valor observado si no está censurado a la derecha \\(u_i\\) es el valor observado si se censura a la derecha Te dan: \\[ {\\small \\begin{array}{c|cccccccccc} \\hline \\text{Observación } (i) &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7 &amp; 8 &amp; 9 &amp; 10\\\\ \\hline d_i &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1,3 &amp; 1,5 &amp; 1,6\\\\ x_i &amp; 0,9 &amp; - &amp; 1,5 &amp; - &amp; - &amp; 1,7 &amp; - &amp; 2,1 &amp; 2,1 &amp; - \\\\ u_i &amp; - &amp; 1,2 &amp; - &amp; 1,5 &amp; 1,6 &amp; - &amp; 1,7 &amp; - &amp; - &amp; 2,3 \\\\ \\hline \\end{array} } \\] Calcular la estimación del límite de producto de Kaplan-Meier, \\(\\hat{S}(1,6)\\) Mostrar solución del ejemplo Solución. Recordemos el conjunto de riesgo \\(R_j = \\sum_{i=1}^n \\left\\{ I(x_i \\geq t_{j}) + I(u_i \\geq t_{j}) - I(d_i \\geq t_{j}) \\right\\}\\). Entonces \\[ \\begin{array}{ccccc} \\hline j &amp; t_j &amp; s_j &amp; R_j &amp; \\hat{S}(t_j) \\\\ \\hline 1 &amp; 0,9 &amp; 1 &amp; 10-3 = 7 &amp; 1-\\frac{1}{7} = \\frac{6}{7} \\\\ 2 &amp; 1,5 &amp; 1 &amp; 8-2 = 6 &amp; \\frac{6}{7}\\left( 1 - \\frac{1}{6} \\right) = \\frac{5}{7}\\\\ 3 &amp; 1,7 &amp; 1 &amp; 5-0 = 5 &amp; \\frac{5}{7}\\left( 1 - \\frac{1}{5} \\right) = \\frac{4}{7}\\\\ 4 &amp; 2,1 &amp; 2 &amp; 3 &amp; \\frac{4}{7}\\left( 1 - \\frac{2}{3}\\right) = \\frac{4}{21}\\\\ \\hline \\end{array} \\] La estimación de Kaplan-Meier es por lo tanto \\(\\hat{S}(1,6) = \\frac{5}{7}\\). Ejemplo 4.3.8. Pregunta de Examen Actuarial. – Continuación. Usando el estimador de Nelson-Aalen, calcular la probabilidad de que la pérdida en una póliza exceda 11, \\(\\hat{S}_{NA}(11)\\). Calcular la aproximación de Greenwood de la varianza de la estimación del límite del producto \\(\\hat{S}(11)\\). Mostrar solución del ejemplo Solución. Como antes, hay cuatro tiempos con eventos (observaciones no censuradas). Para cada tiempo \\(t_j\\) podemos calcular el número de eventos \\(s_j\\) y el conjunto de riesgo \\(R_j\\) de la siguiente manera: \\[ \\begin{array}{cccc} \\hline j &amp; t_j &amp; s_j &amp; R_j \\\\ \\hline 1 &amp; 4 &amp; 2 &amp; 10 \\\\ 2 &amp; 8 &amp; 1 &amp; 5 \\\\ 3 &amp; 12 &amp; 1 &amp; 2 \\\\ 4 &amp; 15 &amp; 1 &amp; 1 \\\\ \\hline \\end{array} \\] El estimador de Nelson-Aalen de \\(S(11)\\) es \\(\\hat{S}_{NA}(11)=e^{-\\hat{H}(11)} = e^{-0,4} = 0,67\\), de modo que \\[ \\begin{aligned} \\hat{H}(11) &amp;= \\sum_{j:t_j\\leq 11} \\frac{s_j}{R_j} = \\sum_{j=1}^{2} \\frac{s_j}{R_j} \\\\ &amp;= \\frac{2}{10} + \\frac{1}{5} = 0,2 + 0,2 = 0,4 .\\\\ \\end{aligned} \\] Del ejercicio anterior, la estimación de Kaplan-Meier de \\(S(11)\\) es \\(\\hat{S}(11) = 0,64\\). Entonces, la estimación de Greenwood de la varianza de la estimación del límite del producto de \\(S(11)\\) es \\[ \\begin{aligned} \\widehat{Var}(\\hat{S}(11)) &amp;= (\\hat{S}(11))^2 \\sum_{j:t_j\\leq 11} \\frac{s_j}{R_j(R_j-s_j)} &amp;= (0,64)^2 \\left(\\frac{2}{10(8)} + \\frac{1}{5(4)} \\right) = 0,0307. \\\\ \\end{aligned} \\] 4.4 Inferencia Bayesiana En esta sección aprende a: Describir el modelo bayesiano como una alternativa al enfoque frecuentista y resumir los cinco componentes de este enfoque de modelización. Describir las distribuciones a posteriori de los parámetros y utilizar estas distribuciones para predecir nuevos resultados. Utilizar distribuciones conjugadas para determinar las distribuciones a posteriori de los parámetros. 4.4.1 Introducción a la Inferencia Bayesiana Hasta este punto, nuestros métodos inferenciales se han centrado en el entorno frecuentista, en el que se extraen muestras repetidamente de una población. El vector de parámetros \\(\\boldsymbol \\theta\\) es fijo pero desconocido, mientras que los resultados \\(X\\) son realizaciones procedentes de variables aleatorias. En contraste, bajo el marco Bayesiano, consideramos los parámetros del modelo y los datos como variables aleatorias. No estamos seguros de los valores de los parámetros \\(\\boldsymbol \\theta\\) y utilizamos herramientas de probabilidad para reflejar esta incertidumbre. Para tener una idea del marco bayesiano, recordemos primero la regla de Bayes \\[ \\Pr(parámetros|datos) = \\frac{\\Pr(datos|parámetros) \\times \\Pr(parámetros)}{\\Pr(datos)} \\] donde \\(\\Pr(parámetros)\\) es la distribución de los parámetros, conocida como la distribución a priori. \\(\\Pr(datos|parámetros)\\) es la distribución de muestreo. En un contexto frecuentista, se usa para realizar inferencias sobre los parámetros y se conoce como probabilidad. \\(\\Pr(parámetros|datos)\\) es la distribución de los parámetros que han observado los datos, conocidos como la distribución a posteriori. \\(\\Pr(datos)\\) es la distribución marginal de los datos. Generalmente se obtiene integrando (o sumando) la distribución conjunta de datos y parámetros sobre los valores de los parámetros. ¿Por qué Bayes? Hay varias ventajas del enfoque bayesiano. Primero, podemos describir la distribución completa de parámetros condicionada a los datos. Esto nos permite, por ejemplo, proporcionar resultados de probabilidad con respecto a la verosimilitud de los parámetros. En segundo lugar, el enfoque bayesiano proporciona una alternativa unificada para estimar parámetros. Algunos métodos no bayesianos, como los mínimos cuadrados, requieren un enfoque separado para estimar los componentes de la varianza. Por el contrario, en los métodos bayesianos, todos los parámetros se pueden tratar de manera similar. Esto es conveniente para explicar los resultados a los usuarios del análisis de datos. Tercero, este enfoque permite a los analistas combinar información previa conocida de otras fuentes con los datos de manera coherente. Este tema se desarrolla en detalle en el capítulo de credibilidad. Cuarto, el análisis bayesiano es particularmente útil para pronosticar respuestas futuras. Caso particular de Poisson - Gamma. Para desarrollar el método bayesiano de forma intuitiva, consideramos el caso de Poisson-Gamma que ocupa un lugar destacado en las aplicaciones actuariales. La idea es considerar un conjunto de variables aleatorias \\(X_1,\\ldots, X_n\\), donde cada \\(X_i\\) podría representar el número de siniestros para el titular de la póliza i-ésima. Supongamos que \\(X_i\\) tiene una distribución de Poisson con parámetro \\(\\lambda\\), análoga a la probabilidad que vimos por primera vez en el Capítulo 2. En un contexto no bayesiano (o frecuentista), el parámetro \\(\\lambda\\) se ve como una cantidad desconocida que no es aleatoria (se dice que es “fija”). En el contexto bayesiano, el parámetro desconocido \\(\\lambda\\) se considera incierto y se modeliza como una variable aleatoria. En este caso particular, utilizamos la distribución gamma para reflejar esta incertidumbre, la distribución a priori. Pensemos en el siguiente esquema de muestreo en dos etapas para argumentar esta configuración probabilística. En la primera etapa, el parámetro \\(\\lambda\\) se extrae de una distribución gamma. En la segunda etapa, para ese valor de \\(\\lambda\\), hay \\(n\\) extracciones de la misma distribución de Poisson, que son independientes, condicionadas a \\(\\lambda\\). De esta configuración sencilla, surgen algunas conclusiones importantes. La distribución de \\(X_i\\) ya no es Poisson. Para el caso particular, es una distribución binomial negativa (ver el siguiente “Fragmento de teoría”). Las variables aleatorias \\(X_1, \\ldots, X_n\\) no son independientes. Esto se debe a que comparten la variable aleatoria común \\(\\lambda\\). Como en el contexto frecuentista, el objetivo es hacer afirmaciones sobre los valores probables de los parámetros, tales como \\(\\lambda\\), dado los datos observados \\(X_1, \\ldots, X_n\\). Sin embargo, debido a que ahora tanto el parámetro como los datos son variables aleatorias, podemos usar el lenguaje de probabilidad condicionada para hacer tales afirmaciones. Como veremos en la Sección 4.4.4, resulta que la distribución de \\(\\lambda\\) dados los datos \\(X_1, \\ldots, X_n\\) también es gamma (con parámetros actualizados), un resultado que simplifica la tarea de inferir valores probables del parámetro \\(\\lambda\\). Mostrar un fragmento de teoría Demostremos que la distribución de \\(X\\) es binomial negativa. Suponemos que la distribución de \\(X\\) dada \\(\\lambda\\) es Poisson, de modo que \\[ \\Pr(X = x|\\lambda) = \\frac{\\lambda^x}{\\Gamma(x+1)} e^{-\\lambda} , \\] usando la notación \\(\\Gamma(x+1) = x!\\) para el entero \\(x\\). Suponga que \\(\\lambda\\) es una extracción de una distribución gamma con parámetros fijos, por ejemplo, \\(\\alpha\\) y \\(\\theta\\), por lo que esto tiene pdf función de probabilidad de densidad \\[ f(\\lambda) = \\frac{\\lambda^{\\alpha-1}}{\\theta^{\\alpha}\\Gamma(\\alpha)}\\exp(-\\lambda/\\theta). \\] Sabemos que una pdf integra uno. Para facilitar el desarrollo, definimos el parámetro recíproco \\(\\theta_r = 1/\\theta\\) y así tenemos \\[ \\int_0^{\\infty} f(\\lambda) ~d\\lambda =1 ~~~ ==&gt; ~~~ \\theta_r^{-\\alpha} \\Gamma(\\alpha) = \\int_0^{\\infty} \\lambda^{\\alpha-1} \\exp\\left(-\\lambda\\theta_r\\right) ~ d\\lambda . \\] A partir del Capítulo de Apéndice 16 en esperanzas iteradas, tenemos que la pmf función masa de probabilidad de \\(X\\) se puede calcular de forma iterada como \\[ \\begin{aligned} \\Pr(X = x) &amp;= \\mathrm{E} \\left\\{\\Pr(X = x|\\lambda)\\right\\}\\\\ &amp;= \\int_0^{\\infty} \\Pr(X = x|\\lambda) f(\\lambda) ~d\\lambda \\\\ &amp;= \\int_0^{\\infty} \\frac{\\lambda^x}{\\Gamma(x+1)} e^{-\\lambda} \\frac{\\lambda^{\\alpha-1}}{\\theta^{\\alpha}\\Gamma(\\alpha)}\\exp(-\\lambda/\\theta) ~d\\lambda\\\\ &amp;= \\frac{1}{\\theta^{\\alpha}\\Gamma(x+1)\\Gamma(\\alpha)} \\int_0^{\\infty} \\lambda^{x+\\alpha-1} \\exp\\left(-\\lambda(1+\\frac{1}{\\theta})\\right) ~d\\lambda \\\\ &amp;= \\frac{1}{\\theta^{\\alpha}\\Gamma(x+1)\\Gamma(\\alpha)} \\Gamma(x+\\alpha)\\left(1+\\frac{1}{\\theta}\\right)^{-(x+\\alpha)} \\\\ &amp;= \\frac{\\Gamma(x+\\alpha)}{\\Gamma(x+1)\\Gamma(\\alpha)}\\left(\\frac{1}{1+\\theta}\\right)^{\\alpha} \\left(\\frac{\\theta}{1+\\theta}\\right)^{x} .\\\\ \\end{aligned} \\] Aquí, utilizamos la igualdad de distribución gamma con la sustitución \\(\\theta_r = 1+1/\\theta\\). Como se puede ver en la Sección2.2.3.3, ésta es una distribución binomial negativa con parámetro \\(r = \\alpha\\) y \\(\\beta = \\theta\\). En este capítulo, usamos ejemplos sencillos que se pueden hacer a mano para ilustrar los fundamentos. Para una implementación práctica, los analistas dependen en gran medida de los métodos de simulación que utilizan métodos computacionales modernos como la simulación Markov Chain Monte Carlo (MCMC). Realizaremos una introducción a las técnicas de simulación en el Capítulo 6, pero las técnicas más intensivas como MCMC requieren referencias adicionales. Ver @ hartman2016 para una introducción a los métodos bayesianos computacionales desde una perspectiva actuarial. 4.4.2 Modelo Bayesiano Con el desarrollo intuitivo de la Sección anterior 4.4.1, ahora reformulamos el modelo bayesiano con un poco más de precisión utilizando la notación matemática. Para simplificar, este resumen supone que tanto los resultados como los parámetros son variables aleatorias continuas. En los ejemplos, a veces le pedimos al lector que aplique estos mismos principios a versiones discretas. Conceptualmente, tanto los casos continuos como los discretos son iguales; mecánicamente, uno reemplaza unpdf función de densidad de probabilidad por una pmf función masa de probabilidad y una integral por una suma. Como se indicó anteriormente, bajo la perspectiva bayesiana, los parámetros y los datos del modelo se consideran aleatorios. Nuestra incertidumbre sobre los parámetros del proceso subyacente de generación de datos se refleja en el uso de herramientas de probabilidad. Distribución A Priori. En concreto, pensemos en los parámetros \\(\\boldsymbol \\theta\\) como un vector aleatorio y denotemos \\(\\pi(\\boldsymbol \\theta)\\) a la distribución de posibles resultados. Éste es el conocimiento que tenemos antes de que se observen los resultados y se denomina distribución a priori. Por lo general, la distribución a priori es una distribución regular y, por lo tanto, se integra o suma uno, dependiendo de si \\(\\boldsymbol \\theta\\) es continuo o discreto. Sin embargo, podemos estar muy inseguros (o no tener idea) sobre la distribución de \\(\\boldsymbol \\theta\\); la maquinaria bayesiana permite la siguiente situación \\[\\int \\pi(\\theta) d\\theta = \\infty, \\] en cuyo caso \\(\\pi(\\cdot)\\) se denomina una impropia prior (improper prior). Distribución del Modelo. La distribución de resultados dado un valor supuesto de \\(\\boldsymbol \\theta\\) se conoce como la distribución del modelo y se denota como \\(f(x|\\boldsymbol \\theta) = f_{X|\\boldsymbol \\theta}(x|\\boldsymbol \\theta)\\). Esta es la función habitual de masa o densidad frecuentista. Ésta es simplemente la probabilidad en el contexto frecuentista y, por lo tanto, también es conveniente usar esto como un descriptor para la distribución del modelo. Distribución conjunta. La distribución de resultados y parámetros del modelo es, como era de esperar, conocida como la distribución conjunta y se denota como \\(f(x, \\boldsymbol \\theta) = f(x|\\boldsymbol \\theta) \\pi(\\boldsymbol \\theta)\\). Distribución marginal de resultados. La distribución de resultados puede expresarse como \\[f(x) = \\int f(x | \\boldsymbol \\theta)\\pi(\\boldsymbol \\theta) ~d \\boldsymbol \\theta.\\] Esto es análogo a una distribución de mixtura frecuentista. En la distribución de la mixtura, combinamos (o “mezclamos”) diferentes subpoblaciones. En el contexto bayesiano, la distribución marginal es una combinación de diferentes realizaciones de parámetros (en algunos contextos, se puede pensar que se combinan diferentes “estados de la naturaleza”). Distribución a posteriori de los parámetros. Después de observar los resultados (de ahí la terminología “a posteriori”), se puede usar el teorema de Bayes para escribir la distribución como \\[\\pi(\\boldsymbol \\theta | x) =\\frac{f(x , \\boldsymbol \\theta)}{f(x)} =\\frac{f(x|\\boldsymbol \\theta )\\pi(\\boldsymbol \\theta)}{f(x)}\\] La idea es actualizar el conocimiento de la distribución de \\(\\boldsymbol \\theta\\) (\\(\\pi(\\boldsymbol \\theta)\\)) con los datos \\(x\\). Determinar los valores potenciales de los parámetros es un aspecto importante de la inferencia estadística. 4.4.3 Inferencia Bayesiana 4.4.3.1 Describiendo la Distribución A Posteriori de los Parámetros Una forma de describir una distribución es mediante intervalos de confianza. Para describiri la distribución de los parámetros a posteriori, se dice que el intervalo \\([a, b]\\) es un intervalo de \\(100(1- \\alpha)\\%\\) de credibilidad para \\(\\boldsymbol \\theta\\) si \\[\\Pr(a \\le \\theta \\le b | \\mathbf{x}) \\ge 1- \\alpha.\\] Como alternativa, se puede realizar el análisis de decisión clásico. En esta configuración, la función de pérdida \\(l(\\hat{\\theta}, \\theta)\\) determina el coste pagado por usar la estimación \\(\\hat{\\theta}\\) en lugar del verdadero \\(\\theta\\). La estimación de Bayes es el valor que minimiza la pérdida esperada \\(\\mathrm{E~}[l(\\hat{\\theta}, \\theta)]\\). Algunos casos especiales importantes incluyen: \\[ {\\small \\begin{array}{cll} \\hline \\text{Función de Pérdida} l(\\hat{\\theta}, \\theta) &amp; \\text{Descripción} &amp; \\text{Estimación de Bayes } \\\\ \\hline (\\hat{\\theta}- \\theta)^2 &amp; \\text{Pérdida de error al cuadrado} &amp; \\mathrm{E}(\\theta|X) \\\\ |\\hat{\\theta}- \\theta| &amp; \\text{Pérdida de desviación absoluta} &amp; \\text{Mediana de} \\pi(\\theta|x) \\\\ I(\\hat{\\theta} =\\theta) &amp; \\text{Pérdida cero-uno (para probabilidades discretas)} &amp; \\text{Moda de } \\pi(\\theta|x) \\\\ \\hline \\end{array} } \\] Minimizar la pérdida esperada es un método riguroso para proporcionar un “mejor supuesto” sobre un valor probable de un parámetro, comparable a un estimador frecuentista del parámetro desconocido (fijo). Ejemplo 4.4.1. Pregunta de Examen Actuarial. Te dan: En una cartera de riesgos, cada asegurado puede tener como máximo un siniestro por año. La probabilidad de siniestro para un asegurado durante un año es \\(q\\). La densidad a priori es \\[\\pi(q) = q^3/0,07, \\ \\ \\ 0,6 &lt;q &lt;0,8\\] Un asegurado seleccionado al azar tiene un siniestro en el año 1 y cero siniestros en el año 2. Para este asegurado, calcular la probabilidad a posteriori de que \\(0,7 &lt;q &lt;0,8\\). Mostrar solución del ejemplo Solución. La densidad a posteriori es proporcional al producto de la función de probabilidad y la densidad a priori. Así, \\[\\pi(q|1,0) \\propto f(1|q)\\ f(0|q)\\ \\pi(q) \\propto q(1-q)q^3 = q^4-q^5.\\] Para obtener la densidad a posteriori exacta, integramos la función anterior en su rango \\((0,6, 0,8)\\) \\[\\int_{0,6}^{0,8} q^4-q^5 dq = \\frac{q^5}{5} - \\left. \\frac{q^6}{6} \\right|_{0,6}^{0,8} = 0,014069 \\ \\Rightarrow \\ \\pi(q|1,0)=\\frac{q^4-q^5}{0,014069}.\\] Entonces \\[\\Pr(0,7&lt;q&lt;0,8|1,0)= \\int_{0,7}^{0,8} \\frac{q^4-q^5}{0,014069}dq = 0,5572.\\] Ejemplo 4.4.2. Pregunta de Examen Actuarial. Te dan: La distribución a priori del parámetro \\(\\Theta\\) tiene una función de densidad de probabilidad: \\[\\pi(\\theta) = \\frac{1}{\\theta^2}, \\ \\ 1 &lt;\\theta &lt;\\infty \\] Dado \\(\\Theta = \\theta\\), la cuantía de los siniestros sigue una distribución de Pareto con parámetros \\(\\alpha = 2\\) y \\(\\theta\\). Se observa una siniestr de 3. Calcular la probabilidad a posteriori de que \\(\\Theta\\) exceda 2. Mostrar solución del ejemplo Solución: La densidad a posteriori, dada una observación con valor 3 es \\[\\pi(\\theta|3) = \\frac{f(3|\\theta)\\pi(\\theta)}{\\int_1^\\infty f(3|\\theta)\\pi(\\theta)d\\theta} = \\frac{\\frac{2\\theta^2}{(3+\\theta)^3}\\frac{1}{\\theta^2}}{\\int_1^\\infty 2(3+\\theta)^{-3} d\\theta} = \\frac{2(3+\\theta)^{-3}}{\\left. -(3+\\theta)^{-2}\\right|_1^\\infty} = 32(3+\\theta)^{-3}, \\ \\ \\theta &gt; 1.\\] Entonces \\[\\Pr(\\Theta&gt;2|3) = \\int_2^\\infty 32(3+\\theta)^{-3}d\\theta = \\left. -16(3+\\theta)^{-2} \\right|_2^\\infty = \\frac{16}{25} = 0,64.\\] 4.4.3.2 Distribución Predictiva Bayesiana Para otro tipo de inferencia estadística, a menudo es interesante “predecir” el valor de un resultado aleatorio que aún no se ha observado. En particular, para los nuevos datos \\(y\\), la distribución predictiva es \\[f(y|x) = \\int f(y|\\theta)\\pi(\\theta | x) d \\theta.\\] A veces también se le llama distribución “a posteriori” ya que la distribución de los nuevos datos está condicionada a un conjunto base de datos. Usando el error al cuadrado como la función de pérdida, la predicción bayesiana de \\(Y\\) es \\[ \\begin{aligned} \\mathrm{E}(Y|X) &amp;= \\int ~y f(y|X) dy = \\int y \\left(\\int f(y|\\theta) \\pi(\\theta|X) d\\theta \\right) dy \\\\ &amp;= \\int \\mathrm{E}(Y|\\theta) \\pi(\\theta|X) ~d\\theta . \\end{aligned} \\] Como se señaló anteriormente, para algunas situaciones la distribución de los parámetros es discreta, no continua. Tener un conjunto discreto de posibles parámetros nos permite pensar en ellos como “estados de la naturaleza” alternativos, lo que proporciona una interpretación útil. Ejemplo 4.4.3. Pregunta de Examen Actuarial. Para una póliza en particular, las probabilidades condicionadas del número anual de siniestros, dado \\(\\Theta = \\theta\\), y la distribución de probabilidad de \\(\\Theta\\) son las siguientes: \\[ {\\small \\begin{array}{l|ccc} \\hline \\text{Número de Siniestros} &amp; 0 &amp; 1 &amp; 2 \\\\ \\text{Probabilidad} &amp; 2\\theta &amp; \\theta &amp; 1-3\\theta \\\\ \\hline \\end{array} } \\] \\[ {\\small \\begin{array}{l|cc} \\hline \\theta &amp; 0,05 &amp; 0,30 \\\\ \\text{Probabilidad} &amp; 0,80 &amp; 0,20 \\\\ \\hline \\end{array} } \\] Se observan dos siniestros en el año 1. Calcular la predicción bayesiana del número de siniestros en el año 2. Mostrar solución del ejemplo Solución. Comenzamos con la distribución a posteriori del parámetro \\[ \\Pr(\\theta|X) = \\frac{\\Pr(X|\\theta)\\Pr(\\theta)}{\\sum_{\\theta}\\Pr(X|\\theta)\\Pr(\\theta)} \\] de modo que \\[ \\begin{aligned} \\Pr(\\theta=0,05|X=2) &amp;= \\frac{\\Pr(X=2|\\theta=0,05)\\Pr(\\theta=0,05)} {\\Pr(X=2|\\theta=0,05)\\Pr(\\theta=0,05)+\\Pr(X=2|\\theta=0,3)\\Pr(\\theta=0,3)}\\\\ &amp;=\\frac{(1-3\\times 0,05)(0,8)}{(1-3\\times 0,05)(0,8)+(1-3\\times 0,3)(0,2)}= \\frac{68}{70}. \\end{aligned} \\] Así, \\(\\Pr(\\theta=0,3|X=1)= 1 - \\Pr(\\theta=0,05|X=1) = \\frac{2}{70}\\). De la distribución del modelo, tenemos \\[ E(X|\\theta) = 0 \\times 2\\theta + 1 \\times \\theta + 2 \\times (1-3\\theta) = 2 - 5 \\theta. \\] Así, \\[ \\begin{aligned} E(Y|X) &amp;= \\sum_{\\theta} \\mathrm{E}(Y|\\theta) \\pi(\\theta|X) \\\\ &amp;= \\mathrm{E}(Y|\\theta=0,05) \\pi(\\theta=0,05|X)+\\mathrm{E}(Y|\\theta=0,3) \\pi(\\theta=0,3|X)\\\\ &amp;= ( 2 - 5 (0,05))\\frac{68}{70} + ( 2 - 5 (0,3))\\frac{2}{70} = 1,714. \\end{aligned} \\] Ejemplo 4.4.4. Pregunta de Examen Actuarial. Te dan: Las pérdidas de las pólizas de seguro de una compañía siguen una distribución de Pareto con función de densidad de probabilidad: \\[ f(x | \\theta) = \\frac{\\theta}{(x + \\theta)^2}, \\ \\ 0 &lt;x &lt;\\infty \\] Para la mitad de las pólizas de la compañía \\(\\theta = 1\\), mientras que para la otra mitad \\(\\theta = 3\\). Para una póliza seleccionada al azar, las pérdidas en el año 1 fueron 5. Calcular la probabilidad a posteriori de que las pérdidas para esta póliza en el año 2 excedan de 8. Mostrar solución del ejemplo Solución. Se nos da la distribución a priori de \\(\\theta\\) como $ (= 1) = (= 3) = $, la distribución condicional \\(f (x | \\theta)\\), y el hecho de que observamos \\(X_1 = 5\\). El objetivo es encontrar la probabilidad predictiva \\(\\Pr(X_2&gt; 8 | X_1 = 5)\\). Las probabilidades a posteriori son \\[ \\begin{aligned} \\Pr(\\theta=1|X_1=5) &amp;= \\frac{f(5|\\theta=1)\\Pr(\\theta=1)}{f(5|\\theta=1)\\Pr(\\theta=1) + f(5|\\theta=3)\\Pr(\\theta=3)} \\\\ &amp;= \\frac{\\frac{1}{36}(\\frac{1}{2})}{\\frac{1}{36}(\\frac{1}{2})+\\frac{3}{64}(\\frac{1}{2})} = \\frac{\\frac{1}{72}}{\\frac{1}{72} + \\frac{3}{128}} = \\frac{16}{43} \\end{aligned} \\] \\[ \\begin{aligned} \\Pr(\\theta=3|X_1=5) &amp;= \\frac{f(5|\\theta=3)\\Pr(\\theta=3)}{f(5|\\theta=1)\\Pr(\\theta=1) + f(5|\\theta=3)\\Pr(\\theta=3)} \\\\ &amp;= 1-\\Pr(\\theta=1|X_1=5) = \\frac{27}{43} \\end{aligned} \\] Tener en cuenta que la probabilidad condicionada de que las pérdidas excedan de 8 es \\[ \\begin{aligned} \\Pr(X_2&gt;8|\\theta) &amp;= \\int_8^\\infty f(x|\\theta)dx \\\\ &amp;= \\int_8^\\infty \\frac{\\theta}{(x+\\theta)^2}dx = \\left. -\\frac{\\theta}{x+\\theta} \\right|_8^\\infty = \\frac{\\theta}{8 + \\theta} \\end{aligned} \\] La probabilidad predictiva es, por lo tanto, \\[ \\begin{aligned} \\Pr(X_2&gt;8|X_1=5) &amp;= \\Pr(X_2&gt;8|\\theta=1) \\Pr(\\theta=1|X_1=5) + \\Pr(X_2&gt;8|\\theta=3) \\Pr(\\theta=3 | X_1=5) \\\\ &amp;= \\frac{1}{8+1}\\left( \\frac{16}{43}\\right) + \\frac{3}{8+3} \\left( \\frac{27}{43}\\right) = 0,2126 \\end{aligned} \\] Ejemplo 4.4.5. Pregunta de Examen Actuarial. Te dan: La probabilidad de que un asegurado tenga al menos una pérdida durante cualquier año es \\(p\\). La distribución a priori de \\(p\\) es uniforme en \\([0, 0,5]\\). Se observa a un asegurado durante 8 años y tiene al menos una pérdida cada año. Calcular la probabilidad a posteriori de que el asegurado tenga al menos una pérdida durante el Año 9. Mostrar solución del ejemplo Solución. La densidad de probabilidad a posteriori es\\[ \\begin{aligned} \\pi(p|1,1,1,1,1,1,1,1) &amp;\\propto \\Pr(1,1,1,1,1,1,1,1|p)\\ \\pi(p) = p^8(2) \\propto p^8 \\\\ \\Rightarrow \\pi(p|1,1,1,1,1,1,1,1) &amp;= \\frac{p^8}{\\int_0^5 p^8 dp} = \\frac{p^8}{(0,5^9)/9} = 9(0,5^{-9})p^8 \\end{aligned} \\] Por lo tanto, la probabilidad a posteriori de que el asegurado tenga al menos una pérdida durante el Año 9 es \\[ \\begin{aligned} \\Pr(X_9=1|1,1,1,1,1,1,1,1) &amp;= \\int_0^5 \\Pr(X_9=1|p) \\pi(p|1,1,1,1,1,1,1,1) dp \\\\ &amp;= \\int_0^5 p(9)(0,5^{-9})p^8 dp = 9(0,5^{-9})(0,5^{10})/10 = 0,45 \\end{aligned} \\] Ejemplo 4.4.6. Pregunta de Examen Actuarial. Te dan: Cada riesgo tiene como máximo una reclamación cada año.\\[ {\\small \\begin{array}{ccc} \\hline \\text{Tipo de Riesgo } &amp; \\text{Probabilidad A Priori } &amp; \\text{Probabilidad Anual de Reclamación } \\\\ \\hline \\text{I} &amp; 0,7 &amp; 0,1 \\\\ \\text{II} &amp; 0,2 &amp; 0,2 \\\\ \\text{III} &amp; 0,1 &amp; 0,4 \\\\ \\hline \\end{array} } \\] Un riesgo elegido al azar tiene tres reclamaciones durante los años 1-6. Calcular la probabilidad a posteriori de una reclamación por este riesgo en el año 7. Mostrar solución del ejemplo Solución. Las probabilidades son de una distribución binomial con 6 ensayos en los que se observaron 3 sucesos. \\[ \\begin{aligned} \\Pr(3|\\text{I}) &amp;= {6 \\choose 3} (0,1^3)(0,9^3) = 0,01458 \\\\ \\Pr(3|\\text{II}) &amp;= {6 \\choose 3} (0,2^3)(0,8^3) = 0,08192 \\\\ \\Pr(3|\\text{III}) &amp;= {6 \\choose 3} (0,4^3)(0,6^3) = 0,27648 \\end{aligned} \\] La probabilidad de observar tres sucesos es \\[ \\begin{aligned} \\Pr(3) &amp;= \\Pr(3|\\text{I})\\Pr(\\text{I}) + \\Pr(3|\\text{II})\\Pr(\\text{II}) + \\Pr(3|\\text{III})\\Pr(\\text{III}) \\\\ &amp;= 0,7(0,01458) + 0,2(0,08192) + 0,1(0,27648) = 0,054238 \\end{aligned} \\] Las tres probabilidades a posteriori son \\[ \\begin{aligned} \\Pr(\\text{I}|3) &amp;= \\frac{\\Pr(3|\\text{I})\\Pr(\\text{I})}{\\Pr(3)} = \\frac{0,7(0,01458)}{0,054238} = 0,18817 \\\\ \\Pr(\\text{II}|3) &amp;= \\frac{\\Pr(3|\\text{II})\\Pr(\\text{II})}{\\Pr(3)} = \\frac{0,2(0,08192)}{0,054238} = 0,30208 \\\\ \\Pr(\\text{III}|3) &amp;= \\frac{\\Pr(3|\\text{III})\\Pr(\\text{III})}{\\Pr(3)} = \\frac{0,1(0,27648)}{0,054238} = 0,50975 \\end{aligned} \\] La probabilidad a posteriori de una reclamación es, entonces, \\[ \\begin{aligned} \\Pr(\\text{siniestro} | 3) &amp;= \\Pr(\\text{claim}|\\text{I})\\Pr(\\text{I} | 3) + \\Pr(\\text{siniestro} | \\text{II})\\Pr(\\text{II} | 3) + \\Pr(\\text{siniestro} | \\text{III}) \\Pr(\\text{III} | 3) \\\\ &amp;= 0,1(0,18817) + 0,2(0,30208) + 0,4(0,50975) = 0,28313 \\end{aligned} \\] 4.4.4 Distribuciones Conjugadas En el marco bayesiano, la clave para la inferencia estadística es comprender la distribución a posteriori de los parámetros. Como se describe en la Sección @ref(S: IntroBayes), el análisis de datos basado en métodos bayesianos utiliza técnicas computacionalmente intensivas como simulación MCMC Markov Chain Monte Carlo. Otro enfoque para calcular distribuciones a posteriori se basa en distribuciones conjugadas. Aunque este enfoque está disponible solo para un número limitado de distribuciones, tiene el atractivo de que proporciona expresiones de forma cerrada para las distribuciones, lo que permite una fácil interpretación de los resultados. Para relacionar las distribuciones a priori y a posteriori de los parámetros, tenemos la relación \\[ \\begin{array}{ccc} \\pi(\\boldsymbol \\theta | x) &amp; = &amp; \\frac{f(x|\\boldsymbol \\theta )\\pi(\\boldsymbol \\theta)}{f(x)} \\\\ &amp; \\propto &amp; f(x|\\boldsymbol \\theta ) \\pi(\\boldsymbol \\theta) \\\\ \\text{a posteriori} &amp; \\text{es proporcional a} &amp; \\text{verosimilitud} \\times \\text{a priori} . \\end{array} \\] Para distribuciones conjugadas, la a posteriori y la a priori provienen de la misma familia de distribuciones. La siguiente ilustración analiza el caso particular de Poisson-gamma, el más conocido en aplicaciones actuariales. Caso Particular – Poisson-Gamma - Continuación. Supongamos una distribución de modelo de Poisson(\\(\\lambda\\)) y que \\(\\lambda\\) siga una distribución a priori gamma(\\(\\alpha, \\theta\\)). En este caso, la distribución a posteriori de \\(\\lambda\\) dados los datos sigue una distribución gamma con nuevos parámetros \\(\\alpha_{post} = \\sum_i x_i + \\alpha\\) y \\(\\theta_{post} = 1/(n + 1 /\\theta)\\). Mostrar detalles del caso particular Caso Particular – Poisson-Gamma – Continuación. La distribución del modelo es \\[f(\\mathbf{x} | \\lambda) = \\prod_{i=1}^n \\frac{\\lambda^{x_i} e^{-\\lambda}}{x_i!} .\\] La distribución a priori es \\[\\pi(\\lambda) = \\frac{\\left(\\lambda/\\theta\\right)^{\\alpha} \\exp(-\\lambda/\\theta)}{\\lambda \\Gamma(\\alpha)}.\\] Por lo tanto, la distribución a posteriori es proporcional a \\[ \\begin{aligned} \\pi(\\lambda | \\mathbf{x}) &amp;\\propto f(\\mathbf{x}|\\theta ) \\pi(\\lambda) \\\\ &amp;= C \\lambda^{\\sum_i x_i + \\alpha -1} \\exp(-\\lambda(n+1/\\theta)) \\end{aligned} \\] donde \\(C\\) es una constante. Se aprecia que se trata de una distribución gamma con nuevos parámetros \\(\\alpha_{post} = \\sum_i x_i + \\alpha\\) y \\(\\theta_{post} = 1/(n + 1/\\theta)\\). Por lo tanto, la distribución gamma es una conjugada a priori para la distribución del modelo de Poisson. Ejemplo 4.4.7. Pregunta de Examen Actuarial. Te dan: La distribución condicionada del número de siniestros por titular de la póliza es una Poisson con un promedio de \\(\\lambda\\). La variable \\(\\lambda\\) tiene una distribución gamma con los parámetros \\(\\alpha\\) y \\(\\theta\\). Para los asegurados con 1 siniestro en el Año 1, la predicción de Bayes para el número de siniestros en el Año 2 es 0,15. Para los asegurados con un promedio de 2 siniestros por año en el año 1 y en el año 2, la predicción de Bayes para el número de siniestros en el año 3 es de 0,20. Calcular \\(\\theta\\). Mostrar solución del ejemplo Solución. Dado que la distribución condicionada del número de siniestros por asegurado, \\(E(X | \\lambda) = Var(X | \\lambda) = \\lambda\\), la predicción de Bayes es \\[ \\begin{aligned} \\mathrm{E}(X_2|X_1) &amp;= \\int \\mathrm{E}(X_2|\\lambda) \\pi(\\lambda|X_1) d\\lambda = \\alpha_{new} \\theta_{new} \\end{aligned} \\] porque la distribución a posteriori es gamma con parámetros \\(\\alpha_{new}\\) y \\(\\theta_{new}\\). Para el año 1, tenemos \\[ 0,15 = (X_1 + \\alpha) \\times \\frac{1}{n+1/\\theta} = (1 + \\alpha) \\times \\frac{1}{1+1/\\theta}, \\] de modo que \\(0,15(1+1/\\theta)= 1 + \\alpha\\). Para el año 2, tenemos \\[ 0,2 = (X_1+X_2 + \\alpha) \\times \\frac{1}{n+1/\\theta} = (4 + \\alpha) \\times \\frac{1}{2+1/\\theta}, \\] de modo que \\(0,2(2+1/\\theta)= 4 + \\alpha\\). Igualando estos resultados \\[ 0,2(2+1/\\theta)=3 + 0,15(1+1/\\theta) \\] resulta que \\(\\theta = 1/55 = 0,018182\\). Las expresiones de forma cerrada significan que los resultados se pueden interpretar y calcular fácilmente; por lo tanto, las distribuciones conjugadas son útiles en la práctica actuarial. Otros dos casos especiales utilizados ampliamente son: La incertidumbre de los parámetros se describe mediante una distribución beta y los resultados tienen una distribución binomial (condicionada al parámetro). La incertidumbre de los parámetros se describe mediante una distribución normal y los resultados se distribuyen condicionalmente como normales. Resultados adicionales sobre las distribuciones conjugadas se resumen en la Sección del Apéndice 16.3. 4.5 Más Recursos y Colaboradores Ejercicios Aquí hay un conjunto de ejercicios que guían al lector a través de algunos de los fundamentos teóricos de Análisis de la Función de Pérdida. Cada tutorial se basa en una o más preguntas de los exámenes actuariales profesionales, generalmente el Examen C de la Sociedad de Actuarios. Tutoriales guiados de Selección de Modelo Autores Edward W. (Jed) Frees y Lisa Gao, University of Wisconsin-Madison, son los principales autores de la versión inicial de este capítulo. Email: jfrees@bus.wisc.edu para comentarios sobre el capítulo y sugerencias de mejora. Los revisores del capítulo incluyen: Andrew Kwon-Nakamura, Hirokazu (Iwahiro) Iwasawa, Eren Dodd. Traducción al español: Catalina Bolancé (Universitat de Barcelona). Bibliography "],
["C-AggLossModels.html", "Chapter 5 Modelos de pérdidas agregadas 5.1 Introducción 5.2 Modelo de riesgo individual 5.3 Modelo de riesgo colectivo 5.4 Cálculo de la distribución de pérdidas agregadas 5.5 Efectos de la modificación de las coberturas 5.6 Otros recursos y colaboradores", " Chapter 5 Modelos de pérdidas agregadas Vista previa del capítulo. Este capítulo presenta modelos de probabilidad para describir la siniestralidad agregada (siniestros totales) de una cartera de pólizas de seguro. Se presentan dos enfoques de modelización tradicionales, el modelo de riesgo individual y el modelo de riesgo colectivo. Además, se analizan estrategias para calcular la distribución de la siniestralidad agregada, entre los que se incluyen métodos exactos en casos específicos, recursión y simulación. Finalmente, se examinan los efectos de las modificaciones individuales en las pólizas, tales como deducibles, coaseguros e inflación, sobre las distribuciones de frecuencia y severidad y, por lo tanto, sobre la distribución de pérdidas agregadas. 5.1 Introducción El objetivo de este capítulo es construir un modelo de probabilidad para describir los siniestros totales de un sistema de seguros que ocurren en un período de tiempo determinado. El sistema de seguros puede ser una única póliza, un contrato de seguro colectivo, una línea de negocio o el conjunto total del negocio de una entidad aseguradora. En este capítulo, siniestros totales se refieren al número o al importe de los siniestros de una cartera de contratos de seguro. Sin embargo, la modelización que se presenta puede adaptarse fácilmente a una configuración más general. Considere una cartera de seguros de \\(n\\) contratos individuales, donde \\(S\\) representa las pérdidas agregadas de la cartera en un período de tiempo determinado. Existen dos enfoques para modelizar las pérdidas agregadas \\(S\\), el modelo de riesgo individual y el modelo de riesgo colectivo. El modelo de riesgo individual considera la pérdida de cada contrato individual y representa las pérdidas agregadas como: \\[\\begin{aligned} S_n=X_1 +X_2 +\\cdots+X_n, \\end{aligned}\\] donde \\(X_i~(i=1,\\ldots,n)\\) se interpreta como el importe de la pérdida del contrato \\(i\\)-ésimo. Cabe destacar que \\(n\\) denota el número de contratos en la cartera y por lo tanto es un número conocido en lugar de una variable aleatoria. En el modelo de riesgo individual normalmente se asume que los \\(X_{i}\\) son independientes. Debido a las diferentes características de cada contrato, como la cobertura y la exposición, los \\(X_{i}\\) no se consideran necesariamente idénticamente distribuidos. Una particularidad de la distribución de cada \\(X_i\\) es la masa de probabilidad en cero que corresponde al evento de no siniestros. El modelo de riesgo colectivo representa las pérdidas agregadas en base a una distribución de frecuencias y una distribución de gravedad: \\[\\begin{aligned} S_N=X_1 +X_2 +\\cdots+X_N. \\end{aligned}\\] Aquí, uno piensa en un número aleatorio de siniestros \\(N\\) que puede representar tanto el número de pérdidas como el número de pagos. En cambio, en el modelo de riesgo individual se considera un número fijo de contratos \\(n\\). Supongamos que \\(X_1, X_2, \\ldots, X_N\\) representa la cuantía de cada pérdida. Cada pérdida puede o no corresponder a un mismo contrato. Por ejemplo, se pueden generar múltiples reclamaciones en un mismo contrato. Normalmente se considera \\(X_i&gt;0\\) ya que si \\(X_i=0\\) entonces el siniestro no ha ocurrido. Frecuentemente se asume que condicionado a \\(N=n\\), \\(X_{1},X_{2},\\ldots ,X_{n}\\) son variables aleatorias iid. La distribución de \\(N\\) se denomina la distribución de frecuencias, y la distribución de \\(X\\) se conoce como la distribución de severidad. Se asume además que \\(N\\) y \\(X\\) son independientes. En el modelo de riesgo colectivo las pérdidas agregadas se pueden descomponer en el proceso de frecuencia (\\(N\\)) y el modelo de gravedad (\\(X\\)). Esta flexibilidad permite al analista estudiar estas dos componentes por separado. Por ejemplo, el crecimiento de las ventas debido a una relajación de los criterios de suscripción podría dar lugar a una mayor frecuencia de pérdidas, pero podría no afectar a la gravedad de las mismas. Del mismo modo, la inflación u otros factores económicos podrían tener un impacto en la severidad pero no en la frecuencia. 5.2 Modelo de riesgo individual Como se menciona previamente, en el modelo de riesgo individual, \\(X_i\\) se considera la pérdida del \\(i\\)-ésimo contrato y se interpreta \\[\\begin{eqnarray*} S_n=X_1 +X_2 +\\cdots+X_n \\end{eqnarray*}\\] como la pérdida agregada de todos los contratos de una cartera o grupo de contratos. Aquí, las \\(X_i\\) no se distribuyen necesariamente de forma idéntica y se cumple que \\[\\begin{aligned} {\\rm E}(S_n) &amp;= \\sum_{i=1}^{n} {\\rm E}(X_i)~. \\end{aligned}\\] Bajo el supuesto de independencia de las \\(X_i\\) (que implica \\(\\mathrm{Cov}\\left( X_i, X_j \\right) = 0\\) para todo \\(i \\neq j\\)), se puede demostrar que \\[\\begin{aligned} {\\rm Var}(S_n) &amp;= \\sum_{i=1}^{n} {\\rm Var}(X_i) \\\\ P_{S_n}(z) &amp;= \\prod_{i=1}^{n}P_{X_i}(z) \\\\ M_{S_n}(t) &amp;= \\prod_{i=1}^{n}M_{X_i}(t), \\end{aligned}\\] donde \\(P_{S_n}(\\cdot)\\) y \\(M_{S_n}(\\cdot)\\) son la función generadora de probabilidad (pgf) y la función generadora de momentos (mgf) de \\(S_n\\), respectivamente. La distribución de cada \\(X_i\\) tiene masa de probabilidad en cero, que corresponde al caso en el que no han habido siniestros en el contrato \\(i\\)-ésimo. Una estrategia para incluir masa en cero en la distribución es construirla en dos partes: \\[\\begin{aligned} X_i = I_i\\times B_i = \\left\\{\\begin{array}{ll} 0~, &amp; \\text{si }~ I_i=0 \\\\ B_i~, &amp; \\text{si }~ I_i=1 \\end{array} \\right. \\end{aligned}\\] Aquí, \\(I_i\\) es una variable de Bernoulli que indica si ocurren o no pérdidas en el contrato \\(i\\)-ésimo, y \\(B_i\\) es una variable aleatoria con soporte no negativo que representa la cuantía de las pérdidas en el contrato condicionado a que han ocurrido. Supongamos que \\(I_1 ,\\ldots,I_n ,B_1 ,\\ldots,B_n\\) son mutuamente independientes. Denotemos \\({\\rm Pr} (I_i =1)=q_i\\), \\(\\mu_i={\\rm E}(B_i)\\), y \\(\\sigma_i^2={\\rm Var}(B_i)\\). Se demuestra (véase Suplemento técnico 5.A.1 para más detalles) que \\[\\begin{aligned} \\mathrm{E}(S_n)&amp; =\\sum_{i=1}^n ~q_i ~\\mu _i \\\\ \\mathrm{Var}(S_n) &amp; =\\sum_{i=1}^n \\left( q_i \\sigma _i^2+q_i (1-q_i)\\mu_i^2 \\right)\\\\ P_{S_n}(z) &amp; =\\prod_{i=1}^n \\left( 1-q_i+q_i P_{B_i}(z) \\right)\\\\ M_{S_n}(t) &amp; =\\prod_{i=1}^n \\left( 1-q_i+q_i M_{B_i}(t) \\right) \\end{aligned}\\] Un caso particular del modelo anterior es cuando \\(B_i\\) sigue una distribución degenerada con \\(\\mu_i=b_i\\) y \\(\\sigma^2_i=0\\). Un ejemplo es un seguro de vida temporal o seguro de capital diferido en el que \\(b_i\\) representa el importe del capital asegurado en el contrato \\(i\\)-ésimo. Otra estrategia para acomodar masa en cero en la pérdida de cada contrato es considerarlos globalmente a nivel de cartera, como en el modelo de riesgo colectivo. Aquí, la pérdida total es \\(S_{N} = X_1 + \\cdots X_N\\), donde \\(N\\) es una variable aleatoria que representa el número de reclamaciones distintas de cero que se produjeron en todo el conjunto de contratos. Por lo tanto, todos los contratos de la cartera pueden no estar representados en esta suma, y \\(S_N=0\\) cuando \\(N=0\\). El modelo de riesgo colectivo se discutirá en detalle en la siguiente sección. Ejemplo 5.2.1. Pregunta de Examen Actuarial. Una compañía de seguros vendió 300 pólizas de seguro contra incendios de la siguiente forma: \\[ {\\small \\begin{matrix} \\begin{array}{c c c} \\hline \\text{Número de} &amp; \\text{Máximo de la} &amp; \\text{Probabilidad de}\\\\ \\text{Polizas} &amp; \\text{Póliza} &amp; \\text{Siniestro por póliza}\\\\ &amp; (M_i) &amp; (q_i) \\\\ \\hline 100 &amp; 400 &amp; 0,05\\\\ 200 &amp; 300 &amp; 0,06\\\\ \\hline \\end{array} \\end{matrix} } \\] Se sabe que: (i) El coste del siniestro por póliza, \\(X_i\\), se distribuye uniformemente entre \\(0\\) y el máximo de la póliza \\(M_i\\). (ii) La probabilidad de ocurrencia de más de un siniestro por póliza es \\(0\\). (iii) Los siniestros son independientes. Calcular la media, \\(\\mathrm{E~}(S_{300})\\), y la varianza, \\(\\mathrm{Var~}(S_{300})\\), de la siniestralidad total. ¿Como variarán los resultados si ahora cada siniestro es igual al máximo de la póliza? Mostrar Solución de Ejemplo Solución. La siniestralidad total \\(S_{300} = X_1+\\cdots+X_{300}\\), donde \\(X_1, \\ldots, X_{300}\\) son independientes pero no idénticamente distribuidos. El coste de los siniestros se distribuye uniformemente en \\((0,M_i)\\), por lo que el coste medio del siniestro es \\(M_i/2\\) y la varianza es \\(M_i^2/12\\). Por tanto, para la póliza \\(i=1,\\ldots,300\\), se tiene \\[ {\\small \\begin{matrix} \\begin{array}{ccccc} \\hline \\text{Número de} &amp; \\text{Máximo de la} &amp; \\text{Probabilidad de} &amp; \\text{Media del} &amp; \\text{Varianza del}\\\\ \\text{Polizas} &amp; \\text{Póliza} &amp; \\text{Siniestro por póliza} &amp; \\text{Coste} &amp; \\text{Coste}\\\\ &amp; (M_i) &amp; (q_{i}) &amp; (\\mu_{i}) &amp; (\\sigma_{i}^2) \\\\ \\hline 100 &amp; 400 &amp; 0.05 &amp; 200 &amp; 400^2/12\\\\ 200 &amp; 300 &amp; 0.06 &amp; 150 &amp; 300^2/12 \\\\ \\hline \\end{array} \\end{matrix} } \\] La media de la siniestralidad total es \\[\\mathrm{E~} (S_{300}) = \\sum_{i=1}^{300} q_i \\mu_i = 100\\left\\{0,05(200)\\right\\} + 200\\left\\{0,06 (150) \\right\\} = 2.800\\] La varianza de la siniestralidad total es \\[\\begin{eqnarray*} \\mathrm{Var~}(S_{300}) &amp;=&amp; \\sum_{i=1}^{300} \\left( q_i \\sigma _i^2+q_i (1-q_i)\\mu_i^2 \\right) ~~~~ \\text{dado que las } X_i \\text{ son independientes} \\\\ &amp;=&amp; 100\\left\\{ 0,05 \\left(\\frac{400^2}{12}\\right) +0,05 (1-0,05 )200^2 \\right\\}+ 200\\left\\{ 0,06 \\left(\\frac{300^2}{12}\\right) +0,06 (1-0,06 )150^2 \\right\\}\\\\ &amp;=&amp; 600.467. \\end{eqnarray*}\\] Continuación. Ahora supongamos que todos reciben el máximo de la póliza \\(M_i\\) si ocurre un siniestro. ¿Cuál es la pérdida agregada esperada \\(\\mathrm{E~}(\\tilde{S})\\) y la varianza de la pérdida agregada \\(\\mathrm{Var~}(\\tilde{S})\\)? La cuantía del siniestro por póliza \\(X_i\\) es ahora determinista y se establece en \\(M_i\\) en vez de ser un valor aleatorio, así que \\(\\sigma_i^2 = \\mathrm{Var~} (X_i) = 0\\) y \\(\\mu_i = M_i\\). Una vez más, la probabilidad que ocurra una reclamación para cada póliza es \\(q_i\\). En este contexto, la pérdida agregada esperada es \\[\\begin{aligned} \\mathrm{E~}(\\tilde{S}) &amp;= \\sum_{i=1}^{300} q_i \\mu_i = 100 \\left\\{0,05(400) \\right\\} + 200 \\left\\{ 0,06(300) \\right\\} = 5.600 \\end{aligned}\\] La varianza de la pérdida agregada es \\[\\begin{aligned} \\mathrm{Var~}(\\tilde{S}) &amp;= \\sum_{i=1}^{300} \\left( q_i \\sigma _i^2+q_i (1-q_i )\\mu_i^2 \\right) = \\sum_{i=1}^{300} \\left( q_i (1-q_i) \\mu_i^2 \\right) \\\\ &amp;= 100 \\left\\{(0,05) (1-0,05) 400^2\\right\\} + 200 \\left\\{(0,06) (1-0,06)300^2\\right\\} \\\\ &amp;= 1.775.200 \\end{aligned}\\] El modelo de riesgo individual también puede utilizarse para la frecuencia de los siniestros. Si \\(X_i\\) representa el número de siniestros para el \\(i\\)-ésimo contrato, entonces \\(S_n\\) se interpreta como el número total de siniestros de la cartera. En este caso, la construcción de la distribución en dos partes se sigue aplicando, ya que continua existiendo masa de probabilidad en cero para las pólizas que no experimentan ningún siniestro. Supongamos que \\(X_i\\) pertenece a la clase \\((a,b,0)\\) con pmf definida como \\(p_{ik} = \\Pr(X_i=k)\\) para \\(k=0,1,\\ldots\\) (véase Sección 2.3). Así mismo, \\(X_i^{T}\\) indica la distribución truncada en cero asociada de la clase \\((a,b,1)\\) con pmf \\(p_{ik}^T=p_{ik}/(1-p_{i0})\\) para \\(k=1,2,\\ldots\\) (véase Sección 2.5.1). Usando la relación entre sus funciones generadoras de probabilidad (véase Suplemento Técnico 5.A.2 para más detalles): \\[\\begin{aligned} P_{X_i}(z) = p_{i0} +(1-p_{i0}) P_{X_i^{T}}(z), \\end{aligned}\\] se puede escribir \\(X_i=I_i\\times B_i\\) con \\(q_i={\\rm Pr}(I_i=1)={\\rm Pr}(X_i&gt;0)=1-p_{i0}\\) y \\(B_i=X_i^T\\). Como se puede observar, en este caso, se obtiene una distribución modificada en cero, ya que la variable \\(I_i\\) recoge la masa de probabilidad modificada en cero con \\(q_i = \\Pr(I_i=1)\\), mientras que \\(B_i=X_i^T\\) cubre la parte de frecuencia discreta que no es cero. Véase Sección 2.5.1 para la relación entre las distribuciones truncadas en cero y modificadas en cero. Ejemplo 5.2.2. Una compañía aseguradora ha vendido una cartera de 100 pólizas de seguro de hogar independientes entre si, en cada una de las cuales la frecuencia de siniestros sigue una distribución de Poisson modificada en cero, como se indica a continuación: \\[ {\\small \\begin{matrix} \\begin{array}{cccc} \\hline \\text{Tipo de} &amp; \\text{Número de} &amp; \\text{Probabilidad of} &amp; \\lambda \\\\ \\text{Póliza} &amp; \\text{Pólizas} &amp; \\text{Al menos un siniestro} &amp; \\\\ \\hline \\text{Riesgo bajo} &amp; 40 &amp; 0,03 &amp; 1 \\\\ \\text{Riesgo alto} &amp; 60 &amp; 0,05 &amp; 2 \\\\ \\hline \\end{array} \\end{matrix} } \\] Calcular el valor esperado y varianza de la frecuencia de siniestros para el conjunto de la cartera. Mostrar Solución de Ejemplo Solución. Para cada póliza se puede escribir la frecuencia de siniestros Poisson cero modificada \\(N_i\\) como \\(N_i = I_i \\times B_i\\), donde \\[q_i = \\Pr(I_i = 1) = \\Pr(N_i &gt; 0) = 1-p_{i0}\\] Para las pólizas de bajo riesgo se tiene \\(q_i = 0,03\\), y para las pólizas de alto riego \\(q_i=0,05\\). Además, \\(B_i = N_i^T\\), la versión truncada en cero de \\(N_i\\). Por tanto, se tiene \\[\\begin{aligned} \\mu_i &amp;={\\rm E}(B_i) = {\\rm E}(N_i^T) = \\frac{\\lambda}{1-e^{-\\lambda}} \\\\ \\sigma_i^2 &amp;={\\rm Var}(B_i) = {\\rm Var}(N_i^T) = \\frac{\\lambda [1-(\\lambda+1)e^{-\\lambda}]}{(1-e^{-\\lambda})^2} \\end{aligned}\\] La frecuencia de siniestros de la cartera sería \\(S_n = \\sum_{i=1}^n N_i\\). En base a las fórmulas anteriores, el número esperado de siniestros de la cartera es \\[\\begin{aligned} \\mathrm{E~} (S_n) &amp;= \\sum_{i=1}^{100} q_i \\mu_i \\\\ &amp; = 40\\left[0,03 \\left(\\frac{1}{1-e^{-1}} \\right) \\right] + 60 \\left[0,05 \\left( \\frac{2}{1-e^{-2}} \\right) \\right] \\\\ &amp;= 40(0,03)(1,5820) + 60(0,05)(2,3130) = 8,8375 \\end{aligned}\\] La varianza de la frecuencia de siniestros de la cartera es \\[\\begin{aligned} \\mathrm{Var~}(S_n) &amp;= \\sum_{i=1}^{100} \\left( q_i \\sigma _i^2+q_i (1-q_i )\\mu_i^2 \\right) \\\\ &amp;= 40 \\left[ 0,03 \\left(\\frac{1-2e^{-1}}{(1-e^{-1})^2} \\right) + 0,03(0,97)(1,5820^2) \\right] + 60 \\left[0,05 \\left( \\frac{2[1-3e^{-2}]}{ (1-e^{-2})^2} \\right) + 0,05(0.95)(2,3130^2) \\right] \\\\ &amp;= 23,7214 \\end{aligned}\\] Cabe señalar que, equivalentemente, se podría calcular la media y varianza de una póliza individual usando la relación entre la distribuciones de Poisson modificada en cero y truncada en cero (véase Sección 2.3). Para entender la distribución de la pérdida agregada se puede utilizar el teorema central del límite para aproximar la distribución de \\(S_n\\) para valores grandes de \\(n\\). Si se denota \\(\\mu_{S_n}={\\rm E}(S_n)\\) y \\(\\sigma^2_{S_n}={\\rm Var}(S_n)\\) y se considera \\(Z\\sim N(0,1)\\), una variable aleatoria normal estándar con cdf \\(\\Phi\\). Entonces, la cdf de \\(S_n\\) se puede aproximar como: \\[\\begin{aligned} F_{S_n}(s) &amp;= {\\rm Pr}({S_n}\\leq s) = \\Pr \\left( \\frac{S_n - \\mu_{S_n}}{\\sigma_{S_n}} \\leq \\frac{s-\\mu_{S_n}}{\\sigma_{S_n}} \\right) \\\\ &amp;\\approx \\Pr\\left( Z \\leq \\frac{s-\\mu_{S_n}}{\\sigma_{S_n}} \\right) = \\Phi \\left(\\frac{s-\\mu_S}{\\sigma_S}\\right). \\end{aligned}\\] Ejemplo 5.2.3. Pregunta Examen Actuarial - Continuación. Como en el Ejemplo 5.2.1, una compañía de seguros ha vendido 300 pólizas de seguro contra incendios, donde el coste del siniestro \\(X_i\\) se distribuye uniformemente entre 0 y el máximo de la póliza \\(M_i\\). Utilizando la aproximación normal, se pide calcular la probabilidad de que el importe total de los siniestros \\(S_{300}\\) supere los \\(3.500\\$\\). Mostrar Solución de Ejemplo Solución. Previamente se ha obtenido que \\(\\mathrm{E}(S_{300})=2.800\\) y \\(\\mathrm{Var}(S_{300}) = 600.467\\). Por lo tanto, \\[\\begin{aligned} {\\rm Pr}(S_{300} &gt; 3.500) &amp;= 1 - {\\rm Pr}(S_{300} \\leq 3.500) \\\\ &amp;\\approx 1- \\Phi \\left( \\frac{3.500-2.800}{\\sqrt{600.467}} \\right) = 1 - \\Phi \\left( 0,90334 \\right) \\\\ &amp;= 1 – 0,8168 = 0,1832 \\end{aligned}\\] En el caso que \\(n\\) sea un valor pequeño, la distribución de \\(S_n\\) será probablemente sesgada, y la aproximación normal no sería una buena elección. Para analizar la distribución de pérdidas agregada, se debe volver a los métodos básicos iniciales. En concreto, la distribución puede derivarse recursivamente. Si se define \\(S_k=X_1 + \\cdots + X_k, k=1,\\ldots,n\\). Para \\(k=1\\): \\[F_{S_1}(s) = {\\rm Pr}(S_1\\leq s) = {\\rm Pr}(X_1\\leq s) = F_{X_1}(s).\\] Para \\(k=2,\\ldots,n\\): \\[\\begin{aligned} F_{S_k}(s)&amp;={\\Pr}(X_1+\\cdots+X_k\\leq s) ={\\Pr}(S_{k-1}+X_k\\leq s) \\\\ &amp;={\\rm E}_{X_k}\\left[{\\rm Pr}(S_{k-1}\\leq s-X_k|X_k)\\right]= {\\rm E}_{X_k}\\left[F_{S_{k-1}}(s-X_k)\\right]. \\end{aligned}\\] Un caso particular es cuando las \\(X_i\\) se distribuyen igual. Supongamos que \\(F_X(x)={\\Pr}(X\\leq x)\\) es la distribución común de \\(X_i, ~i=1,\\ldots,n\\). Se define \\[F^{*n}_X(x)={\\Pr}(X_1+\\cdots+X_n\\leq x)\\] la convolución \\(n\\)-ésima de \\(F_X\\). En general, \\(F_X^{\\ast n}\\) puede calcularse recursivamente. Se inicia la recursión en \\(k=1\\) mediante \\(F_X^{\\ast 1} \\left(x \\right) =F_X(x)\\). Posteriormente, para \\(k=2\\), se tiene \\[\\begin{eqnarray*} F_X^{\\ast 2} \\left(x \\right) &amp;=&amp; \\Pr(X_1 + X_2 \\le x) = \\mathrm{E}_{X_2} \\left[ \\Pr(X_1 \\le x - X_2|X_2) \\right] \\\\ &amp;=&amp; \\mathrm{E}_{X_2} \\left[ F(x - X_2) \\right] \\\\ &amp;=&amp;\\left\\{\\begin{array}{ll} \\int_{0}^{x} F(x-y) f(y) dy &amp; \\text{para } X_i \\text{ continuas } \\\\ \\sum_{y \\le x} F(x-y) f(y) &amp; \\text{para } X_i \\text{ discretas }\\\\ \\end{array}\\right. \\end{eqnarray*}\\] Recuerde que \\(F(0) = 0\\). Del mismo modo, para \\(k=n\\), se cumple que \\(S_n = X_1 + X_2 + \\cdots + X_n\\) y \\[\\begin{eqnarray*} F^{\\ast n}\\left(x\\right) &amp;=&amp; \\Pr(S_n \\le x) = \\Pr(S_{n-1} + X_n \\le x)\\\\ &amp;=&amp;\\mathrm{E}_{X_n} \\left[ \\Pr(S_{n-1} \\le x - X_n|X_n) \\right] \\\\ &amp;=&amp;\\mathrm{E}_X \\left[ F^{\\ast(n-1)}(x - X) \\right] \\\\ &amp;=&amp; \\left\\{\\begin{array}{ll} \\int_{0}^{x} F^{\\ast(n-1)}(x-y)f(y)dy &amp; \\text{para } X_i \\text{ continuas } \\\\ \\sum_{y \\le x} F^{\\ast(n-1)}(x-y)f(y) &amp; \\text{para } X_i \\text{ discretas } \\\\ \\end{array}\\right. \\end{eqnarray*}\\] Cuando las \\(X_i\\) son independientes y pertenecen a la misma familia de distribuciones, en algunos casos \\(S_n\\) tiene una forma cerrada simple. Esto hace que sea fácil calcular \\(\\Pr(S_n \\le x)\\). Esta propiedad se conoce como cerrado bajo convolución, es decir, la distribución de la suma de variables aleatorias independientes pertenece a la misma familia de distribuciones que la de las variables que la componen, pero con distintos parámetros. Algunos ejemplos son: \\[ {\\small \\begin{matrix} \\text{Tabla de formas cerrada para la suma parcial de distribuciones}\\\\ \\begin{array}{l|l|l} \\hline \\text{Distribución de } X_i &amp; \\text{Abreviatura} &amp; \\text{Distribución de } S_n \\\\ \\hline \\text{Normal con media } \\mu_i \\text{ y varianza } \\sigma_i^2 &amp; N(\\mu_i,\\sigma_i^2) &amp; N\\left(\\sum_{i=1}^{n}\\mu_i,~\\sum_{i=1}^{n}\\sigma_i^2\\right) \\\\ \\text{Exponencial con media } \\theta &amp; Exp(\\theta) &amp; Gam(n,\\theta)\\\\ \\text{Gamma con parámetros de forma } \\alpha_i \\text{ y escala } \\theta &amp; Gam(\\alpha_i,\\theta) &amp; Gam\\left(\\sum_{i=1}^n\\alpha_i,\\theta\\right) \\\\ \\text{Poisson con media (y varianza) } \\lambda_i &amp; Poi(\\lambda_i)&amp; Poi\\left(\\sum_{i=1}^{n}\\lambda_i\\right)\\\\ \\text{Binomial con } m_i \\text{ intentos y probabilidad de éxito } q &amp; Bin(m_i, q)&amp; Bin\\left(\\sum_{i=1}^n m_i, q\\right)\\\\ \\text{Geométrica con media } \\beta &amp; Geo(\\beta) &amp; NB(\\beta,n)\\\\ \\text{Binomial Negativa con media } r_i \\beta~ \\text{ y varianza } ~r_i \\beta (1+\\beta) &amp; NB(\\beta,r_i)&amp; NB\\left(\\beta,\\sum_{i=1}^n r_i\\right)\\\\ \\hline \\end{array} \\end{matrix} } \\] Ejemplo 5.2.4. Distribución Gamma. Supongamos que \\(X_1,\\ldots,X_n\\) son variables aleatorias independientes con \\(X_i \\sim Gam(\\alpha_i, \\theta)\\). La mgf de \\(X_i\\) es \\(M_{X_i}(t) = (1 - \\theta t)^{- \\alpha_i}\\). Por tanto, la mgf de la suma \\(S_n = X_1 + \\cdots + X_n\\) es \\[\\begin{aligned} M_{S_n}(t) &amp;= \\prod_{i=1}^n M_{X_i}(t) ~~~~ \\text{por la independencia de las } X_i \\\\ &amp;= \\prod_{i=1}^n (1 - \\theta t)^{- \\alpha_i} = (1-\\theta t)^{-\\sum_{i=1}^n \\alpha_i }~ , \\end{aligned}\\] que es la mgf de una variable aleatoria gamma con parámetros \\((\\sum_{i=1}^n \\alpha_i, \\theta)\\). Es decir, \\(S_n \\sim Gam(\\sum_{i=1}^n \\alpha_i, \\theta)\\). Ejemplo 5.2.5. Distribución Negativa Binomial. Supongamos que \\(X_1,\\ldots, X_n\\) son variables aleatorias independientes con \\(X_i \\sim NB(\\beta, r_i)\\). La pgf de \\(X_i\\) is \\(P_{X_i}(z) = \\left[1-\\beta(z-1) \\right]^{-r_i}\\). Por lo tanto, la pgf de la suma \\(S_n =X_1+\\cdots+X_n\\) es \\[\\begin{aligned} P_{S_n}(z) &amp;= \\mathrm{E~}\\left[ z^{S_n} \\right] = \\mathrm{E~}\\left[ z^{X_1+\\cdots+X_n} \\right] = \\mathrm{E~}\\left[ z^{X_1} z^{X_2} \\cdots z^{X_n} \\right] \\\\ &amp;= \\mathrm{E~}\\left[z^{X_1}\\right] \\cdots \\mathrm{E~}\\left[z^{X_n}\\right] ~~~~ \\text{bajo independencia de las } X_i \\\\ &amp;= \\prod_{i=1}^n P_{X_i}(z) = \\prod_{i=1}^n \\left[1-\\beta(z-1) \\right]^{-r_i} = \\left[1-\\beta(z-1) \\right]^{-\\sum_{i=1}^n r_i} ~, \\end{aligned}\\] que es la pgf de una variable aleatoria negativa binomial con parámetros \\((\\beta, \\sum_{i=1}^n r_i)\\). Es decir, \\(S_n \\sim NB(\\beta, \\sum_{i=1}^n r_i)\\). Ejemplo 5.2.6. Pregunta Examen Actuarial (modificada). El número anual de visitas al médico para cada miembro de una familia de 4 tiene una distribución geométrica con una media de 1,5. El número anual de visitas de los miembros de la familia es independiente entre sí. Un seguro paga 100 por visita al médico a partir de la cuarta visita de la familia. Calcula la probabilidad de que la familia cobre del seguro este año. Mostrar Solución de Ejemplo Solución. El número de visitas al médico para un miembro de la familia es \\(X_i \\sim Geo(\\beta=1,5)\\) y el número de visitas del conjunto de la familia es \\(S_4 = X_1 + X_2 + X_3 + X_4\\). La suma de 4 variables aleatorias geométricas independientes, cada una con una media \\(\\beta=1,5\\), siguen una distribución binomial negativa, i.e. \\(S_4 \\sim NB(\\beta=1,5, r=4)\\). Si el seguro paga 100 por visita a partir de la cuarta visita de la familia, entonces la familia no cobrará del seguro si tienen menos de 4 siniestros. Esta probabilidad es \\[\\begin{aligned} \\Pr(S_4 &lt; 4) &amp;= \\Pr(S_4 = 0) + \\Pr(S_4 = 1) + \\Pr(S_4 = 2) +\\Pr(S_4 = 3) \\\\ &amp;= (1+1,5)^{-4} + \\frac{4(1,5)}{(1+1,5)^5} + \\frac{4(5)(1,5^2)}{2(1+1,5)^6} + \\frac{4(5)(6)(1,5^3)}{3!(1+1,5)^7}\\\\ &amp;= 0,0256 + 0,0614 + 0,0922 + 0,1106 = 0,2898 \\end{aligned}\\] 5.3 Modelo de riesgo colectivo 5.3.1 Momentos y distribución Bajo el modelo de riesgo colectivo \\(S_N=X_1+\\cdots+X_N\\), las \\(\\{X_i\\}\\) son iid, e independientes de \\(N\\). Supongamos que \\(\\mu = {\\rm E}\\left( X_{i}\\right)\\) y \\(\\sigma ^{2} = {\\rm Var}\\left(X_{i}\\right)\\) para todo \\(i\\). Utilizando la ley de esperanza iterada, la media de la pérdida agregada es \\[\\begin{eqnarray*} {\\rm E}(S_N)={\\rm E}_N[{\\rm E}_S(S|N)] = {\\rm E}_N(N\\mu) = \\mu {\\rm E}(N). \\end{eqnarray*}\\] Utilizando la ley de varianza total, la varianza de la pérdida agregada es \\[\\begin{aligned} {\\rm Var}(S_N) &amp;= {\\rm E}_N[{\\rm Var}(S_N|N)] + {\\rm Var}_N[{\\rm E}(S_N|N)] \\\\ &amp;= \\mathrm{E}_N \\left[ \\mathrm{Var}(X_1+\\cdots+X_N) \\right] + \\mathrm{Var}_N\\left[ \\mathrm{E}(X_1+\\cdots+X_N) \\right] \\\\ &amp;= \\mathrm{E}_N \\left[ \\mathrm{Var}(X_1)+\\cdots+ \\mathrm{Var}(X_N) + 2\\mathrm{Cov}(X_1, X_2) + \\cdots + \\mathrm{Cov}(X_{N-1}, X_N) \\right] + \\mathrm{Var}_N\\left[ \\mathrm{E}(X_1) + \\cdots + \\mathrm{E}(X_N) \\right] \\\\ &amp;={\\rm E}_N[N\\sigma^2] + {\\rm Var}_N[N\\mu] ~~~~ \\text{dado que } \\mathrm{Cov}(X_i, X_j)=0 \\text{ para todo } i\\neq j \\text{ debido a la independencia} \\\\ &amp;=\\sigma^2{\\rm E}[N] + \\mu^2{\\rm Var}[N] \\end{aligned}\\] Caso particular: Frecuencia distribuida según una Poisson. Si \\(N \\sim Poi (\\lambda)\\), entonces \\[\\begin{aligned} \\mathrm{E}(N) &amp;= \\mathrm{Var}(N) = \\lambda\\\\ \\mathrm{E}(S) &amp;= \\lambda \\mathrm{E}(X)\\\\ \\mathrm{Var}(S) &amp;= \\lambda (\\sigma^2 + \\mu^2) = \\lambda ~\\mathrm{E} (X^2) . \\end{aligned}\\] Ejemplo 5.3.1. Pregunta de Examen Actuarial. El número de accidentes sigue una distribución de Poisson con media 12. Cada accidente genera 1, 2 ó 3 reclamantes con probabilidades 1/2, 1/3 y 1/6, respectivamente. Calcular la varianza en el número total de reclamantes. Mostrar Solución de Ejemplo Solución. \\[\\begin{aligned} &amp; \\mathrm{E}(X^2) = 1^2 \\left( \\frac{1}{2}\\right) + 2^2\\left(\\frac{1}{3} \\right) + 3^2\\left(\\frac{1}{6}\\right) = \\frac{10}{3} \\\\ \\Rightarrow &amp;\\mathrm{Var}(S_N) = \\lambda \\ \\mathrm{E}(X^2) = 12\\left(\\frac{10}{3}\\right) = 40 \\end{aligned}\\] Alternativamente, utilizando la expresión genérica, \\(\\mathrm{Var}(S_N) = \\sigma^2 \\mathrm{E}(N) + \\mu^2 \\mathrm{Var}(N)\\), donde \\[\\begin{aligned} \\mathrm{E}(N) &amp;= \\mathrm{Var}(N) = 12 \\\\ \\mu &amp;= \\mathrm{E}(X) = 1\\left(\\frac{1}{2}\\right) + 2\\left(\\frac{1}{3}\\right) + 3\\left(\\frac{1}{6}\\right) = \\frac{5}{3} \\\\ \\sigma^2 &amp;= \\mathrm{E}(X^2) - [\\mathrm{E}(X)]^2 = \\frac{10}{3} - \\frac{25}{9} = \\frac{5}{9} \\\\ \\Rightarrow \\ \\mathrm{Var}(S) &amp;= \\left(\\frac{5}{9}\\right)\\left(12\\right) + \\left(\\frac{5}{3}\\right)^2\\left(12\\right) = 40 . \\end{aligned}\\] En general, los momentos de \\(S_N\\) pueden derivarse de su función generadora de momentos (mgf). Como las \\(X_i\\) son iid, denotaremos la mgf de \\(X\\) como \\(M_{X}(t) = \\mathrm{E~}(e^{tX})\\). Usando la ley de esperanza iterada, la mgf de \\(S_N\\) es \\[\\begin{aligned} M_{S_N}(t) &amp;= \\mathrm{E}(e^{t S_N})=\\mathrm{E}_N[~\\mathrm{E}(e^{tS_N}|N)~]\\\\ &amp;= \\mathrm{E}_N \\left[ ~\\mathrm{E}\\left( e^{t(X_1+\\cdots+X_N)}\\right) ~\\right] = \\mathrm{E}_N \\left[ \\mathrm{E}(e^{tX_1})\\cdots\\mathrm{E}(e^{tX_N}) \\right] ~~~~ \\text{dado que las } X_i \\text{ son independientes} \\\\ &amp;= \\mathrm{E}_N[~(M_{X}(t))^N~] \\end{aligned}\\] Ahora, recuerde que la función generadora de probabilidad (pgf) de \\(N\\) es \\(P_N(z) = \\mathrm{E}(z^N)\\). Denotemos \\(M_{X}(t)=z\\). Sustituyendo en la expresión de la mgf de \\(S_N\\) anterior, se demuestra \\[\\begin{aligned} M_{S_N}(t) = \\mathrm{E~}(z^N) = P_{N}(z) = P_{N}[M_{X}(t)]. \\end{aligned}\\] Del mismo modo, si \\(S_N\\) es discreta, se obtiene que la pgf de \\(S_N\\) es: \\[\\begin{aligned} P_{S_N}(z) = P_{N}[P_{X}(z)]. \\end{aligned}\\] Para obtener \\(\\mathrm{E}(S_N) = M_{S_N}&#39;(0)\\), se usa la regla de la cadena \\[ M_{S_N}&#39;(t) = \\frac{\\partial}{\\partial t} P_{N}(M_{X}(t)) = P_{N}&#39;(M_{X}(t)) M_{X}&#39;(t)\\\\ \\] y recuerde que \\(M_{X}(0) = 1, M_{X}&#39;(0) = \\mathrm{E}(X) = \\mu, P_{N}&#39;(1) = \\mathrm{E}(N)\\). Por lo tanto, \\[\\begin{aligned} \\mathrm{E}(S_N) = M_{S_N}&#39;(0) = P_{N}&#39;(M_{X}(0)) M_{X}&#39;(0) = \\mu {\\rm E}(N) \\end{aligned}\\] De forma similar, se puede utilizar la relación \\(\\mathrm{E}(S_N^2) = M_{S_N}&#39;&#39;(0)\\) para obtener \\[\\mathrm{Var}(S_N) = \\sigma^2 \\mathrm{E}(N) + \\mu^2 \\mathrm{Var}(N).\\] Caso particular. Frecuencia según una Poisson. Supongamos que \\(N \\sim Poi (\\lambda)\\). Entonces, la pgf de \\(N\\) es \\(P_N (z) = e^{\\lambda(z-1)}\\) y la mgf de \\(S_N\\) es \\[\\begin{aligned} M_{S_N}(t) &amp;= P_N[M_X(t)] = e^{\\lambda(M_{X}(t) - 1)}. \\end{aligned}\\] Derivando se obtiene \\[\\begin{aligned} M_{S_N}&#39;(t) &amp;= e^{\\lambda(M_{X}(t) - 1)}~ \\lambda~ M_{X}&#39;(t) = M_{S_N}(t) ~\\lambda ~M_{X}&#39;(t)\\\\ M_{S_N}&#39;&#39;(t) &amp;= M_{S}(t) ~\\lambda~ M_{X}&#39;&#39;(t) + [~M_{S}(t)~\\lambda~ M_{X}&#39;(t)~] ~\\lambda~ M_{X}&#39;(t) \\end{aligned}\\] Si se evalúan en \\(t=0\\) se tiene \\[\\begin{aligned} \\mathrm{E}(S_N) &amp;= M_{S_N}&#39;(0) = \\lambda \\mathrm{E}(X) = \\lambda \\mu \\end{aligned}\\] y \\[\\begin{aligned} M_{S_N}&#39;&#39;(0) &amp;= \\lambda \\mathrm{E}(X^2) + \\lambda^2 \\mu^2\\\\ \\Rightarrow \\mathrm{Var}(S_N) &amp;= \\lambda \\mathrm{E}(X^2) + \\lambda^2 \\mu^2 - (\\lambda \\mu)^2 = \\lambda~ \\mathrm{E}(X^2). \\end{aligned}\\] Ejemplo 5.3.2. Pregunta de Examen Actuarial. El productor de un concurso de televisión otorga premios en efectivo. El número de premios, \\(N\\), y la cuantía de cada premio, \\(X\\), tienen las siguientes distribuciones: \\[ {\\small \\begin{matrix} \\begin{array}{ccccc}\\hline n &amp; \\Pr(N=n) &amp; &amp; x &amp; \\Pr(X=x)\\\\ \\hline 1 &amp; 0,8 &amp; &amp; 0 &amp; 0,2 \\\\ 2 &amp; 0,2 &amp; &amp; 100 &amp; 0,7 \\\\ &amp; &amp; &amp; 1000 &amp; 0,1\\\\\\hline \\end{array} \\end{matrix} } \\] El presupuesto para premios es igual al valor esperado del total de los premios más la desviación estándar del valor total de los premios. Calcular el presupuesto. Mostrar Solución de Ejemplo Solución. Se debe calcular la media y la desviación estándar del total (suma) de los premios en efectivo. Los momentos de la distribución de frecuencias \\(N\\) son \\[\\begin{aligned} \\mathrm{E}(N) &amp;= 1 (0,8) + 2 (0,2) =1,2\\\\ \\mathrm{E}(N^2) &amp;= 1^2 (0,8) + 2^2 (0,2) =1,6\\\\ \\mathrm{Var}(N) &amp;= \\mathrm{E}(N^2) - \\left[ \\mathrm{E}(N) \\right]^2= 0,16 \\end{aligned}\\] Los momentos de la distribución de severidad \\(X\\) son \\[\\begin{aligned} \\mathrm{E}(X) &amp;= 0 (0,2) + 100 (0,7) + 1000 (0,1) = 170 = \\mu\\\\ \\mathrm{E}(X^2) &amp;= 0^2 (0,2) + 100^2 (0,7) + 1000^2 (0,1) = 107.000\\\\ \\mathrm{Var}(X) &amp;= \\mathrm{E}(X^2) - \\left[ \\mathrm{E}(X) \\right]^2=78.100 = \\sigma^2 \\end{aligned}\\] Por lo tanto, la media y la varianza del total de los premios en efectivo son \\[\\begin{aligned} \\mathrm{E}(S_N) &amp;= \\mu \\mathrm{E}(N) = 170 (1,2) = 204 \\\\ \\mathrm{Var}(S_N) &amp;= \\sigma^2 \\mathrm{E}(N) + \\mu^2 \\mathrm{Var}(N)\\\\ &amp;= 78.100 (1,2) + 170^2 (0,16) = 98.344 \\end{aligned}\\] El presupuesto necesario es el siguiente \\[\\begin{aligned} Presupuesto &amp;= \\mathrm{E}(S_N) + \\sqrt{\\mathrm{Var}(S_N)} \\\\ &amp;= 204 + \\sqrt{98.344} = 517,60 . \\end{aligned}\\] La distribución de \\(S_N\\) se denomina distribución compuesta, y puede derivarse a partir de la convolución de \\(F_X\\) como sigue: \\[\\begin{aligned} F_{S_N}(s) &amp;= \\Pr \\left(X_1 + \\cdots + X_N \\le s \\right) \\\\ &amp;= \\mathrm{E} \\left[ \\Pr \\left(X_1 + \\cdots + X_N \\le s|N=n \\right) \\right]\\\\ &amp;= \\mathrm{E} \\left[ F_{X}^{\\ast N}(s) \\right] \\\\ &amp;= p_0 + \\sum_{n=1}^{\\infty }p_n F_{X}^{\\ast n}(s) \\end{aligned}\\] Ejemplo 5.3.3. Pregunta de examen actuarial. El número de siniestros en un determinado período sigue una distribución geométrica de media \\(4\\). La cauantía de cada siniestro \\(X\\) tiene la siguiente distribución \\(\\Pr(X=x) = 0,25, \\ x=1,2,3,4\\), es decir, discreta uniforme en \\(\\{1,2,3,4\\}\\). El número de siniestros y los importes de los mismos son independientes. Si \\(S_N\\) denota la cuantía total de la siniestralidad durante el período, calcular \\(F_{S_N}(3)\\). Mostrar Solución de Ejemplo Solución. Por definición, se sabe que \\[\\begin{aligned} F_{S_N}\\left(3 \\right) &amp;= {\\rm Pr}\\left(\\sum_{i=1}^N X_i \\leq 3\\right) = \\sum_{n=0}^\\infty {\\rm Pr}\\left(\\sum_{i=1}^n X_i\\leq 3|N=n\\right){\\rm Pr}(N=n) \\\\ &amp;= \\sum_n F^{\\ast n} \\left(3 \\right) p_n = \\sum_{n=0}^3 F^{\\ast n}(3) p_n \\\\ &amp;= p_0 + F^{\\ast 1}(3) \\ p_1 + F^{\\ast 2}(3) \\ p_2 + F^{\\ast 3}(3) \\ p_3 \\end{aligned}\\] Dado que \\(N \\sim Geo(\\beta=4)\\), entonces \\[\\begin{aligned} p_n &amp;= \\frac{1}{1+\\beta} \\left(\\frac{\\beta}{1+ \\beta} \\right)^n = \\frac{1}{5} \\left(\\frac{4}{5} \\right)^n \\end{aligned}\\] Para la distribución de la severidad de la siniestralidad, de forma recursiva, se dispone de \\[\\begin{aligned} F^{\\ast 1}(3) &amp;= \\Pr(X \\le 3) = \\frac{3}{4} \\\\ F^{\\ast 2}(3) &amp;= \\sum_{y \\le 3} F^{\\ast 1} (3-y) f(y) = F^{\\ast 1}(2)f(1) + F^{\\ast 1}(1)f(2) \\\\ &amp;= \\frac{1}{4}\\left[F^{\\ast 1} (2) + F^{\\ast 1}(1)\\right] = \\frac{1}{4}\\left[{\\rm Pr}(X\\leq 2) + {\\rm Pr}(X \\leq 1) \\right] \\\\ &amp;= \\frac{1}{4} \\left(\\frac{2}{4} + \\frac{1}{4} \\right) = \\frac{3}{16}\\\\ F^{\\ast 3}(3) &amp;= \\Pr(X_1+X_2 + X_3 \\le 3) = \\Pr(X_1=X_2=X_3=1) = \\left(\\frac{1}{4} \\right)^3 \\end{aligned}\\] Cabe señalar que no es necesario calcular recursivamente \\(F^{\\ast 3}(3)\\) ya que como cada \\(X \\in \\{1,2,3,4\\}\\), la única forma de obtener \\(X_1+X_2+X_3 \\leq 3\\) es tener \\(X_1=X_2=X_3=1\\). Además, para \\(n \\geq 4\\), \\(F^{\\ast n} (3)=0\\) dado que la suma de 4 o más \\(X\\) no puede ser menor a 3. Para \\(n=0\\), \\(F^{\\ast 0}(3) = 1\\) ya que la suma de cero veces \\(X\\) es 0, que es siempre menor a 3. Si se establecen sistemáticamente las probabilidades, \\[\\begin {matrix} \\begin{array}{c c c c}\\hline x &amp; F^{\\ast 1}(x) &amp; F^{\\ast 2}(x) &amp; F^{\\ast 3}(x)\\\\ \\hline 0 &amp; &amp; &amp; \\\\ 1 &amp; \\frac{1}{4} &amp; 0 &amp; \\\\ 2 &amp; \\frac{2}{4} &amp; \\left( \\frac{1}{4} \\right)^2 &amp; \\\\ 3 &amp; \\frac{3}{4} &amp; \\frac{3}{16} &amp; \\left( \\frac{1}{4} \\right)^3 \\\\ \\hline \\end{array} \\end{matrix}\\] Finalmente, \\[\\begin{aligned} F_{S_N}(3) &amp;= p_0 + F^{\\ast 1}(3) \\ p_1 + F^{\\ast 2}(3) \\ p_2 + F^{\\ast 3}(3) \\ p_3 \\\\ &amp;= \\frac{1}{5} + \\frac{3}{4}\\left(\\frac{4}{25} \\right) + \\frac{3}{16} \\left( \\frac{16}{125} \\right) + \\frac{1}{64} \\left( \\frac{64}{625}\\right) = 0,3456\\\\ \\end{aligned}\\] Si se conocen \\(\\mathrm{E}(N)\\) y \\(\\mathrm{Var}(N)\\), también se puede utilizar el teorema central del límite para aproximar la distribución de \\(S_N\\) como en el modelo de riesgo individual. Es decir, \\(\\frac{S_N - \\mathrm{E}(S_N)}{\\sqrt{\\mathrm{Var}(S_N)}}\\) sigue aproximadamente la distribución normal estándar \\(N(0,1)\\). Ejemplo 5.3.4. Pregunta Examen Actuarial. Se sabe lo siguiente: \\[ {\\small \\begin{matrix} \\begin{array}{ c | c c } \\hline &amp; \\text{Media} &amp; \\text{Desviación estándar}\\\\ \\hline \\text{Número de siniestros} &amp; 8 &amp; 3\\\\ \\text{Pérdidas individuales} &amp; 10.000 &amp; 3.937\\\\ \\hline \\end{array} \\end{matrix} } \\] Mediante la aproximación normal, determinar la probabilidad que la pérdida total supere el 150\\(\\%\\) de la pérdida esperada. Mostrar Solución de Ejemplo Solución. Para utilizar la aproximación normal, primero debemos encontrar la media y la varianza de la pérdida agregada \\(S\\) \\[\\begin{aligned} \\mathrm{E}(S_N) &amp;= \\mu \\ \\mathrm{E}(N) = 10.000(8) = 80.000\\\\ \\mathrm{Var}(S_N) &amp;= \\sigma^2 \\ \\mathrm{E}(N) + \\mu^2 \\ \\mathrm{Var}(N)\\\\ &amp;= 3937^2(8) + 10000^2 (3^2) = 1.023.999.752\\\\ \\sqrt{\\mathrm{Var}(S_N)} &amp;= 31.999,996 \\approx 32.000 \\end{aligned}\\] Bajo la aproximación normal, la pérdida agregada \\(S_N\\) es aproximadamente normal con media 80.000 y desviación estándar 32.000. La probabilidad que \\(S_N\\) supere el 150\\(\\%\\) de la pérdida agregada esperada es, por lo tanto \\[\\begin{aligned} \\Pr(S_N&gt;1,5 \\mathrm{E}(S_N)~) &amp;= \\Pr \\left( \\frac{S_N - \\mathrm{E} (S_N)}{\\sqrt{\\mathrm{Var}(S_N)}} &gt; \\frac{1,5 ~\\mathrm{E}(S_N) - \\mathrm{E} (S_N)}{\\sqrt{\\mathrm{Var}(S_N)}} \\right) \\\\ &amp;\\approx \\Pr \\left( Z &gt; \\frac{0,5~ \\mathrm{E}(S_N)}{\\sqrt{\\mathrm{Var}(S_N)} } \\right), ~~~~ \\text{donde } Z\\sim N(0,1) \\\\ &amp;= \\Pr \\left( Z &gt; \\frac{0,5(80.000)}{32.000} \\right) = \\Pr( Z &gt; 1,25) \\\\ &amp;= 1-\\Phi(1,25) = 0,1056 \\end{aligned}\\] Ejemplo 5.3.5. Pregunta Examen Actuarial. Para un individuo de más de \\(65\\): (i) El número de reclamaciones por cobertura de medicinas es una variable aleatoria de Poisson con media \\(25\\). (ii) La cuantía de cada reclamación por cobertura de medicinas se distribuye uniformemente entre \\(5\\) y \\(95\\). iii) Las cuantías de las reclamaciones y el número de reclamaciones son independientes entre sí. Estimar la probabilidad que el coste total de las reclamaciones del individuo supere los \\(2000\\) mediante la aproximación normal. Mostrar Solución de Ejemplo Solución. Se sabe que la frecuencia de siniestros \\(N \\sim Poi(\\lambda = 25)\\) y severidad de los siniestros \\(X \\sim U \\left(5, 95 \\right)\\). Para utilizar la aproximación normal, se necesita encontrar la media y varianza del coste total de las reclamaciones \\(S_N\\). Note que \\[\\begin{matrix} \\begin{array}{lll} \\mathrm{E} (N) = 25 &amp; &amp; \\mathrm{Var} (N) = 25\\\\ \\mathrm{E}(X) = \\frac{5+95}{2} = 50 = \\mu &amp; &amp; \\mathrm{Var}(X) = \\frac{(95-5)^2}{12} = 675 = \\sigma^2\\\\ \\end{array} \\end{matrix}\\] Por lo tanto, para \\(S_N\\), \\[\\begin{aligned} \\mathrm{E}(S_N) &amp;= \\mu \\ \\mathrm{E} (N) = 50(25) = 1.250\\\\ \\mathrm{Var}(S_N) &amp;= \\sigma^2 \\ \\mathrm{E}(N) + \\mu^2 \\ \\mathrm{Var}(N)\\\\ &amp;= 675 (25) + 50^2 (25) = 79.375 \\end{aligned}\\] Utilizando la aproximación normal, \\(S_N\\) es aproximadamente normal con media 1.250 y varianza 79.375. La probabilidad de \\(S_N\\) exceda de 2.000 es \\[\\begin{aligned} \\Pr(S_N&gt;2.000) &amp;= \\Pr \\left(\\frac{S_N - \\mathrm{E} (S_N)}{\\sqrt{\\mathrm{Var} (S_N)}} &gt; \\frac{2.000- \\mathrm{E} (S_N)}{\\sqrt{\\mathrm{Var} (S_N)}} \\right) \\\\ &amp;= \\Pr\\left( Z &gt; \\frac{2.000-1.250}{\\sqrt{79.375}} \\right), ~~~~ \\text{donde } Z\\sim N(0,1) \\\\ &amp;= \\Pr (Z &gt; 2,662) = 1-\\Phi(2,662) = 0,003884 \\end{aligned}\\] 5.3.2 Seguro Stop-loss Recuerde las modificaciones de cobertura a nivel de póliza individual en la Sección 3.4. El seguro sobre la pérdida total \\(S_N\\), sujeto a un deducible \\(d\\), se llama seguro neto stop-loss. El valor esperado de la cantidad de la pérdida total que excede al deducible, \\[\\begin{eqnarray*} \\mathrm{E}[(S-d)_+] \\end{eqnarray*}\\] Se denomina prima neta stop-loss. La prima neta stop-loss se calcula como \\[\\begin{eqnarray*} \\mathrm{E}(S_N-d)_+ &amp;=&amp; \\left\\{\\begin{array}{ll} \\int_{d}^{\\infty}(s-d) f_{S_N}(s) ds&amp; \\text{para } S_N\\text{ continua }\\\\ \\sum_{s&gt;d}(s-d) f_{S_N}(s) &amp; \\text{para } S_N \\text{ discreta }\\\\ \\end{array}\\right.\\\\ &amp;=&amp; \\mathrm{E}(S_N) - \\mathrm{E}(S_N\\wedge d)\\\\ \\end{eqnarray*}\\] Ejemplo 5.3.6. Pregunta Examen Actuarial. En una determinada semana el número de proyectos en los que se requiere trabajar horas extras sigue una distribución geométrica con \\(\\beta=2\\). En cada proyecto la distribución del número de horas extras en la semana, \\(X\\), es la siguiente: \\[ {\\small \\begin{matrix} \\begin{array}{ccc} \\hline x &amp; &amp; f(x)\\\\ \\hline 5 &amp; &amp; 0,2 \\\\ 10 &amp; &amp; 0,3 \\\\ 20 &amp; &amp; 0,5\\\\ \\hline \\end{array} \\end{matrix} } \\] El número de proyectos y el número de horas extras son independientes. Se pagan las horas extras cuando exceden las 15 horas semanales. Calcular el número esperado de horas extras por las que se cobrará en la semana. Mostrar Solución de Ejemplo Solución. El número de proyectos en una semana que requieren horas extras sigue una distribución \\(N \\sim Geo(\\beta=2)\\), mientras que el número de horas extras trabajadas por proyecto sigue la distribución \\(X\\) descrita previamente. El número total de horas extras en una semana es \\(S_N\\) y, por lo tanto, se quiere saber \\[\\mathrm{E}(S_N-15)_+ = \\mathrm{E}(S_N) - \\mathrm{E}(S_N \\wedge 15).\\] Para encontrar \\(\\mathrm{E}(S_N) = \\mathrm{E}(X) ~\\mathrm{E}(N)\\), se sabe \\[\\begin{aligned} &amp;\\mathrm{E}(X) = 5(0,2) + 10(0,3)+ 20(0,5)= 14 \\\\ &amp;\\mathrm{E}(N) = 2 \\\\ \\Rightarrow \\ &amp;\\mathrm{E}(S) = \\mathrm{E}(X) ~ \\mathrm{E}(N) = 14(2) = 28 \\end{aligned}\\] Para encontrar \\(\\mathrm{E} (S_N \\wedge 15) = 0 \\Pr (S_N=0) + 5 \\Pr(S_N=5) + 10 \\Pr(S_N=10) + 15 \\Pr(S_N \\geq 15)\\), se sabe \\[\\begin{aligned} \\Pr(S_N=0) &amp;= \\Pr(N=0) = \\frac{1}{1+\\beta} = \\frac{1}{3} \\\\ \\Pr(S_N=5) &amp;= \\Pr(X=5, \\ N=1) = 0,2 \\left(\\frac{2}{9} \\right)= \\frac{0,4}{9}\\\\ \\Pr(S_N=10) &amp;= \\Pr(X=10, \\ N=1) + \\Pr(X_1=X_2=5, N=2) \\\\ &amp;= 0,3 \\left(\\frac{2}{9} \\right) + (0,2)(0,2) \\left( \\frac{4}{27} \\right)= 0,0726 \\\\ \\Pr(S_N \\geq 15) &amp;= 1 - \\left(\\frac{1}{3} + \\frac{0,4}{9} + 0,0726 \\right) = 0,5496\\\\ \\Rightarrow \\mathrm{E}(S_N \\wedge 15) &amp;= 0 \\Pr (S_N=0) + 5 \\Pr(S_N=5) + 10 \\Pr(S_N=10) + 15 \\Pr(S_N \\geq 15) \\\\ &amp;= 0 \\left( \\frac{1}{3} \\right) + 5 \\left( \\frac{0,4}{9} \\right) + 10 (0,0726) + 15 (0,5496) = 9,193\\\\ \\end{aligned}\\] Por lo tanto, \\[\\begin{aligned} \\mathrm{E}(S_N-15)_+ &amp;= \\mathrm{E}(S_N) - \\mathrm{E}(S_N \\wedge 15) \\\\ &amp;= 28 – 9,193 = 18,807 \\end{aligned}\\] Cálculo recursivo de la prima neta Stop-Loss. En el caso discreto, se puede calcular recursivamente como \\[\\begin{aligned} \\mathrm{E}\\left[ \\left( S_N-(j+1)h \\right) _{+} \\right]=\\mathrm{E}\\left[ ( S_N-jh )_{+} \\right] -h \\left( 1-F_{S_N}(jh) \\right) . \\end{aligned}\\] Se asume que el soporte de \\(S_N\\) está igualmente espaciado en unidades de \\(h\\). Para mostrar lo anterior, asumamos que \\(h=1\\). Se tiene que \\[\\begin{aligned} \\mathrm{E}\\left[ \\left( S_N-(j+1) \\right) _{+} \\right] &amp;=\\mathrm{E}(S_N) - \\mathrm{E}[S_N\\wedge (j+1)] \\ ,\\ \\text{ y } \\\\ \\mathrm{E}\\left[ \\left( S_N - j \\right)_+ \\right] &amp;=\\mathrm{E}(S_N) - \\mathrm{E}[S_N\\wedge j] \\end{aligned}\\] Por lo tanto, \\[\\begin{aligned} \\mathrm{E}\\left[ \\left(S_N-(j+1) \\right) _{+}\\right] - \\mathrm{E}\\left[ ( S_N-j )_{+} \\right] &amp;= \\left\\{\\mathrm{E}(S_N) - \\mathrm{E}(S_N\\wedge (j+1)) \\right\\} - \\left\\{\\mathrm{E}(S_N) - \\mathrm{E}(S_N\\wedge j) \\right\\} \\\\ &amp;= \\mathrm{E}\\left(S_N \\wedge j \\right) - \\mathrm{E}\\left[ S \\wedge (j+1) \\right] \\end{aligned}\\] Puede expresarse como \\[\\begin{aligned} \\mathrm{E}\\left[S_N\\wedge (j+1)\\right] &amp;= \\sum_{x=0}^{j}xf_{S_N}(x) + (j+1)~\\Pr(S_N \\ge j+1) \\\\ &amp;= \\sum_{x=0}^{j-1}x f_{S_N}(x) + j~\\Pr(S_N=j) + (j+1)~\\Pr(S_N \\ge j+1) \\end{aligned}\\] Del mismo modo, \\[\\begin{aligned} \\mathrm{E}(S_N\\wedge j) = \\sum_{x=0}^{j-1}xf_{S_N}(x) + j~\\Pr(S_N\\ge j) \\end{aligned}\\] Con estas expresiones se tiene que \\[\\begin{aligned} \\mathrm{E}\\left[ \\left( S_N-(j+1) \\right) _{+} \\right] - \\mathrm{E~}\\left[ ( S_N-j )_{+} \\right] &amp;= \\mathrm{E}\\left(S_N \\wedge j \\right) - \\mathrm{E}\\left[ S \\wedge (j+1) \\right] \\\\ &amp;= \\left\\{ \\sum_{x=0}^{j-1}xf_{S_N}(x) + j~\\Pr(S_N\\ge j) \\right\\} - \\left\\{ \\sum_{x=0}^{j-1}x f_{S_N}(x) + j~\\Pr(S_N=j) + (j+1)~\\Pr(S_N \\ge j+1) \\right\\} \\\\ &amp;= j~\\left[\\Pr(S_N \\geq j) - \\Pr(S_N=j) \\right]- (j+1)~\\Pr(S_N \\ge j+1) \\\\ &amp;= j~\\Pr( S_N &gt; j) - (j+1)~\\Pr(S_N \\ge j+1) ~~~~ \\text{ (nótese que } \\Pr(S_N &gt; j) = \\Pr(S_N \\geq j+1) \\text{)} \\\\ &amp;= -\\Pr(S_N\\ge j+1) = -\\left[1 - F_{S_N}(j)\\right], \\end{aligned}\\] como se buscaba. Ejemplo 5.3.7. Pregunta Examen Actuarial - Continuación. Recordemos que el objetivo de esta pregunta era calcular \\(\\mathrm{E~}(S_N-15)_+\\). Tenga en cuenta que el soporte de \\(S_N\\) está igualmente espaciado en unidades de 5, por lo que esta pregunta también puede resolverse recursivamente mediante la expresión anterior con \\(h=5\\): Paso 1: \\[\\begin{aligned} \\mathrm{E~}(S_N-5)_+ &amp;= \\mathrm{E}(S_N) - 5 [1-\\Pr(S_N \\leq 0) ]\\\\ %\\Pr (S_N\\geq 5) \\\\ &amp;= 28 - 5 \\left(1 - \\frac{1}{3}\\right) = \\frac{74}{3}=24,6667 \\end{aligned}\\] Paso 2: \\[\\begin{aligned} \\mathrm{E~}(S_N-10)_+ &amp;= \\mathrm{E~}(S_N-5)_+ - 5 [1-\\Pr(S_N \\leq 5)]\\\\ %\\Pr (S_N\\ge 10) \\\\ &amp;= \\frac{74}{3} - 5\\left( 1 - \\frac{1}{3} - \\frac{0,4}{9}\\right) = 21,555 \\end{aligned}\\] Paso 3: \\[\\begin{aligned} \\mathrm{E~}(S_N-15)_+ &amp;= \\mathrm{E~}(S_N-10)_+ - 5 [1-\\Pr(S_N \\leq 10)] \\\\ %\\Pr (S_N\\ge 15) \\\\ &amp;= \\mathrm{E~}(S_N-10)_+ - 5\\Pr (S_N\\ge 15) \\\\ &amp;= 21,555 - 5 (0,5496) = 18,807 \\end{aligned}\\] 5.3.3 Resultados analíticos Existen algunas combinaciones de distribuciones de frecuencia y severidad de los siniestros que generan una distribución fácil de utilizar para las pérdidas agregadas. Esta sección proporciona algunos ejemplos sencillos. Aunque estos ejemplos son convenientes desde el punto de vista computacional, por lo general son demasiado sencillos para ser utilizados en la práctica. Ejemplo 5.3.8. Se obtiene una expresión cerrada para la distribución de la pérdida agregada cuando se considera una distribución geométrica para la frecuencia y una distribución exponencial para la severidad. Supongamos que el número de siniestros \\(N\\) sigue una geométrica con media \\(\\mathrm{E}(N)=\\beta\\), y que la cuantía del siniestro \\(X\\) sigue una exponencial con \\(\\mathrm{E}(X)=\\theta\\). Recuerde que la pgf de \\(N\\) y la mgf de \\(X\\) son: \\[\\begin{aligned} P_N (z) &amp;=\\frac{1}{1- \\beta (z-1)}\\\\ M_{X}(t) &amp;=\\frac{1}{1-\\theta t} \\end{aligned}\\] Por lo tanto, la mgf de la pérdida agregada \\(S_N\\) puede expresarse de dos formas (para más detalles, véase Suplemento Técnico 5.A.3) \\[\\begin{eqnarray} M_{S_N}(t) &amp;=&amp; P_N [M_{X}(t)] = \\frac{1}{1 - \\beta \\left( \\frac{1}{1-\\theta t} - 1\\right)} \\nonumber\\\\ &amp;=&amp; 1+ \\frac{\\beta}{1+\\beta} \\left([1-\\theta(1+\\beta)t]^{-1}-1 \\right)\\\\ &amp;=&amp; \\frac{1}{1+\\beta}(1) +\\frac{\\beta}{1+\\beta} \\left( \\frac{1}{1-\\theta (1+\\beta)t}\\right) \\end{eqnarray}\\] A partir de (5.1), se aprecia que \\(S_N\\) es equivalente a una distribución compuesta de \\(S_N=X^{*}_1+\\cdots+X^{*}_{N^{*}}\\), donde \\(N^{*}\\) es una Bernoulli con media \\(\\beta/(1+\\beta)\\) y \\(X^{*}\\) es una exponencial con media \\(\\theta(1+\\beta)\\). Para obtenerlo, se analiza la mgf de \\(S\\): \\[\\begin{aligned} M_{S_N}(t) = P_N [M_{X}(t)] = P_{N^{*}} [M_{X^{*}}(t)], \\end{aligned}\\] donde \\[\\begin{aligned} P_{N^*} (z) &amp;=1+ \\frac{\\beta}{1+ \\beta} (z-1),\\\\ M_{X^*} (t) &amp;=\\frac{1}{1- {{\\theta(1+\\beta)}} t}. \\end{aligned}\\] A partir de (5.2), se aprecia que \\(S_N\\) es también equivalente a una mixtura de dos puntos en 0 y en \\(X^{*}\\). En concreto, \\[\\begin{eqnarray*} S_N &amp;=&amp; \\left\\{ \\begin{array}{cl} 0 &amp; {\\rm con~ probabilidad ~Pr}(N^*=0) = 1/(1+\\beta) \\\\ Y^{*} &amp; {\\rm con~ probabilidad ~Pr}(N^*=1) = \\beta/(1+\\beta) \\end{array} \\right.. \\end{eqnarray*}\\] La función de distribución de \\(S_N\\) es: \\[\\begin{eqnarray*} \\Pr(S_N=0) &amp;=&amp; \\frac{1}{1+\\beta}\\\\ \\Pr(S_N&gt;s) &amp;=&amp; \\Pr(X^*&gt;s) =\\frac{\\beta}{1+\\beta} \\exp\\left( -\\frac{s}{ \\theta (1+\\beta)}\\right) \\end{eqnarray*}\\] con pdf \\[\\begin{eqnarray*} f_{S_N}(s) = \\frac{\\beta}{\\theta (1+\\beta)^2}\\exp\\left( -\\frac{s}{ \\theta (1+\\beta)}\\right). \\end{eqnarray*}\\] Ejemplo 5.3.9. Supongamos un modelo de riesgo colectivo en el que la severidad sigue una exponencial y con una distribución de frecuencias arbitraria. Recordemos que si \\(X_i\\sim Exp(\\theta)\\), la suma de iid exponenciales, \\(S_n=X_1+\\cdots+X_n\\), sigue una distribución gamma, es decir, \\(S_n\\sim Gam(n,\\theta)\\). Su cdf es: \\[\\begin{eqnarray*} F_{X}^{\\ast n}(s) &amp;=&amp; \\Pr (S_n \\le s) = \\int_{0}^{s} \\frac{1}{\\Gamma(n)\\theta^n}s^{n-1}\\exp\\left(-\\frac{s}{\\theta}\\right) ds\\\\ &amp;=&amp; 1-\\sum_{j=0}^{n-1}\\frac{1}{j!}\\left( \\frac{s}{\\theta}\\right)^j e^{-s/\\theta } . \\end{eqnarray*}\\] La última igualdad se deriva aplicando integración por partes \\(n-1\\) veces. Para la distribución de pérdidas agregadas, se puede intercambiar el orden de las sumas en la segunda línea, obteniendo \\[\\begin{eqnarray*} F_{S}\\left(s\\right) &amp;=&amp; p_{0}+\\sum_{n=1}^{\\infty }p_n F_{X}^{\\ast n}\\left(s\\right)\\\\ &amp;=&amp; 1 - \\sum_{n=1}^{\\infty }p_n \\sum_{j=0}^{n-1}\\frac{1}{j!} \\left( \\frac{s}{\\theta}\\right)^j e^{-s/\\theta }\\\\ &amp;=&amp; 1-e^{-s/\\theta}\\sum_{j=0}^{\\infty} \\frac{1}{j!} \\left( \\frac{s}{\\theta} \\right)^j \\overline{P}_j \\end{eqnarray*}\\] donde \\(\\overline{P}_j =p_{j+1}+p_{j+2}+\\cdots = \\Pr (N&gt;j)\\) es la “función de supervivencia” de la distribución del número de siniestros. 5.3.4 Distribución Tweedie En esta sección se analiza una distribución compuesta concreta en la que el número de siniestros sigue una distribución de Poisson y la cuantía del siniestro sigue una distribución gamma. Esta especificación genera lo que se conoce como distribución Tweedie. La distribución Tweedie tiene masa de probabilidad en cero y una componente continua para valores positivos. Esta característica hace que sea ampliamente utilizada en la modelización de la siniestralidad en seguros, donde la masa en cero se interpreta como ningún siniestro y la componente positiva como el coste de los siniestros. Concretamente, consideremos el modelo de riesgo colectivo \\(S_N=X_1+\\cdots+X_N\\). Supongamos que \\(N\\) sigue una distribución Poisson con media \\(\\lambda\\), y cada \\(X_i\\) sigue una distribución gamma con parámetro de forma \\(\\alpha\\) y parámetro de escala \\(\\gamma\\). La distribución Tweedie se deriva como la suma de Poisson de variables gamma. Para comprender la distribución de \\(S_N\\), primero examinemos la masa de probabilidad en cero. La pérdida total es cero cuando no se producen siniestros, es decir, \\[{\\rm Pr}(S_N=0)= {\\rm Pr}(N=0)=e^{-\\lambda}.\\] Además, cabe señalar que \\(S_N\\) condicionada a \\(N=n\\), denotada como \\(S_n=X_1+\\cdots+X_n\\), sigue una distribución gamma con parámetro de forma \\(n\\alpha\\) y escala \\(\\gamma\\). Para \\(s&gt;0\\) la densidad de la distribución Tweedie se calcula como \\[\\begin{aligned} f_{S_n}(s)&amp;=\\sum_{n=1}^{\\infty} p_n f_{S_n}(s)\\\\ &amp;=\\sum_{n=1}^{\\infty}e^{-\\lambda}\\frac{(\\lambda)^n}{n!}\\frac{\\gamma^{na}}{\\Gamma(n\\alpha)}s^{n\\alpha-1}e^{-s\\gamma} \\end{aligned}\\] Así, la distribución Tweedie se puede interpretar como una mixtura en cero y una distribución para valores positivos, lo que la convierte en una herramienta adecuada para la modelización de la siniestralidad y para el cálculo de las primas puras en seguros. La media y la varianza del modelo Tweedie-Poisson compuesto son: \\[{\\rm E} (S_N)=\\lambda\\frac{\\alpha}{\\gamma}~~~~{\\rm y}~~~~{\\rm Var} (S)=\\lambda\\frac{\\alpha(1+\\alpha)}{\\gamma^2}.\\] Otra característica importante es que la distribución Tweedie es un caso especial de los modelos de dispersión exponencial, una clase de modelos utilizados para describir la componente aleatoria en los modelos lineales generalizados. Para apreciarlo, consideremos la siguiente reparametrización: \\[\\begin{equation*} \\lambda=\\frac{\\mu^{2-p}}{\\phi(2-p)},~~~~\\alpha=\\frac{2-p}{p-1},~~~~\\frac{1}{\\gamma}=\\phi(p-1)\\mu^{p-1} \\end{equation*}\\] A partir de estas relaciones se puede demostrar que la distribución de \\(S_N\\) es \\[f_{S_N}(s)=\\exp\\left[\\frac{1}{\\phi}\\left(\\frac{-s}{(p-1)\\mu^{p-1}}-\\frac{\\mu^{2-p}}{2-p}\\right)+C(s;\\phi)\\right]\\] donde \\[\\begin{equation*} C(s;\\phi/\\omega_i)=\\left\\{\\begin{array}{ll} \\displaystyle 0 &amp; {\\rm if}~ y=0 \\\\ \\displaystyle \\ln \\sum\\limits_{n\\ge 1} \\left\\{\\frac{(1/\\phi)^{1/(p-1)}y^{(2-p)/(p-1)}}{(2-p)(p-1)^{(2-p)/(p-1)}}\\right\\}^{n}\\frac{1}{n!\\Gamma(n(2-p)/(p-1))s} &amp; {\\rm if}~ y&gt;0 \\end{array}\\right. \\end{equation*}\\] Por tanto, la distribución de \\(S_N\\) pertenece a la familia exponencial con parámetros \\(\\mu\\), \\(\\phi\\), y \\(1 &lt; p &lt; 2\\), y se obtiene que \\[{\\rm E} (S_N)=\\mu~~~~{\\rm y}~~~~{\\rm Var} (S_N)=\\phi\\mu^{p}.\\] Lo anterior permite utilizar la distribución Tweedie para modelizar los siniestros en los modelos lineales generalizados. Cabe mencionar los dos casos límite del modelo Tweedie: \\(p\\rightarrow 1\\) conduce a la distribución Poisson y \\(p\\rightarrow 2\\) conduce a la distribución gamma. De este modo, el modelo Tweedie se sitúa entre las distribuciones gamma y Poisson, lo que intuitivamente tiene sentido ya que es la suma de Poisson de variables aleatorias gamma. 5.4 Cálculo de la distribución de pérdidas agregadas El cálculo de la distribución de pérdidas agregadas es un problema difícil e importante. Como se ha visto, tanto para el modelo de riesgo individual como para el modelo de riesgo colectivo, el cálculo de la distribución frecuentemente implica la evaluación de una convolución de orden \\(n\\). Para hacer manejable el problema, una posible estrategia es considerar una distribución que sea fácil de evaluar para aproximar la distribución de pérdidas agregadas. Por ejemplo, la distribución normal es una elección natural basada en el teorema central del límite, en el que los parámetros de la distribución normal pueden estimarse calculando los momentos. Este enfoque tiene ventajas y limitaciones. La principal ventaja es la facilidad de cálculo. La desventaja es: primero, el tamaño y la dirección del error de aproximación son desconocidos; segundo, la aproximación puede fallar en capturar algunas características especiales de la pérdida agregada tales como la masa en el punto cero. Esta sección describe dos enfoques prácticos para calcular la distribución de la pérdida agregada, el método recursivo y la simulación. 5.4.1 Método recursivo El método recursivo se aplica a los modelos compuestos en los que la componente de la frecuencia \\(N\\) pertenece a la clase \\((a,b,0)\\) o \\((a,b,1)\\) (véanse las Secciones 2.3 y 2.5.1) y la componente de la severidad \\(X\\) sigue una distribución discreta. En caso que \\(X\\) sea continua, una práctica habitual es primero discretizar la distribución de la severidad y, posteriormente, aplicar el método recursivo. Supongamos que \\(N\\) está en la clase \\((a,b,1)\\) tal que \\(p_{k}=\\left( a+\\frac{b}{k} \\right) p_{k-1}, k = 2,3,\\ldots\\). Supongamos además que el soporte de \\(X\\) es \\(\\{0,1,\\ldots,m\\}\\), discreto y finito. Entonces, la función de probabilidad de \\(S_N\\) es: \\[\\begin{aligned} f_{S_N}(s)&amp;=\\Pr (S=s) \\\\ &amp;=\\frac{1}{1-af_{X}(0)}\\left\\{ \\left[ p_1 -(a+b)p_{0}\\right] f_X (s)+\\sum_{x=1}^{s\\wedge m}\\left( a+\\frac{bx}{s} \\right) f_X (x)f_{S_N}(s-x)\\right\\}. \\end{aligned}\\] Si \\(N\\) está en la clase \\((a,b,0)\\), entonces \\(p_1=(a+b)p_0\\) y, por tanto, \\[ f_{S_N}(s)=\\frac{1}{1-af_X (0)}\\left\\{ \\sum_{x=1}^{s\\wedge m}\\left( a+\\frac{bx }{s}\\right) f_X (x)f_{S_N}(s-x)\\right\\}. \\] Caso particular: Frecuencia según una Poisson. Si \\(N \\sim Poi(\\lambda)\\), entonces \\(a=0\\) y \\(b=\\lambda\\), y, por tanto, \\[ f_{S_N}(s)=\\frac{\\lambda }{s}\\left\\{ \\sum_{x=1}^{s \\wedge m} x f_X (x) f_{S_N} (s-x)\\right\\} . \\] Ejemplo 5.4.1. Pregunta Examen Actuarial. El número de siniestros en un determinado período \\(N\\) sigue una distribución geométrica de media 4. La cuantía de cada siniestro \\(X\\) tiene \\({\\rm Pr} (X = x) = 0,25\\), para \\(x = 1,2,3,4\\). El número de siniestros y la cuantía de los mismos son independientes. \\(S_N\\) es el coste total de los siniestros en el período. Calcular \\(F_{S_N}(3)\\). Mostrar Solución de Ejemplo Solución. La distribución de severidad \\(X\\) es la siguiente \\[f_X (x) = \\frac{1}{4}, \\ \\ x=1, 2, 3, 4.\\] La distribución de frecuencias \\(N\\) es geométrica de media 4, la cual pertenece a la clase \\((a,b,0)\\) con \\(b=0\\), \\(a=\\frac{\\beta}{1+\\beta} = \\frac{4}{5}\\), y \\(p_0 = \\frac{1}{1+\\beta} = \\frac{1}{5}\\). El soporte de la componente de severidad \\(X\\) es \\(\\{1,\\ldots,m=4 \\}\\), discreto y finito. Por lo tanto, se puede utilizar el método recursivo \\[\\begin{aligned} f_{S_N} (x) &amp;= 1 \\sum_{y=1}^{x\\wedge m} (a+0) f_X (y) f_{S_N} (x-y) \\\\ &amp;= \\frac{4}{5} \\sum_{y=1}^{x\\wedge m} f_X (y) f_{S_N} (x-y) \\end{aligned}\\] En concreto, se tiene que \\[\\begin{aligned} f_{S_N} (0) &amp;= \\Pr(N=0) = p_0=\\frac{1}{5}\\\\ f_{S_N} (1) &amp;= \\frac{4}{5}\\sum_{y=1}^{1} f_X (y) f_{S_N} (1-y) = \\frac{4}{5} f_X(1) f_{S_N}(0)\\\\ &amp;= \\frac{4}{5}\\left( \\frac{1}{4}\\right)\\left(\\frac{1}{5} \\right) = \\frac{1}{25}\\\\ f_{S_N} (2) &amp;= \\frac{4}{5}\\sum_{y=1}^{2} f_X (y) f_{S_N} (2-y) = \\frac{4}{5} \\left[ f_X(1)f_{S_N}(1) + f_X(2) f_{S_N}(0) \\right] \\\\ &amp;= \\frac{4}{5}\\left[ \\frac{1}{4} \\left( \\frac{1}{25} + \\frac{1}{5}\\right) \\right] = \\frac{4}{5}\\left( \\frac{6}{100}\\right) = \\frac{6}{125}\\\\ f_{S_N} (3) &amp;= \\frac{4}{5} \\left[ f_X(1) f_{S_N}(2) + f_X(2)f_{S_N}(1) + f_X(3) f_{S_N}(0) \\right]\\\\ &amp;= \\frac{4}{5}\\left[ \\frac{1}{4} \\left( \\frac{1}{25} + \\frac{1}{5} + \\frac{6}{125}\\right) \\right] = \\frac{1}{5}\\left( \\frac{5+25+6}{125}\\right) = 0,0576\\\\ \\Rightarrow \\ F_{S_N} (3) &amp;= f_{S_N} (0)+f_{S_N} (1)+f_{S_N} (2) +f_{S_N} (3) = 0,3456 \\end{aligned}\\] 5.4.2 Simulación La distribución de pérdidas agregadas puede evaluarse mediante simulación de Monte Carlo. La idea es que se puede calcular la distribución empírica de \\(S_N\\) utilizando una muestra aleatoria. El valor esperado y la varianza de la pérdida agregada también pueden estimarse a partir de la media muestral y varianza muestral de los valores simulados. A continuación se resumen los procedimientos de simulación para los modelos de pérdidas agregadas. Supongamos que \\(m\\) es el tamaño de la muestra aleatoria generada de pérdidas agregadas. Modelo de Riesgo Individual \\(S_n=X_1+\\cdots+X_n\\) Supongamos el contador \\(j=1,\\ldots,m\\). Se fija \\(j=1\\). Se genera cada realización de pérdida individual \\(x_{ij}\\) para \\(i=1,\\ldots,n\\). Por ejemplo, se puede utilizar el método de transformación inversa (Sección 6.2). Se calcula la pérdida total \\(s_j = x_{1j} + \\cdots + x_{nj}\\). Se repiten los dos pasos anteriores para \\(j=2,\\ldots,m\\) hasta obtener una muestra de tamaño \\(m\\) de \\(S_n\\), es decir, \\(\\{s_1,\\ldots,s_m\\}\\). Modelo de riesgo colectivo \\(S_N=X_1+\\cdots+X_N\\) Supongamos el contador \\(j=1,\\ldots,m\\). Se fija \\(j=1\\). Se genera el número de siniestros \\(n_j\\) de la distribución de frecuencias \\(N\\). Dado \\(n_j\\), se genera a partir de la distribución de severidad \\(X\\) la cuantía de cada siniestro independiente, denotado por \\(x_{1j},\\ldots,x_{n_j j}\\). Se calcula la pérdida agregada \\(s_j = x_{1j} + \\cdots + x_{n_j j}\\). Se repiten los tres pasos anteriores para \\(j=2,\\ldots,m\\) hasta obtener una muestra de tamaño \\(m\\) de \\(S_N\\), es decir, \\(\\{s_1,\\ldots, s_m\\}\\). A partir de la muestra aleatoria de \\(S\\), la distribución empírica se puede calcular como \\[\\hat{F}_S(s)=\\frac{1}{m}\\sum_{i=1}^{m}I(s_i\\leq s),\\] donde \\(I(\\cdot)\\) es una función indicadora. La distribución empírica \\(\\hat{F}_S(s)\\) convergerá casi seguramente a \\({F}_S(s)\\) a medida que el tamaño muestral \\(m\\rightarrow \\infty\\). El procedimiento anterior asume que se conocen las distribuciones de probabilidad, incluidos los valores de los parámetros, de las distribuciones de frecuencia y severidad. En la práctica, primero habría que seleccionar estas distribuciones, estimar sus parámetros a partir de los datos, y luego evaluar la calidad del ajuste del modelo utilizando diferentes herramientas de validación del modelo (véase el capítulo 4). Por ejemplo, los supuestos del modelo de riesgo colectivo sugieren una estimación en dos etapas, en la que se construye un modelo para el número de siniestros \\(N\\) a partir de los datos de conteo de siniestros, y otro modelo para la severidad de los siniestros \\(X\\) a partir de los datos del importe de los siniestros. *** Ejemplo 5.4.2. Consideremos el ejemplo 5.3.5 con la frecuencia de siniestros del individuo \\(N \\sim Poi(\\lambda=25)\\) y severidad de los siniestros \\(X \\sim U(5,95)\\). A partir de una muestra simulada de 10.000 observaciones, estimar la media y la varianza de la pérdida agregada \\(S_N\\). Además, utilizar la muestra simulada para estimar la probabilidad que el coste total de la siniestralidad para esta persona será superior a 2000 y compararla con la estimación basada en la aproximación normal del ejemplo 5.3.5. Mostrar Solución de Ejemplo Solución. Se sigue el algoritmo para el modelo de riesgo colectivo, en el que primero se simulan las frecuencias \\(n_1,\\ldots,n_{10000}\\), y condicionado a \\(n_j,~j=1,\\ldots,10000\\), se simula cada pérdida individual \\(x_{ij},~i=1,\\ldots n_j\\). set.seed(4321) # Para reproducir los resultados m &lt;- 10000 # Número de observaciones a simular lambda &lt;- 25 # Parámetro de la distribución de frecuencias N a &lt;- 5; b &lt;- 95 # Parámetros de la distribución de severidad X S &lt;- rep(NA, m) # Creación un vector vacío para almacenar las observaciones S n &lt;- rpois(m, lambda) # Se generan m=10000 observaciones de N de una Poisson for(j in 1:m){ n_j &lt;- n[j] # A partir de cada n_j (j=1,...,m), se generan n_j observaciones de X de una uniforme x_j &lt;- runif(n_j, min=a, max=b) s_j &lt;- sum(x_j) # Se calcula la pérdida agregada s_j S[j] &lt;- s_j # Se almacena s_j en el vector de observaciones } mean(S) # Compararlo con el valor teórico de 1250 ## [1] 1248.09 var(S) # Compararlo con el valor teórico de 79375 ## [1] 77441.22 mean(S&gt;2000) # Proporción de observaciones simuladas s_j que son &gt; 2000 ## [1] 0.0062 # Compararlo con el método de aproximación normal de 0,003884 A partir de la simulación se estima que la media y varianza de la siniestralidad agregada es aproximadamente 1248 y 77441 respectivamente, en comparación con los valores teóricos de 1.250 y 79.375. Además, se estima que la probabilidad que las pérdidas agregadas excedan 2000 es 0.0062, en comparación con la estimación de aproximación normal de 0,003884. Se puede evaluar si es apropiada la aproximación normal comparando la distribución empírica de las pérdidas agregadas simuladas con la densidad de la distribución normal utilizada para la aproximación normal, \\(N(\\mu=1,250~, ~\\sigma^2=79,375)\\): Las pérdidas simuladas son ligeramente más asimétricas a la derecha que la distribución normal, con una cola a la derecha más pesada. Lo anterior explicaría el hecho que el estimador de \\(\\Pr(S_N &gt; 2000)\\) de la aproximación normal es menor que el estimador basado en la simulación. 5.5 Efectos de la modificación de las coberturas 5.5.1 Impacto de la exposición en la frecuencia Esta sección se centra en un modelo de riesgo individual para el número de siniestros. Recordemos que el modelo de riesgo individual implica un número fijo de contratos \\(n\\) y variables aleatorias de pérdidas independientes \\(X_i\\). Considere el número de siniestros de un grupo de pólizas \\(n\\): \\[S=X_1+\\cdots+X_n\\] donde se asume que las \\(X_i\\) son iid que representan el número de siniestros de cada póliza \\(i\\). En este caso, la exposición de la cartera es \\(n\\), utilizando la póliza como base de exposición. La pgf de \\(S\\) es \\[\\begin{aligned} P_{S}(z)&amp;={\\rm E}(z^S)={\\rm E}\\left(z^{\\sum_{i=1}^nX_i}\\right)\\\\ &amp;=\\prod_{i=1}^n{\\rm E}(z^{X_i})=[P_X(z)]^n \\end{aligned}\\] Caso particular: Poisson. Si \\(X_i\\sim Poi(\\lambda)\\), su pgf es \\(P_X(z)=e^{\\lambda(z-1)}\\). Entonces la pgf de \\(S\\) es \\[P_{S}(z)=[e^{\\lambda(z-1)}]^n=e^{n\\lambda(z-1)}.\\] Por tanto \\(S\\sim Poi(n\\lambda)\\). Es decir, la suma de \\(n\\) variables aleatorias de Poisson independientes, cada una de media \\(\\lambda\\), sigue una distribución de Poisson de media \\(n\\lambda\\). Caso particular: Binomial Negativa. Si \\(X_i\\sim NB(\\beta,r)\\), su pgf es \\(P_X(z)=[1-\\beta(z-1)]^{-r}\\). Entonces la pgf de \\(S\\) es \\[P_{S}(z)=[[1-\\beta(z-1)]^{-r}]^n=[1-\\beta(z-1)]^{-nr}.\\] Por tanto \\(S\\sim NB(\\beta,nr)\\). Ejemplo 5.5.1. Supongamos que el número de siniestros por vehículo sigue una Poisson con media \\(\\lambda\\). Dados los siguientes datos sobre el número observado de siniestros para cada hogar, estima \\(\\lambda\\) por máxima verosimilitud. \\[ {\\small \\begin{matrix} \\begin{array}{c|c|c} \\hline \\text{Hogar ID} &amp; \\text{Número de vehículos} &amp; \\text{Número de siniestros} \\\\ \\hline 1 &amp; 2 &amp; 0 \\\\ 2 &amp; 1 &amp; 2 \\\\ 3 &amp; 3 &amp; 2 \\\\ 4 &amp; 1 &amp; 0 \\\\ 5 &amp; 1 &amp; 1 \\\\ \\hline \\end{array} \\end{matrix} } \\] Mostrar Solución de Ejemplo Solución. Cada uno de los 5 hogares tiene un número de exposiciones \\(n_j\\) (número de vehículos) y un número de siniestros \\(S_j\\), \\(j=1,...,5\\). En cada hogar el número de siniestros \\(S_j \\sim Poi (n_j \\lambda)\\). La función de verosimilitud es \\[\\begin{aligned} L(\\lambda) &amp;= \\prod_{j=1}^5 \\Pr(S_j=s_j) = \\prod_{j=1}^5 \\frac{e^{-n_j\\lambda} (n_j \\lambda)^{s_j}}{s_j!} \\\\ &amp;= \\left(\\frac{e^{-2\\lambda} (2 \\lambda)^{0}}{0!} \\right) \\left(\\frac{e^{-1\\lambda} (1 \\lambda)^{2}}{2!} \\right) \\left(\\frac{e^{-3\\lambda} (3 \\lambda)^{2}}{2!} \\right) \\left(\\frac{e^{-1\\lambda} (1 \\lambda)^{0}}{0!} \\right) \\left(\\frac{e^{-1\\lambda} (1 \\lambda)^{1}}{1!} \\right) \\\\ &amp;\\propto e^{-8\\lambda} \\lambda^5 \\end{aligned}\\] Tomando el logaritmo de verosimilid, se tiene \\[\\begin{aligned} l(\\lambda) = \\log L(\\lambda) = -8\\lambda + 5\\log(\\lambda) \\end{aligned}\\] Igualando a cero la primera derivada del logaritmo de verosimilitud, se obtiene \\(\\hat{\\lambda} = \\frac{5}{8}\\) Si la exposición de la cartera cambia de \\(n_1\\) a \\(n_2\\), se puede establecer la siguiente relación entre el número total de siniestros: \\[P_{S_{n_2}}(z)=[P_X(z)]^{n_2}=[P_X(z)^{n_1}]^{n_2/n_1}=P_{S_{n_1}}(z)^{n_2/n_1}.\\] 5.5.2 Impacto de los deducibles en la frecuencia de siniestros Esta sección examina el efecto de los deducibles en la frecuencia de los siniestros. Intuitivamente, si se introduce un deducible en la póliza, disminuirán los siniestros reclamados ya que no se reclamará si la cuantía reclamada es inferior al deducible. Incluso si el asegurado realiza la reclamación, puede que no se realice ningún pago en la póliza, ya que puede denegarse el siniestro o que la cuantía del mismo se determine finalmente por debajo del deducible. Denotemos \\(N^L\\) el número de pérdidas (es decir, el número de siniestros sin deducible), y \\(N^P\\) el número de pagos cuando se establece un deducible \\(d\\). El objetivo es identificar la distribución de \\(N^P\\) dada la distribución de \\(N^L\\). A continuación se demuestra que la relación entre \\(N^L\\) y \\(N^P\\) puede establecerse en el marco del modelo de riesgo agregado. Cabe señalar que, en ocasiones, cambios en los deducibles podrían afectar al comportamiento de siniestralidad del asegurado. Suponemos aquí que esto no ocurre, es decir, que las distribuciones subyacentes de pérdidas, tanto para la frecuencia como para la severidad, se mantienen sin cambios cuando varía el deducible. Dado que ocurren \\(N^L\\) pérdidas, suponemos que \\(X_1,X_2\\ldots,X_{N^L}\\) son las cuantías asociadas de las pérdidas. Para \\(j=1,\\ldots,N^L\\), se define \\[\\begin{eqnarray*} I_j&amp;=&amp; \\left \\{ \\begin{array}{cc} 1 &amp; \\text{si} ~X_j&gt;d\\\\ 0 &amp; \\text{el resto de casos}\\\\ \\end{array} \\right.. \\end{eqnarray*}\\] Por tanto, se establece \\[N^P=I_1+I_2+\\cdots+I_{N_L},\\] Es decir, el número total de pagos es igual al número de pérdidas por encima del valor del deducible. Dado que las \\(I_j\\) son variables aleatorias de Bernoulli independientes con probabilidad de éxito \\(v=\\Pr(X&gt;d)\\), la suma de un número fijo de estas variables es una variable aleatoria binomial. Condicionado a \\(N^L\\), \\(N^P\\) sigue una distribución binomial, es decir, \\(N^P | N^L \\sim Bin(N^L, v)\\), donde \\(v=\\Pr(X&gt;d)\\). Lo anterior implica que \\[\\begin{aligned} \\mathrm{E}\\left(z^{N^P}|N^L\\right)&amp;= \\left[ 1+v(z-1)\\right]^{N^L} \\end{aligned}\\] Por tanto, la pgf de \\(N^P\\) es \\[\\begin{aligned} P_{N^P}(z)&amp;= \\mathrm{E}_{N^P}\\left(z^{N^P}\\right)=\\mathrm{E}_{N^L}\\left[\\mathrm{E}_{N^P}\\left(z^{N^P}|N^L\\right)\\right]\\\\ &amp;= \\mathrm{E}_{N^L}\\left[(1+v(z-1))^{N^L}\\right]\\\\ &amp;= P_{N^L}\\left(1+v(z-1)\\right) \\end{aligned}\\] Así, se puede definir la pgf de \\(N^P\\) como la pgf de \\(N^L\\), evaluada en un nuevo argumento \\(z^* = 1+v(z-1)\\). Esto es, \\(P_{N^P}(z)=P_{N^L}(z^*)\\). Casos particulares: \\(N^L\\sim Poi (\\lambda)\\). La pgf de \\(N^L\\) es \\(P_{N^L}=e^{\\lambda(z-1)}\\). De este modo, la pgf de \\(N^P\\) es \\[\\begin{aligned} P_{N^P}(z) &amp;= e^{ \\lambda(1+v(z-1)-1)} \\\\ &amp;= e^{\\lambda v(z-1)} , \\end{aligned}\\] Por tanto, \\(N^P \\sim Poi(\\lambda v)\\). Esto significa que el número de pagos tiene la misma distribución que el número de pérdidas, pero con un número esperado de pagos igual a \\(\\lambda v = \\lambda \\Pr(X&gt;d)\\). \\(N^L \\sim NB(\\beta, r)\\). La pgf de \\(N^L\\) es \\(P_{N^{L}}\\left( z\\right) =\\left[ 1-\\beta \\left( z-1\\right)\\right]^{-r}\\). De este modo, la pgf de \\(N^P\\) es \\[\\begin{aligned} P_{N^P}(z)&amp;= \\left( 1-\\beta (1+v(z-1)-1)\\right)^{-r}\\\\ &amp;= \\left( 1-\\beta v(z-1)\\right)^{-r}, \\end{aligned}\\] Por tanto, \\(N^P \\sim NB(\\beta v, r)\\). Esto significa que el número de pagos tiene la misma distribución que el número de pérdidas, pero con parámetros \\(\\beta v\\) y \\(r\\). Ejemplo 5.5.2. Supongamos que las pérdidas \\(X_i\\sim Pareto(\\alpha=4,\\ \\theta=150)\\). Sabemos que la frecuencia de pérdidas es \\(N^L\\sim Poi(\\lambda)\\) y la frecuencia de pagos es \\(N^{P}_1\\sim Poi(0,4)\\) con un deducible de valor igual a \\(d_1=30\\). Encontrar la distribución de la frecuencia de pagos \\(N^{P}_2\\) cuando el valor del deducible es \\(d_2=100\\). Mostrar Solución de Ejemplo Solución. Al ser la frecuencia de pérdidas \\(N^L\\) Poisson, las medias de la distribución de pérdidas \\(N^L\\) y la primera distribución de pagos \\(N^{P}_1\\) (con deducible \\(d_1=30\\)) se relacionan como \\(0,4 = \\lambda v_1\\), donde \\[\\begin{aligned} &amp;v_1 = \\Pr(X &gt; 30) = \\left( \\frac{150}{30+150}\\right)^4=\\left( \\frac{5}{6}\\right)^4 \\\\ \\Rightarrow \\ &amp; \\lambda = 0.4 \\left( \\frac{6}{5} \\right)^4 \\end{aligned}\\] Ahora, se puede definir la segunda distribución de pagos \\(N^{P}_2\\) (con deducible \\(d_2=100\\)) como Poisson con media \\(\\lambda_2 = \\lambda v_2\\), donde \\[\\begin{aligned} &amp; v_2 = \\Pr(X&gt;100)=\\left( \\frac{150}{100+150}\\right)^4=\\left( \\frac{3}{5}\\right)^4 \\\\ \\Rightarrow \\ &amp; \\lambda_2 = \\lambda v_2 = 0,4\\left( \\frac{6}{5} \\right)^4 \\left( \\frac{3}{5} \\right)^4 = 0,1075 \\end{aligned}\\] Ejemplo 5.5.3. Continuación. Ahora supongamos que la frecuencia de pérdidas es \\(N^L \\sim NB(\\beta,\\ r)\\) y para el deducible \\(d_1=30\\), la frecuencia de pagos \\(N^{P}_1\\) es negativa binomial con media \\(0,4\\). Encontrar la media de la frecuencia de pagos \\(N^{P}_2\\) para el deducible \\(d_2=100\\). Mostrar Solución de Ejemplo Solución. Al ser la frecuencia de pérdidas \\(N^L\\) una binomial negativa, el parámetro \\(\\beta\\) de la distribución \\(N^L\\) y el parámetro \\(\\beta_1\\) de la primera distribución de pagos \\(N^{P}_1\\) se relacionan como \\(\\beta_1 = \\beta v_1\\), donde \\[v_1 = \\Pr(X &gt; 30) = \\left( \\frac{5}{6} \\right)^4\\] Así, la media de \\(N^{P}_1\\) y la media de \\(N^L\\) se relacionan vía \\[\\begin{aligned} &amp;0,4 = r \\beta_1 = r \\left(\\beta v_1\\right) \\\\ \\Rightarrow \\ &amp; r\\beta = \\frac{0,4}{v_1} = 0,4 \\left(\\frac{6}{5} \\right)^4 \\end{aligned}\\] Nótese que \\(v_2 = \\Pr(X &gt; 100) = \\left( \\frac{3}{5}\\right)^4\\) como en el ejemplo original. Entonces, la segunda distribución de frecuencia de pagos con deducible \\(d_2=100\\) es \\(N^{P}_2 \\sim NB(\\beta v_2, \\ r)\\) con media \\[\\begin{aligned} r (\\beta v_2) = (r \\beta) v_2 = 0,4 \\left( \\frac{6}{5}\\right)^4 \\left( \\frac{3}{5} \\right)^4 = 0,1075 \\end{aligned}\\] A continuación, se examina el caso más general en el que \\(N^L\\) es una distribución cero modificada. Recordemos que una distribución cero modificada puede definirse en términos de una distribución no modificada (como se señala en la Sección 2.5.1). Es decir, \\[\\begin{aligned} p_k^M = c~p_k^0, {~\\rm para~} k=1,2,3,\\ldots, {~\\rm con~}c = \\frac{1-p_0^M}{1-p_0^0}, \\end{aligned}\\] donde \\(p^0_k\\) es la pmf de una distribución no modificada. En el caso que \\(p_0^M=0\\), se denomina una distribución cero truncada, o \\(ZT\\). Para otros valores arbitrarios de \\(p_0^M\\), es una distribución cero modificada, o \\(ZM\\). La pgf de la distribución modificada se obtiene como \\[\\begin{aligned} P^M(z) &amp;= 1-c+c~P^0(z), \\end{aligned}\\] expresada en términos de la pgf de la distribución no modificada, \\(P^0(z)\\). Cuando \\(N^L\\) sigue una distribución cero modificada, la distribución de \\(N^P\\) se establece usando la misma relación anterior, \\(P_{N^P}(z)=P_{N^L}\\left(1+v(z-1)\\right)\\). Casos particulares: \\(N^{L}\\) es una variable aleatoria ZM-Poisson con parámetros \\(\\lambda\\) y \\(p_0^{M}\\). La pgf de \\(N^L\\) es \\[P_{N^{L}}(z)=1-\\cfrac{1-p_0^{M}}{1-e^{-\\lambda}}+\\cfrac{1-p_0^{M}}{1-e^{-\\lambda}}\\left( e^{\\lambda(z-1)} \\right).\\] Por tanto, la pgf de \\(N^P\\) es \\[P_{N^{P}}(z)=1-\\cfrac{1-p_0^{M}}{1-e^{-\\lambda}}+\\cfrac{1-p_0^{M}}{1-e^{-\\lambda}}\\left( e^{\\lambda v(z-1)} \\right).\\] Así el número de pagos sigue también una distribución ZM-Poisson con parámetros \\(\\lambda v\\) y \\(p_0^{M}\\). La probabilidad en cero se puede evaluar mediante \\({\\rm Pr}(N^P=0) = P_{N^P}(0)\\). \\(N^{L}\\) es una variable aleatoria ZM-binomial negativa con parámetros \\(\\beta\\), \\(r\\), y \\(p_0^{M}\\). La pgf de \\(N^L\\) es \\[P_{N^{L}}(z)=1-\\cfrac{1-p_0^{M}}{1-(1+\\beta)^{-r}}+\\cfrac{1-p_0^{M}}{1-(1+\\beta)^{-r}}\\left[ 1-\\beta \\left( z-1\\right)\\right]^{-r}.\\] Por tanto, la pgf de \\(N^P\\) es \\[P_{N^{P}}(z)=1-\\cfrac{1-p_0^{M}}{1-(1+\\beta)^{-r}}+\\cfrac{1-p_0^{M}}{1-(1+\\beta)^{-r}}\\left[ 1-\\beta v\\left( z-1\\right)\\right]^{-r}.\\] Así, el número de pagos sigue también una distribución ZM-binomial negativa con parámetros \\(\\beta v\\), \\(r\\), y \\(p_0^{M}\\). Del mismo modo, la probabilidad en cero se puede evaluar mediante \\({\\rm Pr}(N^P=0) = P_{N^P}(0)\\). Ejemplo 5.5.4. Las pérdidas agregadas se modelizan de la siguiente manera: (i) El número de pérdidas sigue una distribución Poisson modificada en cero con \\(\\lambda=3\\) y \\(p_0^M = 0,5\\). (ii) La cuantía de la pérdida sigue una distribución Burr con \\(\\alpha=3, \\theta=50, \\gamma=1\\). (iii) Se introduce un deducible \\(d=30\\) para cada pérdida. (iv) El número de pérdidas y su cuantía son independientes entre sí. Calcular \\(\\mathrm{E}(N^P)\\) y \\(\\mathrm{Var}(N^P)\\). Mostrar Solución de Ejemplo Solución. Dado que \\(N^L\\) sigue una distribución ZM-Poisson con parámetros \\(\\lambda\\) y \\(p_0^M\\), sabemos que \\(N^P\\) también sigue una distribución ZM-Poisson, pero con parámetros \\(\\lambda v\\) y \\(p_0^M\\), donde \\[v = \\Pr(X&gt;30) = \\left( \\frac{1}{1+(30/50)} \\right)^3 = 0,2441\\] Por tanto, \\(N^P\\) sigue una distribución ZM-Poisson con parámetros \\(\\lambda^\\ast = \\lambda v= 0,7324\\) y \\(p_0^M = 0,5\\). Finalmente, \\[\\begin{aligned} \\mathrm{E} (N^P) &amp;= (1-p_0^M) \\frac{\\lambda^\\ast}{1-e^{-\\lambda^\\ast}} = 0,5 \\left( \\frac{0,7324}{1-e^{-0,7324}} \\right) \\\\ &amp;= 0,7053 \\\\ \\mathrm{Var} (N^P) &amp;= (1-p_0^M) \\left( \\frac{\\lambda^\\ast[1-(\\lambda^\\ast + 1) e^{-\\lambda^\\ast}]}{(1-e^{-\\lambda^\\ast})^2} \\right) + p_0^M(1-p_0^M) \\left(\\frac{\\lambda^\\ast}{1-e^{-\\lambda^\\ast}} \\right)^2 \\\\ &amp;= 0,5 \\left( \\frac{0,7324(1-1,7324 e^{-0,7324})}{(1-e^{-0,7324})^2} \\right) + 0,5^2 \\left( \\frac{0,7324}{1-e^{-0,7324}} \\right)^2 \\\\ &amp;= 0,7244 \\end{aligned}\\] 5.5.3 Impacto de las modificaciones de la póliza en la siniestralidad agregada En esta sección, se examina el efecto de un cambio en el deducible sobre los pagos agregados de una cartera de seguros. Se asume que la presencia de límites en la póliza (\\(u\\)), coaseguro (\\(\\alpha\\)) e inflación (\\(r\\)) no tienen ningún efecto en la distribución subyacente de la frecuencia de pagos realizados por la aseguradora. Al igual que en la sección anterior, asumimos que cambios en los deducibles tampoco afectan las distribuciones subyacentes de pérdidas, ni la de frecuencia ni la de severidad. Recordar la notación \\(N^L\\) para el número de pérdidas. Con la cuantía de la pérdida inicial \\(X\\) y el deducible de la póliza \\(d\\), se usa \\(N^P\\) para el número de pagos (como se definió en la sección anterior 5.5.2). Asimismo, se define el importe en base a las pérdidas \\[\\begin{eqnarray*} X^{L}&amp;=\\left\\{ \\begin{array}{ll} 0 ~, &amp; \\text{si } ~X&lt;\\cfrac{d}{1+r} \\\\ \\alpha[(1+r)X-d]~, &amp; \\text{si } ~\\cfrac{d}{1+r}\\leq X&lt;\\cfrac{u}{1+r} \\\\ \\alpha(u-d)~, &amp; \\text{si } ~X \\ge \\cfrac{u}{1+r}\\\\ \\end{array} \\right., \\end{eqnarray*}\\] y la cuantía en base a los pagos \\[\\begin{eqnarray*} X^{P}&amp;=\\left\\{ \\begin{array}{ll} {\\rm indeterminado} ~, &amp; \\text{si }~ X&lt;\\cfrac{d}{1+r} \\\\ \\alpha[(1+r)X-d]~, &amp; \\text{si }~ \\cfrac{d}{1+r}\\leq X&lt;\\cfrac{u}{1+r} \\\\ \\alpha(u-d)~, &amp; \\text{si } ~ X \\ge \\cfrac{u}{1+r}\\\\ \\end{array} \\right.. \\end{eqnarray*}\\] Aquí, \\(r\\), \\(u\\), y \\(\\alpha\\) representan la tasa de inflación, el límite de la póliza y el coseguro, respectivamente. Por lo tanto, los costes agregados (cuantías de los pagos) pueden expresarse ya sea en base a pérdidas o a pagos: \\[\\begin{aligned} S &amp;= X^L_1 + \\cdots + X^L_{N^L} \\\\ &amp;=X^P_1 + \\cdots + X^P_{N^P} ~. \\end{aligned}\\] Los fundamentos del modelo de riesgo colectivo pueden aplicarse. Por ejemplo, se tiene que: \\[\\begin{aligned} {\\rm E}(S) &amp;= {\\rm E}\\left(N^L\\right) {\\rm E}\\left(X^L\\right) = {\\rm E}\\left(N^P\\right) {\\rm E}\\left(X^P\\right)\\\\ {\\rm Var}(S) &amp;= {\\rm E}\\left(N^L\\right) {\\rm Var}\\left(X^L\\right) + \\left[{\\rm E}\\left(X^L\\right)\\right]^2 {\\rm Var}(N^L) \\\\ &amp;= {\\rm E}\\left(N^P\\right) {\\rm Var}\\left(X^P\\right) + \\left[{\\rm E}\\left(X^P\\right)\\right]^2 {\\rm Var}(N^P)\\\\ M_S(z)&amp;=P_{N^L}\\left[M_{X^L}(z)\\right]=P_{N^P}\\left[M_{X^P}(z)\\right] \\end{aligned}\\] Ejemplo 5.5.5. Pregunta Examen Actuarial. Una póliza dental colectiva sigue una distribución binomial negativa en el número de siniestros con media 300 y varianza 800. La severidad inicial se indica en la siguiente tabla: \\[ {\\small \\begin{matrix} \\begin{array}{ c | c } \\hline \\text{Severidad} &amp; \\text{Probabilidad}\\\\ \\hline 40 &amp; 0.25\\\\ 80 &amp; 0.25\\\\ 120 &amp; 0.25\\\\ 200 &amp; 0.25\\\\ \\hline \\end{array} \\end{matrix} } \\] Se espera que la severidad aumente un 50% sin cambiar de frecuencia. Se introduce un deducible de 100 por siniestro. Calcular el valor esperado de la pérdida agregada \\(S\\) después de estos cambios. Mostrar Solución de Ejemplo Solución. El coste por pérdida con un incremento en la severidad del 50% y un deducible por siniestro de 100 es \\[\\begin{eqnarray*} X^L &amp;=&amp; \\left\\{ \\begin{array}{cc} 0 &amp; 1,5x&lt;100 \\\\ 1,5x-100 &amp; 1,5x\\ge 100\\\\ \\end{array} \\right. \\end{eqnarray*}\\] El valor esperado es \\[\\begin{aligned} \\mathrm{E}(X^L) &amp;= \\frac{1}{4} \\left[ \\left(1,5(40)-100\\right)_+ + \\left(1,5(80)-100\\right)_+ + \\left(1,5(120)-100\\right)_+ + \\left(1,5(200)-100\\right)_+ \\right] \\\\ &amp;= \\frac{1}{4}\\left[ (60-100)_+ + (120-100)_+ + (180-100)_+ + (300-100)_+\\right] \\\\ &amp;= \\frac{1}{4}\\left[ 0 + 20 + 80 + 200 \\right] = 75 \\end{aligned}\\] Por tanto, la pérdida agregada esperada es \\[\\mathrm{E}(S)=\\mathrm{E}(N) ~ \\mathrm{E} \\left(X^L \\right)= 300 (75) = 22.500 .\\] Ejemplo 5.5.6. Continuación. ¿Cuál es la varianza de la pérdida agregada, \\(\\mathrm{Var~}(S)\\)? Mostrar Solución de Ejemplo Solución. En base a las pérdidas se tiene \\[\\begin{aligned} \\mathrm{Var}(S) &amp;= \\mathrm{E}(N) ~ \\mathrm{Var}\\left( X^L \\right) + \\left[ \\mathrm{E} \\left(X^L\\right) \\right]^2 ~ \\mathrm{Var} (N) \\end{aligned}\\] donde \\(\\mathrm{E}(N) = 300\\) y \\(\\mathrm{Var}(N) = 800\\). Se obtiene que \\[\\begin{aligned} &amp;\\mathrm{E} \\left[ (X^L)^2 \\right] = \\frac{1}{4} \\left[ 0^2 + 20^2 + 80^2 + 200^2 \\right] = 11.700 \\\\ \\Rightarrow \\ &amp; \\mathrm{Var}(X^L) = \\mathrm{E} \\left[ (X^L)^2 \\right] - \\left[ \\mathrm{E}(X^L) \\right]^2 = 11.700 - 75^2 = 6.075 \\end{aligned}\\] Por tanto, la varianza del coste total de siniestralidad es \\[\\begin{aligned} \\mathrm{Var}(S) &amp;= 300(6.075) + 75^2 (800) = 6.322.500 \\end{aligned}\\] Método alternativo: en base a los pagos. Anteriormente, se ha calculado el coste total esperado de siniestralidad multiplicando el número esperado de pérdidas por el coste esperado por pérdida. Recuerde que también podemos multiplicar el número esperado de pagos por el coste esperado por pago. En este caso, tenemos \\[S=X_1^P + \\cdots + X_{N_P}^P \\] La probabilidad de un pago es \\[\\Pr(1,5X \\ge 100)=\\Pr(X \\ge 66,\\bar{6})=\\frac{3}{4} .\\] Por tanto, el número de pagos, \\(N^P\\) tiene una distribución binomial negativa (véase el caso particular de la binomial negativa en Sección 5.5.2) con media \\[\\mathrm{E}(N^P) = \\mathrm{E}(N^L)~\\Pr(1,5X \\geq 100) = 300 \\left(\\frac{3}{4} \\right)=225\\] El coste por pago es \\[\\begin{eqnarray*} X^P &amp;=&amp; \\left\\{ \\begin{array}{ll} \\text{indeterminado}~, &amp; \\text{si }~ 1,5x&lt;100 \\\\ 1,5x-100~, &amp; \\text{si } ~ 1,5x\\ge 100\\\\ \\end{array} \\right. \\end{eqnarray*}\\] Su esperanza es \\[\\mathrm{E}(X^P)=\\frac{\\mathrm{E}(X^L)}{\\Pr(1,5X &gt; 100)}=\\frac{75}{(3/4)}=100\\] Por lo tanto, al igual que antes, la pérdida esperada agregada es \\[\\mathrm{E}(S)=\\mathrm{E}(X^P) ~ \\mathrm{E}(N^P) = 100(225)=22.500\\] Ejemplo 5.5.7. Pregunta Examen Actuarial. Una compañía asegura una flota de vehículos. Las pérdidas agregadas siguen una distribución compuesta de Poisson. El número esperado de pérdidas es 20. Las pérdidas, independientemente del tipo de vehículo, siguen una distribución exponencial con \\(\\theta=200\\). Para reducir el coste del seguro, se introducen dos modificaciones: (i) No se asegurará a un cierto tipo de vehículos. Se estima que reducirá la frecuencia de pérdidas en un 20\\(\\%\\). (ii) Se incluirá un deducible de 100 por pérdida. Calcular la cantidad total esperada que pagará la compañía después de las modificaciones. Mostrar Solución de Ejemplo Solución. En base a las pérdidas, se incluye un deducible de 100. Por tanto, el valor esperado por pérdida es \\[\\begin{aligned} \\mathrm{E}( X^L) &amp;= E[(X-100)_+] = E(X) - E(X\\wedge 100) \\\\ &amp;= 200 - 200(1-e^{-100/200}) = 121.31 \\end{aligned}\\] Dado que la frecuencia de pérdidas se ha reducido en un 20\\(\\%\\), el número esperado de pérdidas es \\[\\mathrm{E}(N^L) = 0,8(20) = 16\\] Por tanto, la cantidad total esperada que pagará después de las modificaciones es \\[\\mathrm{E}(S) = \\mathrm{E}(X^L)~ \\mathrm{E} (N^L) = 121,31(16) = 1.941\\] Método alternativo: en base a los pagos. La cantidad total esperada que pagará después de las modificaciones también se puede calcular en base a los pagos. Con el deducible de 100, la probabilidad que ocurra un pago es \\(\\Pr(X &gt; 100) = e^{-100/200}\\). Para la severidad por pago, tomando la expresión \\(\\mathrm{E}(X^L)\\) del ejemplo original, se tiene \\[\\begin{aligned} \\mathrm{E} (X^P) = \\frac{\\mathrm{E} (X^L)}{\\Pr(X &gt; 100)} = \\frac{200 - 200(1-e^{-100/200})}{e^{-100/200}} = 200 \\end{aligned}\\] Este resultado es esperable—cabe recordar que la distribución exponencial no tiene memoria, por lo que el coste esperado de los siniestros por encima de 100 sigue distribuyéndose según una exponencial de media 200. Ahora, tomemos la fecuencia de pagos \\[\\mathrm{E} (N^P) = \\mathrm{E}(N^L)~\\Pr(X&gt;100) = 16 ~e^{-100/200} = 9,7\\] Combinando ambos resultados, se obtiene la misma respuesta en base a los pagos que la obtenida anteriormente en base a las pérdidas \\[\\mathrm{E}(S) = \\mathrm{E} (X^P)~ \\mathrm{E} (N^P)= 200(9,7) = 1.941\\] 5.6 Otros recursos y colaboradores 5.6.0.1 Ejercicios Aquí se ofrece un conjunto de ejercicios que guían al lector a través de algunos de los fundamentos teóricos de Loss Data Analytics. Cada tutorial se basa en una o más preguntas de los exámenes actuariales profesionales, normalmente el Examen C de la Society of Acturies. Aggregate Loss Guided Tutorials Colaboradores Peng Shi y Lisa Gao, Universidad de Wisconsin-Madison, son los principales autores de la version inicial de este capítulo. Email: pshi@bus.wisc.edu para comentarios sobre los capítulos y posibles mejoras. Revisores de los capítulos, entre otros: Vytaras Brazauska, Mark Maxwell, Jiadong Ren, Di (Cindy) Xu. Traducción al español: Miguel Santolino (Universitat de Barcelona) ###TS 5.A.1. Propiedades del Modelo de Riesgo Individual {-} El valor esperado de la pérdida agregada en el modelo de riesgo individual, \\[\\begin{aligned} \\mathrm{E}(S_n) &amp;=\\sum_{i=1}^n ~ \\mathrm{E}(X_i) = \\sum_{i=1}^n ~ \\mathrm{E}(I_i \\times B_i) = \\sum_{i=1}^n ~ \\mathrm{E}(I_i) ~~ \\mathrm{E}(B_i) ~~~~ \\text{dada la independencia entre las } I_i \\text{ y las } B_i \\\\ &amp;= \\sum_{i=1}^n \\Pr(I_i=1) ~ \\mu_i ~~~~ \\text{ya que el valor esperado de la variable indicadora es igual a la probabilidad que sea } 1 \\\\ &amp;= \\sum_{i=1}^n ~ q_i ~ \\mu_i \\end{aligned}\\] La varianza de la pérdida agregada en el modelo de riesgo individual, \\[\\begin{aligned} \\mathrm{Var}(S_n) &amp;= \\sum_{i=1}^n \\mathrm{Var}(X_i) ~~~~ \\text{ dada la independencia entre las } X_i \\\\ &amp;= \\sum_{i=1}^n ~ \\left( ~ \\mathrm{E}\\left[ \\mathrm{Var}(X_i | I_i) \\right] + \\mathrm{Var}\\left[ \\mathrm{E}(X_i|I_i) \\right] ~ \\right) ~~~~ \\text{a partir de las formulas de varianza condicionada} \\\\ &amp;= \\sum_{i=1}^n \\left( q_i ~ \\sigma_i^2 ~ + ~ q_i ~ (1-q_i) ~ \\mu_i^2 \\right) \\end{aligned}\\] Para verlo, tenga en cuenta que \\[\\begin{aligned} \\mathrm{E}\\left[ \\mathrm{Var}(X_i | I_i) \\right] &amp;= \\mathrm{Var}(X_i|I_i=0) ~ \\Pr(I_i=0) + \\mathrm{Var}(X_i|I_i=1) ~ \\Pr(I_i=1) \\\\ &amp;= q_i ~ \\sigma_i^2 + (1-q_i) ~ (0) = q_i ~ \\sigma_i^2, \\end{aligned}\\] y \\[\\begin{aligned} \\mathrm{Var}\\left[ \\mathrm{E}(X_i|I_i) \\right] &amp;= q_i ~ (1-q_i) ~ \\mu_i^2~, \\end{aligned}\\] en base a la varianza de la Bernoulli ya que \\(\\mathrm{E}(X_i|I_i) = 0\\) cuando \\(I_i=0\\) (probabilidad \\(\\Pr(I_i=0) = 1-q_i\\)) y \\(\\mathrm{E}(X_i|I_i) = \\mu_i\\) cuando \\(I_i=1\\) (probabilidad \\(\\Pr(I_i=1)= q_i\\)). La función generadora de probabilidad de la pérdida agregada en el modelo de riesgo individual, \\[\\begin{aligned} P_{S_n}(z) &amp;= \\prod_{i=1}^n ~ P_{X_i}(z) ~~~~ \\text{dada la independencia de las } X_i \\\\ &amp;= \\prod_{i=1}^n ~ \\mathrm{E}(z^{~X_i}) = \\prod_{i=1}^n ~ \\mathrm{E}(z^{~I_i \\times B_i}) = \\mathrm{E} \\left[ \\mathrm{E}(z^{~I_i \\times B_i} | I_i) \\right] ~~~~ \\text{por la ley de esperanza iterada} \\\\ &amp;= \\prod_{i=1}^n \\left[ ~ E\\left(z^{~I_i \\times B_i} | I_i=0\\right) ~ \\Pr(I_i=0) + E\\left(z^{~I_i \\times B_i} | I_i=1\\right) ~ \\Pr(I_i=1) ~ \\right] \\\\ &amp;= \\prod_{i=1}^n ~ \\left[ ~ (1) ~ (1-q_i) + P_{B_i}(z) ~ q_i ~ \\right] = \\prod_{i=1}^n \\left(~ 1-q_i + q_i ~ P_{B_i}(z) ~\\right) \\end{aligned}\\] Por último, la función generadora de momentos de la pérdida agregada en el modelo de riesgo individual, \\[\\begin{aligned} M_{S_n}(t) &amp;= \\prod_{i=1}^n ~ M_{X_i}(t) ~~~~ \\text{dada la independencia de las } X_i \\\\ &amp;= \\prod_{i=1}^n ~ \\mathrm{E}(e^{t~X_i}) = \\prod_{i=1}^n ~ \\mathrm{E}\\left(e^{~t~(I_i \\times B_i)} \\right) = \\prod_{i=1}^n ~ \\mathrm{E} \\left[ \\mathrm{E} \\left( e^{~t~(I_i \\times B_i)} | I_i \\right) \\right] ~~~~ \\text{por la ley de esperanza iterada} \\\\ &amp;= \\prod_{i=1}^n ~ \\left[~ \\mathrm{E}\\left(e^{~t~(I_i \\times B_i)} | I_i=0 \\right) ~ \\Pr(I_i=0) + \\mathrm{E}\\left( e^{~t~(I_i \\times B_i)} | I_i=1 \\right) ~ \\Pr(I_i=1) ~\\right] \\\\ &amp;= \\prod_{i=1}^n ~ \\left[ ~ (1) ~ (1-q_i) + M_{B_i}(t) ~ q_i ~ \\right] = \\prod_{i=1}^n \\left(~ 1-q_i + q_i ~ M_{B_i}(t) ~\\right) \\end{aligned}\\] ###TS 5.A.2. Relación entre las funciones generadoras de probabilidad de \\(X_i\\) y \\(X_i^T\\) {-} Supongamos que \\(X_i\\) pertenece a la clase \\((a,b,0)\\) con pmf \\(p_{ik} = \\Pr(X_i = k)\\) para \\(k=0,1,\\ldots\\) y \\(X_i^T\\) es la distribución asociada truncada en cero de la clase \\((a,b,1)\\) con pmf \\(p_{ik}^T = p_{ik}/(1-p_{i0})\\) para \\(k=1,2,\\ldots\\). La relación entre la pgf de \\(X_i\\) y la pgf de \\(X_i^T\\) es la siguiente \\[\\begin{aligned} P_{X_i}(z) &amp;= \\mathrm{E~}(z^{X_i}) = \\mathrm{E}\\left[ \\mathrm{E}\\left( z^{X_i} | X_i \\right) \\right] ~~~~ \\text{por la ley de esperanza iterada} \\\\ &amp;= \\mathrm{E}\\left( z^{X_i} | X_i=0 \\right)~ \\Pr(X_i=0) + \\mathrm{E}\\left( z^{X_i} | X_i&gt;0 \\right) ~ \\Pr(X_i&gt;0) \\\\ &amp;= (1)~ p_{i0} + \\mathrm{E}(z^{X_i^T}) ~ (1-p_{i0}) ~~~~ \\text{dado que } (X_i | X_i&gt;0) \\text{ es la variable aleatoria truncada en cero } X_i^T \\\\ &amp;= p_{i0} +(1-p_{i0}) P_{X_i^{T}}(z) \\end{aligned}\\] ###TS 5.A.3. Ejemplo 5.3.8 Función generadora de momentos de la pérdida agregada \\(S_N\\) {-} En el caso que \\(N\\sim Geo(\\beta)\\) y \\(X\\sim Exp(\\theta)\\), se obtiene \\[\\begin{aligned} P_N (z) &amp;=\\frac{1}{1- \\beta (z-1)}\\\\ M_{X}(t) &amp;=\\frac{1}{1-\\theta t} \\end{aligned}\\] Por tanto, la mgf de la pérdida agregada \\(S_N\\) es \\[\\begin{aligned} M_{S_N}(t) &amp;= P_N [M_{X}(t)] = \\frac{1}{1 - \\beta \\left( \\frac{1}{1-\\theta t} - 1\\right)} \\\\ &amp;= \\frac{1}{1 - \\beta \\left( \\frac{\\theta t}{1-\\theta t} \\right)} + 1 - 1 = 1+ \\frac{\\beta \\left( \\frac{\\theta t}{1-\\theta t} \\right)}{1 - \\beta \\left( \\frac{\\theta t}{1-\\theta t} \\right)} \\\\ &amp;= 1 + \\frac{\\beta \\theta t}{(1-\\theta t) - \\beta \\theta t} = 1+ \\frac{\\beta \\theta t}{1-\\theta t (1+\\beta)} \\cdot \\frac{1+\\beta}{1+\\beta} \\\\ &amp;= 1 + \\frac{\\beta}{1+\\beta} \\left[ \\frac{\\theta (1+\\beta) t}{1-\\theta(1+\\beta)t} \\right] \\\\ &amp;= 1 + \\frac{\\beta}{1+\\beta} \\left[ \\frac{1}{1-\\theta(1+\\beta)t} - 1 \\right], \\\\ \\end{aligned}\\] que coincide con la expresión (5.1). Para la expresión alternativa de la mgf (5.2), se puede continuar a partir de aquí: \\[\\begin{aligned} M_{S_N}(t) &amp;= 1 + \\frac{\\beta}{1+\\beta} \\left[ \\frac{\\theta (1+\\beta) t}{1-\\theta(1+\\beta)t} \\right] \\\\ &amp;= \\frac{1+\\beta}{1+\\beta} + \\frac{\\beta}{1+\\beta} \\left[ \\frac{\\theta (1+\\beta) t}{1-\\theta(1+\\beta)t} \\right] \\\\ &amp;= \\frac{1}{1+\\beta} + \\frac{\\beta}{1+\\beta} + \\frac{\\beta}{1+\\beta} \\left[ \\frac{\\theta (1+\\beta) t}{1-\\theta(1+\\beta)t} \\right] \\\\ &amp;= \\frac{1}{1+\\beta} + \\frac{\\beta}{1+\\beta}\\left[1 + \\frac{\\theta (1+\\beta) t}{1-\\theta (1+\\beta)t} \\right] \\\\ &amp;= \\frac{1}{1+\\beta} +\\frac{\\beta}{1+\\beta} \\left[ \\frac{1}{1-\\theta (1+\\beta)t}\\right] \\end{aligned}\\] "],
["C-Simulation.html", "Chapter 6 Simulación y remuestreo 6.1 Fundamentos de la simulación 6.2 Bootstrapping y remuestreo 6.3 Validación cruzada 6.4 Importance Sampling 6.5 Monte Carlo Markov Chain (MCMC) 6.6 Recursos adicionales y colaboradores", " Chapter 6 Simulación y remuestreo Vista previa del capítulo. La simulación es un método computacionalmente intenso usado para resolver problemas difíciles. En lugar de crear procesos físicos y experimentar con ellos para entender sus características operacionales, un estudio de simulación se basa en una representación computacional – considera varias condiciones hipotéticas como inputs y resume los resultados. Aunque se trata de una simulación, un gran número de condiciones hipotéticas pueden ser rápidamente examinadas con un bajo coste. La sección 6.1 introduce la simulación, una herramienta computacional maravillosa que es especialmente útil en entornos complejos multivariantes. También podemos usar la simulación para realizar extracciones de una distribución empírica – proceso que se llama remuestreo. El remuestreo permite valorar la incertidumbre de las estimaciones en modelos complejos. La sección 6.2 introduce el remuestreo en el contexto del bootstrapping para determinar la precisión de los estimadores. Las secciones siguientes introducen otros temas del remuestreo. La Sección 6.3 sobre la validación cruzada muestra como usarla para la selección y validación de modelos. La sección 6.4 sobre la importancia del muestreo describe el remuestreo en áreas específicas de interés, como en aplicaciones actuariales con colas largas. La sección 6.5 sobre el método de Monte Carlo basado en cadenas de Markov (MCMC, en sus siglas en inglés) introduce la simulación y el motor del remuestreo que apunta en buena medida el análisis Bayesiano moderno. 6.1 Fundamentos de la simulación En esta sección, se muestra como: Generar realizaciones aproximadamente independientes distribuidas uniformemente Transformar las realizaciones distribuidas uniformemente en observaciones de la distribución de probabilidad de interés Calcular cantidades de interés y determinar la precisión de las cantidades calculadas 6.1.1 Generación de observaciones uniformes independientes Las simulaciones que consideramos son generadas por ordenadores. La principal ventaja de este enfoque es que pueden ser replicadas, permitiéndonos realizar comprobaciones y mejorar nuestro trabajo. Naturalmente, esto también significa que no son realmente aleatorias. Sin embargo, se han desarrollado algoritmos para que los resultados se comporten como aleatorios a efectos prácticos. En concreto, pasan test de independencia sofisticados y pueden ser diseñados de modo que provengan de una única distribución – nuestro supuesto iid, idénticamente e independientemente distribuidas, según sus siglas en inglés. Para tener una idea de lo que estos algoritmos hacen, consideramos un método de importancia histórica. Generador Lineal Congruencial. Para generar una secuencia de números aleatorios, comenzamos con \\(B_0\\), un valor inicial que es conocido como semilla. Este valor se actualiza utilizando la relación recursiva \\[B_{n+1} = a B_n + c \\text{ modulo }m, ~~ n=0, 1, 2, \\ldots .\\] Este algoritmo se denomina generador lineal congruencial . El caso \\(c=0\\) se denomina generador congruencial multiplicativo; es particularmente útil para cálculos realmente rápidos. Como valores ilustrativos de \\(a\\) y \\(m\\), Microsoft’s Visual Basic usa \\(m=2^{24}\\), \\(a=1,140,671,485\\), y \\(c = 12,820,163\\) (ver https://en.wikipedia.org/wiki/Linear_congruential_generator). Este es el generador subyacente en la generación de números aleatorios en el programa Microsoft Excel. La secuencia usada por el analista se define como \\(U_n=B_n/m.\\) El analista puede interpretar la secuencia {\\(U_{i}\\)} como (aproximadamente) idénticamente e independientemente uniformemente distribuida en el intervalo (0,1). Para ilustrar el algoritmo, se considera lo siguiente. Ejemplo 6.1.1. Secuencia ilustrativa. Se asume \\(m=15\\), \\(a=3\\), \\(c=2\\) y \\(B_0=1\\). Entonces se tiene: paso \\(n\\) \\(B_n\\) \\(U_n\\) 0 \\(B_0=1\\) 1 \\(B_1 =\\mod(3 \\times 1 +2) = 5\\) \\(U_1 = \\frac{5}{15}\\) 2 \\(B_2 =\\mod(3 \\times 5 +2) = 2\\) \\(U_2 = \\frac{2}{15}\\) 3 \\(B_3 =\\mod(3 \\times 2 +2) = 8\\) \\(U_3 = \\frac{8}{15}\\) 4 \\(B_4 =\\mod(3 \\times 8 +2) = 11\\) \\(U_4 = \\frac{11}{15}\\) A veces, a los resultados aleatorios generados por ordenadores se les conoce como números pseudo-aleatorios, para reflejar el hecho de que son generados por una máquina y pueden ser replicados. Es decir, a pesar de que {\\(U_{i}\\)} parece ser i.i.d, puede ser reproducido usando el mismo valor de semilla (y el mismo algoritmo). Ejemplo 6.1.2. Generación de números aleatorios uniformes en R. El siguiente código muestra como generar tres números uniformes (0,1) en R usando el comando runif. La función set.seed() establece el valor inicial de la semilla. En muchos paquetes informáticos, la semilla inicial se establece usando el reloj del sistema, si no se especifica otra cosa. Tres variables aleatorias uniformes set.seed(2017) U &lt;- runif(3) knitr::kable(U, digits=5, align = &quot;c&quot;, col.names = &quot;Uniforme&quot;) Uniforme 0.92424 0.53718 0.46920 El generador lineal congruencial es simplemente un método para generar valores pseudo-aleatorios. Es fácil entender y es (todavía) ampliamente usado. El generador lineal congruencial tiene limitaciones, incluyendo el hecho de que es posible detectar patrones a largo plazo en el tiempo en las secuencias que genera (es necesario recordar que se puede interpretar independencia como una falta total de patrón funcional). No sorprende que se hayan desarrollado técnicas avanzadas para hacer frente a algunos de estos inconvenientes. 6.1.2 Método de la transformada inversa Se parte de una secuencia de números aleatorios uniformes, y a continuación se transforma en la distribución de interés, sea \\(F\\). Una técnica destacada es el método de la transformada inversa, definido como \\[ X_i=F^{-1}\\left( U_i \\right) . \\] Aquí, se recuerda que en la Sección 4.1.1 se ha introducido la función de distribución inversa, \\(F^{-1}\\), también referenciada como función cuantil. En concreto, se define como \\[ F^{-1}(y) = \\inf_x ~ \\{ F(x) \\ge y \\} . \\] Se recuerda que \\(\\inf\\) representa ínfimo o el máxima cota inferior. Es en esencia el valor más pequeño de x que satisface la desigualdad \\(\\{F(x) \\ge y\\}\\). El resultado es que la secuencia {\\(X_{i}\\)} es aproximadamente iid con función de distribución \\(F\\). El resultado de la transformada inversa puede obtenerse cuando la variable aleatoria es continua, discreta o una combinación híbrida de ambas. Ahora se presenta una serie de ejemplos para ilustrar el alcance de sus aplicaciones. Ejemplo 6.1.3. Generar valores aleatorios exponenciales. Se desea generar observaciones según una distribución exponencial con parámetro de escala \\(\\theta\\) de manera que \\(F(x) = 1 - e^{-x/\\theta}\\). Para calcular la transformada inversa, se siguen los siguientes pasos: \\[ \\begin{aligned} y = F(x) &amp;\\iff y = 1-e^{-x/\\theta} \\\\ &amp;\\iff-\\theta \\ln(1-y) = x = F^{-1}(y) . \\end{aligned} \\] Por tanto, si \\(U\\) tiene una distribución uniforme (0,1), entonces \\(X = -\\theta \\ln(1-U)\\) tiene una distribución exponencial con parámetro \\(\\theta\\). El siguiente código de R muestra como se puede comenzar con los mismos tres números aleatorios uniformes del Ejemplo 6.1.2 y transformarlos en variables aleatorias exponenciales independientes con media 10. Alternativamente, se puede usar directamente la función rexp de R para generar valores aleatorios según una distribución exponencial. El algoritmo que se construye en esta rutina es diferente por eso incluso con el mismo valor inicial de semilla, las realizaciones individuales pueden ser diferentes. set.seed(2017) U &lt;- runif(3) X1 &lt;- -10*log(1-U) set.seed(2017) X2 &lt;- rexp(3, rate = 1/10) Tres variables aleatorias uniformes Uniforme Exponencial 1 Exponencial 2 0.92424 25.80219 3.25222 0.53718 7.70409 8.47652 0.46920 6.33362 5.40176 Ejemplo 6.1.4. Generar valores aleatorios Pareto. Se desea generar observaciones según una distribución de Pareto con parámetros \\(\\alpha\\) y \\(\\theta\\) de modo que \\(F(x) = 1 - \\left(\\frac{\\theta}{x+\\theta} \\right)^{\\alpha}\\). Para calcular la transformada inversa, se pueden seguir los siguientes pasos: \\[ \\begin{aligned} y = F(x) &amp;\\Leftrightarrow 1-y = \\left(\\frac{\\theta}{x+\\theta} \\right)^{\\alpha} \\\\ &amp;\\Leftrightarrow \\left(1-y\\right)^{-1/\\alpha} = \\frac{x+\\theta}{\\theta} = \\frac{x}{\\theta} +1 \\\\ &amp;\\Leftrightarrow \\theta \\left((1-y)^{-1/\\alpha} - 1\\right) = x = F^{-1}(y) .\\end{aligned} \\] Por tanto, \\(X = \\theta \\left((1-U)^{-1/\\alpha} - 1\\right)\\) tiene una distribución de Pareto con parámetros \\(\\alpha\\) y \\(\\theta\\). Justificación de la transformada inversa. ¿Por qué la variable aleatoria \\(X = F^{-1}(U)\\) tiene función de distribución \\(F\\)? Mostrar un fragmento de teoría Esto es fácil de establecer en el caso continuo. Dado que \\(U\\) es una variable aleatoria uniforme en (0,1), se sabe que \\(\\Pr(U \\le y) = y\\), para \\(0 \\le y \\le 1\\). Entonces, \\[ \\begin{aligned} \\Pr(X \\le x) &amp;= \\Pr(F^{-1}(U) \\le x) \\\\ &amp;= \\Pr(F(F^{-1}(U)) \\le F(x)) \\\\ &amp;= \\Pr(U \\le F(x)) = F(x) \\end{aligned} \\] Tal y como es requerido. El paso clave es que \\(F(F^{-1}(u)) = u\\) para cada \\(u\\), es claramente cierto cuando \\(F\\) es estrictamente creciente. Ahora se consideran algunos ejemplos discretos. Ejemplo 6.1.5. Generar valores aleatorios Bernoulli. Se desea simular variables aleatorias que siguen una distribución Bernoulli con parámetro \\(p=0.85\\). Figure 6.1: Función de distribución de una variable aleatoria binaria El gráfico de la función de distribución de la Figura 6.1 muestra que la función cuantil puede expresarse como \\[ \\begin{aligned} F^{-1}(y) = \\left\\{ \\begin{array}{cc} 0 &amp; 0&lt;y \\leq 0.85 \\\\ 1 &amp; 0.85 &lt; y \\leq 1.0 . \\end{array} \\right. \\end{aligned} \\] Por tanto, con la transformada inversa se puede definir \\[ \\begin{aligned} X = \\left\\{ \\begin{array}{cc} 0 &amp; 0&lt;U \\leq 0.85 \\\\ 1 &amp; 0.85 &lt; U \\leq 1.0 \\end{array} \\right. \\end{aligned} \\] A modo ilustrativo, se generan tres números aleatorios para obtener set.seed(2017) U &lt;- runif(3) X &lt;- 1*(U &gt; 0.85) Tres variables aleatorias Uniforme Binaria X 0.92424 1 0.53718 0 0.46920 0 Ejemplo 6.1.6. Generación de valores aleatorios de una distribución discreta. Se considera el tiempo hasta que tiene lugar el fallo de una máquina en los primeros cinco años. La distribución de los tiempos de fallo viene dada por: Distribución discreta \\(~~~~~~~~~~\\) \\(~~~~~~~~~~\\) \\(~~~~~~~~~~\\) \\(~~~~~~~~~~\\) \\(~~~~~~~~~~\\) Tiempo 1.0 2.0 3.0 4.0 5.0 Probabilidad 0.1 0.2 0.1 0.4 0.2 Función de distribución \\(F(x)\\) 0.1 0.3 0.4 0.8 1.0 Figure 6.2: Función de Distribución de una Variable Aleatoria Discreta Usando el gráfico de la función de distribución en la Figura 6.2, con la transformada inversa se define \\[ \\small{ \\begin{aligned} X = \\left\\{ \\begin{array}{cc} 1 &amp; 0&lt;U \\leq 0.1 \\\\ 2 &amp; 0.1 &lt; U \\leq 0.3\\\\ 3 &amp; 0.3 &lt; U \\leq 0.4\\\\ 4 &amp; 0.4 &lt; U \\leq 0.8 \\\\ 5 &amp; 0.8 &lt; U \\leq 1.0 . \\end{array} \\right. \\end{aligned} } \\] Para variables aleatorias discretas en general puede no existir una ordenación de valores. Por ejemplo, una persona puede tener uno de los cinco posibles tipos de seguros de vida y en ese caso el siguiente algoritmo se puede usar para generar valores aleatorios: \\[ {\\small \\begin{aligned} X = \\left\\{ \\begin{array}{cc} \\textrm{whole life} &amp; 0&lt;U \\leq 0.1 \\\\ \\textrm{endowment} &amp; 0.1 &lt; U \\leq 0.3\\\\ \\textrm{term life} &amp; 0.3 &lt; U \\leq 0.4\\\\ \\textrm{universal life} &amp; 0.4 &lt; U \\leq 0.8 \\\\ \\textrm{variable life} &amp; 0.8 &lt; U \\leq 1.0 . \\end{array} \\right. \\end{aligned} } \\] Otro analista puede usar un procedimiento alternativo como este: \\[ {\\small \\begin{aligned} X = \\left\\{ \\begin{array}{cc} \\textrm{whole life} &amp; 0.9&lt;U&lt;1.0 \\\\ \\textrm{endowment} &amp; 0.7 \\leq U &lt; 0.9\\\\ \\textrm{term life} &amp; 0.6 \\leq U &lt; 0.7\\\\ \\textrm{universal life} &amp; 0.2 \\leq U &lt; 0.6 \\\\ \\textrm{variable life} &amp; 0 \\leq U &lt; 0.2 . \\end{array} \\right. \\end{aligned} } \\] Ambos algoritmos producen (a largo plazo) las mismas probabilidades, e.g., \\(\\Pr(\\textrm{whole life})=0.1\\), etcétera. Por eso, ninguno es incorrecto. Es necesario tener en cuenta que hay muchos caminos para llegar a un mismo resultado. De manera similar, se podría emplear un algoritmo alternativo para valores ordenados (como los tiempos de fallo 1, 2, 3, 4, o 5, o más). Ejemplo 6.1.7. Generar valores aleatorios de una distribución híbrida. Se considera una variable aleatoria que es 0 con probabilidad 70% y tiene distribución exponencial con parámetro \\(\\theta= 10,000\\) con probabilidad 30%. En una aplicación actuarial, esto podría corresponder a un 70% de probabilidad de no tener un siniestro y un 30% de probabilidades de tenerlo – si un siniestro ocurre, tiene una distribución exponencial. La función de distribución, representada en la Figura 6.3, viene dada por \\[ \\begin{aligned} F(y) = \\left\\{ \\begin{array}{cc} 0 &amp; x&lt;0 \\\\ 1 - 0.3 \\exp(-x/10000) &amp; x \\ge 0 . \\end{array} \\right. \\end{aligned} \\] Figure 6.3: Función de distribución de una variable aleatoria híbrida En la Figura 6.3, se puede ver que la transformada inversa para generar variables aleatorias con esta función de distribución es \\[ \\begin{aligned} X = F^{-1}(U) = \\left\\{ \\begin{array}{cc} 0 &amp; 0&lt; U \\leq 0.7 \\\\ -1000 \\ln (\\frac{1-U}{0.3}) &amp; 0.7 &lt; U &lt; 1 . \\end{array} \\right. \\end{aligned} \\] Para variables aleatorias discretas e híbridas, la clave es dibujar el gráfico de la función de distribución que permita visualizar valores potenciales de la función inversa. 6.1.3 Precisión de la simulación De las subsecciones anteriores, se sabe cómo simular valores independientes de una distribución de interés. Con estas realizaciones, se puede construir una distribución empírica y aproximar la distribución subyacente con la precisión necesaria. A medida que se introduzcan más aplicaciones actuariales en este libro, se verá que la simulación puede ser aplicada en una gran variedad de contextos. Muchas de estas aplicaciones pueden reducirse a un problema de aproximar \\(\\mathrm{E~}h(X)\\), donde \\(h(\\cdot)\\) es una función conocida. En base a \\(R\\) simulaciones (réplicas), se obtiene \\(X_1,\\ldots,X_R\\). A partir de esta muestra simulada, se puede calcular la media \\[ \\overline{h}_R=\\frac{1}{R}\\sum_{i=1}^{R} h(X_i) \\] que se usa como la aproximación simulada (estimación) de \\(\\mathrm{E~}h(X)\\). Para estimar la precisión de esta aproximación se usa la varianza de la simulación \\[ s_{h,R}^2 = \\frac{1}{R-1} \\sum_{i=1}^{R}\\left( h(X_i) -\\overline{h}_R \\right) ^2. \\] A partir del supuesto de independencia, el error estándar de la estimación es \\(s_{h,R}/\\sqrt{R}\\). Esto se puede hacer tan pequeño como se desee incrementando el número de réplicas \\(R\\). Ejemplo. 6.1.8. Gestión de carteras. En la Sección 3.4, se explicó como calcular el valor esperado de pólizas con franquicias. Como ejemplo de algo que no puede hacerse con expresiones cerradas, se consideran ahora dos riesgos. Esta es una variación de un ejemplo más complejo que será presentado como Ejemplo 10.3.6. Se consideran dos riesgos patrimoniales de una empresa de telecomunicaciones: \\(X_1\\) - edificios, modelizado usando una distribución gamma con media 200 y parámetro de escala 100. \\(X_2\\) - vehículos de motor, modelizado con una distribución gamma con media 400 y parámetro de escala 200. El riesgo total se denota como \\(X = X_1 + X_2.\\) Por simplicidad, se asume que los riesgos son independientes. Para gestionar el riesgo, se busca la protección de un seguro. Se desea gestionar internamente cuantías pequeñas asociadas a edificios y vehículos de motor, hasta \\(M\\). El riesgo retenido es \\(Y_{retenido}=\\) \\(\\min(X_1 + X_2,M)\\). La porción del asegurador es \\(Y_{asegurador} = X- Y_{retenido}\\). Para ser más concretos, se usa \\(M=\\) 400 así como \\(R=\\) 1000000 simulaciones. a. Con las especificaciones, se desea determinar la cuantía esperada de siniestros y la desviación estándar asociada de (i) lo retenido, (ii) lo aceptado por el asegurador, y (iii) la cuantía total. Se muestra el código R para la definición de los riesgos # Simulación de los riesgos nSim &lt;- 1e6 #número de simulaciones set.seed(2017) #se fija la semilla para reproducir la secuencia generada X1 &lt;- rgamma(nSim,alpha1,scale = theta1) X2 &lt;- rgamma(nSim,alpha2,scale = theta2) # Riesgos de la cartera X &lt;- X1 + X2 Yretained &lt;- pmin(X, M) Yinsurer &lt;- X - Yretained Aquí está el código para las cuantías de siniestros esperadas. Se muestra el código R para calcular las cuantías # Cuantías esperadas de siniestros ExpVec &lt;- t(as.matrix(c(mean(Yretained),mean(Yinsurer),mean(X)))) sdVec &lt;- t(as.matrix(c(sd(Yretained),sd(Yinsurer),sd(X)))) outMat &lt;- rbind(ExpVec, sdVec) colnames(outMat) &lt;- c(&quot;Retenido&quot;, &quot;Asegurador&quot;,&quot;Total&quot;) row.names(outMat) &lt;- c(&quot;Media&quot;,&quot;Desviación estándar&quot;) round(outMat,digits=2) Retenido Asegurador Total Media 365.17 235.01 600.18 Desviación estándar 69.51 280.86 316.36 Los resultados de estos cálculos son: round(outMat,digits=2) Retenido Asegurador Total Media 365.17 235.01 600.18 Desviación estándar 69.51 280.86 316.36 b. Para siniestros asegurados, la aproximación del error estandar de la simulación es \\(s_{h,R}/\\sqrt{1000000} =\\) 280.86 \\(/\\sqrt{1000000} =\\) 0.281. Para este ejemplo, la simulación es rápida y un valor grande como 1000000 es una elección fácil. En cualquier caso, para problemas complejos, el tamaño de la simulación puede ser un problema. Se muestra el código R para establecer la visualización Yinsurefct &lt;- function(numSim){ X1 &lt;- rgamma(numSim,alpha1,scale = theta1) X2 &lt;- rgamma(numSim,alpha2,scale = theta2) # Riesgos de la cartera X &lt;- X1 + X2 Yinsurer &lt;- X - pmin(X, M) return(Yinsurer) } R &lt;- 1e3 nPath &lt;- 20 set.seed(2017) simU &lt;- matrix(Yinsurefct(R*nPath),R,nPath) sumP2 &lt;- apply(simU, 2, cumsum)/(1:R) La Figura 6.4 permite visualizar el desarrollo de la aproximación a medida que aumenta el número de simulaciones. matplot(1:R,sumP2[,1:20],type=&quot;l&quot;,col=rgb(1,0,0,.2), ylim=c(100, 400), xlab=expression(paste(&quot;Número de simulaciones (&quot;, italic(&#39;R&#39;), &quot;)&quot;)), ylab=&quot;Siniestros esperados por el asegurador&quot;) abline(h=mean(Yinsurer),lty=2) bonds &lt;- cbind(1.96*sd(Yinsurer)*sqrt(1/(1:R)),-1.96*sd(Yinsurer)*sqrt(1/(1:R))) matlines(1:R,bonds+mean(Yinsurer),col=&quot;red&quot;,lty=1) Figure 6.4: Estimación del número de siniestros esperados por el asegurador versus número de simulaciones. Determinación del número de simulaciones ¿Cuántos valores simulados se recomiendan? ¿100? ¿1,000,000? Se puede usar el teorema central del límite para responder a esta cuestión. Como criterio para la confianza en el resultado, se supone que se desea estar dentro del 1% de la media con 95% de certeza. Es decir, se desea \\(\\Pr \\left( |\\overline{h}_R - \\mathrm{E~}h(X)| \\le 0.01 \\mathrm{E~}h(X) \\right) \\le 0.95\\). De acuerdo con el teorema central del límite, la estimación debe tener distribución aproximadamente normal, por lo que se desea que \\(R\\) sea suficientemente grande para satisfacer \\(0.01 \\mathrm{E~}h(X)/\\sqrt{\\mathrm{Var~}h(X)/R}) \\ge 1.96\\). (Se recuerda que 1.96 es el percentil 97.5 de una distribución normal estándar.) Reemplazando \\(\\mathrm{E~}h(X)\\) y \\(\\mathrm{Var~}h(X)\\) con sus estimaciones, se continúa la simulación hasta \\[ \\frac{.01\\overline{h}_R}{s_{h,R}/\\sqrt{R}}\\geq 1.96 \\] o equivalentemente \\[\\begin{equation} R \\geq 38,416\\frac{s_{h,R}^2}{\\overline{h}_R^2}. \\tag{6.1} \\end{equation}\\] Este criterio es una aplicación directa de la aproximación a la normal. Nótese que \\(\\overline{h}_R\\) y \\(s_{h,R}\\) no son conocidos de antemano, por lo que se tendrán que hacer estimaciones, bien haciendo un pequeño estudio piloto de antemano o interrumpiendo el procedimiento intermitentemente para ver si el criterio se satisface. Ejemplo. 6.1.8. Gestión de carteras - continuación En este ejemplo, el número medio de siniestros es 235.011 y la correspondiente desviación estándar es 280.862. Usando la ecuación (6.1), para estar dentro del 10% de la media, se requerirán al menos 54.87 miles de simulaciones. Sin embargo, para estar dentro del 1% se necesitarán al menos 5.49 millones de simulaciones. Ejemplo. 6.1.9. Elección de la aproximación. Una importante aplicación de la simulación es la aproximación de \\(\\mathrm{E~}h(X)\\). En este ejemplo, se muestra que la elección de la función \\(h(\\cdot)\\) y de la distribución de \\(X\\) pueden jugar un papel importante. Se considera la siguiente pregunta: ¿cuál es \\(\\Pr[X&gt;2]\\) cuando \\(X\\) tiene una distribución de Cauchy, con densidad \\(f(x) =\\left(\\pi(1+x^2)\\right)^{-1}\\), en la recta real? El valor real es \\[ \\Pr\\left[X&gt;2\\right] = \\int_2^\\infty \\frac{dx}{\\pi(1+x^2)} . \\] Se puede usar una función de integración numérica en R (que funciona normalmente bien con integrales impropias) true_value &lt;- integrate(function(x) 1/(pi*(1+x^2)),lower=2,upper=Inf)$value que es igual a 0.14758. Alternativamente, se pueden usar técnicas de simulación para aproximar la cantidad. Usando el cálculo, se puede comprobar que la función cuantil de una distribución de Cauchy es \\(F^{-1}(y) = \\tan \\left( \\pi(y-0.5) \\right)\\). Entonces, con variables uniformes (0,1) simuladas, \\(U_1, \\ldots, U_R\\), se puede construir el estimador \\[ p_1 = \\frac{1}{R}\\sum_{i=1}^R \\mathrm{I}(F^{-1}(U_i)&gt;2) = \\frac{1}{R}\\sum_{i=1}^R \\mathrm{I}(\\tan \\left( \\pi(U_i-0.5) \\right)&gt;2) . \\] Se muestra el código R Q &lt;- function(u) tan(pi*(u-.5)) R &lt;- 1e6 set.seed(1) X &lt;- Q(runif(R)) p1 &lt;- mean(X&gt;2) se.p1 &lt;- sd(X&gt;2)/sqrt(R) p1 [1] 0.147439 se.p1 [1] 0.0003545432 Con un millón de simulaciones, se obtiene una estimación de 0.14744 con error estándar 0.355 (dividido por 1000). Se puede demostrar que la varianza de \\(p_1\\) es de orden \\(0.127/R\\). Con otras elecciones de \\(h(\\cdot)\\) y \\(F(\\cdot)\\), es en realidad posible reducir la incertidumbre incluso usando el mismo número de simulaciones en R. Para empezar, se puede usar la simetría de la distribución de Cauchy para determinar que \\(\\Pr[X&gt;2]=0.5\\cdot\\Pr[|X|&gt;2]\\). Con ello, se puede construir un nuevo estimador \\[ p_2 = \\frac{1}{2R}\\sum_{i=1}^R \\mathrm{I}(|F^{-1}(U_i)|&gt;2) . \\] Con un millón de simulaciones, se obtiene una estimación de 0.14748 con error estándar 0.228 (dividido por 1000). Se puede demostrar que la varianza de \\(p_2\\) es de orden \\(0.052/R\\). &lt;!—Esto puede visualizarse abajo –&gt; Pero se puede ir un paso más adelante. La integral impropia puede expresarse como una integral definida por su simple propiedad de simetría (dado que la función es simétrica y la integral en la recta real es igual a \\(1\\)) \\[ \\int_2^\\infty \\frac{dx}{\\pi(1+x^2)}=\\frac{1}{2}-\\int_0^2\\frac{dx}{\\pi(1+x^2)} . \\] De esta expresión, una aproximación natural sería \\[ p_3 = \\frac{1}{2}-\\frac{1}{R}\\sum_{i=1}^R h_3(2U_i), ~~~~~~\\text{where}~h_3(x)=\\frac{2}{\\pi(1+x^2)} . \\] Con un millón de simulaciones, se obtiene una estimación de 0.14756 con error estándar 0.169 (divido por 1000). Se puede probar que la varianza de \\(p_3\\) es del orden \\(0.0285/R\\). Finalmente, también se puede considerar algún cambio de variable en la integral \\[ \\int_2^\\infty \\frac{dx}{\\pi(1+x^2)}=\\int_0^{1/2}\\frac{y^{-2}dy}{\\pi(1-y^{-2})} . \\] De esta expresión, una aproximación natural sería \\[ p_4 = \\frac{1}{R}\\sum_{i=1}^R h_4(U_i/2),~~~~~\\text{where}~h_4(x)=\\frac{1}{2\\pi(1+x^2)} . \\] La expresión parece bastante similar a la anterior, Con un millón de simulaciones, se obtiene una estimación de 0.14759 con error estándar 0.01 (dividido por 1000). Se puede probar que la varianza de \\(p_4\\) es de orden \\(0.00009/R\\), que es mucho menor que los valores obtenidos hasta ahora! Tabla 6.1 resume las cuatro elecciones de \\(h(\\cdot)\\) y \\(F(\\cdot)\\) para aproximar \\(\\Pr[X&gt;2] =\\) 0.14758. El error estándar varía notablemente. Por tanto, si se desea un determinado grado de precisión, entonces el número de simulaciones depende mucho de cómo se escriban las integrales que se desean aproximar. Tabla 6.1. Resumen de las cuatro elecciones para aproximar \\(\\Pr[X&gt;2]\\). Estimador Definición Función de soporte Estimación Error estándar \\(p_1\\) \\(\\frac{1}{R}\\sum_{i=1}^R \\mathrm{I}(F^{-1}(U_i)&gt;2)\\) \\(~~~~~~F^{-1}(u)=\\tan \\left( \\pi(u-0.5) \\right)~~~~~~~\\) 0.147439 0.000355 \\(p_2\\) \\(\\frac{1}{2R}\\sum_{i=1}^R \\mathrm{I}(|F^{-1}(U_i)|&gt;2)\\) \\(F^{-1}(u)=\\tan \\left( \\pi(u-0.5) \\right)\\) 0.147477 0.000228 \\(p_3\\) \\(\\frac{1}{2}-\\frac{1}{R}\\sum_{i=1}^R h_3(2U_i)\\) \\(h_3(x)=\\frac{2}{\\pi(1+x^2)}\\) 0.147558 0.000169 \\(p_4\\) \\(\\frac{1}{R}\\sum_{i=1}^R h_4(U_i/2)\\) \\(h_4(x)=\\frac{1}{2\\pi(1+x^2)}\\) 0.147587 0.000010 6.1.4 Simulación e inferencia estadística Las simulaciones no solo ayudan a aproximar valores esperados, sino que también son útiles para calcular otros aspectos de las funciones de distribución. En particular, son muy útiles cuando las distribuciones de los estadísticos de prueba son muy complicadas de derivar; en este caso, se pueden usar simulaciones para aproximar la distribución de referencia. Se ilustra esto con el test de Kolmogorov-Smirnov que se presenta en la Sección 4.1.2.2. Ejemplo. 6.1.10. Distribución del test de Kolmogorov-Smirnov. Se tiene disponible \\(n=100\\) observaciones \\(\\{x_1,\\cdots,x_n\\}\\) que, sin que lo sepa el analista, han sido generadas por una distribución gamma de parámetros \\(\\alpha = 6\\) y \\(\\theta=2\\). El analista cree que los datos provienen de una distribución lognormal con parámetros 1 y 0.4 y desearía comprobar esta hipótesis. El primer paso es visualizar los datos. Se muestra el código R para establecer la visualización set.seed(1) n &lt;- 100 x &lt;- rgamma(n, 6, 2) u=seq(0,7,by=.01) vx = c(0,sort(x)) vy = (0:n)/n A partir de aquí, la Figura 6.5 proporciona un gráfico del histograma y distribución empírica. A modo de referencia, se superpone con línea rojas discontinua la distribución lognormal. par(mfrow=c(1,2)) hist(x,probability = TRUE,main=&quot;Histogram&quot;, col=&quot;light blue&quot;,border=&quot;white&quot;,xlim=c(0,7),ylim=c(0,.4)) lines(u,dlnorm(u,1,.4),col=&quot;red&quot;,lty=2) plot(vx,vy,type=&quot;l&quot;,xlab=&quot;x&quot;,ylab=&quot;Cumulative Distribution&quot;,main=&quot;Empirical cdf&quot;) lines(u,plnorm(u,1,.4),col=&quot;red&quot;,lty=2) Figure 6.5: Histograma y función de distribución empírica de los datos usados en el test de Kolmogorov-Smirnov. Las líneas rojas discontinuas son ajustadas en base a una (incorrecta) hipótesis de distribución lognormal. Es necesario recordad qeu el estadístico de Kolmogorov-Smirnov es igual a la mayor discrepancia entre la distribución empírica y la correspondiente a la hipótesis. Esto es \\(\\max_x |F_n(x)-F_0(x)|\\), donde \\(F_0\\) es la distribución lognormal de la hipótesis. Se puede calcular esto de forma directa como: Se muestra el código R para el cálculo directo del estadístico KS # test statistic D &lt;- function(data, F0){ F &lt;- Vectorize(function(x) mean((data&lt;=x))) n &lt;- length(data) x &lt;- sort(data) d1=abs(F(x+1e-6)-F0(x+1e-6)) d2=abs(F(x-1e-6)-F0(x-1e-6)) return(max(c(d1,d2))) } D(x,function(x) plnorm(x,1,.4)) [1] 0.09703627 Afortunadamente, para la distribución lognormal, R ha construido test que permiten determinar esto sin necesidad de realizar una programación complicada: ks.test(x, plnorm, mean=1, sd=0.4) One-sample Kolmogorov-Smirnov test data: x D = 0.097037, p-value = 0.3031 alternative hypothesis: two-sided Sin embargo, para muchas distribuciones de interés actuarial, no se dispone de programas pre-construidos. Se puede usar la simulación para comprobar la relevancia de un estadístico de prueba. En concreto, para calcular el \\(p\\)-valor, se generan miles de muestras aleatorias de una distribución \\(LN(1,0.4)\\) (con el mismo tamaño), y se calcula empíricamente la distribución del estadístico, Se muestra el código R para la distribución simulada del estadístico KS ns &lt;- 1e4 d_KS &lt;- rep(NA,ns) # cálculo de los estadísticos de prueba para un valor elevado de ns (número de muestras simuladas, según sus siglas en inglés) for(s in 1:ns) d_KS[s] &lt;- D(rlnorm(n,1,.4),function(x) plnorm(x,1,.4)) mean(d_KS&gt;D(x,function(x) plnorm(x,1,.4))) [1] 0.2843 hist(d_KS,probability = TRUE,col=&quot;light blue&quot;,border=&quot;white&quot;,xlab=&quot;Estadístico de prueba&quot;,main=&quot;&quot;) lines(density(d_KS),col=&quot;red&quot;) abline(v=D(x,function(x) plnorm(x,1,.4)),lty=2,col=&quot;red&quot;) Figure 6.6: Distribución simulada del estadístico de prueba de Kolmogorov-Smirnov. La línea roja discontinua vertical marca el estadístico de prueba para una muestra de 100. La distribución simulada basada en 10,000 muestras aleatorias se resume en la Figura 6.6. Aquí, el estadístico excede el valor empírico (0.09704) en 28.43% de los escenarios, mientras que el \\(p\\)-valor teórico es 0.3031. Tanto para la simulación como para los \\(p\\)-valores teóricos, las conclusiones son las mismas; los datos no proporcionan evidencia suficiente para rechazar la hipótesis de la distribución lognormal. Aunque se trate solo de una aproximación, el enfoque basado en la simulación funciona en una gran variedad de distribuciones y estadísticos de prueba sin necesitar desarrollar los detalles de la teoría de base en cada situación. Se puede resumir el procedimiento para desarrollar distribuciones simuladas y p-valores como sigue: Obtén una muestra de tamaño n, es decir, \\(X_1, \\ldots, X_n\\), de una función de distribución conocida \\(F\\). Calcula el estadístico de interés, denotado por \\(\\hat{\\theta}(X_1, \\ldots, X_n)\\). Se le llama \\(\\hat{\\theta}^r\\) para la réplica résima. Se repite \\(r=1, \\ldots, R\\) veces para obtener una muestra de estadísticos, \\(\\hat{\\theta}^1, \\ldots,\\hat{\\theta}^R\\). De la muestra de estadísticos en el paso 2, \\(\\{\\hat{\\theta}^1, \\ldots,\\hat{\\theta}^R\\}\\), se calcula una medida de resumen de interés, como el p-valor. 6.2 Bootstrapping y remuestreo En esta sección, se muestra como: Generar una distribución no paramétrica bootstrap para un estadístico de interés Usar la distribución bootstrap para generar estimaciones de la precisión del estadístico de interés, incluyendo sesgo, desviaciones estándar, e intervalos de confianza Realizar análisis bootstrap para distribuciones paramétricas 6.2.1 Fundamentos del Bootstrap La simulación presentada hasta ahora se basa en un muestreo a partir de una distribución conocida. La Sección 6.1 mostró como usar técnicas de simulación para obtener muestras y calcular cantidades de estas distribuciones conocidas. Sin embargo, la ciencia estadística se dedica a proporcionar inferencias sobre distribuciones que son desconocidas. Se recopilan estadísticos de resumen basados en esta distribución desconocida de una población. Pero, ¿cómo se puede realizar un muestreo de una distribución desconocida? Naturalmente, no se pueden simular valores de una distribución desconocida pero sí que se pueden obtener valores de una muestra de observaciones. Si la muestra es una buena representación de una población, entonces nuestras extracciones simuladas de una muestra se aproximan bien a las extracciones simuladas de una población. El proceso de obtener una muestra de una muestra se llama remuestreo o bootstrapping. El término bootstrap proviene de la frase (en inglés) “pulling oneself up by one’s bootstraps” (Efron, 1979). En el remuestreo, la muestra original juega el papel de la población y las estimaciones obtenidas a partir de la muestra juegan el papel de los verdaderos parámetros de la población. El algoritmo de remuestreo es el mismo que el introducido en la Sección 6.1.4 excepto que ahora usa extracciones simuladas de la muestra. Es común usar \\(\\{X_1, \\ldots, X_n\\}\\) para denotar la muestra original y \\(\\{X_1^*, \\ldots, X_n^*\\}\\) para los valores simulados. Las extracciones se realizan con reemplazamiento para que los valores simulados sean independientes entre ellos, la misma suposición que para la muestra original. Para cada muestra, también se realizan n extracciones simuladas, el mismo valor que el tamaño muestral. Para distinguir este proceso de la simulación, es común usar B (de bootstrap) para representar el número de muestras simuladas. También se puede escribir \\(\\{X_1^{(b)}, \\ldots, X_n^{(b)}\\}\\), \\(b=1,\\ldots, B\\) lo cual resulta más claro. Hay dos métodos básicos de remuestreo, model-free y model-based (tomando sus nombres en inglés), que son, respectivamente, no paramétrico y paramétrico. En el enfoque no paramétrico, no se hace ninguna suposición sobre la distribución de la población de origen. Las extracciones simuladas provienen de la función de distribución empírica \\(F_n(\\cdot)\\), por lo que cada extracción proviene de \\(\\{X_1, \\ldots, X_n\\}\\) con probabilidad 1/n. Por contra, para el enfoque paramétrico, se asume que se tiene conocimiento de la familia de la distribución F. La muestra original \\(X_1, \\ldots, X_n\\) se usa para estimar los parámetros de esa familia, es decir, \\(\\hat{\\theta}\\). Entonces, las extracciones simuladas se toman de \\(F(\\hat{\\theta})\\). En la Sección 6.2.4 se comenta este enfoque con más detalle. Bootstrap no paramétrico La idea del bootstrap no paramétrico es usar el método inverso en \\(F_n\\), la función de distribución empírica acumulada, representada en la Figura 6.7. Figure 6.7: Inversa de la función de distribución empírica Debido a que \\(F_n\\) es una función escalonada, \\(F_n^{-1}\\) toma valores en \\(\\{x_1,\\cdots,x_n\\}\\). Más concretamente, puede verse la ilustración de la Figura 6.8. - si \\(y\\in(0,1/n)\\) (con probabilidad \\(1/n\\)) se extrae el valor más pequeño (\\(\\min\\{x_i\\}\\)) - si \\(y\\in(1/n,2/n)\\) (con probabilidad \\(1/n\\)) se extrae el segundo valor más pequeño, - … - si \\(y\\in((n-1)/n,1)\\) (con probabilidad \\(1/n\\)) se extrae el mayor valor (\\(\\max\\{x_i\\}\\)). Figure 6.8: Inversa de la función de distribución empírica Usar el método inverso con \\(F_n\\) significa muestrear a partir de \\(\\{x_1,\\cdots,x_n\\}\\), con probabilidad \\(1/n\\). Generar una muestra bootstrap de tamaño \\(B\\) significa muestrear a partir de \\(\\{x_1,\\cdots,x_n\\}\\), con probabilidad \\(1/n\\), con reemplazamiento. A continuación, se puede consultar el siguiente código de R ilustrativo. Muestra el código R para crear una muestra con Bootstrap set.seed(1) n &lt;- 10 x &lt;- rexp(n, 1/6) m &lt;- 8 bootvalues &lt;- sample(x, size=m, replace=TRUE) [1] 2.6164 5.7394 5.7394 2.6164 2.6164 7.0899 0.8823 5.7394 Se observa que el valor 0.8388 se ha obtenido tres veces. 6.2.2 Precisión del bootstrap: Sesgo, desviación estándar, y MSE (error cuadrático medio, en sus siglas en inglés) Se resume el procedimiento para el bootstrap no paramétrico como sigue: Para la muestra \\(\\{X_1, \\ldots, X_n\\}\\), se extrae una muestra de tamaño n (con reemplazamiento), es decir, \\(X_1^*, \\ldots, X_n^*\\). De las extracciones simuladas se calcula el estadístico de interés, denotado como \\(\\hat{\\theta}(X_1^*, \\ldots, X_n^*)\\). Se denomina \\(\\hat{\\theta}_b^*\\) para la réplica bésima. Se repite esto \\(b=1, \\ldots, B\\) veces para obtener una muestra de estadísticos, \\(\\hat{\\theta}_1^*, \\ldots,\\hat{\\theta}_B^*\\). Para la muestra de estadísticos en el paso 2, \\(\\{\\hat{\\theta}_1^*, \\ldots, \\hat{\\theta}_B^*\\}\\), se calcula una medida de resumen de interés. En esta sección, se centra el interés en tres medidas de resumen, el sesgo, la desviación estándar, y el error cuadrático medio (MSE). Tabla 6.2 resume estas tres medidas. Aquí, \\(\\overline{\\hat{\\theta^*}}\\) es el promedio de \\(\\{\\hat{\\theta}_1^*, \\ldots,\\hat{\\theta}_B^*\\}\\). \\[ {\\small \\begin{matrix} \\text{Tabla 6.2. Medidas de resumen bootstrap}\\\\ \\begin{array}{l|c|c|c} \\hline \\text{Medida de la población}&amp; \\text{Definición de la población}&amp;\\text{Aproximación bootstrap }&amp;\\text{Símbolo bootstrap}\\\\ \\hline \\text{Sesgo} &amp; \\mathrm{E}(\\hat{\\theta})-\\theta&amp;\\overline{\\hat{\\theta^*}}-\\hat{\\theta}&amp; Bias_{boot}(\\hat{\\theta}) \\\\\\hline \\text{Desviación estándar} &amp; \\sqrt{\\mathrm{Var}(\\hat{\\theta})} &amp; \\sqrt{\\frac{1}{B-1} \\sum_{b=1}^{B}\\left(\\hat{\\theta}_b^* -\\overline{\\hat{\\theta^*}} \\right) ^2}&amp;s_{boot}(\\hat{\\theta}) \\\\\\hline \\text{Error cuadrático medio} &amp;\\mathrm{E}(\\hat{\\theta}-\\theta)^2 &amp; \\frac{1}{B} \\sum_{b=1}^{B}\\left(\\hat{\\theta}_b^* -\\hat{\\theta} \\right)^2&amp;MSE_{boot}(\\hat{\\theta})\\\\ \\hline \\end{array}\\end{matrix} } \\] Ejemplo 6.2.1. Siniestros con daños corporales y ratio de eliminación de pérdida. Para mostrar cómo el bootstrap puede usarse para cuantificar la precisión de los estimadores, se retoma el Ejemplo 4.1.11 sobre los datos de siniestros con daños corporales donde se introdujo el estimador no paramétrico de la ratio de eliminación de pérdidas. Tabla 6.3 resume los resultados de la estimación bootstrap. Por ejemplo, para \\(d=14000\\), se vió en el Ejemplo 4.1.11 que la estimación no paramétrica de LER es 0.97678. Este valor tiene un sesgo estimado de 0.00018 con una desviación estándar de 0.00701. Para algunas aplicaciones, se puede desear aplicar el sesgo estimado a la estimación original para obtener un estimador corregido por el sesgo. En ello se centra el próximo ejemplo. Para esta ilustración, el sesgo es pequeño por lo que dicha corrección no es relevante. Muestra el código R para la estimaciones bootstrap de LER # Ejemplo de Derrig et al BIData &lt;- read.csv(&quot;../../Data/DerrigResampling.csv&quot;, header =T) BIData$Censored &lt;- 1*(BIData$AmountPaid &gt;= BIData$PolicyLimit) BIDataUncensored &lt;- subset(BIData, Censored == 0) LER.boot &lt;- function(ded, data, indices){ resample.data &lt;- data[indices,] sumClaims &lt;- sum(resample.data$AmountPaid) sumClaims_d &lt;- sum(pmin(resample.data$AmountPaid,ded)) LER &lt;- sumClaims_d/sumClaims return(LER) } ##Derrig et al set.seed(2019) dVec2 &lt;- c(4000, 5000, 10500, 11500, 14000, 18500) OutBoot &lt;- matrix(0,length(dVec2),6) colnames(OutBoot) &lt;- c(&quot;d&quot;,&quot;Estimación NP &quot;,&quot;Sesgo bootstrap&quot;, &quot;Bootstrap SD&quot;, &quot;Límite inferior del CI (intervalo de confianza, en sus siglas en inglés) Normal al 95%&quot;, &quot;Límite superior del CI Normal al 95%&quot;) for (i in 1:length(dVec2)) { OutBoot[i,1] &lt;- dVec2[i] results &lt;- boot(data=BIDataUncensored, statistic=LER.boot, R=1000, ded=dVec2[i]) OutBoot[i,2] &lt;- results$t0 biasboot &lt;- mean(results$t)-results$t0 -&gt; OutBoot[i,3] sdboot &lt;- sd(results$t) -&gt; OutBoot[i,4] temp &lt;- boot.ci(results) OutBoot[i,5] &lt;- temp$normal[2] OutBoot[i,6] &lt;- temp$normal[3] } Tabla 6.3. Estimaciones bootstrap para el LER en franquicias seleccionadas d Estimación NP Sesgo bootstrap Bootstrap SD Límite inferior del CI (intervalo de confianza, en sus siglas en inglés) Normal al 95% Límite superior del CI Normal al 95% 4000 0.54113 0.00011 0.01237 0.51678 0.56527 5000 0.64960 0.00027 0.01412 0.62166 0.67700 10500 0.93563 0.00004 0.01017 0.91567 0.95553 11500 0.95281 -0.00003 0.00941 0.93439 0.97128 14000 0.97678 0.00016 0.00687 0.96316 0.99008 18500 0.99382 0.00014 0.00331 0.98719 1.00017 La desviación estándar bootstrap proporciona una medida de precisión. Para una aplicación de las desviaciones estándar, se puede usar la aproximación normal para crear un intervalo de confianza. Por ejemplo, la función de R boot.ci produce intervalos de confianza normales al 95%. Se producen creando un intervalo de dos veces la amplitud de 1.95994 desviaciones estándar bootstrap, centrado en el estimador corregido por el sesgo (1.95994 es el cuantil 97.5 de la distribución normal estándar). Por ejemplo, el intervalo inferior del 95% CI normal en \\(d=14000\\) es \\((0.97678-0.00018)- 1.95994*0.00701\\) \\(= 0.96286\\). Más adelante se comentan los intervalos de confianza bootstrap en la siguiente sección. Ejemplo 6.2.2. Estimar \\(\\exp(\\mu)\\). El bootstrap se puede usar para cuantificar el sesgo de un estimador, por ejemplo. Consideramos una muestra \\(\\mathbf{x}=\\{x_1,\\cdots,x_n\\}\\) que es iid con media \\(\\mu\\). sample_x &lt;- c(2.46,2.80,3.28,3.86,2.85,3.67,3.37,3.40,5.22,2.55, 2.79,4.50,3.37,2.88,1.44,2.56,2.00,2.07,2.19,1.77) Se supone que la cantidad de interés es \\(\\theta=\\exp(\\mu)\\). Un estimador natural sería \\(\\widehat{\\theta}_1=\\exp(\\overline{x})\\). Este estimador tiene sesgo (debido a la desigualdad Jensen) pero es asintóticamente insesgado. Para nuestra muestra, la estimación es como se muestra a continuación. (theta_1 &lt;- exp(mean(sample_x))) [1] 19.13463 Se puede usar el teorema central del límite para obtener una corrección usando \\[ \\overline{X}\\approx\\mathcal{N}\\left(\\mu,\\frac{\\sigma^2}{n}\\right)\\text{ where }\\sigma^2=\\text{Var}[X_i] , \\] De modo que, con la función generatriz de momentos normal, se tiene \\[ \\mathrm{E}~\\exp[\\overline{X}] \\approx \\exp\\left(\\mu+\\frac{\\sigma^2}{2n}\\right) . \\] Por tanto, se puede considerar \\[ \\widehat{\\theta}_2=\\exp\\left(\\overline{x}-\\frac{\\widehat{\\sigma}^2}{2n}\\right) . \\] Para nuestros datos, resulta lo siguiente. n &lt;- length(sample_x) (theta_2 &lt;- exp(mean(sample_x)-var(sample_x)/(2*n))) [1] 18.73334 Otra estrategia (que no vamos a desarrollar aquí) sería usar una aproximación de Taylor para obtener un estimador más preciso (como en el método delta), \\[ g(\\overline{x})=g(\\mu)+(\\overline{x}-\\mu)g&#39;(\\mu)+(\\overline{x}-\\mu)^2\\frac{g&#39;&#39;(\\mu)}{2}+\\cdots \\] La alternativa que se explora es usar una estrategia bootstrap: dada una muestra bootstrap, \\(\\mathbf{x}^{\\ast}_{b}\\), sea \\(\\overline{x}^{\\ast}_{b}\\) dsu media, y se establece \\[ \\widehat{\\theta}_3=\\frac{1}{B}\\sum_{b=1}^B\\exp(\\overline{x}^{\\ast}_{b}) . \\] Para implementarlo, se proporciona el siguiente código. Se muestra el código R para crear muestras bootstrap library(boot) results &lt;- boot(data=sample_x, statistic=function(y,indices) exp(mean(y[indices])), R=1000) theta_3 &lt;- mean(results$t) Entonces, se puede plot(results) y print(results) para observar lo siguiente. Figure 6.9: Distribución de las réplicas bootstrap. El panel de la izquierda es un histograma de réplicas. El panel de la derecha es un gráfico cuantil-cuantil, que compara la distribución bootstrap con la distribución normal estándar. ORDINARY NONPARAMETRIC BOOTSTRAP Call: boot(data = sample_x, statistic = function(y, indices) exp(mean(y[indices])), R = 1000) Bootstrap Statistics : original bias std. error t1* 19.13463 0.2536551 3.909725 Esto resulta en tres estimadores, el estimador bruto \\(\\widehat{\\theta}_1=\\) 19.135, la corrección de segundo orden \\(\\widehat{\\theta}_2=\\) 18.733, y el estimador bootstrap \\(\\widehat{\\theta}_3=\\) 19.388. ¿Como funciona esto con diferentes tamaños de muestra? Ahora se supone que \\(x_i\\)’s son generadas a partir de una distribución lognormal \\(LN(0,1)\\), de modo que \\(\\mu = \\exp(0 + 1/2) = 1.648721\\) y \\(\\theta = \\exp(1.648721)\\) \\(= 5.200326\\). Se usa la simulación para extraer los tamaños muestrales pero luego se actúa como si fueran un conjunto de observaciones realizadas. Véase el siguiente código ilustrativo. Se muestral el código R para crear muestras bootstrap param &lt;- function(x){ n &lt;- length(x) theta_1 &lt;- exp(mean(x)) theta_2 &lt;- exp(mean(x)-var(x)/(2*n)) results &lt;- boot(data=x, statistic=function(y,indices) exp(mean(y[indices])), R=999) theta_3 &lt;- mean(results$t) return(c(theta_1,theta_2,theta_3)) } set.seed(2074) ns&lt;- 200 est &lt;- function(n){ call_param &lt;- function(i) param(rlnorm(n,0,1)) V &lt;- Vectorize(call_param)(1:ns) apply(V,1,median) } VN=seq(15,100,by=5) Est &lt;- Vectorize(est)(VN) Los resultados de la comparación se resumen en la Figura 6.10. Esta figura muestra que el estimador bootstrap está más cerca del verdadero valor del parámetro para casi todos los tamaños muestrales. El sesgo de los tres estimadores decrece al aumentar el tamaño muestral. matplot(VN,t(Est),type=&quot;l&quot;, col=2:4, lty=2:4, ylim=exp(exp(1/2))+c(-1,1), xlab=&quot;sample size (n)&quot;, ylab=&quot;estimator&quot;) abline(h=exp(exp(1/2)),lty=1, col=1) legend(&quot;topleft&quot;, c(&quot;estimador bruto&quot;, &quot;corrección de segundo orden&quot;, &quot;bootstrap&quot;), col=2:4,lty=2:4, bty=&quot;n&quot;) Figure 6.10: Comparación de estimaciones. El verdadero valor del parámetro viene dado por la línea continua horizontal en 5.20. 6.2.3 Intervalos de confianza El procedimiento bootstrap genera B réplicas \\(\\hat{\\theta}_1^*, \\ldots,\\hat{\\theta}_B^*\\) del estimador \\(\\hat{\\theta}\\). En el Ejemplo 6.2.1, se mostró cómo usar las aproximaciones a la normal estándar para crear intervalos de confianza de los parámetros de interés. Sin embargo, dado que el interés se centra en usar el bootstrap para evitar confiar en supuestos de aproximación a la normal, no sorprende que haya disponibilidad de intervalos de confianza alternativos. Para un estimador \\(\\hat{\\theta}\\), el intervalo de confianza básico bootstrap es \\[\\begin{equation} \\left(2 \\hat{\\theta} - q_U, 2 \\hat{\\theta} - q_L \\right) , \\tag{6.2} \\end{equation}\\] donde \\(q_L\\) y \\(q_U\\) son los cuantiles al 2.5% inferior y superior de la muestra bootstrap \\(\\hat{\\theta}_1^*, \\ldots,\\hat{\\theta}_B^*\\). Para ver de dónde viene esto, se toma como punto de partida la idea de que \\((q_L, q_U)\\) proporciona un intervalo al 95% para \\(\\hat{\\theta}_1^*, \\ldots,\\hat{\\theta}_B^*\\). Por tanto, para un \\(\\hat{\\theta}_b^*\\) aleatorio, hay un 95% de probabilidades de que \\(q_L \\le \\hat{\\theta}_b^* \\le q_U\\). Revirtiendo las desigualdades y añadiendo \\(\\hat{\\theta}\\) a cada lado se obtiene un intervalo al 95% \\[ \\hat{\\theta} -q_U \\le \\hat{\\theta} - \\hat{\\theta}_b^* \\le \\hat{\\theta} -q_L . \\] Por tanto, \\(\\left( \\hat{\\theta}-q_U, \\hat{\\theta} -q_L\\right)\\) es un intervalo al 95% para \\(\\hat{\\theta} - \\hat{\\theta}_b^*\\). La idea de la aproximación bootstrap indica que ello es también un intervalo al 95% para \\(\\theta - \\hat{\\theta}\\). Añadiendo \\(\\hat{\\theta}\\) a cada lado da un intervalo al 95% en la ecuación (6.2). Hay muchos intervalos bootstrap alternativos. El más sencillo de explicar es el intervalo basado en los percentiles bootstrap que se define como \\(\\left(q_L, q_U\\right)\\). No obstante, presenta la desventaja de tener un comportamiento potencialmente pobre en las colas, lo cual puede ser un inconveniente en algunos problemas actuariales de interés. Ejemplo 6.2.3. Siniestros con daños corporales y medidas de riesgo. Para ver cómo funcionan los intervalos de confianza bootstrap, se retoma los datos sobre siniestros del automóvil con daños corporales considerados en el Ejemplo 6.2.1. En lugar de la ratio de eliminación de pérdida, se desea estimar el percentil al 95% \\(F^{-1}(0.95)\\) y una medida definida como \\[ TVaR_{0.95)}[X] = \\mathrm{E}[X | X &gt; F^{-1}(0.95)] . \\] Esta medida se llama tail value-at-risk; es el valor esperado de \\(X\\) condicionado a que \\(X\\) exceda el percentil al 95%. En la Sección 10.2 se explica como los cuantiles y el tail value-at-risk son los dos ejemplos más importantes de las llamadas medidas de riesgo. Por el momento, se considerarán simplemente como medidas que se quieren estimar. Para el percentil, se usa el estimador no paramétrico \\(F^{-1}_n(0.95)\\) definido en la Sección 4.1.1.3. Para el tail value-at-risk, se usa el principio plug-in para definir el estimador no paramétrico \\[ TVaR_{n,0.95}[X] = \\frac{\\sum_{i=1}^n X_i I(X_i &gt; F^{-1}_n(0.95))}{\\sum_{i=1}^n I(X_i &gt; F^{-1}_n(0.95))} ~. \\] En esta expresión, el denominador cuenta el número de observaciones que exceden el percentil al 95% \\(F^{-1}_n(0.95)\\). El numerador suma las pérdidas para aquellas observaciones que exceden \\(F^{-1}_n(0.95)\\). Tabla 6.4 resume el estimador para para fracciones seleccionadas. Se muestra el código R para crear muestras basadas en el cuantil Bootstrap # Example from Derrig et al #BIData &lt;- read.csv(&quot;./Data/DerrigResampling.csv&quot;, header =T) BIData$Censored &lt;- 1*(BIData$AmountPaid &gt;= BIData$PolicyLimit) BIDataUncensored &lt;- subset(BIData, Censored == 0) set.seed(2017) PercentVec &lt;- c(0.50, 0.80, 0.90, 0.95, 0.98) OutBoot1 &lt;- matrix(0,5,10) colnames(OutBoot1) &lt;- c(&quot;Fracción&quot;,&quot;Estimación NP &quot;, &quot;Sesgo bootstrap&quot;, &quot;Bootstrap SD&quot;, &quot;Límite inferior del CI Normal al 95%&quot;, &quot;Límite superior del CI Normal al 95%&quot;, &quot;Límite inferior del CI básico al 95% &quot;, &quot;Límite superior del CI básico al 95%&quot;, &quot;Límite inferior del CI percentil al 95%&quot;, &quot;Límite superior del CI percentil al 95% &quot;) for (i in 1:length(PercentVec)) { OutBoot1[i,1] &lt;- PercentVec[i] results &lt;- boot(data=BIDataUncensored$AmountPaid, statistic=function(X,indices) quantile(X[indices],PercentVec[i]), R=1000) if (i==1){bootreal &lt;- results$t} OutBoot1[i,2] &lt;- results$t0 OutBoot1[i,3] &lt;- mean(results$t)-results$t0 OutBoot1[i,4] &lt;- sd(results$t) temp &lt;- boot.ci(results, type = c(&quot;norm&quot;, &quot;basic&quot;, &quot;perc&quot;)) OutBoot1[i,5] &lt;- temp$normal[2] OutBoot1[i,6] &lt;- temp$normal[3] OutBoot1[i,7] &lt;- temp$basic[4] OutBoot1[i,8] &lt;- temp$basic[5] OutBoot1[i,9] &lt;- temp$percent[4] OutBoot1[i,10] &lt;- temp$percent[5] } Tabla 6.4. Estimaciones bootstrap de cuantiles en fracciones seleccionadas Fracción Estimación NP Sesgo bootstrap Bootstrap SD Límite inferior del CI Normal al 95% Límite superior del CI Normal al 95% Límite inferior del CI básico al 95% Límite superior del CI básico al 95% Límite inferior del CI percentil al 95% Límite superior del CI percentil al 95% 0.50 6500.00 -128.02 200.36 6235.32 7020.72 6300.00 7000.00 6000.00 6700.00 0.80 9078.40 89.51 200.27 8596.38 9381.41 8533.20 9230.40 8926.40 9623.60 0.90 11454.00 55.95 480.66 10455.96 12340.13 10530.49 12415.00 10493.00 12377.51 0.95 13313.40 13.59 667.74 11991.07 14608.55 11509.70 14321.00 12305.80 15117.10 0.98 16758.72 101.46 1273.45 14161.34 19153.19 14517.44 19326.95 14190.49 19000.00 Por ejemplo, cuando la fracción es 0.50, se observa que los cuantiles al 2.5th por abajo y por arriba de las simulaciones bootstrap son \\(q_L=\\) 6000 y \\(q_u=\\) 6700, respectivamente. Ello forma el intervalo de confianza percentil bootstrap. Con el estimador no paramétrico 6500, se obtienen los límites inferiores y superiores de los intervalos de confianza básicos 6300 y 7000, respectivamente. La Tabla 6.4 también muestra las estimaciones bootstrap del sesgo, desviación estándar, y el intervalo de confianza normal, conceptos introducidos en la sección anterior. La Tabla 6.5 muestra cálculos similares para el tail value-at-risk. En cada caso, se observa que la desviación estándar bootstrap aumenta a medida que la fracción aumenta. Ello es un reflejo de que cada vez hay menos observaciones disponibles para estimar los cuantiles a medida que la fracción aumenta, y por lo tanto hay una mayor imprecisión. La amplitud de los intervalos de confianza también aumenta. Resulta interesante ver que no parece haber el mismo patrón en las estimaciones del sesgo. Se muestra el código R para crear muestras basadas en el TVar Bootstrap CTE.boot &lt;- function(data, indices, RiskLevel){ resample.data &lt;- data[indices,] X &lt;- resample.data$AmountPaid cutoff &lt;- quantile(X, RiskLevel) CTE &lt;- sum(X*(X &gt; cutoff))/sum(X &gt; cutoff) return(CTE) } set.seed(2017) PercentVec &lt;- c(0.50, 0.80, 0.90, 0.95, 0.98) OutBoot1 &lt;- matrix(0,5,10) colnames(OutBoot1) &lt;- c(&quot;Fracción&quot;,&quot;Estimación NP&quot;, &quot;Sesgo bootstrap&quot;, &quot;Bootstrap SD&quot;, &quot;Límite inferior del CI normal al 95% &quot;, &quot;Límite superior del CI normal al 95% &quot;, &quot;Límite inferior del CI básico al 95%&quot;, &quot;Límite superior del CI básico al 95%&quot;, &quot;Límite inferior del CI percentil al 95%&quot;, &quot;Límite superior del CI Percentil al 95% &quot;) for (i in 1:length(PercentVec)) { OutBoot1[i,1] &lt;- PercentVec[i] results &lt;- boot(data=BIDataUncensored, statistic=CTE.boot, R=1000, RiskLevel=PercentVec[i]) OutBoot1[i,2] &lt;- results$t0 OutBoot1[i,3] &lt;- mean(results$t)-results$t0 OutBoot1[i,4] &lt;- sd(results$t) temp &lt;- boot.ci(results, type = c(&quot;norm&quot;, &quot;basic&quot;, &quot;perc&quot;)) OutBoot1[i,5] &lt;- temp$normal[2] OutBoot1[i,6] &lt;- temp$normal[3] OutBoot1[i,7] &lt;- temp$basic[4] OutBoot1[i,8] &lt;- temp$basic[5] OutBoot1[i,9] &lt;- temp$percent[4] OutBoot1[i,10] &lt;- temp$percent[5] } Tabla 6.5. Estimación bootstrap del TVaR en niveles de riesgo seleccionados Fracción Estimación NP Sesgo bootstrap Bootstrap SD Límite inferior del CI normal al 95% Límite superior del CI normal al 95% Límite inferior del CI básico al 95% Límite superior del CI básico al 95% Límite inferior del CI percentil al 95% Límite superior del CI Percentil al 95% 0.50 9794.69 -120.82 273.35 9379.74 10451.27 9355.14 10448.87 9140.51 10234.24 0.80 12454.18 30.68 481.88 11479.03 13367.96 11490.62 13378.52 11529.84 13417.74 0.90 14720.05 17.51 718.23 13294.82 16110.25 13255.45 16040.72 13399.38 16184.65 0.95 17072.43 5.99 1103.14 14904.31 19228.56 14924.50 19100.88 15043.97 19220.36 0.98 20140.56 73.43 1587.64 16955.40 23178.85 16942.36 22984.40 17296.71 23338.75 6.2.4 Bootstrap paramétrico La idea del bootstrap no paramétrico es remuestrear extrayendo variables independientes a partir de la función de distribución acumulada empirica \\(F_n\\). Por otra parte, en el bootstrap paramétrico, se extraen variables independientes de \\(F_{\\widehat{\\theta}}\\) donde la distribución subyacente se asume que pertenece a una familia paramétrica \\(\\mathcal{F}=\\{F_{\\theta},\\theta\\in\\Theta\\}\\). Normalmente, los parámetros de la distribución se estiman en base a una muestra y se denotan como \\(\\hat{\\theta}\\). Ejemplo 6.2.4. Distribución Lognormal. Se considera nuevamente la base de datos sample_x &lt;- c(2.46,2.80,3.28,3.86,2.85,3.67,3.37,3.40, 5.22,2.55,2.79,4.50,3.37,2.88,1.44,2.56,2.00,2.07,2.19,1.77) El bootstrap clásico (no paramétrico) se basaba en muestras x &lt;- sample(sample_x,replace=TRUE) Mientras que para el bootstrap paramétrico, se asume que la distribución de \\(x_i\\)’s es de una familia específica, por ejemplo la distribución lognormal. library(MASS) fit &lt;- fitdistr(sample_x, dlnorm, list(meanlog = 1, sdlog = 1)) fit meanlog sdlog 1.03630697 0.30593440 (0.06840901) (0.04837027) Entonces se realiza la extracción partiendo de esta distribución. x &lt;- rlnorm(length(sample_x), meanlog=fit$estimate[1], sdlog=fit$estimate[2]) Se muestra el código R para muestras con bootstrap paramétrico set.seed(2074) CV &lt;- matrix(NA,1e5,2) for(s in 1:nrow(CV)){ x1 &lt;- sample(sample_x,replace=TRUE) x2 &lt;- rlnorm(length(sample_x), meanlog=fit$estimate[1], sdlog=fit$estimate[2]) CV[s,] &lt;- c(sd(x1)/mean(x1),sd(x2)/mean(x2)) } La Figura 6.11 compara las distribuciones bootstrap para el coeficiente de variación, una de ellas basada en el enfoque no paramétrico y la otra basada en el enfoque paramétrico, asumiendo una distribución lognormal. plot(density(CV[,1]),col=&quot;red&quot;,main=&quot;&quot;,xlab=&quot;Coeficiente de variación&quot;, lty=1) lines(density(CV[,2]),col=&quot;blue&quot;,lty=2) abline(v=sd(sample_x)/mean(sample_x),lty=3) legend(&quot;topright&quot;,c(&quot;nonparametric&quot;,&quot;parametric(LN)&quot;), col=c(&quot;red&quot;,&quot;blue&quot;),lty=1:2,bty=&quot;n&quot;) Figure 6.11: Comparación de las distribuciones Bootstrap no paramétrico y paramétrico para el coeficiente de variación Ejemplo 6.2.5. Bootstrap de observaciones censuradas. El bootstrap paramétrico extrae realizaciones simuladas de una estimación paramétrica de una función de distribución. Del mismo modo, se pueden extraer realizaciones simuladas de la estimación de una función de distribución. A modo de ejemplo, se pueden realizar extracciones de estimaciones suavizadas de una función de distribución según lo introducido en la Sección 4.1.1.4. Otro caso especial, considerado aquí, es extraer una estimación del estimador de Kaplan-Meier introducido en la Sección 4.3.2.2. De esta forma, se pueden manejar observaciones que están censuradas. Concretamente, se consideran nuevamente los datos sobre daños corporales de los Ejemplos 6.2.1 y 6.2.3 pero ahora se incluyen 17 siniestros que están censurados por límites en la póliza. En el Ejemplo 4.3.6, se usó esta base de datos completa para estimar el estimador de Kaplan-Meier de la función de supervivencia introducida en la Sección 4.3.2.2. La Tabla 6.6 presenta las estimaciones bootstrap de los cuantiles obtenidos de la estimación de la función de supervivencia Kaplan-Meier. Incluye las estimaciones de la precisión bootstrap, sesgo y desviación estándar, así como el intervalo de confianza básico al 95%. Muestra el código R para las estimaciones Bootstrap Kaplan-Meier # Example from Derrig et al library(survival) # for Surv(), survfit() BIData$UnCensored &lt;- 1*(BIData$AmountPaid &lt; BIData$PolicyLimit) ## KM estimate KM0 &lt;- survfit(Surv(AmountPaid, UnCensored) ~ 1, type=&quot;kaplan-meier&quot;, data=BIData) set.seed(2019) PercentVec &lt;- c(0.50, 0.80, 0.90, 0.95, 0.98) OutBoot1 &lt;- matrix(NA,5,6) colnames(OutBoot1) &lt;- c(&quot;Fracción&quot;,&quot;Estimación KM NP&quot;, &quot;Sesgo bootstrap&quot;, &quot;Bootstrap SD&quot;, &quot;Intervalo inferior del CI básico al 95% &quot;, &quot;Intervalo superior del CI básico al 95% &quot;) KM.survobj &lt;- Surv(BIData$AmountPaid, BIData$UnCensored) for (i in 1:length(PercentVec)) { OutBoot1[i,1] &lt;- PercentVec[i] results &lt;- bootkm(KM.survobj, q=1-PercentVec[i], B=1000, pr = FALSE) if (i==1){bootreal &lt;- results} OutBoot1[i,2] &lt;- quantile(KM0, PercentVec[i])$quantile OutBoot1[i,3] &lt;- mean(results)-OutBoot1[i,2] OutBoot1[i,4] &lt;- sd(results) # temp &lt;- boot.ci(results, type = c(&quot;norm&quot;, &quot;basic&quot;,&quot;perc&quot;)) OutBoot1[i,5] &lt;- 2*OutBoot1[i,2]-quantile(results,.975, type=6) OutBoot1[i,6] &lt;- 2*OutBoot1[i,2]-quantile(results,.025, type=6) } Tabla 6.6. Estimaciones Bootstrap Kaplan-Meier de cuantiles en fracciones seleccionadas Fracción Estimación KM NP Sesgo bootstrap Bootstrap SD Intervalo inferior del CI básico al 95% Intervalo superior del CI básico al 95% 0.50 6500 18.77 177.38 6067 6869 0.80 9500 167.08 429.59 8355 9949 0.90 12756 37.73 675.21 10812 13677 0.95 18500 Inf NaN 12500 22300 0.98 25000 Inf NaN -Inf 27308 Los resultados de la Tabla 6.6 son consistentes con los resultados de la submuestra no censurada de la Tabla 6.4. En la Tabla 6.6, se observa la dificultad de estimar cuantiles de fracciones grandes debido a la censura. No obstante, para fracciones de tamaños moderados (0.50, 0.80, y 0.90), las estimaciones del Kaplan-Meier no paramétrico (KM NP) del cuantil son consistentes con los resultados de la Tabla 6.4. La desviación estándar bootstrap es más pequeña al nivel de 0.50 (correspondiente a la mediana) pero mayor para los niveles 0.80 y 0.90. El análisis de los datos censurados resumido en Tabla 6.6 usa más datos que el análisis de la submuestra no censurada que aparece en la Tabla 6.4 pero también presenta dificultades para extraer información para cuantiles elevados. 6.3 Validación cruzada En esta sección, se muestra como: Comparar y contrastar la validación cruzada a las técnicas de simulación y los métodos bootstrap. Usar técnicas de validación cruzada para la selección de modelos Explicar el método jackknife como caso especial de validación cruzada y calcular las estimaciones jackknife del sesgo y de los errores estándar La validación cruzada, brevemente introducida en la Sección 4.2.4, es una técnica basada en simular resultados y por ello es conveniente pensar en su propósito en comparación con otras técnicas de simulación ya introducidas en este capítulo. La simulación, o Monte-Carlo, introducida en la Sección 6.1, permite calcular valores esperados o otras medidas de resumen de distribuciones estadísticas, como \\(p\\)-valores, fácilmente. El bootstrap, y otros métodos de remuestreo introducidos en la Sección 6.2, proporciona estimadores de la precisión, o variabilidad, de los estadísticos. La validación cruzada es importante para valorar con qué precisión un modelo predictivo funcionará en la práctica. Existe superposición, pero sin embargo es útil pensar acerca del objetivo general asociado con cada uno de los métodos. Para presentar la validación cruzada, es conveniente recordar de la Sección 4.2 algunas de las ideas clave de la validación de modelos. Cuando se valora, o valida, un modelo, se mide el funcionamiento o desempeño del modelo en datos nuevos, o al menos no aquéllos que hayan sido usados para ajustar el modelo. Un enfoque clásico, descrito en la Sección 4.2.3, es dividir la muestra en dos partes: una parte (la base de datos de entrenamiento) se usa para ajustar el modelo y la otra (la base de datos de prueba) se usa para validar. Sin embargo, una limitación de este enfoque es que los resultados dependen de la partición; aunque la muestra general sea fija, la partición entre submuestras de entrenamiento y prueba varía aleatoriamente. Una muestra de entrenamiento diferente implica una estimación para los parámetros diferente. Unos parámetros diferentes para el modelo y una muestra de prueba diferente implican unos estadísticos de validación diferentes. Dos analistas pueden usar los mismos datos y los mismos modelos y pueden llegar a conclusiones diferentes sobre la viabilidad de un modelo (basado en diferentes particiones aleatorias), una situación frustrante. 6.3.1 Validación cruzada k-fold Para mitigar esta dificultad, es común usar un enfoque de validación cruzada como el introducido en la Sección 4.2.4. La idea clave es emular el enfoque básico de entrenamiento/validación para la validación del modelo repitiéndolo muchas veces y tomando medias a partir de las diferentes particiones de los datos. Una ventaja clave es que el estadístico de validación no está ligado a un modelo paramétrico (o no paramétrico) específico – se puede usar un estadístico no paramétrico o un estadístico que tiene una interpretación económica – y puede ser usado para comparar modelos que no están anidados (diferente a como ocurre con los procedimientos de la ratio de verosimilitud). Ejemplo 6.3.1. Fondo de propiedad de Wisconsin. Para los datos del fondo de propiedad de 2010 introducido en la Sección 1.3, se ajustan una gamma y una Pareto a los 1,377 datos de siniestros. Para ver en detalle la bondad de ajuste asociada se puede consultar el Apéndice Sección 15.4.4. Ahora se considera el estadístico de Kolmogorov-Smirnov introducido en la Sección 4.1.2.2. Cuando se realiza el ajuste sobre la totalidad de los datos, el estadístico de bondad del ajuste de Kolmogorov-Smirnov para la distribución gamma resulta ser 0.0478 y para la distribución de Pareto es 0.2639. El valor más bajo para la distribución de Pareto indica que esta distribución tiene mejor ajuste que la gamma. Para ver cómo funciona la validación cruzada k-fold, se divide aleatoriamente los datos en \\(k=8\\) grupos, o folds (en inglés), cada uno con \\(1377/8 \\approx 172\\) observaciones. Entonces, se ajustan una gamma y un modelo de Pareto a la base de datos con los primeros siete folds (sobre \\(172*7 = 1204\\) observaciones), se determinan los parámetros estimados, y entonces se usan estos modelos ajustados con los datos restantes para determinar el estadístico de Kolmogorov-Smirnov. Muestra el código R para la validación cruzada Kolmogorov-Smirnov # Reordenación aleatoria de los datos - &quot;shuffle it&quot; en inglés n &lt;- nrow(claim_data) set.seed(12347) cvdata &lt;- claim_data[sample(n), ] # Number of folds k &lt;- 8 cvalvec &lt;- matrix(0,2,k) for (i in 1:k) { indices &lt;- (((i-1) * round((1/k)*nrow(cvdata))) + 1):((i*round((1/k) * nrow(cvdata)))) # Pareto fit.pareto &lt;- vglm(Claim ~ 1, paretoII, loc = 0, data = cvdata[-indices,]) ksResultPareto &lt;- ks.test(cvdata[indices,]$Claim, &quot;pparetoII&quot;, loc = 0, shape = exp(coef(fit.pareto)[2]), scale = exp(coef(fit.pareto)[1])) cvalvec[1,i] &lt;- ksResultPareto$statistic # Gamma fit.gamma &lt;- glm(Claim ~ 1, data = cvdata[-indices,], family = Gamma(link = log)) gamma_theta &lt;- exp(coef(fit.gamma)) * gamma.dispersion(fit.gamma) alpha &lt;- 1 / gamma.dispersion(fit.gamma) ksResultGamma &lt;- ks.test(cvdata[indices,]$Claim, &quot;pgamma&quot;, shape = alpha, scale = gamma_theta) cvalvec[2,i] &lt;- ksResultGamma$statistic } KScv &lt;- rowSums(cvalvec)/k Los resultados aparecen en la Figura 6.12 donde el eje horizontal es Fold=1. Este proceso se repite para los otros siete folds. Los resultados se resumen en la Figura 6.12 y se aprecia que la Pareto es una distribución más confiable que la gamma. # Representación de los estadísticos matplot(1:k,t(cvalvec),type=&quot;b&quot;, col=c(1,3), lty=1:2, ylim=c(0,0.4), pch = 0, xlab=&quot;Fold&quot;, ylab=&quot;KS Statistic&quot;) legend(&quot;left&quot;, c(&quot;Pareto&quot;, &quot;Gamma&quot;), col=c(1,3),lty=1:2, bty=&quot;n&quot;) Figure 6.12: Estadísticos de Kolmogorov-Smirnov (KS) con validación cruzada para los datos de siniestros del fondo de propiedad. La línea continua negra corresponde a la distribución de Pareto, la línea verde discontinua corresponde a la gamma. El estadístico KS mide la mayor desviación entre la distribución ajustada y la empírica para cada uno de los 8 grupos, o folds, de los datos seleccionados aleatoriamente. 6.3.2 Validación cruzada dejando uno fuera El caso especial donde \\(k=n\\) es conocido como validación cruzada dejando uno fuera. Este caso tiene importancia históricamente y está muy relacionado con los estadísticos jackknife, un precursor de la técnica bootstrap. A pesar de que se presenta como un caso especial de validación cruzada, es conveniente dar una definición explícita. Se considera un estadístico genérico \\(\\widehat{\\theta}=t(\\boldsymbol{x})\\) que es un estimador del parámetro de interés \\(\\theta\\). La idea de jackknife es calcular \\(n\\) valores \\(\\widehat{\\theta}_{-i}=t(\\boldsymbol{x}_{-i})\\), donde \\(\\boldsymbol{x}_{-i}\\) es una submuestra de \\(\\boldsymbol{x}\\) con el \\(i\\)-ésimo valor eliminado. La media de esos valores se denota como \\[ \\overline{\\widehat{\\theta}}_{(\\cdot)}=\\frac{1}{n}\\sum_{i=1}^n \\widehat{\\theta}_{-i} . \\] Esos valores pueden usarse para crear estimaciones del sesgo del estadístico \\(\\widehat{\\theta}\\) \\[\\begin{equation} Bias_{jack} = (n-1) \\left(\\overline{\\widehat{\\theta}}_{(\\cdot)} - \\widehat{\\theta}\\right) \\tag{6.3} \\end{equation}\\] así como de una estimación de la desviación estándar \\[\\begin{equation} s_{jack} =\\sqrt{\\frac{n-1}{n}\\sum_{i=1}^n \\left(\\widehat{\\theta}_{-i} -\\overline{\\widehat{\\theta}}_{(\\cdot)}\\right)^2} ~. \\tag{6.4} \\end{equation}\\] Ejemplo 6.3.2. Coeficiente de variación. A modo de ilustración, se considera una muestra pequeña ficticia \\(\\boldsymbol{x}=\\{x_1,\\ldots,x_n\\}\\) con realizaciones sample_x &lt;- c(2.46,2.80,3.28,3.86,2.85,3.67,3.37,3.40, 5.22,2.55,2.79,4.50,3.37,2.88,1.44,2.56,2.00,2.07,2.19,1.77) Se desea determinar el coeficiente de variación \\(\\theta = CV = \\sqrt{\\mathrm{Var~}X}/\\mathrm{E~}X\\). Con esta base de datos, el estimador del coeficiente de variación resulta ser 0.31196. Pero, ¿cómo de fiable es este resultado? Para contestar a esta pregunta, se pueden calcular las estimaciones de jackknife del sesgo y su desviación estándar. El siguiente código muestra el estimador jackknife del sesgo es \\(Bias_{jack} =\\) -0.00627 y la desviación típica jackknife es \\(s_{jack} =\\) 0.01293. CVar &lt;- function(x) sqrt(var(x))/mean(x) JackCVar &lt;- function(i) sqrt(var(sample_x[-i]))/mean(sample_x[-i]) JackTheta &lt;- Vectorize(JackCVar)(1:length(sample_x)) BiasJack &lt;- (length(sample_x)-1)*(mean(JackTheta) - CVar(sample_x)) sd(JackTheta) Ejemplo 6.3.3. Siniestros con daños corporales y ratios de eliminación de pérdida. En el Ejemplo 6.2.1, se mostró como calcular estimaciones bootstrap del sesgo y desviación estándar para la ratio de eliminación de pérdidas usando los datos de siniestros con daños corporales del Ejemplo 4.1.11. Se continúa ahora proporcionando cuantías comparables usando los estadísticos jackknife. Tabla 6.7 resume los resultados de la estimación jackknife. Muestra como la estimación jackknife del sesgo y la desviación estándar de la ratio de eliminación \\(\\mathrm{E}~\\min(X,d)/\\mathrm{E}~X\\) son ampliamente consistentes con la metodología bootstrap. Es más, se pueden usar las desviaciones estándar para construir intervalos de confianza basados en la normal, centrados alrededor del estimador corregido por el sesgo. Por ejemplo, para \\(d=14000\\), se vio en el Ejemplo 4.1.11 que el estimador no paramétrico de LER es 0.97678. Tiene un sesgo estimado de 0.00010, y resulta un estimador (jackknife) corregido por el sesgo igual a 0.97688. Los intervalos de confianza al 95% se obtienen creando un intervalo de dos veces la longitud de 1.96 desviaciones estándar jackknife, centrado sobre el estimador corregido por el sesgo (1.96 es aproximadamente el cuantil 97.5 de la distribución normal estándar). Se muestra el código R # Example from Derrig et al BIData &lt;- read.csv(&quot;../../Data/DerrigResampling.csv&quot;, header =T) BIData$Censored &lt;- 1*(BIData$AmountPaid &gt;= BIData$PolicyLimit) BIDataUncensored &lt;- subset(BIData, Censored == 0) LER.boot &lt;- function(ded, data, indices){ resample.data &lt;- data[indices,] sumClaims &lt;- sum(resample.data$AmountPaid) sumClaims_d &lt;- sum(pmin(resample.data$AmountPaid,ded)) LER &lt;- sumClaims_d/sumClaims return(LER) } x &lt;- BIDataUncensored$AmountPaid LER.jack&lt;- function(ded,i){ LER &lt;- sum(pmin(x[-i],ded))/sum(x[-i]) return(LER) } LER &lt;- function(ded) sum(pmin(x,ded))/sum(x) ##Derrig et al set.seed(2019) dVec2 &lt;- c(4000, 5000, 10500, 11500, 14000, 18500) OutJack &lt;- matrix(0,length(dVec2),8) colnames(OutJack) &lt;- c(&quot;d&quot;,&quot;Estimación NP&quot;,&quot;Sesgo Bootstrap &quot;, &quot;Bootstrap SD&quot;, &quot;Sesgo Jackknife &quot;, &quot;Jackknife SD&quot;,&quot;Límite inferior del 95% Jackknife CI&quot;, &quot;Límite superior del 95% Jackknife CI&quot;) for (j in 1:length(dVec2)) { OutJack[j,1] &lt;- dVec2[j] results &lt;- boot(data=BIDataUncensored, statistic=LER.boot, R=1000, ded=dVec2[j]) OutJack[j,2] &lt;- results$t0 biasboot &lt;- mean(results$t)-results$t0 -&gt; OutJack[j,3] sdboot &lt;- sd(results$t) -&gt; OutJack[j,4] temp &lt;- boot.ci(results) LER.jack.ded&lt;- function(i) LER.jack(ded=dVec2[j],i) JackTheta.ded &lt;- Vectorize(LER.jack.ded)(1:length(x)) OutJack[j,5] &lt;- BiasJack.ded &lt;- (length(x)-1)*(mean(JackTheta.ded) - LER(ded=dVec2[j])) OutJack[j,6] &lt;- sd(JackTheta.ded) OutJack[j,7:8] &lt;- mean(JackTheta.ded)+qt(c(0.025,0.975),length(x)-1)*OutJack[j,6] } Table 6.7. Estimaciones Jackknife del LER en las franquicias seleccionadas d Estimación NP Sesgo Bootstrap Bootstrap SD Sesgo Jackknife Jackknife SD Límite inferior del 95% Jackknife CI Límite superior del 95% Jackknife CI 4000 0.54113 0.00011 0.01237 0.00031 0.00061 0.53993 0.54233 5000 0.64960 0.00027 0.01412 0.00033 0.00068 0.64825 0.65094 10500 0.93563 0.00004 0.01017 0.00019 0.00053 0.93460 0.93667 11500 0.95281 -0.00003 0.00941 0.00016 0.00047 0.95189 0.95373 14000 0.97678 0.00016 0.00687 0.00010 0.00034 0.97612 0.97745 18500 0.99382 0.00014 0.00331 0.00003 0.00017 0.99350 0.99415 Discusión. Una de las cosas más interesantes sobre el caso especial de validación cruzada dejando uno fuera es la habilidad de replicar estimaciones de manera exacta. Es decir, cuando el tamaño del grupo o fold es solo uno, entonces no hay incertidumbre adicional inducida por la validación cruzada. Esto significa que los analistas pueden replicar de manera exacta el trabajo de otro, lo cual es una importante consideración. Los estadísticos Jackknife fueron desarrollados para entender la precisión de estimadores, produciendo estimadores de sesgo y desviación estándar en las ecuaciones (6.3) y (6.4). Esto tiene que ver con algunas metas que se han asociado con las técnicas de bootstrap, no con métodos de validación cruzada. Esto demuestra como las técnicas estadísticas pueden usarse para alcanzar diferentes metas. 6.3.3 Validación cruzada y Bootstrap El bootstrap es útil para proporcionar estimadores de la precisión, o variabilidad, de los estadísticos. También puede ser útil para la validación de modelos. El enfoque bootstrap para la validación de modelos es similar al enfoque dejando uno fuera y los procedimientos de validación k fold: Se crea una muestra de bootstrap a través del remuestreo (con reemplazamiento) \\(n\\) índices en \\(\\{1,\\cdots,n\\}\\). Esta será la muestra de entrenamiento. Se estima el modelo considerado en base a esta muestra. La muestra de prueba, o muestra de validación, consiste en esas observaciones no seleccionadas para en entrenamiento. Se evalúa el modelo ajustado (basado en los datos de entrenamiento) usando los datos de prueba. Este proceso se repite muchas (digamos \\(B\\)) veces. Se toma la media de los resultados y se selecciona al modelo basado en el estadístico de evaluación promedio. Ejemplo 6.3.4. Fondo de propiedad de Wisconsin. Se vuelve a considerar el ejemplo 6.3.1 donde se investiga el ajuste de unas distribuciones gamma y Pareto a los datos del fondo de propiedad. Nuevamente se compara el desempeño predictivo usando el estadístico de Kolmogorov-Smirnov pero esta vez usando el procedimiento bootstrap para partir los datos entre muestra de entrenamiento y prueba. A continuación, se muestra el código ilustrativo. Muestra el código R para procedimientos de validación Bootstrap # library(MASS) # library(VGAM) # library(goftest) # claim_lev &lt;- read.csv(&quot;../../Data/CLAIMLEVEL.csv&quot;, header = TRUE) # # 2010 subset # claim_data &lt;- subset(claim_lev, Year == 2010); n &lt;- nrow(claim_data) set.seed(12347) indices &lt;- 1:n # Número de muestras Bootstrap B &lt;- 100 cvalvec &lt;- matrix(0,2,B) for (i in 1:B) { bootindex &lt;- unique(sample(indices, size=n, replace= TRUE)) traindata &lt;- claim_data[bootindex,] testdata &lt;- claim_data[-bootindex,] # Pareto fit.pareto &lt;- vglm(Claim ~ 1, paretoII, loc = 0, data = traindata) ksResultPareto &lt;- ks.test(testdata$Claim, &quot;pparetoII&quot;, loc = 0, shape = exp(coef(fit.pareto)[2]), scale = exp(coef(fit.pareto)[1])) cvalvec[1,i] &lt;- ksResultPareto$statistic # Gamma fit.gamma &lt;- glm(Claim ~ 1, data = traindata, family = Gamma(link = log)) gamma_theta &lt;- exp(coef(fit.gamma)) * gamma.dispersion(fit.gamma) alpha &lt;- 1 / gamma.dispersion(fit.gamma) ksResultGamma &lt;- ks.test(testdata$Claim, &quot;pgamma&quot;, shape = alpha, scale = gamma_theta) cvalvec[2,i] &lt;- ksResultGamma$statistic } KSBoot &lt;- rowSums(cvalvec)/B Se ha realizado el muestreo usando \\(B=\\) 100 réplicas. El estadístico KS promedio de la distribución Pareto era 0.058, que puede compararse con el promedio para la distribución gamma, 0.262. Esto es consistente con los resultados anteriores y proporciona una evidencia más de que el modelo Pareto es mejor para estos datos que el gamma. 6.4 Importance Sampling En la Sección 6.1 se introducen las técnicas de Monte Carlo usando la técnica de la inversa: generar una variable aleatoria \\(X\\) con distribución \\(F\\), aplicar \\(F^{-1}\\) para llamar a un generador aleatorio (uniforme en el intervalo unitario). ¿Qué pasa si queremos realizar extracciones de acuerdo con \\(X\\), condicionado a \\(X\\in[a,b]\\) ? Se puede usar un mecanismo de aceptación-rechazo : extraer \\(x\\) de la distribución \\(F\\) si \\(x\\in[a,b]\\) : se mantiene (“aceptación”) si \\(x\\notin[a,b]\\) : se extrae otro (“rechazo”) Se observa que de \\(n\\) valores inicialmente generados, se mantienen sólo \\([F(b)-F(a)]\\cdot n\\) extracciones, en promedio. Ejemplo 6.4.1. Extracciones de una distribución Normal. Supongamos que se realizan extracciones de una distribución normal con media 2.5 y varianza 1, \\(N(2.5,1)\\), pero sólo se tiene interés en extracciones en extracciones mayores que \\(a \\ge 2\\) y menores que \\(b \\le 4\\). Es decir, se puede usar sólo una proporción de extracciones igual a \\(F(4)-F(2) = \\Phi(4-2.5)-\\Phi(2-2.5)\\) = 0.9332 - 0.3085 = 0.6247. La Figura 6.13 demuestra que algunas extracciones caen en el intervalo \\((2,4)\\) y otras están fuera. Muestra el código R para el mecanismo de aceptación-rechazo mu = 2.5 sigma = 1 a = 2 b = 4 Fa = pnorm(a,mu,sigma) Fb = pnorm(b,mu,sigma) pic_ani = function(){ u=seq(0,5,by=.01) plot(u,pnorm(u,mu,sigma),col=&quot;white&quot;,ylab=&quot;&quot;,xlab=&quot;&quot;) rect(-1,-1,6,2,col=rgb(1,0,0,.2),border=NA) rect(a,Fa,b,Fb,col=&quot;white&quot;,border=NA) lines(u,pnorm(u,mu,sigma),lwd=2) abline(v=c(a,b),lty=2,col=&quot;red&quot;) ru &lt;- runif(1) clr &lt;- &quot;red&quot; if((qnorm(ru,mu,sigma)&gt;=a)&amp;(qnorm(ru,mu,sigma)&lt;=b)) clr &lt;- &quot;blue&quot; segments(-1,ru,qnorm(ru,mu,sigma),ru,col=clr,lwd=2) arrows(qnorm(ru,mu,sigma),ru,qnorm(ru,mu,sigma),0,col=clr,lwd=2,length = .1) } for (i in 1:numAnimation) {pic_ani()} Figure 6.13: Demostración animada de extracciones dentro y fuera de (2,4) En su lugar, se pueden realizar extracciones de acuerdo con la distribución condicional \\(F^{\\star}\\) definida como \\[ F^{\\star}(x) = \\Pr(X \\le x | a &lt; X \\le b) =\\frac{F(x)-F(a)}{F(b)-F(a)}, \\ \\ \\ \\text{for } a &lt; x \\le b . \\] Usando el método de la transformada inversa de la Sección 6.1.2, se tiene que la extracción \\[ X^\\star=F^{\\star-1}\\left( U \\right) = F^{-1}\\left(F(a)+U\\cdot[F(b)-F(a)]\\right) \\] tiene distribución \\(F^{\\star}\\). Expresado de otra forma, se define \\[ \\tilde{U} = (1-U)\\cdot F(a)+U\\cdot F(b) \\] y entonces se usa \\(F^{-1}(\\tilde{U})\\). Con este enfoque, cada extracción cuenta. Esto puede estar relacionado con la importancia del mecanismo de muestreo : se realizan extracciones más frecuentemente en regiones donde se espera tener cantidades que tienen algún interés. Esta transformación puede ser considerada como “un cambio de medida.” Muestra el código R para la importancia del muestreo por el método de la transformada inversa pic_ani = function(){ u=seq(0,5,by=.01) plot(u,pnorm(u,mu,sigma),col=&quot;white&quot;,ylab=&quot;&quot;,xlab=&quot;&quot;) rect(-1,-1,6,2,col=rgb(1,0,0,.2),border=NA) rect(a,Fa,b,Fb,col=&quot;white&quot;,border=NA) lines(u,pnorm(u,mu,sigma),lwd=2) abline(h=pnorm(c(a,b),mu,sigma),lty=2,col=&quot;red&quot;) ru &lt;- runif(1) rutilde &lt;- (1-ru)*Fa+ru*Fb segments(-1,rutilde,qnorm(rutilde,mu,sigma),rutilde,col=&quot;blue&quot;,lwd=2) arrows(qnorm(rutilde,mu,sigma),rutilde,qnorm(rutilde,mu,sigma),0,col=&quot;blue&quot;,lwd=2,length = .1) } for (i in 1:numAnimation) {pic_ani()} En el Ejemplo 6.4.1., la inversa de la distribución normal está disponible fácilmente (en R, la función es qnorm). Sin embargo, para otras aplicaciones, este no es el caso. Entonces, simplemente se usan métodos numéricos para determinar \\(X^\\star\\) como la solución de la ecuación \\(F(X^\\star) =\\tilde{U}\\) donde \\(\\tilde{U}=(1-U)\\cdot F(a)+U\\cdot F(b)\\). Véase el siguiente código ilustrativo. Muestra el código R para la importancia del muestreo via soluciones numéricas pic_ani = function(){ u=seq(0,5,by=.01) plot(u,pnorm(u,mu,sigma),col=&quot;white&quot;,ylab=&quot;&quot;,xlab=&quot;&quot;) rect(-1,-1,6,2,col=rgb(1,0,0,.2),border=NA) rect(2,-1,4,2,col=&quot;white&quot;,border=NA) lines(u,pnorm(u,mu,sigma),lty=2) pnormstar &lt;- Vectorize(function(x){ y=(pnorm(x,mu,sigma)-Fa)/(Fb-Fa) if(x&lt;=a) y &lt;- 0 if(x&gt;=b) y &lt;- 1 return(y) }) qnormstar &lt;- function(u) as.numeric(uniroot((function (x) pnormstar(x) - u), lower = 2, upper = 4)[1]) lines(u,pnormstar(u),lwd=2) abline(v=c(2,4),lty=2,col=&quot;red&quot;) ru &lt;- runif(1) segments(-1,ru,qnormstar(ru),ru,col=&quot;blue&quot;,lwd=2) arrows(qnormstar(ru),ru,qnormstar(ru),0,col=&quot;blue&quot;,lwd=2,length = .1) } for (i in 1:numAnimation) {pic_ani()} 6.5 Monte Carlo Markov Chain (MCMC) Esta sección se está escribiendo y no está complete ni editada. El contenido que se muestra es para haceros una idea de lo que contendrá la versión final. La idea de las técnicas de Monte Carlo se basa en la ley de los grandes números (que asegura la convergencia de la media hacia la integral) y el teorema central del límite (que se usa para cuantificar la incertidumbre en los cálculos). Es necesario recordar que si \\((X_i)\\) es una secuencia i.id. de variables aleatorias con distribución \\(F\\), entonces \\[ \\frac{1}{\\sqrt{n}}\\left(\\sum_{i=1}^n h(X_i)-\\int h(x)dF(x)\\right)\\overset{\\mathcal{L}}{\\rightarrow }\\mathcal{N}(0,\\sigma^2),\\text{ as }n\\rightarrow\\infty. \\] para alguna varianza \\(\\sigma^2&gt;0\\). Pero de hecho, el teorema ergódico se puede usar para rebajar el resultado anterior, dado que no es neceario tener independencia de las variables. Más concretamente, si \\((X_i)\\) es un proceso de Markov con medida invariante \\(\\mu\\), bajo algunos supuestos técnicos adicionales, se puede obtener que \\[ \\frac{1}{\\sqrt{n}}\\left(\\sum_{i=1}^n h(X_i)-\\int h(x)d\\mu(x)\\right)\\overset{\\mathcal{L}}{\\rightarrow }\\mathcal{N}(0,\\sigma_\\star^2),\\text{ as }n\\rightarrow\\infty. \\] para alguna varianza \\(\\sigma_\\star^2&gt;0\\). Por lo tanto, de esta propiedad, se puede ver que es posible no necesariamente generar valores independientes a partir de \\(F\\), sino también generar un proceso de markov con medida invariante \\(F\\), y considerar medias sobre el proceso (no necesariamente independiente). Se considera el caso de un vector Gausiano restringido: se desean generar parejas aleatorias de un vector aleatorio \\(\\boldsymbol{X}\\), pero sólo interesa el caso en que la suma de los (‘composants’)` es suficientemente grande, lo que puede expresarse como \\(\\boldsymbol{X}^T\\boldsymbol{1}&gt; m\\) para algún valor real \\(m\\). Por supuesto, es posible usar el algoritmo aceptación-rechazo, pero se ha vito que puede ser bastante ineficiente. Se puede usar el Hastings Metropolis y el muestreo de Gibbs para generar un proceso de Markov con esta medida invariante. 6.5.1 Hastings Metropolis El algoritmo es bastante simple de generar a partir de \\(f\\): se comienza con un valor factible \\(x_1\\). Entonces, en el paso \\(t\\), se necesita especificar una transición núcleo: dado \\(x_t\\), se necesita la distribución condicional de \\(X_{t+1}\\) dado \\(x_t\\). El algoritmo funcionará bien si la distribución condicional se puede simular fácilmente. Sea \\(\\pi(\\cdot|x_t)\\) esta probabilidad. Se obtiene un valor potencial \\(x_{t+1}^\\star\\), y \\(u\\), de una distribución uniforme. Se calcula \\[ R= \\frac{f(x_{t+1}^\\star)}{f(x_t)} \\] y si \\(u &lt; r\\), entonces \\(x_{t+1}=x_t^\\star\\) si \\(u\\leq r\\), entonces \\(x_{t+1}=x_t\\) Aquí \\(r\\) se denomina ratio-aceptación: se acepta el nuevo valor con probabilidad \\(r\\) (o en realidad el menor entre \\(1\\) y \\(r\\) dado que \\(r\\) puede exceder \\(1\\)). Por ejemplo, se asume que \\(f(\\cdot|x_t)\\) es uniforme en \\([x_t-\\varepsilon,x_t+\\varepsilon]\\) para algún \\(\\varepsilon&gt;0\\), y donde \\(f\\) (la distribución objetivo) es la \\(\\mathcal{N}(0,1)\\). Nunca se realizarán extracciones de \\(f\\), pero se usará para calcular la ratio de aceptación en cada paso. Se muestra el código R metrop1 &lt;- function(n=1000,eps=0.5){ vec &lt;- matrix(NA, n, 3) x=0 vec[1] &lt;- x for (i in 2:n) { innov &lt;- runif(1,-eps,eps) mov &lt;- x+innov R &lt;- min(1,dnorm(mov)/dnorm(x)) u &lt;- runif(1) if (u &lt; R) x &lt;- mov vec[i,] &lt;- c(x,mov,R) } return(vec)} En el código de arriba, vec contiene los valores de \\(\\boldsymbol{x}=(x_1,x_2,\\cdots)\\), innov es la innovación. Se muestra el código R #install.packages(&#39;gifski&#39;) #if (packageVersion(&#39;knitr&#39;) &lt; &#39;1.20.14&#39;) { # remotes::install_github(&#39;yihui/knitr&#39;) #} vec &lt;- metrop1(25) u=seq(-3,3,by=.01) pic_ani = function(k){ plot(1:k,vec[1:k,1],pch=19,xlim=c(0,25),ylim=c(-2,2),xlab=&quot;&quot;,ylab=&quot;&quot;) if(vec[k+1,1]==vec[k+1,2]) points(k+1,vec[k+1,1],col=&quot;blue&quot;,pch=19) if(vec[k+1,1]!=vec[k+1,2]) points(k+1,vec[k+1,1],col=&quot;red&quot;,pch=19) points(k+1,vec[k+1,2],cex=1.5) arrows(k+1,vec[k,1]-.5,k+1,vec[k,1]+.5,col=&quot;green&quot;,angle=90,code = 3,length=.1) polygon(c(k+dnorm(u)*10,rep(k,length(u))),c(u,rev(u)),col=rgb(0,1,0,.3), border=NA) segments(k,vec[k,1],k+dnorm(vec[k,1])*10,vec[k,1]) segments(k,vec[k+1,2],k+dnorm(vec[k+1,2])*10,vec[k+1,2]) text(k,2,round(vec[k+1,3],digits=3)) } for (k in 2:23) {pic_ani(k)} Ahora, si se usan más simulaciones, se obtiene vec &lt;- metrop1(10000) simx &lt;- vec[1000:10000,1] par(mfrow=c(1,4)) plot(simx,type=&quot;l&quot;) hist(simx,probability = TRUE,col=&quot;light blue&quot;,border=&quot;white&quot;) lines(u,dnorm(u),col=&quot;red&quot;) qqnorm(simx) acf(simx,lag=100,lwd=2,col=&quot;light blue&quot;) 6.5.2 Muestreo de Gibbs Se considera algún vector \\(\\boldsymbol{X}=(X_1,\\cdots,X_d)\\) con components independientes, \\(X_i\\sim\\mathcal{E}(\\lambda_i)\\). Se realiza un muestro para muestrear de \\(\\boldsymbol{X}\\) dado \\(\\boldsymbol{X}^T\\boldsymbol{1}&gt;s\\) para algún umbral \\(s&gt;0\\). se comienza con algún valor inicial \\(\\boldsymbol{x}_0\\) tal que se elige (aleatoriamente) \\(i\\in\\{1,\\cdots,d\\}\\) \\(X_i\\) dado que \\(X_i &gt; s-\\boldsymbol{x}_{(-i)}^T\\boldsymbol{1}\\) tiene una distribucion Exponencial \\(\\mathcal{E}(\\lambda_i)\\) se extrae \\(Y\\sim \\mathcal{E}(\\lambda_i)\\) y se establece \\(x_i=y +(s-\\boldsymbol{x}_{(-i)}^T\\boldsymbol{1})_+\\) hasta que \\(\\boldsymbol{x}_{(-i)}^T\\boldsymbol{1}+x_i&gt;s\\) Se muestra el Código R sim &lt;- NULL lambda &lt;- c(1,2) X &lt;- c(3,3) s &lt;- 5 for(k in 1:1000){ i &lt;- sample(1:2,1) X[i] &lt;- rexp(1,lambda[i])+max(0,s-sum(X[-i])) while(sum(X)&lt;s){ X[i] &lt;- rexp(1,lambda[i])+max(0,s-sum(X[-i])) } sim &lt;- rbind(sim,X) } plot(sim,xlim=c(1,11),ylim=c(0,4.3)) polygon(c(-1,-1,6),c(-1,6,-1),col=&quot;red&quot;,density=15,border=NA) abline(5,-1,col=&quot;red&quot;) La construcción de la secuencia (los algoritmos MCMC son iterativos) puede visualizarse abajo Se muestra el código R lambda &lt;- c(1,2) X &lt;- c(3,3) sim &lt;- X s &lt;- 5 for(k in 1:100){ set.seed(k) i &lt;- sample(1:2,1) X[i] &lt;- rexp(1,lambda[i])+max(0,s-sum(X[-i])) while(sum(X)&lt;s){ X[i] &lt;- rexp(1,lambda[i])+max(0,s-sum(X[-i])) } sim &lt;- rbind(sim,X) } pic_ani = function(n){ plot(sim[1:n,],xlim=c(1,11),ylim=c(0,5),xlab=&quot;&quot;,ylab=&quot;&quot;) i=which(apply(sim[(n-1):n,],2,diff)==0) if(i==1) abline(v=sim[n,1],col=&quot;grey&quot;) if(i==2) abline(h=sim[n,2],col=&quot;grey&quot;) if(n&gt;=1) points(sim[n,1],sim[n,2],pch=19,col=&quot;blue&quot;,cex=1.4) if(n&gt;=2) points(sim[n-1,1],sim[n-1,2],pch=19,col=&quot;red&quot;,cex=1.4) polygon(c(-1,-1,6),c(-1,6,-1),col=&quot;red&quot;,density=15,border=NA) abline(5,-1,col=&quot;red&quot;) } for (i in 2:100) {pic_ani(i)} 6.6 Recursos adicionales y colaboradores Include historical references for jackknife (Quenouille, Tukey, Efron) Aquí se muestran algunos links para aprender más sobre reproducibilidad y aleatoriedad y cómo ir de un generador aleatorio a una función muestra. Colaboradores Arthur Charpentier, Université du Quebec á Montreal, y Edward W. (Jed) Frees, University of Wisconsin-Madison, son los principales autores de la versión inicial de este capítulo. Email: jfrees@bus.wisc.edu y/o arthur.charpentier@gmail.com para comentarios sobre este capítulo y sugerencias de mejora. Revisores del capítulo: Escribir a Jed o Arthur; para añadir tu nombre aquí. Traducción al español: Ana María Pérez-Marín (Universitat de Barcelona). 6.6.1 TS 6.A. Bootstrap Applications in Predictive Modeling This section is being written. "],
["C-PremiumFoundations.html", "Chapter 7 Premium Foundations 7.1 Introduction to Ratemaking 7.2 Aggregate Ratemaking Methods 7.3 Pricing Principles 7.4 Heterogeneous Risks 7.5 Development and Trending 7.6 Selecting a Premium 7.7 Further Resources and Contributors", " Chapter 7 Premium Foundations Chapter Preview. Setting prices for insurance products, premiums, is an important task for actuaries and other data analysts. This chapter introduces the foundations for pricing non-life products. 7.1 Introduction to Ratemaking In this section, you learn how to: Describe expectations as a baseline method for determining insurance premiums Analyze an accounting equation for relating premiums to losses, expenses and profits Summarize a strategy for extending pricing to include heterogeneous risks and trends over time This chapter explains how you can think about determining the appropriate price for an insurance product. As described in Section 1.2, one of the core actuarial functions is ratemaking, where the analyst seeks to determine the right price for a risk. As this is a core function, let us first take a step back to define terms. A price is a quantity, usually of money, that is exchanged for a good or service. In insurance, we typically use the word premium for the amount of money charged for insurance protection against contingent events. The amount of protection varies by risk being insured. For example, in homeowners insurance the amount of insurance protection depends on the value of the house. In life insurance, the amount of protection depends on a policyholder’s financial status (e.g. income and wealth) as well as a perceived need for financial security. So, it is common to express insurance prices as a unit of the protection being purchased, for example, an amount per thousands (e.g., of dollars or Euros) for coverage of a home or benefit in the event of death. Because they are expressed in standardized units, these prices/premiums are known as rates. To determine premiums, it is common in economics to consider the supply and demand of a product. The demand is sensitive to price as well as the existence of competiting firms and substitute products. The supply is a function of the resources required for production. For the individual firm, the price is set to meet some objective such as profit maximization which is met by choosing the output level that balances costs and revenues at the margins. However, a peculiarity of insurance is that the costs of insurance protection are not known at the sale of the contract. If the insured contingent event, such as the loss of a house or life, does not occur, then the contract costs are only administrative (to set up the contract) and are relatively minor. If the insured event occurs, then the cost includes not only administrative costs but also payment of the amount insured and expenses to settle claims. So, the cost is random; when the contract is written, by design neither the insurer nor the insured knows the contract costs. Moreover, costs may not be revealed for months or years. For example, a typical time to settlement in medical malpractice is five years. Because costs are unknown at the time of sale, insurance pricing differs from common economic approaches. This chapter squarely addresses the uncertain nature of costs by introducing traditional actuarial approaches that determine prices as a function of insurance costs. As we will see, this pricing approach is sufficient for some insurance markets such as personal automobile or homeowners where the insurer has a portfolio of many independent risks. However, there are other insurance markets where actuarial prices only provide an input to general market prices. To reinforce this distinction, actuarial cost-based premiums are sometimes known as technical prices. From the perspective of economists, corporate decisions such as pricing are to be evaluated with reference to their impact on the firm’s market value. This objective is more comprehensive than the static notion of profit maximization. That is, you can think of the value of the firm represents the capitalized value of all future expected profits. Decisions impacting this value in turn affect all groups having claims on the firm, including stockholders, bondholders, policyowners (in the case of mutual companies), and so forth. For cost-based prices, it is helpful to think of a premium as revenue source that provides for claim payments, contract expenses, and an operating margin. We formalize this in an accounting equation \\[\\begin{equation} \\small{ \\text{Premium = Loss + Expense + UW Profit} . } \\tag{7.1} \\end{equation}\\] Expenses can be split into those that vary by premium (such as sales commissions) and those that do not (such as building costs and employee salaries). The term UW Profit is a residual that stands for underwriting profit. It may also include include a cost of capital (for example, an annual dividend to company investors). Because fixed expenses and costs of capital are difficult to interpret for individual contracts, we think of the equation (7.1) relationship as holding over the sum of many contracts (a portfolio) and work with it in aggregate. Then, in Section 7.2 we use this approach to help us think about setting premiums, for example by setting profit objectives. Specifically, Sections 7.2.1 and 7.2.2 introduce two prevailing methods used in practice for determining premiums, the pure premium and the loss ratio methods. The Loss in equation (7.1) is random and so, as a baseline, we use the expected costs to determine rates. There are several ways to motivate this perspective that we expand upon in Section 7.3. For now, we will suppose that the insurer enters into many contracts with risks that are similar except, by pure chance, in some cases the insured event occurs and in others it does not. The insurer is obligated to pay the total amount of claims payments for all contracts. If risks are similar, then all policyholders should be responsible for the same amount which is the average claim payment. So, from this perspective, it makes sense to look at the average claim payment over many insureds. From probability theory, specifically the law of large numbers, we know that the average of iid risks is close to the expected amount, so we use the expectation as a baseline pricing principle. Nonetheless, by using expected losses, we essentially assume that the uncertainty is non-existent. If the insurers sells enough independent policies, this may be a reasonable approximation. However, there will be other cases, such as a single contract issued to a large corporation to insure all of its buildings against fire damage, where the use of only an expectation for pricing is not sufficient. So, Section 7.3 also summarizes alternative premium principles that incorporate uncertainty into our pricing. Note that an emphasis of this text is estimation of the entire distribution of losses so the analyst is not restricted to working only with expectations. The aggregate methods derived from equation (7.1) focus on collections of homogeneous risks that are similar except for the occurrence of random losses. In statistical language that we have introduced, this is a discussion about risks that have identical distributions. Naturally, when examining risks that insurers work with, there are many variations in the risks being insured including the features of the contracts and the people being insured. Section 7.4 extends pricing considerations to heterogeneous collections of risks. Section 7.5 introduces ideas of development and trending. When developing rates, we want to use the most recent loss experience because the goal is to develop rates that are forward looking. However, at contract initiation, recent loss experience is often not known; it may be several years until it is fully realized. So, this section introduces concepts needed for incorporating recent loss experience into our premium development. Development and trending of experience is related to but also differs from the idea of experience rating that suggests that experience reveals hidden information about the insured and so should be incorporated in our forward thinking viewpoint. Chapter 9 discusses this idea in more detail. The final section of this chapter introduces methods for selecting a premium. This is done by comparing a premium rating method to losses from a held-out portfolio and selecting the method that produces the best match with the held-out data. For a typical insurance portfolio, most policies produce zero losses, that is, do not have a claim. Because the distribution of held-out losses is a combination of (a large number of) zeros and continuous amounts, special techniques are useful. Section 7.6 introduces concepts of concentration curves and corresponding Gini statistics to help in this selection. The chapter also includes a technical supplement on government regulation of insurance rates to keep our work grounded in applications. 7.2 Aggregate Ratemaking Methods In this section, you learn how to: Define a pure premium as a loss cost as well as in terms of frequency and severity Calculate an indicated rate using pure premiums, expenses, and profit loadings Define a loss ratio Calculate an indicated rate change using loss ratios Compare the pure premium and loss ratio methods for determining premiums It is common to consider an aggregate portfolio of insurance experience. Consistent with earlier notation, consider a collection of n contracts with losses \\(X_1, \\ldots, X_n\\). In this section, we assume that contracts have the same loss distribution, that is they form a homogeneous portfolio, and so are iid. For motivation, you can think about personal insurance such as auto or homeowners where insurers write many contracts on risks that appear very similar. Further, the assumption of identical distributions is not as limiting as you might think. In Section 7.4.1 we will introduce the idea of an exposure variable that allows us to rescale experience to make it comparable. For example, by rescaling losses we will be able to treat homeowner losses from a 100,000 house and a 200,000 house as coming from the same distribution. For now, we simply assume that \\(X_1, \\ldots, X_n\\) are iid. 7.2.1 Pure Premium Method If the number in the group, n, is large, then the average provides a good approximation of the expected loss \\[ \\small{ \\mathrm{E}(X) \\approx \\frac{\\sum_{i=1}^n X_i}{n} = \\frac{\\text{Loss}}{\\text{Exposure}} = \\text{Pure Premium}. } \\] With this as motivation, we define the pure premium to be the sum of losses divided by the exposure; it is also known as a loss cost. In the case of homogeneous risks, all policies are treated the same and we can use the number of policies n for the exposure. In Section 7.4.1 we extend the concept of exposure when policies are not the same. We can multiply and divide by the number of claims, claim count, to get \\[ \\small{ \\text{Pure Premium} = \\frac{\\text{claim count}}{\\text{Exposure}} \\times \\frac{\\text{Loss}}{\\text{claim count}} = \\text{frequency} \\times \\text{severity} . } \\] So, when premiums are determined using the pure premium method, we either take the average loss (loss cost) or use the frequency severity approach. To get a bit closer to applications in practice, we now return to equation (7.1) that includes expenses. Equation (7.1) also refers to UW Profit for underwriting profit. When rescaled by premiums, this is known as the profit loading. Because claims are uncertain, the insurer must hold capital to ensure that all claims are paid. Holding this extra capital is a cost of doing business, investors in the company need to be compensated for this, thus the extra loading. We now decompose Expenses into those that vary by premium, Variable, and those that do not, Fixed so that Expenses = Variable + Fixed. Thinking of variable expenses and profit as a fraction of premiums, we define \\[ \\small{ V = \\frac{\\text{Variable}}{\\text{Premium}} ~~~ \\text{and}~~~ Q = \\frac{\\text{UW Profit}}{\\text{Premium}} ~. } \\] With these definitions and equation (7.1), we may write \\[ \\small{ \\begin{matrix} \\begin{array}{ll} \\text{Premium} &amp;= \\text{Losses + Fixed} + \\text{Premium} \\times \\frac{\\text{Variable + UW Profit}}{\\text{Premium}} \\\\ &amp; = \\text{Losses + Fixed} + \\text{Premium} \\times (V+Q) . \\end{array} \\end{matrix} } \\] Solving for premiums yields \\[\\begin{equation} \\small{ \\text{Premium} = \\frac{\\text{Losses + Fixed}}{1-V-Q} . } \\tag{7.2} \\end{equation}\\] Dividing by exposure, the rate can be calculated as \\[ \\begin{matrix} \\begin{array}{ll} \\text{Rate} &amp;= \\frac{\\text{Premium}}{\\text{Exposure}} = \\frac{\\text{Losses/Exposure + Fixed/Exposure}}{1-V-Q} \\\\ &amp;= \\frac{\\text{Pure Premium + Fixed/Exposure}}{1-V-Q} ~. \\end{array} \\end{matrix} \\] In words, this is \\[ \\small{ \\text{Rate} =\\frac{\\text{pure premium + fixed expense per exposure}}{\\text{1 - variable expense factor - profit and contingencies factor}} . } \\] Example. CAS Exam 5, 2004, Number 13. Determine the indicated rate per exposure unit, given the following information: Frequency per exposure unit = 0.25 Severity = $100 Fixed expense per exposure unit = $10 Variable expense factor = 20% Profit and contingencies factor = 5% Show Example Solution Solution. Under the pure premium method, the indicated rate is \\[ \\begin{matrix} \\begin{array}{ll} \\text{Rate} &amp;= \\frac{\\text{pure premium + fixed expense per exposure}}{\\text{1 - variable expense factor - profit and contingencies factor}}\\\\ &amp;= \\frac{\\text{frequency} \\times \\text{severity} ~+~10}{1-0.20-0.05} = \\frac{0.25 \\times 100 +10}{1-0.20-0.05} = 46.67 . \\end{array} \\end{matrix} \\] From the example, note that the rates produced by the pure premium method are commonly known as indicated rates. From our development, note also that the profit is associated with underwriting aspect of the contract and not investments. Premiums are typically paid at the beginning of a contract and insurers receive investment income from holding this money. However, due in part to the short-term nature of the contracts, investment income is typically ignored in pricing. This builds a bit of conservatism into the process that insurers welcome. It is probably most relevant in the very long “tail” lines such as workers’ compensation and medical malpractice. In these lines, it can sometimes take 20 years or even longer to settle claims. But, these are also the most volatile lines; claim payments far in the future are less extreme when viewed in discounted sense. 7.2.2 Loss Ratio Method The loss ratio is the ratio of the sum of losses to the premium \\[ \\small{ \\text{Loss Ratio} = \\frac{\\text{Loss}}{\\text{Premium}} . } \\] When determining premiums, it is a bit counter-intuitive to emphasize this ratio because the premium component is built into the denominator. As we will see, the idea is that the loss ratio method develops rate changes rather than rates; we can use rate changes to update past experience to get a current rate. To do this, rate changes consist of the ratio of the experience loss ratio to the target loss ratio. This adjustment factor is then applied to current rates to get new indicated rates. To see how this works in a simple context, let us return to equation (7.1) but now ignore expenses to get \\(\\small{\\text{Premium = Losses + UW Profit}}\\). Dividing by premiums yields \\[ \\small{ \\frac{\\text{UW Profit}}{\\text{Premium}} = 1 - LR = 1 - \\frac{\\text{Loss}}{\\text{Premium}} . } \\] Suppose that we have in mind a new “target” profit loading, say \\(Q_{target}\\). Assuming that losses, exposure, and other things about the contract stay the same, then to achieve the new target profit loading we adjust the premium. Use the ICF for the indicated change factor that is defined through the expression \\[ \\small{ \\frac{\\text{new UW Profit}}{\\text{Premium}} = Q_{target} = 1 - \\frac{\\text{Loss}}{ICF \\times \\text{Premium}}. } \\] Solving for ICF, we get \\[ \\small{ ICF = \\frac{\\text{Loss}}{\\text{Premium} \\times (1-Q_{target})} = \\frac{LR}{1-Q_{target}}. } \\] So, for example, if we have a current loss ratio = 85% and a target profit loading \\(\\small{Q_{target}=0.20}\\), then \\(\\small{ICF = 0.85/0.80 = 1.0625}\\), meaning that we increase premiums by 6.25%. Now let’s see how this works with expenses in equation (7.1). We can use the same development as in Section 7.2.1 and so start with equation (7.2), solve for the profit loading to get \\[ \\small{ Q = 1 - \\frac{\\text{Loss+Fixed}}{\\text{Premium}} - V . } \\] We interpret the quantity Fixed /Premium + V as the “operating expense ratio.” Now, fix the profit percentage Q at a target and adjust premiums through the “indicated change factor” \\(ICF\\) \\[ \\small{ Q_{target} = 1 -\\frac{\\text{Loss + Fixed}}{\\text{Premium}\\times ICF} - V . } \\] Solving for \\(ICF\\) yields \\[\\begin{equation} \\small{ ICF = \\frac{\\text{Loss + Fixed}}{\\text{Premium} \\times (1 - V - Q_{target})} . } \\tag{7.3} \\end{equation}\\] Example. Loss Ratio Indicated Change Factor. Assume the following information: Projected ultimate loss and LAE ratio = 65% Projected fixed expense ratio = 6.5% Variable expense = 25% Target UW profit = 10% With these assumptions, with equation (7.3), the indicated change factor can be calculated as \\[ \\small{ ICF = \\frac{\\text{(Losses + Fixed)}/\\text{Premium}}{ 1 - V - Q_{target}} = \\frac{0.65 + 0.065}{1- 0.25 - 0.10} = 1.10 . } \\] This means that overall average rate level should be increased by 10%. We later provide a comparison of the pure premium and loss ratio methods in Section 7.5.3. As inputs, this section will require discussions of trended exposures and on-level premiums defined in Section 7.5. 7.3 Pricing Principles In this section, you learn how to: Describe common actuarial pricing principles Describe properties of pricing principles Choose a pricing principle based on a desired property Approaches to pricing vary by the type of contract. For example, personal automobile is common (it is known as part of the retail general insurance market in the United Kingdom). Here, one can expect to do pricing based on a large pool of independent contracts, a situation in which expectations of losses provide an excellent starting point. In contrast, an actuary may wish to price an insurance contract issued to a large employer that covers complex health benefits for thousands of employees. In this example, knowledge of the entire distribution of potential losses, not just the expected value, is critical for starting the pricing negotiations. To cover a range of potential applications, this section describes general premium principles and their properties that one can use to decide whether or not a specific principle is applicable in a given situation. 7.3.1 Premium Principles This chapter introduces traditional actuarial pricing principles that provide a price based only on the insurance loss distribution; the price does not depend on the demand for insurance or other aspects of the costs such as expenses. Assume that the loss \\(X\\) has a distribution function \\(F(\\cdot)\\) and that there exists some functional \\(H\\) that takes \\(F(\\cdot)\\) into the positive real line, denoted as \\(P = H(F)\\). For notation purposes, it is often convenient to substitute the random variable \\(X\\) for its distribution function and write \\(P = H(X)\\). Table 7.1 provides several examples. Table 7.1: Common Premium Principles Description Definition (\\(H(X)\\)) Net (pure) premium \\(E[X]\\) Expected value \\((1+\\alpha)E[X]\\) Standard deviation \\(E[X]+\\alpha ~SD(X)\\) Variance \\(E[X]+\\alpha ~Var(X)\\) Zero utility solution of \\(u(w) = E ~u(w + P - X)\\) Exponential \\(\\frac{1}{\\alpha} \\ln E ~e^{\\alpha X}\\) A premium principle is similar to a risk measure that is introduced in Section 10.3. Mathematically, both are functions that maps the loss rv of interest to a numerical value. From a practical viewpoint, a premium principle provides a guide as to how much an insurer will charge for accepting a risk \\(X\\). In contrast, a risk measure quantifies the level of uncertainty, or riskiness, that an insurer can use to decide on a capital level to be assured of remaining solvent. As noted above, the net, or pure, premium essentially assumes no uncertainty. The expected value, standard deviation, and variance principles each add an explicit loading for riskiness through parameter \\(\\alpha \\ge 0\\). For the principle of zero utility, we think of an insurer with utility function \\(u(\\cdot)\\) and wealth w as being indifferent to accepting and not accepting risk \\(X\\). In this case, \\(P\\) is known as an indifference price or, in economics, a reservation price. With exponential utilility, the principle of zero utility reduces to the exponential premium principle, that is, assuming \\(u(x) = (1-e^{-\\alpha x})/\\alpha\\). For small values of risk parameters, the variance principle is approximately equal to exponential premium principle, as illustrated in the following special case. Special Case: Gamma Distribution. Consider a loss that is gamma distributed with parameters \\(\\alpha\\) and \\(\\theta\\). From the Appendix D in 18, the mean is \\(\\alpha \\theta\\) and the variance is \\(\\alpha \\theta^2\\). Using \\(\\alpha_{Var}\\) for the risk parameter, the variance premium is \\(H_{Var}(X) = \\alpha \\theta+\\alpha_{Var} ~(\\alpha \\theta^2)\\). From this appendix, it is straightforward to derive the well-known moment generating function, \\(M(t) = E e^{tX} = (1-t\\theta)^{-\\alpha}\\). With this and a risk parameter \\(\\alpha_{Exp}\\), we may express the exponential premium as \\[ H_{Exp}(X) = \\frac{-\\alpha}{\\alpha_{Exp}} \\ln\\left(1-\\alpha_{Exp} \\theta\\right). \\] To see the relationship between \\(H_{Var}(X)\\) and \\(H_{Var}(X)\\), we choose \\(\\alpha_{Exp} = 2 \\alpha_{Var}\\). With an approximation from calculus (\\(\\ln(1-x) = -x - x^2/2 - x^3/3 - \\cdots\\)), we write \\[ H_{Exp}(X) = \\frac{-\\alpha}{\\alpha_{Exp}} \\ln\\left(1-\\alpha_{Exp} \\theta\\right) = \\frac{-\\alpha}{\\alpha_{Exp}} \\left\\{ -\\alpha_{Exp} \\theta -(\\alpha_{Exp} \\theta)^2/2 - \\cdots\\right\\} \\\\ \\approx \\alpha \\theta + \\frac{\\alpha_{Exp}}{2}(\\alpha \\theta^2 ) = H_{Var}(X). \\] 7.3.2 Properties of Premium Principles Properties of premium principles help guide the selection of a premium principle in applications. Table 7.2 provides examples of properties of premium principles. Table 7.2: Common Properties of Premium Principles Description Definition Nonnegative loading \\(H(X) \\ge E[X]\\) Additivity \\(H(X_1+X_2) = H(X_1) + H(X_2)\\), for independent \\(X_1, X_2\\) Scale invariance \\(H(cX) = c H(X)\\), for \\(c \\ge 0\\) Consistency \\(H(c+X) = c + H(X)\\) No rip-off \\(H(X) \\le max ~range ~\\{X\\}\\) This is simply a subset of the many properties quoted in the actuarial literature. For example, the review paper of Young (2014) lists 15 properties. See also the properties described as coherent axioms that we introduce for risk measures in Section 10.3. Some of the properties listed in Table 7.2 are mild in the sense that they will nearly always be satisfied. For example, the no rip-off property indicates that the premium charge will be smaller than the maximal value of the loss \\(X\\). Other properties may not be so mild. For example, for a portfolio of independent risks, the actuary may want the additivity property to hold. It is easy to see that this property holds for the expected value, variance, and exponential premium principles but not for the standard deviation principle. Another example is the consistency property that does not hold for the expected value principle when the risk loading parameter \\(\\alpha\\) is positive. The scale invariance principle is known as homogeneity of degree one in economics. It allows, for example, us to work in different currencies (e.g., from dollars to Euros) as well as a host of other applications and will be discussed further in the following Section 7.4. Although a generally accepted principle, we note that this principle does not hold for a large values of \\(X\\) that may border on a surplus constraint of an insurer; if an insurer has a large probability of becoming insolvent, then that insurer may not wish to use linear pricing. It is easy to check that this principle holds for the expected value and standard deviation principles, although not for the variance and exponential principles. 7.4 Heterogeneous Risks In this section, you learn how to: Describe insurance exposures in terms of scale distributions Explain an exposure in terms of common types of insurance such as auto and homeowners insurance Describe how rating factors can be used to account for the heterogeneity among risks in a collection Measure the impact of a rating factor through relativities As noted in Section 7.1, there are many variations in the risks being insured, the features of the contracts, and the people being insured. As an example, you might have a twin brother or sister who works in the same town and earns a roughly similar amount of money. Still, when it comes to selecting choices in rental insurance to insure contents of your apartment, you can imagine differences in the amount of contents to be insured, choices of deductibles for the amount of risk retained, and perhaps different levels of uncertainty given the relative safety of your neighborhoods. People, and risks that they insure, are different. When thinking about a collection of different, or heterogeneous, risks, one option is to price all risks the same. This is common, for example, in government sponsored programs for flood or health insurance. However, it is also common to have different prices where the differences are commensurate with the risk being insured. 7.4.1 Exposure to Risk One easy way to make heterogeneous risks comparable is through the concept of an exposure. To explain exposures, let us use scale distributions that we learned about in Chapter 3. To recall a scale distribution, suppose that \\(X\\) has a parametric distribution and define a rescaled version \\(R = X/E\\), \\(E &gt; 0\\). If \\(R\\) is in the same parametric family as \\(X\\), then the distribution is said to be a scale distribution. As we have seen, the gamma, exponential, and Pareto distributions are examples of scale distributions. Intuitively, the idea behind exposures is to make risks more comparable to one another. For example, it may be that risks \\(X_1, \\ldots, X_n\\) come from different distributions and yet, with the choice of the right exposures, the rates \\(R_1, \\ldots, R_n\\) come from the same distribution. Here, we interpret the rate \\(R_i = X_i/E_i\\) to be the loss divided by exposure. Table 7.3 provides a few examples. We remark that this table refers to “earned” car and house years, concepts that will be explained in Section 7.5. \\[ \\small{ \\begin{matrix} \\begin{array}{ll} \\text{Type of Insurance} &amp; \\text{Exposure Basis} \\\\\\hline \\text{Personal Automobile} &amp; \\text{Earned Car Year, Amount of Insurance Coverage} \\\\ \\text{Homeowners} &amp; \\text{Earned House Year, Amount of Insurance Coverage}\\\\ \\text{Workers Compensation} &amp; \\text{Payroll}\\\\ \\text{Commercial General Liability} &amp; \\text{Sales Revenue, Payroll, Square Footage, Number of Units}\\\\ \\text{Commercial Business Property} &amp; \\text{Amount of Insurance Coverage}\\\\ \\text{Physician&#39;s Professional Liability} &amp; \\text{Number of Physician Years}\\\\ \\text{Professional Liability} &amp; \\text{Number of Professionals (e.g., Lawyers or Accountants)}\\\\ \\text{Personal Articles Floater} &amp; \\text{Value of Item} \\\\ \\hline \\end{array} \\end{matrix} } \\] Table 7.3 : Commonly used Exposures in Different Types of Insurance An exposure is a type of rating factor, a concept that we define explicitly in the next Section 7.4.2. It is typically the most important rating factor, so important that both premiums and losses are quoted on a “per exposure” basis. For frequency and severity modeling, it is customary to think about the frequency aspect as proportional to exposure and the severity aspect in terms of loss per claim (not dependent upon exposure). However, this does not cover the entire story. For many lines of business, it is convenient for exposures to be proportional to inflation. Inflation is typically viewed as unrelated to frequency but proportional to severity. Criteria for Choosing an Exposure An exposure base should meet the following criteria. It should: be an accurate measure of the quantitative exposure to loss be easy for the insurer to determine (at the time the policy is calculated) and not subject to manipulation by the insured, be easy to understand by the insured and to calculate by the insurer, consider any preexisting exposure base established within the industry, and for some lines of business, it is proportional to inflation. In this way, rates are not sensitive to the changing value of money over time as these changes are captured in exposure base. To illustrate, consider personal automobile coverage. Instead of the exposure basis “earned car year,” a more accurate measure of the quantitative exposure to loss might be number of miles driven. However, this measure is difficult to determine at the time the policy is issued and subject to potential manipulation by the insured. As another example, the exposure measure in commercial business property, e.g. fire insurance, is typically the amount of insurance coverage. As property values grow with inflation, so will the amount of insurance coverage. Thus, rates quoted on a per amount of insurance coverage are less sensitive to inflation than otherwise. 7.4.2 Rating Factors A rating factor, or rating variable, is simply a characteristic of the policyholder or risk being insured by which rates vary. For example, when you purchase auto insurance, it is likely that the insurer has rates that differ by age, gender, type of car and where it is garaged, accident history, and so forth. These variables are known as rating factors. Although some variables may be continuous, such as age, most are categorical - factor is a label that is used for categorical variables. In fact, even with continuous variables such as age, it is common to categorize them by creating groups such as “young,” “intermediate,” and “old” for rating purposes. Table 7.4 provides just a few examples. In many jurisdictions, the personal insurance market (e.g., auto and homeowners) is very competitive - using 10 or 20 variables for rating purposes is not uncommon. \\[ \\small{ \\begin{matrix} \\begin{array}{l|l}\\hline \\text{Type of Insurance} &amp; \\text{Rating Factors}\\\\\\hline\\hline \\text{Personal Automobile} &amp; \\text{Driver Age and Gender, Model Year, Accident History}\\\\ \\text{Homeowners} &amp; \\text{Amount of Insurance, Age of Home, Construction Type}\\\\ \\text{Workers Compensation} &amp; \\text{Occupation Class Code}\\\\ \\text{Commercial General Liability} &amp; \\text{Classification, Territory, Limit of Liability}\\\\ \\text{Medical Malpractice} &amp; \\text{Specialty, Territory, Limit of Liability}\\\\ \\text{Commercial Automobile} &amp; \\text{Driver Class, Territory, Limit of Liability}\\\\ \\hline \\end{array} \\end{matrix} } \\] Table 7.4 : Commonly used Rating Factors in Different Types of Insurance Example. Losses and Premium by Amount of Insurance and Territory. To illustrate, Table 7.5 presents a small fictitious data set from Werner and Modlin (2016). The data consists of loss and loss adjustment expenses (LossLAE), decomposed by three levels of AOI, amount of insurance, and three territories (Terr). For each combination of AOI and Terr, we also have available the number of policies issued, given as the Exposure. \\[ \\small{ \\begin{matrix} \\begin{array}{cc|rrr} \\hline AOI &amp; Terr &amp; Exposure &amp; LossLAE &amp; Premium \\\\\\hline \\text{Low} &amp; 1 &amp; 7 &amp; 210.93 &amp; 335.99 \\\\ \\text{Medium} &amp; 1 &amp; 108 &amp; 4,458.05 &amp; 6,479.87 \\\\ \\text{High} &amp; 1 &amp; 179 &amp; 10,565.98 &amp; 14,498.71 \\\\\\hline \\text{Low} &amp; 2 &amp; 130 &amp; 6,206.12 &amp; 10,399.79 \\\\ \\text{Medium} &amp; 2 &amp; 126 &amp; 8,239.95 &amp; 12,599.75 \\\\ \\text{High} &amp; 2 &amp; 129 &amp; 12,063.68 &amp; 17,414.65 \\\\\\hline \\text{Low} &amp; 3 &amp; 143 &amp; 8,441.25 &amp; 14,871.70 \\\\ \\text{Medium} &amp; 3 &amp; 126 &amp; 10,188.70 &amp; 16,379.68 \\\\ \\text{High} &amp; 3 &amp; 40 &amp; 4,625.34 &amp; 7,019.86 \\\\ \\hline \\text{Total} &amp; &amp; 988 &amp; 65,000.00 &amp; 99,664.01 \\\\\\hline \\hline \\end{array} \\end{matrix} } \\] Table 7.5 : Losses and Premium by Amount of Insurance and Territory In this case, the rating factors AOI and Terr produce nine cells. Note that one might combine the cell “territory one with a low amount of insurance”\" with another cell because there are only 7 policies in that cell. Doing so is perfectly acceptable - considerations of this sort is one of the main jobs of the analyst. An outline on selecting variables is in Chapter 8, including Technical Supplement TS 8.B. Alternatively, you can also think about reinforcing information about the cell (Terr 1, Low AOI) by “borrowing” information from neighboring cells (e.g., other territories with the same AOI, or other amounts of AOI within Terr 1). This is the subject of credibility that is introduced in Chapter 9. To understand the impact of rating factors, it is common to use relativities. A relativity is the difference of the expected risk between a specific level of a rating factor and an accepted baseline value. In this book, we work with relativities defined through ratios; it is also possible to define relativities through arithmetic differences. Thus, our relativity is defined as \\[ \\text{Relativity}_j = \\frac{\\text{(Loss/Exposure)}_j}{\\text{(Loss/Exposure)}_{Base}} . \\] Example. Losses and Premium by Amount of Insurance and Territory - Continued. Traditional classification methods consider only one classification variable at a time - they are univariate. Thus, if we wanted relativities losses and expenses (LossLAE) by amount of insurance, we might sum over territories to get the information displayed in Table 7.6. \\[ \\small{ \\begin{matrix} \\begin{array}{c|rrrr} \\hline AOI &amp; Exposure &amp; LossLAE &amp; Loss/Exp &amp;Relativity \\\\\\hline \\text{Low} &amp; 280 &amp; 14858.3 &amp; 53.065 &amp;0.835 \\\\ \\text{Medium} &amp; 360 &amp; 22886.7 &amp; 63.574 &amp;1.000 \\\\ \\text{High} &amp; 348 &amp; 27255.0 &amp; 78.319 &amp; 1.232 \\\\\\hline \\text{Total} &amp; 988 &amp; 65,000.0 &amp; \\\\\\hline \\hline \\end{array} \\end{matrix} } \\] Table 7.6 : Losses and Relativities by Amount of Insurance Thus, for example, losses and expenses per unit of exposure are 23.2% higher for risks with a high amount of insurance compared to those with a medium amount. These relativities do not control for territory. The introduction of rating factors allows the analyst to create cells that define small collections of risks – the goal is to choose the right combination of rating factors so that all risks within a cell may be treated the same. In statistical terminology, we want all risks within a cell to have the same distribution (subject to rescaling by an exposure variable). This is the foundation of insurance pricing. All risks within a cell have the same price yet risks from different cells may have different prices. Said another way, insurers are allowed to charge different rates for different risks; discrimination of risks is legal and routinely done. Nonetheless, the basis of discrimination, the choice of risk factors, is the subject of extensive debate. The actuarial community, insurance management, regulators, and consumer advocates are all active participants in this debate. Technical Supplement TS 7.A describes these issues from a regulatory perspective. In addition to statistical criteria for assessing the significance of a rating factor, analysts much pay attention to business concerns of the company (e.g., is it expensive to implement a rating factor?), social criteria (is a variable under the control of a policyholder?), legal criteria (are there regulations that prohibit the use of a rating factor such as gender?), and other societal issues. These questions are largely beyond the scope of this text. Nonetheless, because they are so fundamental to pricing of insurance, a brief overview is given in Chapter 8, including Technical Supplement TS 8.B. 7.5 Development and Trending In this section, you learn how to: Define and calculate different types of exposure and premium summary measures that appear in financial reports Describe the development of a claim over several payments and link that to various unpaid claim measures, including those incurred but not reported (IBNR) as well as case reserves Compare and contrast relative strengths and weaknesses of the pure premium and loss ratio methods for ratemaking As we have seen in Section 7.2, insurers consider aggregate information for ratemaking such as exposures to risk, premiums, expenses, claims, and payments. This aggregate information is also useful for managing an insurers’ activities; financial reports are commonly created at least annually and oftentimes quarterly. At any given financial reporting date, information about recent policies and claims will be ongoing and necessarily incomplete; this section introduces concepts for projecting risk information so that it is usful for ratemaking purposes. Information about the risks, such as exposures, premium, claim counts, losses, and rating factors, is typically organized into three databases: policy database - contains information about the risk being insured, the policyholder, and the contract provisions claims database - contains information about each claim; these are linked to the policy database. payment database - contains information on each claims transaction, typically payments but may also changes to case reserves. These are linked to the claims database. With these detailed databases, it is straightforward (in principle) to sum up policy level detail to aggregate information needed for financial reports. This section describes various summary measures commonly used. 7.5.1 Exposures and Premiums A financial reporting period is a length of time that is fixed in the calendar; we use January 1 to December 31 for the examples in this book although other reporting periods are also common. The reporting period is fixed but policies may begin at any time during the year. Even if all policies have a common contract length of (say) one year, because of the differing starting time, they can end at any time during the financial reporting. Figure 7.1 presents four illustrative policies. Because of these differing starting and end times, there needs to be some standards as to what types of measures are most useful for summarizing experience in a given reporting period. Figure 7.1: Timeline of Exposures for Four 12-Month Policies. Some commonly used exposure measures are: written exposures, the amount of exposures on policies issued (underwritten or written) during the period in question, earned exposures, the exposure units actually exposed to loss during the period, that is, where coverage has already been provided unearned exposures, represent the portion of the written exposures for which coverage has not yet been provided as of that point in time, and in force exposures, exposure units exposed to loss at a given point in time. Table 7.12 gives detailed illustrative calculations for the four illustrative policies. \\[ \\small{ \\begin{matrix} \\begin{array}{cl|cc|cc|cc|c} \\hline &amp; &amp; &amp; &amp; &amp; &amp; &amp;&amp;\\text{In-Force} \\\\ &amp;\\text{Effective} &amp; \\text{Written}&amp; \\text{Exposure} &amp; \\text{Earned} &amp;\\text{Exposure}&amp; \\text{Unearned} &amp;\\text{Exposure}&amp; \\text{Exposure} \\\\ {Policy} &amp;\\text{Date} &amp; 2019 &amp; 2020 &amp; 2019 &amp; 2020 &amp; 2019 &amp; 2020 &amp; \\text{1 Jan 2020} \\\\ \\hline \\text{A}&amp;\\text{1 Jan 2019} &amp; 1.00 &amp; 0.00 &amp; 1.00 &amp; 0.00&amp; 0.00 &amp; 0.00 &amp; 0.00 \\\\ \\text{B}&amp;\\text{1 April 2019} &amp; 1.00 &amp; 0.00 &amp; 0.75 &amp; 0.25 &amp; 0.25 &amp; 0.00&amp; 1.00 \\\\ \\text{C}&amp;\\text{1 July 2019} &amp; 1.00 &amp; 0.00 &amp; 0.50 &amp; 0.50 &amp; 0.50 &amp; 0.00&amp; 1.00 \\\\ \\text{D}&amp;\\text{1 Oct 2019} &amp; 1.00 &amp; 0.00 &amp; 0.25 &amp; 0.75 &amp; 0.75 &amp; 0.00&amp; 1.00 \\\\ \\hline &amp; Total &amp; 4.00 &amp; 0.00 &amp; 2.50 &amp; 1.50 &amp; 1.50 &amp; 0.00 &amp; 3.00 \\\\ \\hline \\hline \\end{array} \\end{matrix} } \\] Table 7.12: Exposures for Four 12-Month Policies This summarization is sometimes known as the calendar year method of aggregation to serve as a contrast to the policy year method. In the latter method, all policies start at the beginning of the year. This method is useful for ratemaking methods based on individual contracts and we do not pursue this further here. In the same way as exposures, one can summarizes premiums. Premiums, like exposures, can be either written, earned, unearned, or in force. Consider the following example. Example. 7.5.1. CAS Exam 5, 2003, Number 10. A 12-month policy is written on March 1, 2002 for a premium of $900. As of December 31, 2002, which of the following is true? \\[ \\small{ \\begin{matrix} \\begin{array}{l|ccc} \\hline &amp; \\text{Calendar Year} &amp; \\text{Calendar Year} \\\\ &amp; \\text{2002 Written} &amp; \\text{2002 Earned} &amp; \\text{Inforce} \\\\ &amp; \\text{Premium} &amp; \\text{Premium} &amp; \\text{Premium} \\\\\\hline A. &amp; 900 &amp; 900 &amp; 900 \\\\ B. &amp; 750 &amp; 750 &amp; 900 \\\\ C. &amp; 900 &amp; 750 &amp; 750 \\\\ D. &amp; 750 &amp; 750 &amp; 750 \\\\ E. &amp; 900 &amp; 750 &amp; 900 \\\\\\hline \\end{array} \\end{matrix} } \\] Show Example Solution Only earned premium differs from written premium and inforce premium and therefore needs to be computed. Thus, earned premium at Dec 31, 2002, equals \\(\\$900 \\times 10/12 = \\$750\\). Answer E. 7.5.2 Losses, Claims, and Payments Broadly speaking, the terms loss and claim refer to the amount of compensation paid or potentially payable to the claimant under the terms of the insurance policy. Definitions can vary: Sometimes, the term claim is used interchangeably with the term loss. In some insurance and actuarial sources, the term loss is used for the amount of damage sustained in an insured event. The claim is the amount paid by the insurer with differences typically due to deductibles, upper policy limits, and the like. In economic usages, a claim is a demand for payment by an insured or by an injured third-party under the terms and conditions of insurance contract and the loss is the amount paid by the insurer. This text will follow the second bullet. However, when reading other sources, you will need to take care when thinking about definitions for the terms loss and claim. To establish additional terminology, it is helpful to follow the timeline of a claim as it develops. In Figure 7.2, the claim occurs at time \\(t_1\\) and the insuring company is notified at time \\(t_3\\). There can be a long gap between occurrence and notification such that the end of a company financial reporting period, known as a valuation date, occurs (\\(t_2\\)). In this case, the claim is said to be incurred but not reported at this valuation date. After claim notification, there may one or more loss payments. Not all of the payments may be made by the next valuation date (\\(t_4\\)). As the claim develops, eventually the company deems its financial obligations on the claim to be resolved and declares the claim closed. However, it is possible that new facts arise and the claim must be re-opened, giving rise to additional loss payments prior to being closed again. Figure 7.2: Timeline of Claim Development. Accident date - the date of the occurrence which gave rise to the claim. This is also known as the date of loss or the occurrence date. Report date - the date the insurer receives notice of the claim. Claims not currently known by the insurer are referred to as unreported claims or incurred but not reported (IBNR) claims. Until the claim is settled, the reported claim is considered an open claim. Once the claim is settled, it is categorized as a closed claim. In some instances, further activity may occur after the claim is closed, and the claim may be re-opened. Recall that a loss is the amount paid or payable to claimants under the terms of insurance policies. Further, we have Paid losses are those losses for a particular period that have actually been paid to claimants. Where there is an expectation that payment will be made in the future, a claim will have an associated case reserve representing the estimated amount of that payment. Reported Losses, also known as case incurred, is Paid Losses + Case Reserves The ultimate loss is the amount of money required to close and settle all claims for a defined group of policies. 7.5.3 Comparing Pure Premium and Loss Ratio Methods Now that we have learned how exposures, premiums, and claims develop over time, we can consider how they can be used for ratemaking. We have seen that insurers offer many different types of policies that cover different policyholders and amounts of risks. This aggregation is sometimes loosely referred to as the mix of business. Importantly, the mix changes over time as policyholders come and go, amounts of risks change, and so forth. The exposures, premiums, and types of risks from a prior financial reporting may not be representative of the period that rates are being developed for. The process of extrapolating exposures, premiums, and risk types is known as trending. For example, an on-level earned premium is that earned premium that would have resulted for the experience period had the current rates been in effect for the entire period. Most trending methods used in practice are mathematically straight-forward although they can become complicated given contractual and administrative complexities. We refer the reader to standard references that describe approaches in detail such as Werner and Modlin (2016) and Friedland (2013). Loss Ratio Method The expression for the loss ratio method indicated change factor in equation (7.3) assumes a certain amount of consistency in the portfolio experience over time. For another approach, we can define the experience loss ratio to be: \\[ \\small{ LR_{experience} = \\frac{\\text{experience losses}}{\\text{experience period earned exposure}\\times \\text{current rate}} . } \\] Here, we think of the experience period earned exposure \\(\\times\\) current rate as the experience premium. Using equation (7.2), we can write a loss ratio as \\[ \\small{ LR = \\frac{\\text{Losses}}{\\text{Premium}}=\\frac{1-V-Q}{\\text{(Losses + Fixed)}/\\text{Losses}}=\\frac{1-V-Q}{1+G} ~, } \\] where \\(G = \\text{Fixed} / \\text{Losses}\\), the ratio of fixed expenses to premiums. With this expression, we define the target loss ratio \\[ \\small{ LR_{target} = \\frac{1-V-Q}{1+G} = \\frac{1-\\text{premium related expense factor - profit and contingencies factor}} {1+\\text{ratio of non-premium related expenses to losses}} . } \\] With these, the indicated change factor is \\[\\begin{equation} \\small{ ICF =\\frac{LR_{experience}}{LR_{target}}. } \\tag{7.4} \\end{equation}\\] Comparing equation (7.3) to (7.4), we see that the latter offers more flexibility to explicitly incorporate trended experience. As the loss ratio method is based on rate changes, this flexibility is certainly warranted. Comparison of Methods Assuming that exposures, premiums, and claims have been trended to be representative of a period that rates are being developed for, we are now in a position to compare the pure premium and loss ratio methods for ratemaking. We start with the observation that for the same data inputs, these two approaches produce the same results. That is, they are algebraically equivalent. However, the rely on different inputs: \\[ \\small{ \\begin{array}{l|l}\\hline \\text{Pure Premium Method} &amp; \\text{Loss Ratio Method} \\\\ \\hline \\text{Based on exposures} &amp; \\text{Based on premiums} \\\\ \\text{Does not require existing rates} &amp; \\text{Requires existing rates} \\\\ \\text{Does not use on-level premiums} &amp; \\text{Uses on-level premiums} \\\\ \\text{Produces indicated rates} &amp; \\text{Produces indicated rate changes} \\\\ \\hline \\end{array} } \\] Comparing the pure premium and loss ratio methods, we note that: The pure premium method requires well-defined, responsive exposures. The loss ratio method cannot be used for new business because it produces indicated rate changes. The pure premium method is preferable where on-level premium is difficult to calculate. In some instances, such as commercial lines where individual risk rating adjustments are made to individual policies, it is difficult to determine the on-level earned premium required for the loss ratio method. In many developed countries like the US where lines of business have been in existence, the loss ratio approach is more popular. Example. 7.5.2. CAS Exam 5, 2006, Number 36. You are given the following information: Experience period on-level earned premium = $500,000 Experience period trended and developed losses = $300,000 Experience period earned exposure = 10,000 Premium-related expenses factor = 23% Non-premium related expenses = $21,000 Profit and contingency factor = 5% Calculate the indicated rate level change using the loss ratio method. Calculate the indicated rate level change using the pure premium method. Describe one situation in which it is preferable to use the loss ratio method, and one situation in which it is preferable to use the pure premium method. Show Example Solution We will calculate the experience and target loss ratios, then take the ratio to get the indicated rate change. The experience loss ratio is \\[ \\small{ LR_{experience} = \\frac{\\text{experience losses}}{\\text{experience period premium}} =\\frac{300000}{500000} = 0.60. } \\] The target loss ratio is: \\[ \\small{ \\begin{matrix} \\begin{array}{ll} LR_{target} &amp;= \\frac{1-V-Q}{1+G} = \\frac{1-\\text{premium related expense factor - profit and contingencies factor}} {1+\\text{ratio of non-premium related expenses to losses}}\\\\ &amp;= \\frac{1-0.23 - 0.05}{1+0.07} = 0.673 . \\end{array} \\end{matrix} } \\] Here, the ratio of non-premium related expenses to losses is \\(G = \\frac{21000}{300000} = 0.07\\). Thus, the (new) indicated rate level change is \\[ \\small{ ICF =\\frac{LR_{experience}}{LR_{target}} -1 = \\frac{0.60}{0.673} -1 = -10.8\\%. } \\] (b) Using the pure premium method, the indicated change factor, \\(ICF\\), is \\[ \\small{ \\begin{matrix} \\begin{array}{ll} ICF &amp;= \\frac{\\text{Losses + Fixed}}{\\text{Premium} \\times (1 - Q - V)}\\\\ &amp;= \\frac{300000+ 21000}{500000 \\times (1 - 0.23 - 0.05)} = 0.892 . \\end{array} \\end{matrix} } \\] Thus, the indicated rate level change is \\(0.892 -1 = -10.8\\%\\). The loss ratio method is preferable when the exposure unit is not available. The loss ratio method is preferable when the exposure unit is not reasonably consistent between risks. The pure premium method is preferable for a new line of business. The pure premium method is preferable where on-level premiums are difficult to calculate. 7.6 Selecting a Premium In this section, you learn how to: Describe skewed distributions via a Lorenz curve and Gini index Define a concentration curve and the corresponding Gini statistic Use the concentration curve and Gini statistic for premium selection base on out-of-sample validation For a portfolio of insurance contracts, insurers collect premiums and pay out losses. After making adjustments for expenses and profit considerations, tools for comparing distributions of premiums and losses can be helpful when selecting a premium calculation principle. 7.6.1 Classic Lorenz Curve In welfare economics, it is common to compare distributions via the Lorenz curve, developed by Max Otto Lorenz (Lorenz 1905). A Lorenz curve is a graph of the proportion of a population on the horizontal axis and a distribution function of interest on the vertical axis. It is typically used to represent income distributions. When the income distribution is perfectly aligned with the population distribution, the Lorenz curve results in a 45 degree line that is known as the line of equality. Because the graph compares two distribution functions, one can also think of a Lorenz curve as a type of pp plot that was introduced in Section 4.1.2.1. The area between the Lorenz curve and the line of equality is a measure of the discrepancy between the income and population distributions. Two times this area is known as the Gini index, introduced by Corrado Gini in 1912. Example – Classic Lorenz Curve. For an insurance example, Figure 7.3 shows a distribution of insurance losses. This figure is based on a random sample of 2000 losses. The left-hand panel shows a right-skewed histogram of losses. The right-hand panel provides the corresponding Lorenz curve, showing again a skewed distribution. For example, the arrow marks the point where 60 percent of the policyholders have 30 percent of losses. The 45 degree line is the line of equality; if each policyholder has the same loss, then the loss distribution would be at this line. The Gini index, twice the area between the Lorenz curve and the 45 degree line, is 37.6 percent for this data set. Figure 7.3: Distribution of Insurance Losses. The left-hand panel is a density plot of losses. The right-hand panel presents the same data using a Lorenz curve. 7.6.2 Performance Curve and a Gini Statistic We now introduce a modification of the classic Lorenz curve and Gini statistic that is useful in insurance applications. Specifically, we introduce a performance curve that, in this case, is a graph of the distribution of losses versus premiums, where both losses and premiums are ordered by premiums. To make the ideas concrete, we provide some notation and consider \\(i=1, \\ldots, n\\) policies. For the \\(i\\)th policy, let \\(y_i\\) denote the insurance loss, \\(\\mathbf{x}_i\\) be a set of rating variables known to the analyst, and \\(P_i=P(\\mathbf{x}_i)\\) be the associated premium that is a function of \\(\\mathbf{x}_i\\). The set of information used to calculate the performance curve for the \\(i\\)th policy is \\((y_i, P_i)\\). Performance Curve It is convenient to first sort the set of policies based on premiums (from smallest to largest) and then compute the premium and loss distributions. The premium distribution is \\[\\begin{equation} \\hat{F}_P(s) = \\frac{ \\sum_{i=1}^n P_i ~\\mathrm{I}(P_i \\leq s) }{\\sum_{i=1}^n P_i} , \\tag{7.5} \\end{equation}\\] and the loss distribution is \\[\\begin{equation} \\hat{F}_{L}(s) = \\frac{ \\sum_{i=1}^n y_i ~\\mathrm{I}(P_i \\leq s) }{\\sum_{i=1}^n y_i} , \\tag{7.6} \\end{equation}\\] where \\(\\mathrm{I}(\\cdot)\\) is the indicator function, returning a 1 if the event is true and zero otherwise. For a given value \\(s\\), \\(\\hat{F}_P(s)\\) gives the proportion of premiums less than or equal to \\(s\\), and \\(\\hat{F}_{L}(s)\\) gives the proportion of losses for those policyholders with premiums less than or equal to \\(s\\). The graph \\(\\left(\\hat{F}_P(s),\\hat{F}_{L}(s) \\right)\\) is known as a performance curve. Example – Loss Distribution. Suppose we have \\(n=5\\) policyholders with experience as follows. The data have been ordered by premiums. Variable \\(i\\) 1 2 3 4 5 Premium \\(P(\\mathbf{x}_i)\\) 2 4 5 7 16 Cumulative Premiums \\(\\sum_{j=1}^i P(\\mathbf{x}_j)\\) 2 6 11 18 34 Loss \\(y_i\\) 2 5 6 6 17 Cumulative Loss \\(\\sum_{j=1}^i y_j\\) 2 7 13 19 36 Figure 7.4 compares the Lorenz to the performance curve. The left-hand panel shows the Lorenz curve. The horizontal axis is the cumulative proportion of policyholders (0, 0.2, 0.4, and so forth) and the vertical axis is the cumulative proportion of losses (0, 2/36, 7/36, and so forth). For the Lorenz curve, you first order by the loss size (which turns out to be the same order as premiums for this simple dataset). This figure shows a large separation between the distributions of losses and policyholders. The right-hand panel shows the performance curve. Because observations are sorted by premiums, the first point after the origin (reading from left to right) is (2/34, 2/36). The second point is (6/34, 7/36), with the pattern continuing. From the figure, we see that there is little separation between losses and premiums. Figure 7.4: Lorenz versus Performance Curve The performance curve can be helpful to the analyst who thinks about forming profitable portfolios for the insurer. For example, suppose that \\(s\\) is chosen to represent the 95th percentile of the premium distribution. Then, the horizontal axis, \\(\\hat{F}_P(s)\\), represents the fraction of premiums for this portfolio and the vertical axis, \\(\\hat{F}_L(s)\\), the fraction of losses for this portfolio. When developing premium principles, analysts wish to avoid unprofitable situations and make profits, or at least break even. The expectation of the numerator in equation (7.6) is \\(\\sum_{i=1}^n \\mathrm{E}~ y_i=\\sum_{i=1}^n \\mu_i\\). Thus, if the premium principle is chosen such that \\(P_i= \\mu_i\\), then we anticipate a close relation between the premium and loss distributions, resulting in a 45 degree line. The 45 degree line presents equality between losses and premiums, a break-even situation which is the benchmark for insurance pricing. Gini Statistic The classic Lorenz curve shows the proportion of policyholders on the horizontal axis and the loss distribution function on the vertical axis. The performance curve extends the classical Lorenz curve in two ways, (1) through the ordering of risks and prices by prices and (2) by allowing prices to vary by observation. We summarize the performance curve in the same way as the classic Lorenz curve using a Gini statistic, defined as twice the area between the curve and a 45 degree line. The analyst seeks ordered performance curves that approach passing through the 45 degree line; these have least separation between the loss and premium distributions and therefore small Gini statistics. Specifically, the Gini statistic can be calculated as follows. Suppose that the empirical performance curve is given by \\(\\{ (a_0=0, b_0=0), (a_1, b_1), \\ldots,\\) \\((a_n=1, b_n=1) \\}\\) for a sample of \\(n\\) observations. Here, we use \\(a_j = \\hat{F}_P(P_j)\\) and \\(b_j = \\hat{F}_{L}(P_j)\\). Then, the empirical Gini statistic is \\[\\begin{eqnarray} \\widehat{Gini} &amp;=&amp; 2\\sum_{j=0}^{n-1} (a_{j+1} - a_j) \\left \\{ \\frac{a_{j+1}+a_j}{2} - \\frac{b_{j+1}+b_j}{2} \\right\\} \\nonumber \\\\ &amp;=&amp; 1 - \\sum_{j=0}^{n-1} (a_{j+1} - a_j) (b_{j+1}+b_j) . \\tag{7.7} \\end{eqnarray}\\] Show Gini Formula Details To understand the formula for the Gini statistic, here is a sketch of a parallelogram connecting points \\((a_1, b_1)\\), \\((a_2, b_2)\\), and a 45 degree line. You can use basic geometry to check that the area of the figure is \\(Area = (a_2 - a_1) \\left \\{\\frac{a_2+a_1}{2} - \\frac{b_2+b_1}{2} \\right\\}\\). The definition of the Gini statistic in equation (7.7) is simply twice the sum of the parallelograms. The second equality in equation (7.7) is the result of some straight-forward algebra. Example – Loss Distribution: Continued. The Gini statistic for the Lorenz curve (left-hand panel of Figure 7.4) is 34.4 percent. In contrast, the Gini statistic for performance curve (right-hand panel) is 1.7 percent. 7.6.3 Out-of-Sample Validation The benefits of out-of-sample validation for model selection were introduced in Section 4.2. We now demonstrate the use of the a Gini statistic and performance curve in this context. The procedure follows: Use an in-sample data set to estimate several competing models, each producing a premium function. Designate an out-of-sample, or validation, data set of the form \\(\\{(y_i, \\mathbf{x}_i), i=1,\\ldots,n\\}\\). Use the explanatory variables from the validation sample to form premiums of the form \\(P(\\mathbf{x}_i)\\). Compute the Gini statistic for each model. Choose the model with the lowest Gini statistic. Example – Community Rating versus Premiums that Vary by State. Suppose that we have experience from 25 states and that, for each state, we have available 200 observations that can be used to predict future losses. For simplicity, assume that the analyst knows that these losses were generated by a gamma distribution with a common shape parameter equal to 5. Unknown to the analyst, the scale parameters vary by state, from a low of 20 to 66. To compute base premiums, the analyst assumes a scale parameter that is common to all states that is to be estimated from the data. You can think of this common premium as based on a community rating principle. As an alternative, the analyst allows the scale parameters to vary by state and will again use the data to estimate these parameters. An out of sample validation set of 100 losses from each state is available. For each of the two rating procedures, determine the performance curve and the corresponding Gini statistic. Choose the rate procedure with the lower Gini statistic. Show Example Solution Recall for the gamma distribution that the mean equals the shape times the scale or, 5 times the scale parameter, for our example. So, you can check that the maximum likelihood estimates are simply the average experience. For our base premium, we assume a common distribution among all states. For these simulated data, the average in-sample loss is \\(P_1\\)=221.36. As an alternative, we use averages that are state-specific; these averages form our premiums \\(P_2\\). Because this illustration uses means that vary by states, we anticipate this alternative rating procedure to be preferred to the community rating procedure. Out of sample claims were generated from the same gamma distribution as the in-sample model, with 100 observations for each state. The following R code shows how to calculate the performance curves. y &lt;- Outy P1 &lt;- Flatpred P2 &lt;- Predvec n1 = length(y) XYmat = data.frame(cbind(y,P1,P2)) XYmatPOrder = XYmat[order(P1),] # Sort by premiums P1 DFy1 = c(0,cumsum(XYmatPOrder$y)/sum(y)) DFx1 = c(0,cumsum(XYmatPOrder$P1)/sum(P1)) XYmatPOrder = XYmat[order(P2),] # Sort by premiums P2 DFy2 = c(0,cumsum(XYmatPOrder$y)/sum(y)) DFx2 = c(0,cumsum(XYmatPOrder$P2)/sum(P2)) # FIGURE 3 par(mfrow=c(1, 2)) # Lorenz Curve plot(DFx1,DFy1,xlim=c(0,1),ylim=c(0,1), type=&quot;b&quot;, cex= 0.2, xlab=&quot;Premium Distn&quot;,ylab=&quot;&quot;, main=&quot;Flat&quot;);abline(0,1) mtext(&quot;Loss Distn&quot;, side=2, line=-0.5, at=1.1, las=1, cex=1.0) # Performance Curve plot(DFx2,DFy2,xlim=c(0,1),ylim=c(0,1), type=&quot;b&quot;, cex= 0.2, xlab=&quot;Premium Distn&quot;,ylab=&quot;&quot;, main=&quot;State Specific&quot;);abline(0,1) mtext(&quot;Loss Distn&quot;, side=2, line=-0.5, at=1.1, las=1, cex=1.0) For these data, the Gini statistics are 19.6 percent for the flat rate premium and -0.702 percent for the state-specific alternative. This indicates that the state-specific alternative procedure is strongly preferred to the base community rating procedure. Discussion In insurance claims modeling, standard out-of-sample validation measures are not the most informative due to the high proportions of zeros (corresponding to no claim) and the skewed fat-tailed distribution of the positive values. In contrast, the Gini statistic works well with many zeros (see the demonstration in (Edward W. Frees, Meyers, and Cummings 2014)). The value of the performance curves and Gini statistics have been recently advanced in the paper of Denuit, Sznajder, and Trufin (2019). Properties of an extended version, dealing with relatives for new premiums, were developed by Frees, Meyers, and Cummings (2011) and Edward W. Frees, Meyers, and Cummings (2014). In these articles you can find formulas for the standard errors and additional background information. 7.7 Further Resources and Contributors This chapter serves as a bridge between the technical introduction of this book and an introduction to pricing and ratemaking for practicing actuaries. For readers interested in learn practical aspects of pricing, we recommend introductions by the Society of Actuaries in Friedland (2013) and by the Casualty Actuarial Society in Werner and Modlin (2016). For a classic risk management introduction to pricing, see Niehaus and Harrington (2003). See also Finger (2006) and Edward W Frees (2014). Bühlmann (1985) was the first in the academic literature to argue that pricing should be done first at the portfolio level (he referred to this as a top down approach) which would be subsequently reconciled with pricing of individual contracts. See also the discussion in Kaas et al. (2008), Chapter 5. For more background on pricing principles, a classic treatment is by Gerber (1979) with a more modern approach in Kaas et al. (2008). For more discussion of a pricing from a financial economics viewpoint, see Bauer, Phillips, and Zanjani (2013). Edward W. (Jed) Frees, University of Wisconsin-Madison, and José Garrido, Concordia University are the principal authors of the initial version of this chapter. Email: jfrees@bus.wisc.edu and/or jose.garrido@concordia.ca for chapter comments and suggested improvements. Chapter reviewers include: Write Jed or José to add you name here. TS 7.A. Rate Regulation Insurance regulation helps to ensure the financial stability of insurers and to protect consumers. Insurers receive premiums in return for promises to pay in the event of a contingent (insured) event. Like other financial institutions such as banks, there is a strong public interest in promoting the continuing viability of insurers. Market Conduct To help protect consumers, regulators impose administrative rules on the behavior of market participants. These rules, known as market conduct regulation, provide systems of regulatory controls that require insurers to demonstrate that they are providing fair and reliable services, including rating, in accordance with the statutes and regulations of a jurisdiction. Product regulation serves to protect consumers by ensuring that insurance policy provisions are reasonable and fair, and do not contain major gaps in coverage that might be misunderstood by consumers and leave them unprotected. The insurance product is the insurance contract (policy) and the coverage it provides. Insurance contracts are regulated for these reasons: Insurance policies are complex legal documents that are often difficult to interpret and understand. Insurers write insurance policies and sell them to the public on a “take it or leave it” basis. Market conduct includes rules for intermediaries such as agents (who sell insurance to individuals) and brokers (who sell insurance to businesses). Market conduct also includes competition policy regulation, designed to ensure an efficient and competitive marketplace that offers low prices to consumers. Rate Regulation Rate regulation helps guide the development of premiums and so is the focus of this chapter. As with other aspects of market conduct regulation, the intent of these regulations is to ensure that insurers not take unfair advantage of consumers. Rate (and policy form) regulation is common worldwide. The amount of regulatory scrutiny varies by insurance product. Rate regulation is uncommon in life insurance. Further, in non-life insurance, most commercial lines and reinsurance are free from regulation. Rate regulation is common in automobile insurance, health insurance, workers compensation, medical malpractice, and homeowners insurance. These are markets in which insurance is mandatory or in which universal coverage is thought to be socially desirable. There are three principles that guide rate regulation: rates should be adequate (to maintain insurance company solvency), but not excessive (not so high as to lead to exorbitant profits), nor unfairly discriminatory (price differences must reflect expected claim and expense differences). Recently, in auto and home insurance, the twin issues of availability and affordability, which are not explicitly included in the guiding principles, have been assuming greater importance in regulatory decisions. Rates are Not Unfairly Discriminatory Some government regulations of insurance restrict the amount, or level, of premium rates. These are based on the first two of the three guiding rate regulation principles, that rates be adequate but not excessive. This type of regulation is discussed further in the following section on types of rate regulation. Other government regulations restrict the type of information that can be used in risk classification. These are based on the third guiding principle, that rates not be unfairly discriminatory. “Discrimination” in an insurance context has a different meaning than commonly used; for our purposes, discrimination means the ability to distinguish among things or, in our case, policyholders. The real issue is what is meant by the adjective “fair.” In life insurance, it has long been held that it is reasonable and fair to charge different premium rates by age. For example, a life insurance premium differs dramatically between an 80 year old and someone aged 20. In contrast, it is unheard of to use rates that differ by: ethnicity/race, political affiliation, or religion. It is not a matter of whether data can be used to establish statistical significance among the levels of any of these variables. Rather, it is a societal decision as to what constitutes notions of “fairness.” Different jurisdictions have taken different stances on what constitutes a fair rating variable. For example, in some juridictions for some insurance products, gender is no longer a permissible variable. As an illustration, the European Union now prohibits the use of gender for automobile rating. As another example, in the U.S., many discussions have revolved around the use of credit ratings to be used in automobile insurance pricing. Credit ratings are designed to measure consumer financial reponsibility. Yet, some argue that credit rates are good proxies for ethnicity and hence should be prohibited. In an age where more data is being used in imaginative ways, discussions of what constitutes a fair rating variable will only become more important going forward and much of that discussion is beyond the scope of this text. However, it is relevant to the discussion to remark that actuaries and other data analysts can contribute to societal discussions on what constitutes a “fair” rating variable in unique ways by establishing the magnitude of price differences when using variables under discussion. Types of Rate Regulation There are several methods, that vary by the level of scrutiny, by which regulators may restrict the rates that insurers offer. The most restrictive is a government prescribed regulatory system, where the government regulator determines and promulgates the rates, classifications, forms, and so forth, to which all insurers must adhere. Also restrictive are prior approval systems. Here, the insurer must file rates, rules, and so forth, with government regulators. Depending on the statute, the filing becomes effective when a specified waiting period elapses (if the government regulator does not take specific action on the filing, it is deemed approved automatically) or when the government regulator formally approves the filing. The least restrictive is a no file or record maintenance system where the insurer need not file rates, rules, and so forth, with the government regulator. The regulator may periodically examine the insurer to ensure compliance with the law. Another relatively flexible system is the file only system, also known as competitive rating, where the insurer simply keeps files to ensure compliance with the law. In between these two extremes are the (1) file and use, (2) use and file, (3) modified prior approval, and (4) flex rating systems. File and Use: The insurer must file rates, rules, and so forth, with the government regulator. The filing becomes effective immediately or on a future date specified by the filer. Use and File: The filing becomes effective when used. The insurer must file rates, rules, and so forth, with the government regulator within a specified time period after first use. Modified Prior Approval: This is a hybrid of “prior approval” and “file and use” laws. If the rate revision is based solely on a change in loss experience then “file and use” may apply. However, if the rate revision is based on a change in expense relationships or rate classifications, then “prior approval” may apply. Flex (or Band) Rating: The insurer may increase or decrease a rate within a “flex band,” or range, without approval of the government regulator. Generally, either “file and use” or “use and file” provisions apply. For a broad introduction to government insurance regulation from a global perspective, see the website of the International Association of Insurance Supervisors (IAIS). ﻿ Bibliography "],
["C-RiskClass.html", "Chapter 8 Clasificación de riesgos 8.1 Introducción 8.2 Modelo de Regresión de Poisson 8.3 Variables Categóricas y Tarifa Multiplicativa 8.4 Más recursos y colaboradores", " Chapter 8 Clasificación de riesgos Resumen del capítulo. Este capítulo motiva el uso de la clasificación de riesgos en la fijación de precios de seguros y presenta a los lectores la regresión de Poisson como un ejemplo destacado de clasificación de riesgos. En la Sección ?? explicamos por qué las aseguradoras necesitan incorporar diversas características de riesgo, o factores de tarificación, de los asegurados individuales en los precios de los contratos de seguro. Luego presentamos la Sección 8.2 donde mostramos la regresión de Poisson como una herramienta de fijación de precios para lograr diferencias en las primas. El concepto de exposición también se introduce en esta sección. Como la mayoría de los factores de tarificación son categóricos, en la Sección 8.3 mostramos cómo se puede incorporar el modelo de tarifa multiplicativa en el modelo de regresión de Poisson en la práctica, junto con ejemplos numéricos para ilustrarlo. 8.1 Introducción En esta sección, se aprende: Por qué las primas deben variar entre los asegurados según sus diferentes clases de riesgo. El significado de la espiral de selección adversa. La necesidad de clasificar los riesgos. A través de los contratos de seguro, los asegurados transfieren de manera efectiva sus riesgos a la aseguradora a cambio de primas. Para que la aseguradora permanezca en el negocio, el ingreso de la prima recaudada de un grupo de asegurados debe ser al menos igual al beneficio que se obtiene. En los productos de seguros generales donde se cobra una prima por un solo período, por ejemplo, anual, la prima bruta del seguro basada en el principio de equivalencia se define como \\[ \\text{Prima Pura = Pérdidas esperadas + Gastos esperados + Beneficio}. \\] Por lo tanto, ignorando los gastos denominados “de fricción” asociados con los gastos administrativos y el beneficio, la prima neta o pura cobrada por el asegurador debe ser igual a las pérdidas esperadas que se producen por el riesgo que se transfiere por parte del tomador del seguro. Si todos los asegurados en una cartera tienen perfiles de riesgo idénticos, la aseguradora simplemente cobra la misma prima para todos los asegurados porque tienen la misma pérdida esperada. En realidad, sin embargo, los asegurados no son necesariamente homogéneos. Por ejemplo, el riesgo de mortalidad en el seguro de vida depende de las características del asegurado, como la edad, el sexo y el estilo de vida. En el seguro de automóviles, esas características pueden incluir la edad, la ocupación, el tipo o el uso del automóvil y el área donde reside el conductor. El conocimiento de estas características o variables puede mejorar la capacidad de calcular primas justas para los asegurados individuales, ya que pueden usarse para estimar o predecir las pérdidas esperadas con mayor precisión. Selección adversa. De hecho, si el asegurador no diferencia las características de riesgo de los asegurados individuales y simplemente cobra la misma prima a todos los asegurados en función de la pérdida promedio en la cartera, el asegurador se enfrenta a la llamada selección adversa , una situación en la que las personas con una mayor probabilidad de pérdidas son atraídas hacia la cartera y las personas de bajo riesgo son repelidas. Por ejemplo, consideremos una entidad de seguros de salud donde el tabaquismo es un factor de riesgo importante para la mortalidad y la morbilidad. La mayoría de las aseguradoras de salud en el mercado establecen primas diferentes según la condición de fumador, por lo que los fumadores pagan primas más altas que los no fumadores, con otras características idénticas. Ahora supongamos que hay una aseguradora, llamémosla EquitabAll, que ofrece la misma prima a todos los asegurados, independientemente de su condición de fumador, a diferencia de otros competidores. La prima neta de EquitabAll se calcula, naturalmente, a partir de una pérdida con la mortalidad promedio que representa tanto a los fumadores como a los no fumadores. Es decir, la prima neta es un promedio ponderado de las pérdidas, siendo las ponderaciones la proporción de fumadores y no fumadores, respectivamente. Por lo tanto, es fácil ver que un fumador tiene un mayor incentivo para contratar un seguro de EquitabAll que de otras aseguradoras, ya que la prima ofrecida por EquitabAll es relativamente menor. Al mismo tiempo, los no fumadores prefieren contratar un seguro en otra compañía donde se ofrezcan primas más bajas, calculadas sólo para el grupo de no fumadores. Como resultado, habrá más fumadores y menos no fumadores en la cartera de EquitabAll, lo que conduce a pérdidas mayores de lo esperado y, por lo tanto, a una prima más alta para los asegurados en el próximo período para cubrir los costos más altos. Con el aumento de la nueva prima en el próximo período, los no fumadores en EquitabAll tendrán incentivos aún mayores para cambiar de aseguradora. A medida que este ciclo continúa con el tiempo, EquitabAll retendría gradualmente a más fumadores y menos no fumadores en su cartera con la prima elevándose continuamente, lo que eventualmente llevaría al colapso del negocio. En la literatura, este fenómeno se conoce como espiral de selección adversa o espiral de muerte. Por lo tanto, incorporar y diferenciar características de riesgo importantes de las personas en el proceso de fijación de precios del seguro es una componente relevante tanto para la determinación de la prima justa para los asegurados individuales como para la sostenibilidad a largo plazo de las aseguradoras. Factores de tarificación. Para incorporar las características de riesgo relevantes de los asegurados en el proceso de fijación de precios, las aseguradoras mantienen un sistema de clasificación que asigna cada asegurado a una de las clases de riesgo en función de un número relativamente pequeño de características de riesgo que se consideran las más relevantes. Estas características utilizadas en el sistema de clasificación se denominan factores de tarificación, que son variables a priori en el sentido de que se conocen antes de que comience el contrato (por ejemplo, sexo, estado de salud, tipo de vehículo, etc., se conocen durante la suscripción). Todos los asegurados que comparten factores de riesgo idénticos se asignan a la misma clase de riesgo y se consideran homogéneos desde el punto de vista de los precios; la aseguradora en consecuencia les cobra la misma prima o precio. Con respecto a los factores de riesgo y las primas, el Estándar de Práctica Actuarial (ASOP No. 12) de Actuarial Standards Board (2018) establece que el actuario debe seleccionar las características de riesgo que están relacionadas con los resultados esperados, y que las primas dentro de un sistema de clasificación de riesgos se consideran equitativas si sus diferencias reflejan diferencias materiales en el coste esperado de las características de riesgo. En el proceso de elección de los factores de riesgo, ASOP también requiere que el actuario considere lo siguiente: relación de las características de riesgo y los resultados esperados, causalidad, objetividad, practicidad, ley aplicable, prácticas de la industria y prácticas comerciales. En el lado cuantitativo, una tarea importante para el actuario en la construcción de cualquier clasificación de riesgos es construir un modelo estadístico que pueda determinar la pérdida esperada dados los diversos factores de clasificación de un asegurado. El enfoque estándar es adoptar un modelo de regresión que produzca la pérdida esperada como resultado cuando los factores de riesgo relevantes se den como inputs. En este capítulo aprendemos la regresión de Poisson, que se puede usar cuando la pérdida es una variable de conteo, como un ejemplo destacado de una herramienta de fijación de precios de seguros. 8.2 Modelo de Regresión de Poisson El modelo de regresión de Poisson se ha utilizado con éxito en una amplia gama de aplicaciones y tiene la ventaja de permitir expresiones de forma cerrada para cantidades importantes, lo que proporciona una intuición e interpretación informativa. En esta sección presentamos la regresión de Poisson como una extensión natural de la distribución de Poisson. En esta sección, se aprende a: Entender las regresiones de Poisson como una herramienta útil para combinar distribuciones individuales de Poisson de manera unificada. Conocer el concepto de exposición y su importancia. Aprender formalmente cómo formular el modelo de regresión de Poisson utilizando variables indicadoras cuando las variables explicativas son categóricas. 8.2.1 Necesidad de la Regresión de Poisson Distribución de Poisson Para presentar la regresión de Poisson, consideremos una cartera hipotética de seguros de salud donde todos los asegurados son de la misma edad y solo un factor de riesgo, el tabaquismo, es relevante. Por lo tanto, el estado de ser fumador es una variable categórica que contiene dos tipos diferentes: fumador y no fumador. En la literatura estadística, los diferentes tipos en una variable categórica dada se denominan comúnmente niveles. Como hay dos niveles para el estado de fumar, podemos denotar fumadores y no fumadores por nivel 1 y 2, respectivamente. Aquí la numeración es arbitraria y nominal. Supongamos ahora que estamos interesados en fijar el precio de un seguro de salud en el que la prima de cada asegurado se determina por la cantidad de visitas ambulatorias al consultorio del médico durante un año. Se supone que el coste médico para cada visita es el mismo, independientemente del estado de si es fumador o no por simplicidad. Por lo tanto, si creemos que el tabaquismo es un factor de riesgo válido en este seguro de salud, es natural considerar los datos por separado para cada grupo de tabaquismo. En la [Tabla 8.1] presentamos los datos para esta cartera. \\[ {\\small \\begin{matrix} \\begin{array}{cc|cc|cc} \\hline \\text{Fumador} &amp; \\text{(Nivel 1)} &amp; \\text{No fumador}&amp;\\text{(Nivel 2)} &amp; &amp; \\text{Ambos}\\\\ \\text{Valor} &amp; \\text{Observaciones} &amp; \\text{Valor} &amp; \\text{Observaciones} &amp; \\text{Valor} &amp; \\text{Observaciones} \\\\ \\hline 0 &amp; 2213 &amp; 0 &amp; 6671 &amp; 0 &amp; 8884 \\\\ 1 &amp; 178 &amp; 1 &amp; 430 &amp; 1 &amp; 608 \\\\ 2 &amp; 11 &amp; 2 &amp; 25 &amp; 2 &amp; 36 \\\\ 3 &amp; 6 &amp; 3 &amp; 9 &amp; 3 &amp; 15 \\\\ 4 &amp; 0 &amp; 4 &amp; 4 &amp; 4 &amp; 4 \\\\ 5 &amp; 1 &amp; 5 &amp; 2 &amp; 5 &amp; 3 \\\\ \\hline \\text{Total} &amp; 2409 &amp; \\text{Total} &amp; 7141 &amp; \\text{Total} &amp; 9550 \\\\ \\text{Media} &amp; 0,0926 &amp; \\text{Media} &amp; 0,0746 &amp; \\text{Media} &amp; 0,0792 \\\\ \\hline \\end{array} \\end{matrix} } \\] Table 8.1 : Número de visitas a la consulta médica el año pasado Como este conjunto de datos contiene recuentos aleatorios, intentamos ajustar una distribución de Poisson para cada nivel. Como se introdujo en la Sección 2.2.3.2, la función de densidad de probabilidad de Poisson con media \\(\\mu\\) viene dada por: \\[\\begin{equation} \\Pr(Y=y)=\\frac{\\mu^y e^{-\\mu}}{y!},\\qquad y=0,1,2, \\ldots \\tag{8.1} \\end{equation}\\] y \\(\\mathrm{E~}{(Y)}=\\mathrm{Var~}{(Y)}=\\mu\\). En contextos de regresión, es habitual usar \\(\\mu\\) para parámetros que denotan la media en lugar del parámetro de Poisson \\(\\lambda\\), aunque ciertamente ambos símbolos son adecuados. Como vimos en la sección 2.4, la mle de la distribución de Poisson viene dada por la media muestral. Por lo tanto, si denotamos el parámetro media de Poisson para cada nivel por \\(\\mu_{(1)}\\) (fumador) y \\(\\mu_{(2)}\\) (no fumador), vemos en la [Tabla 8.1] que \\(\\hat{\\mu}_{(1)}= 0,0926\\) y \\(\\hat{\\mu}_{(2)} = 0,0746\\). Este simple ejemplo muestra la idea básica de clasificación de riesgo. Dependiendo de la condición de fumador, un asegurado tendrá una característica de riesgo diferente y ésta puede incorporarse a través del parámetro variable de Poisson en el cálculo de la prima justa. En este ejemplo, la proporción de frecuencias de pérdida esperadas es \\(\\frac{\\hat{\\mu} _{(1)}}{\\hat{\\mu}_{(2)}}= 1,2402\\), lo que implica que los fumadores tienden a visitar la consulta médica 24,02\\(\\%\\) veces más frecuentemente en comparación con los no fumadores. También es informativo tener en cuenta que si la aseguradora cobra la misma prima a todos los asegurados, independientemente del estado de ser fumador, en función de la característica promedio de la cartera, como fue el caso de la compañía EquitabAll descrito en la Introducción, la frecuencia esperada (o la prima) \\(\\hat{\\mu}\\) es 0,0792, obtenida de la última columna de [Tabla 8.1]. Se verifica fácilmente que: \\[\\begin{equation} \\hat{\\mu} = \\left(\\frac{n_1}{n_1+n_2}\\right)\\hat{\\mu}_{(1)}+\\left(\\frac{n_2}{n_1+n_2}\\right)\\hat{\\mu}_{(2)}=0,0792, \\tag{8.2} \\end{equation}\\] donde \\(n_i\\) es el número de observaciones en cada nivel. Claramente, esta prima es un promedio ponderado de las primas para cada nivel con un peso igual a la proporción de asegurados en ese nivel. Una regresión de Poisson simple En el ejemplo anterior, hemos ajustado una distribución de Poisson para cada nivel por separado, pero en realidad podemos combinarlos de manera unificada para que un solo modelo de Poisson pueda abarcar los estados de fumadores y no fumadores. Esto se puede hacer relacionando el parámetro medio de Poisson con el factor de riesgo. En otras palabras, hacemos que la media de Poisson, que es la frecuencia de pérdida esperada, responda al cambio en el estado de ser o no fumador. El enfoque convencional para tratar con una variable categórica es adoptar indicadores o variables ficticias que toman valores 1 o 0, de modo que activemos el interruptor para un nivel y lo apaguemos para otros. Por lo tanto, podemos proponernos usar: \\[\\begin{equation} \\mu=\\beta_0+\\beta_1 x_1 \\tag{8.3} \\end{equation}\\] o bien, como se hace habitualmente, en forma log lineal: \\[\\begin{equation} \\log \\mu=\\beta_0+\\beta_1 x_1, \\tag{8.4} \\end{equation}\\] donde \\(x_1\\) es una variable indicadora con \\[\\begin{equation} x_1= \\begin{cases} 1 &amp; \\text{si fuma}, \\\\ 0 &amp; \\text{en caso contrario}. \\end{cases} \\tag{8.5} \\end{equation}\\] En general, preferimos la relación log lineal (8.4) frente a la lineal de (8.3) para prevenir los efectos no deseados de producir valores negativos para \\(\\mu\\), que podrían darse cuando hay una gran variedad de factores de riesgo diferentes y niveles distintos. La especificación de (8.4) y (8.5) entonces proporciona parámetros de frecuencia de Poisson diferentes dependiendo del nivel del correspondiente factor de riesgo: \\[\\begin{equation} \\log \\mu= \\begin{cases} \\beta_0+\\beta_1 \\\\ \\beta_0 \\end{cases} \\quad \\text{o equivalentemente,}\\qquad \\mu= \\begin{cases} e^{\\beta_0+\\beta_1} &amp; \\text{si fuma (nivel 1)}, \\\\ e^{\\beta_0} &amp; \\text{si no fuma (nivel 2)}, \\end{cases} \\tag{8.6} \\end{equation}\\] consiguiendo el resultado que perseguimos. Ésta es la forma más simple de la regresión de Poisson. Tengamos en cuenta que requerimos una sola variable indicadora para modelar dos niveles en este caso. Alternativamente, también es posible usar dos variables indicadoras a través de un esquema de codificación diferente. Este esquema requiere eliminar el término constante para que (8.4) quede como \\[\\begin{equation} \\log \\mu=\\beta_1 x_1+\\beta_2 x_2, \\tag{8.7} \\end{equation}\\] donde \\(x_2\\) es la segunda variable indicadora tal que \\[\\begin{equation} x_2= \\begin{cases} 1 &amp; \\text{si no fuma}, \\\\ 0 &amp; \\text{en caso contrario}. \\end{cases} \\tag{8.8} \\end{equation}\\] Entonces obtenemos, a partir de (8.7), \\[\\begin{equation} \\log \\mu= \\begin{cases} \\beta_1 \\\\ \\beta_2 \\end{cases} \\quad \\text{or}\\qquad \\mu= \\begin{cases} e^{\\beta_1} &amp; \\text{si fuma (level 1)}, \\\\ e^{\\beta_2} &amp; \\text{si no fuma (level 2)}. \\end{cases} \\tag{8.9} \\end{equation}\\] El resultado numérico de (8.6) es el mismo que (8.9) ya que todos los coeficientes se dan como números en la estimación real, siendo la configuración inicial más común en la mayoría textos; usaremos la inicial aquí también. Con este modelo de regresión de Poisson, podemos comprender fácilmente cómo los coeficientes \\(\\beta_0\\) y \\(\\beta_1\\) están vinculados a la frecuencia de pérdida esperada en cada nivel. Según (8.6), la media de Poisson de los fumadores, \\(\\mu_{(1)}\\), viene dada por \\[\\begin{equation} \\mu_{(1)}=e^{\\beta_0+\\beta_1}=\\mu_{(2)} \\,e^{\\beta_1} \\quad \\text{or}\\quad \\mu_{(1)}/\\mu_{(2)} =e^{\\beta_1} \\tag{8.10} \\end{equation}\\] donde \\(\\mu_{(2)}\\) es la media de la distribución de Poisson para los no fumadores. Esta relación entre los fumadores y los no fumadores sugiere una forma útil de comparar los riesgos incluidos en diferentes niveles de un factor de riesgo dado. Es decir, el aumento proporcional en la frecuencia de pérdida esperada de los fumadores en comparación con la de los no fumadores se da simplemente por un factor multiplicativo \\(e^{\\beta_1}\\). Dicho de otra manera, si establecemos la frecuencia de pérdida esperada de los no fumadores como el valor base, la frecuencia de pérdida esperada de los fumadores se obtiene aplicando el factor \\(e^{\\beta_1}\\) al valor base. Manejo de casos de niveles múltiples Podemos extender fácilmente el caso de dos niveles a uno de varios niveles en el que intervienen \\(l\\) diferentes niveles para un solo factor de tarificación. Para esto, generalmente necesitamos \\(l-1\\) variables indicadoras para formular \\[\\begin{equation} \\log \\mu=\\beta_0+\\beta_1 x_1+\\cdots+\\beta_{l-1} x_{l-1}, \\tag{8.11} \\end{equation}\\] donde \\(x_k\\) es una variable indicadora que toma el valor 1 si la póliza pertenece al nivel \\(k\\) y 0 en caso contrario, para \\(k=1,2, \\ldots, l-1\\). Al omitir la variable indicadora asociada con el último nivel en (8.11) , elegimos efectivamente el nivel \\(l\\) como el caso base, pero esta elección es arbitraria y no importa numéricamente. El parámetro de Poisson resultante para las pólizas el nivel \\(k\\) se convierte, a partir de (8.11), \\[\\begin{equation} \\nonumber \\mu= \\begin{cases} e^{\\beta_0+\\beta_k} &amp; \\text{si la póliza pertenece al nivel $k$ (k=1,2, ..., l-1)}, \\\\ e^{\\beta_0} &amp; \\text{si la póliza pertenece al nivel $l$}. \\end{cases} \\end{equation}\\] Por lo tanto, si denotamos el parámetro de Poisson para pólizas en el nivel \\(k\\) como \\(\\mu_{(k)}\\), podemos relacionar el parámetro de Poisson para diferentes niveles a través de \\(\\mu_{(k)} = \\mu_{(l)}\\, e^{\\beta_k}\\), \\(k= 1,2,\\ldots, l-1\\). Esto indica que, al igual que en el caso de dos niveles, la frecuencia de pérdida esperada del nivel \\(k\\)-ésimo se obtiene a partir del valor base multiplicado por el factor relativo \\(e^{\\beta_k}\\). Esta interpretación relativa se vuelve extremadamente útil cuando hay muchos factores de riesgo con niveles múltiples, y nos lleva a una mejor comprensión del riesgo subyacente y una predicción más precisa de las pérdidas futuras. Finalmente, observamos que la media de una distribución de Poisson está completamente determinada por los parámetros \\(\\beta_k\\)’s, que se estiman a partir del conjunto de datos; El procedimiento de estimación de parámetros se discute más adelante en este capítulo. 8.2.2 Regresión de Poisson Ahora describimos la regresión de Poisson en un entorno formal y más general. Supongamos que hay \\(n\\) asegurados independientes con un conjunto de factores de tarificación caracterizados por un vector variable de dimensión \\(k\\)9. El factor de tarificación del asegurado \\(i\\)-ésimo se denota así por el vector \\(\\mathbf{ x}_i=(1, x_{i1}, \\ldots, x_{ik})^{\\prime}\\), y el asegurado se dice que ha registrado un valor de pérdidas igual a \\(y_i \\in \\{0,1,2, \\ldots \\}\\) desde el último período de observación de pérdidas, para \\(i=1, \\ldots, n\\). En la literatura de regresión, los valores \\(x_{i1}, \\ldots, x_{ik}\\) se conocen generalmente como variables explicativas, ya que estas son medidas que proporcionan información sobre la variable de interés \\(y_i\\). En esencia, el análisis de regresión es un método para cuantificar la relación entre una variable de interés y variables explicativas. También asumimos, por ahora, que todos los asegurados tienen un mismo período de observación de pérdidas igual a una unidad, o la misma exposición de 1, para mantener las cosas simples; discutiremos más detalles sobre la exposición en la siguiente subsección. Como se hizo anteriormente, describimos la regresión de Poisson a través de su función de la media. Para esto, primero denotamos que \\(\\mu_i\\) es el número entero que representa las pérdida esperada del titular de la póliza \\(i\\)-ésima mediante la especificación de Poisson (8.1): \\[\\begin{equation} \\mu_i=\\mathrm{E~}{(y_i|\\mathbf{ x}_i)}, \\qquad y_i \\sim Pois(\\mu_i), \\, i=1, \\ldots, n. \\tag{8.12} \\end{equation}\\] La condición dentro de la operación de la esperanza en (8.12)) indica que la frecuencia de pérdida \\(\\mu_i\\) es el output del modelo que responde al conjunto dado de factores de riesgo o variables explicativas. En principio, la media condicional \\(\\mathrm{E~}{(y_i|\\mathbf{ x}_i)}\\) en (8.12) puede tomar diferentes formas dependiendo de cómo especifiquemos la relación entre \\(\\mathbf{x}\\) y \\(y\\). La opción estándar para la regresión de Poisson es adoptar la función exponencial, como mencionamos anteriormente, de forma que \\[\\begin{equation} \\mu_i=\\mathrm{E~}{(y_i|\\mathbf{ x}_i)}=e^{\\mathbf{ x}^{\\prime}_i\\beta}, \\qquad y_i \\sim Pois(\\mu_i), \\, i=1, \\ldots, n. \\tag{8.13} \\end{equation}\\] Aquí \\(\\beta=(\\beta_0, \\ldots, \\beta_k)^{\\prime}\\) es el vector de coeficientes de manera que \\(\\mathbf{ x}^{\\prime}_i\\beta=\\beta_0+\\beta_1x_{i1} +\\ldots+\\beta_k x_{ik}\\). La función exponencial en (8.13) asegura que \\(\\mu_i &gt;0\\) para cualquier conjunto de factores de tarificación \\(\\mathbf{ x}_i\\). A menudo (8.13) se reescribe en forma log lineal \\[\\begin{equation} \\log \\mu_i=\\log \\mathrm{E~}{(y_i|\\mathbf{ x}_i)}=\\mathbf{ x}^{\\prime}_i\\beta, \\qquad y_i \\sim Pois(\\mu_i), \\, i=1, \\ldots, n \\tag{8.14} \\end{equation}\\] para poner explícitamente que la relación entre la parte de la derecha está expresada en forma lineal, \\(\\mathbf{ x}^{\\prime}_i\\beta\\). De nuevo, vemos que la correspondencia funciona bien dado que ambos lados de (8.14), \\(\\log \\mu_i\\) y \\(\\mathbf{ x}_i\\beta\\), pueden cubrir todos los valores reales. Esta es la formulación de la regresión de Poisson, suponiendo que todos los asegurados tienen el mismo período unitario de exposición. Sin embargo, cuando las exposiciones difieren entre los asegurados, como es el caso en la mayoría de los casos prácticos, necesitamos revisar esta formulación agregando el componente de exposición como un término adicional en (8.14). 8.2.3 Incorporación de la exposición Concepto de Exposición Para determinar el tamaño de las pérdidas potenciales en cualquier tipo de seguro, siempre se debe conocer la exposición correspondiente. El concepto de exposición es un ingrediente extremadamente importante en la fijación de precios de seguros, aunque generalmente lo damos por sentado. Por ejemplo, cuando decimos que la frecuencia de reclamaciones esperada de una póliza de seguro de salud es 0,2, no significa nada sin la especificación de la exposición, como, en este caso, por mes o por año. De hecho, todas las primas y pérdidas necesitan especificar la exposición con precisión y deben explicitarse en consecuencia; de lo contrario, todos los análisis estadísticos y predicciones posteriores se distorsionarán. En la sección anterior asumimos la misma unidad de exposición para todos los asegurados, pero esto no es realista en la práctica. En el seguro de salud, por ejemplo, dos asegurados diferentes con diferentes períodos de cobertura de seguro (por ejemplo, 3 meses y 12 meses, respectivamente) podrían haber registrado el mismo número de reclamaciones. Como el número esperado de reclamaciones sería proporcional a la duración de la cobertura, no debemos tratar las experiencias de pérdida de estos dos asegurados de manera idéntica en el proceso de modelización. Esto motiva la necesidad de usar el concepto de exposición en la regresión de Poisson. La distribución de Poisson en (8.1) se parametriza a través de su media. Para comprender la exposición, parametrizamos alternativamente el parametro de la pmf de Poisson en términos del parámetro tasa \\(\\lambda\\), según la definición del proceso de Poisson: \\[\\begin{equation} \\Pr(Y=y)=\\frac{(\\lambda t)^y e^{-\\lambda t}}{y!},\\qquad y=0,1,2, \\ldots \\tag{8.15} \\end{equation}\\] con \\(\\mathrm{E~}{(Y)}=\\mathrm{Var~}{(Y)}=\\lambda t\\). Aquí \\(\\lambda\\) se conoce como la tasa o intensidad por unidad de período del proceso de Poisson y \\(t\\) representa el período de tiempo o exposición, que ha de ser un valor constante conocido. Para \\(\\lambda\\) dados, la distribución de Poisson (8.15) produce un mayor valor en el conteo de pérdidas esperadas a medida que la exposición \\(t\\) aumenta. Claramente, (8.15) se reduce a (8.1) cuando \\(t=1\\), lo que significa que la media y la tasa se vuelven iguales para la unidad de exposición, el caso que consideramos en la subsección anterior. En principio, la exposición no necesita ser medida en unidades de tiempo y puede representar diferentes cosas dependiendo del problema en cuestión. Por ejemplo: En el seguro de salud, la tasa puede ser la aparición de una enfermedad específica por cada 1.000 personas y la exposición es el número de personas consideradas en la unidad de 1.000. En el seguro de automóviles, la tasa puede ser el número de accidentes por año de un conductor y la exposición es la duración del período observado para el conductor en la unidad de un año. En la compensación a trabajadores que cubre la pérdida salarial como resultado de una lesión o enfermedad relacionada con el trabajo de un empleado, la tasa puede ser la probabilidad de lesión durante el tiempo del empleo por dólar y la exposición es la cuantía de la nómina en dólares. En marketing, la tasa puede ser la cantidad de clientes que ingresan a una tienda por hora y la exposición es la cantidad de horas observadas. En ingeniería civil, la tasa puede ser el número de grietas importantes en el camino pavimentado 10 kms y la exposición es la longitud del camino considerado en la unidad de 10 kms. En la modelización del riesgo de crédito, la tasa puede ser el número de eventos de incumplimiento por cada 1000 empresas y la exposición es el número de empresas consideradas en unidades de 1.000. Los actuarios pueden usar diferentes bases de exposición para una pérdida asegurable determinada. Por ejemplo, en el seguro de automóviles, tanto el número de kilómetros recorridos como el número de meses cubiertos por el seguro pueden usarse como bases de exposición. Aquí, el primero es más preciso y útil para modelizar las pérdidas por accidentes automovilísticos, pero es más difícil de medir y administrar para las aseguradoras. Por lo tanto, una buena base de exposición puede no ser la mejor en teoría debido a varias limitaciones prácticas. Por regla general, una base de exposición debe ser fácil de determinar, medible con precisión, legal y socialmente aceptable y libre de posibles manipulaciones por parte de los asegurados. Incorporación de la exposición en la regresión de Poisson Como las exposiciones afectan la media de Poisson, la construcción de regresiones de Poisson requiere que separemos cuidadosamente la tasa y la exposición en el proceso de modelización. Centrándonos en el contexto del seguro, denotemos la tasa del evento de pérdida del asegurado \\(i\\)-ésimo como \\(\\lambda_i\\), la exposición conocida (la duración de la cobertura) como \\(m_i\\) y el valor del conteo de pérdidas esperado bajo la exposición dada por \\(\\mu_i\\). Luego, la formulación de regresión de Poisson en (8.13) y (8.14) debe revisarse según (8.15) como \\[\\begin{equation} \\mu_i=\\mathrm{E~}{(y_i|\\mathbf{ x}_i)}=m_i \\,\\lambda_i=m_i \\, e^{\\mathbf{ x}^{\\prime}_i\\beta}, \\qquad y_i \\sim Pois(\\mu_i), \\, i=1, \\ldots, n, \\tag{8.16} \\end{equation}\\] lo que produce \\[\\begin{equation} \\log \\mu_i=\\log m_i+\\mathbf{ x}^{\\prime}_i\\beta, \\qquad y_i \\sim Pois(\\mu_i), \\, i=1, \\ldots, \\tag{8.17} \\end{equation}\\] Añadiendo \\(\\log m_i\\) en (8.17) no supone ningún problema en el ajuste dado que siempre podemos especificar esto como una variable explicativa adicional, puesto que es una constante conocida, y fijar su coeficiente a 1. En la literatura, el logaritmo de la exposición, \\(\\log m_i\\), se suele denominar el offset. 8.2.4 Ejercicios Respecto a la Table 8.1 contestad lo siguiente. Verificad la media de los valores de la tabla. Verificad el número en la ecuación (8.2). Producid los valores de conteo ajustados en la distribución de Poisson para cada nivel de la situación de fumador en la tabla. En la formulación de la regresión de Poisson (8.12), considera el uso de \\(\\mu_i=\\mathrm{E~}{(y_i|\\mathbf{ x}_i)}=({\\mathbf{ x}^{\\prime}_i\\beta})^2\\), para \\(i=1, \\ldots, n\\), en lugar de la función exponencial. ¿Qué problema potencial puede aperecer? 8.3 Variables Categóricas y Tarifa Multiplicativa En esta sección, se aprende: El modelo de tarifa multiplicativa cuando los factores de tarificación son categóricos. Cómo construir el modelo de regresión de Poisson basado en la estructura tarifaria multiplicativa. 8.3.1 Factores de Tarificación y Tarifa En la práctica, la mayoría de los factores de tarificación en seguros son variables categóricas, lo que significa que toman uno de la cantidad predeterminada de valores posibles. Los ejemplos de variables categóricas incluyen el sexo, el tipo de automóviles, la región de residencia y la ocupación del conductor. Las variables continuas, como la edad o el kilometraje del vehículo, también pueden agruparse por intervalos y tratarse como variables categóricas. Por lo tanto, podemos imaginar que, con un pequeño número de factores de tarificación, habrá muchos asegurados que caigan en la misma clase de riesgo, y pagarán la misma prima. Para el resto de este capítulo asumimos que todos los factores de tarificación son variables categóricas. Para ilustrar cómo se utilizan las variables categóricas en el proceso de fijación de precios, consideramos un seguro hipotético para automóviles con solo dos factores: Tipo de vehículo: Tipo A (propiedad personal) y B (propiedad de la empresa). Usamos el índice \\(j = 1\\) y \\(2\\) para representar respectivamente cada nivel de este factor de tarificación. Grupo de edad del conductor: joven (edad \\(&lt;\\) 25), adulto (25 \\(\\le\\) edad \\(&lt;\\) 60) y mayor (edad \\(\\ge\\) 60). Utilizamos el índice \\(k = 1, 2\\) y \\(3\\), respectivamente, para este factor. A partir de esta regla de clasificación, podemos crear una tabla o lista organizada, como la que se muestra en la [Tabla 8.2], que recopila a todos los asegurados. Claramente hay \\(2\\times 3 = 6\\) diferentes clases de riesgo en total. Cada fila de la tabla muestra una combinación de diferentes características de riesgo de los asegurados individuales. Nuestro objetivo es calcular seis primas diferentes para cada una de estas combinaciones. Una vez que se ha determinado la prima para cada fila utilizando la exposición y el número de reclamaciones dadas, la aseguradora puede reemplazar las dos últimas columnas en la [Tabla 8.2] con una sola columna que contiene las primas calculadas. Esta nueva tabla puede servir como un manual para determinar la prima para un nuevo asegurado dados los factores de tarificación durante el proceso de suscripción. En los seguros no de vida, una tabla (o un conjunto de tablas) o una lista que contiene cada conjunto de factores de tarificación y la prima asociada se conoce como una tarifa. Cada combinación única de los factores de calificación en una tarifa se llama celda de tarifa; así, en la [Tabla 8.2] el número de celdas de tarifa es seis, igual que el número de clases de riesgo. \\[ {\\small \\begin{matrix} \\begin{array}{ccrrc} \\hline \\text{Factores} &amp;\\text{Tarificación} &amp; \\text{Exposición} &amp; \\text{Número de reclamaciones} \\\\ \\text{Tipo }(j) &amp; \\text{Edad }(k) &amp; \\text{anual} &amp; \\text{observadas}\\\\ \\hline \\hline j=1 &amp; k=1 &amp; 89,1 &amp; 9\\\\ 1 &amp; 2 &amp; 208,5&amp; 8\\\\ 1 &amp; 3 &amp; 155,2 &amp; 6 \\\\ 2 &amp; 1 &amp; 19,3 &amp; 1 \\\\ 2 &amp; 2 &amp; 360,4 &amp; 13 \\\\ 2 &amp; 3 &amp; 276,7 &amp; 6 \\\\ \\hline \\end{array} \\end{matrix} } \\] Table 8.2 : Ilustración de registro de pérdidas en el seguro de automóviles Veamos ahora la información sobre pérdidas en la [Tabla 8.2] más de cerca. La exposición en cada fila representa la suma de la duración de las coberturas de seguro, o los tiempos vigentes, en la unidad de año, de todos los asegurados en esa celda de tarifa. Del mismo modo, el recuento de reclamaciones en cada fila es el número de reclamaciones en cada celda. Naturalmente, las exposiciones y los recuentos de reclamaciones varían debido a la diferente cantidad de conductores en las celdas, así como a diferentes períodos de tiempo de vigencia entre los conductores dentro de cada celda. En el marco de la regresión de Poisson, denotamos la exposición y el recuento de reclamaciones de la celda \\((j, k)\\) como \\(m_ {jk}\\) y \\(y_ {jk}\\), respectivamente, y definimos el recuento de reclamaciones por unidad de exposición como \\[\\begin{equation} \\nonumber z_{jk}= \\frac{y_{jk}}{ m_{jk}}, \\qquad j=1,2;\\, k=1, 2,3. \\end{equation}\\] Por ejemplo, \\(z_{12}=8/208,5=0,03837\\), lo que significa que un asegurado en la celda de tarifa (1,2) tendría 0,03837 accidentes si estuviera asegurado durante un año completo en promedio. El conjunto de valores de \\(z_{ij}\\) corresponde al parámetro de tasa media en la distribución de Poisson (8.15), ya que son las tasas de ocurrencia de eventos por unidad de exposición. Es decir, tenemos \\(z_{jk}=\\hat{\\lambda}_{jk}\\) donde \\({\\lambda}_{jk}\\) es el parámetro tasa de la Poisson. Sin embargo, generando los valores de \\(z_ {ij}\\) lo que se hace simplemente es comparar las frecuencias de pérdida promedio entre las clases de riesgo. Para explotar completamente el conjunto de datos, construiremos un modelo de precios a partir de la [Tabla 8.2] utilizando la regresión de Poisson en el resto del capítulo. Comentar que los registros de pérdidas reales utilizados por las aseguradoras generalmente incluyen muchos más factores de riesgo, en cuyo caso el número de celdas crece exponencialmente. La tarifa consiste entonces en un conjunto de tablas, en lugar de una, separadas por algunos de los factores básicos de tarificación, como el sexo o el territorio. 8.3.2 Modelo de Tarifa Multiplicativa En esta subsección, presentamos el modelo de tarifa multiplicativa, una estructura de precios muy utilizada que puede usarse naturalmente dentro del marco de regresión de Poisson. Los desarrollos aquí se basan en la [Tabla 8.2]. Recordemos que el recuento de pérdidas de un asegurado se describe mediante el modelo de regresión de Poisson con tasa o media \\(\\lambda\\) y exposición \\(m\\), de modo que el recuento de pérdidas esperado se convierte en \\(m \\lambda\\). Como \\(m\\) es una constante conocida, estamos esencialmente interesados en modelizar \\(\\lambda\\), de modo que responda al cambio en los factores de tarificación. Entre otras formas funcionales posibles, comúnmente elegimos la relación multiplicativa10 para modelar la tasa de Poisson \\(\\lambda_{jk}\\) para el factor de tarificación (\\(j,k\\)): \\[\\begin{equation} \\lambda_{jk}= f_0 \\times f_{1j} \\times f_{2k}, \\qquad j=1,2;\\, k=1, 2,3. \\tag{8.18} \\end{equation}\\] Aquí \\(\\{ f_{1j}, j=1,2\\}\\) son los parámetros asociados con los dos niveles en el primer factor de calificación, tipo de automóvil y \\(\\{ f_{2k}, k=1,2,3\\}\\) están asociados con los tres niveles de la franja de edad, el segundo factor de tarificación. Por ejemplo, la media de Poisson para un asegurado de mediana edad (adulto) con un vehículo Tipo B viene dada por \\(\\lambda_{22}=f_0 \\times f_{12} \\times f_{22}\\). El primer término \\(f_0\\) es un valor base que se discutirá en breve. Por lo tanto, estos seis parámetros se entienden como representaciones numéricas de los niveles dentro de cada factor de tarificación y deben estimarse a partir del conjunto de datos. La forma multiplicativa (8.18) ) es fácil de entender y usar, porque muestra claramente cómo cambia el recuento de pérdidas esperadas (por unidad de exposición) a medida que varía cada factor de tarificación. Por ejemplo, si \\(f_{11}=1\\) y \\(f_{12}=1,2\\), el recuento de pérdidas esperadas de un asegurado con un vehículo del tipo B sería un 20\\(\\%\\) mayor que el tipo A, cuando el resto de factores son los mismos. En los seguros no de vida, los parámetros \\(f_{1j}\\) y \\(f_{2k}\\) se conocen como relatividades, ya que determinan la cantidad de pérdida esperada que debería cambiar en relación con el valor base \\(f_0\\). La idea de la relatividad es bastante útil en la práctica, ya que podemos decidir la prima para un asegurado simplemente multiplicando una serie de relatividades correspondientes al valor base. Eliminar un factor de calificación existente o agregar uno nuevo también es transparente con esta estructura multiplicativa. Además, la aseguradora puede ajustar fácilmente la prima general para todos los asegurados controlando el valor base \\(f_0\\) sin cambiar las relatividades individuales. Sin embargo, al adoptar la forma multiplicativa, asumimos implícitamente que no existe una interacción importante entre los factores de riesgo. Cuando se usa la forma multiplicativa, debemos abordar un problema de identificación. Es decir, para cualquier \\(c&gt; 0\\), podemos escribir \\[\\begin{equation} \\lambda_{jk}= f_0 \\times \\frac{f_{1j}}{c} \\times c\\,f_{2k}. \\end{equation}\\] Al comparar con (8.18)), vemos que se puede obtener exactamente el mismo parámetro de tasa \\(\\lambda_{jk}\\) para relatividades individuales muy diferentes. Esta sobre-parametrización, que significa que muchos conjuntos diferentes de parámetros llegan a un modelo idéntico, obviamente requiere alguna restricción sobre \\(f_{1j}\\) y \\(f_{2k}\\). La práctica estándar es hacer que una relatividad en cada factor de tarificación sea igual a uno. Esto puede hacerse arbitrariamente en teoría, pero la práctica estándar es hacer que la relatividad de la clase más común (clase base) sea igual a uno. Asumiremos que los vehículos de tipo A y los conductores jóvenes son las clases más frecuentes, es decir, \\(f_{11} = 1\\) y \\(f_{21} = 1\\). De esta manera, todas las demás relatividades se determinan de manera única. La celda de tarifa \\((j,k) = (1,1)\\) se llama entonces celda de tarifa base, donde la tasa simplemente se convierte en \\(\\lambda_{11} = f_0\\), correspondiente al valor base de acuerdo con (8.18). Por lo tanto, el valor base \\(f_0\\) generalmente se interpreta como la media de Poisson de la celda de tarifa base. De nuevo, (8.18) se transforma mediante el logaritmo y puede re-escribirse como: \\[\\begin{equation} \\log \\lambda_{jk}= \\log f_0 + \\log f_{1j} + \\log f_{2k}, \\tag{8.19} \\end{equation}\\] ya que es más fácil trabajar en el proceso de estimación, similar a (8.14). Esta forma lineal de registro hace que las relatividades de registro del nivel base en cada factor de tarificación sean iguales a cero, es decir, \\(\\log f_{11}=\\log f_{21}=0\\), y nos lleva a la siguiente alternativa, que es una expresión más explícita para (8.19): \\[\\begin{equation} \\log \\lambda=\\begin{cases} \\log f_0 + \\quad 0 \\quad \\,\\,+ \\quad 0 \\quad \\,\\,&amp; \\text{para una póliza en a celda $(1,1)$}, \\\\ \\log f_0+ \\quad 0 \\quad \\,\\,+\\log f_{22}&amp; \\text{para una póliza en a celda $(1,2)$}, \\\\ \\log f_0+ \\quad 0 \\quad \\,\\,+\\log f_{23}&amp; \\text{para una póliza en a celda $(1,3)$}, \\\\ \\log f_0+\\log f_{12}+ \\quad 0 \\quad \\,\\,&amp; \\text{para una póliza en a celda $(2,1)$}, \\\\ \\log f_0+\\log f_{12}+\\log f_{22}&amp; \\text{para una póliza en a celda $(2,2)$}, \\\\ \\log f_0+\\log f_{12}+\\log f_{23}&amp; \\text{para una póliza en a celda $(2,3)$}. \\\\ \\end{cases} \\tag{8.20} \\end{equation}\\] Esto muestra claramente que el parámetro de Poisson \\(\\lambda\\) varía según las diferentes celdas de la tarifa, con la misma forma lineal logarítmica utilizada en el marco de la regresión de Poisson. De hecho, se puede ver que(8.20) es una versión extendida de la expresión anterior (8.6) con múltiples factores de riesgo y que las relatividades logarítmicas ahora juegan el papel de los parámetros \\(\\beta_i\\). Por lo tanto, todas las relatividades pueden estimarse fácilmente mediante el ajuste de una regresión de Poisson con un conjunto de variables indicadoras elegidas adecuadamente. 8.3.3 Regresión de Poisson para la Tarifa Multiplicativa Variables Indicadoras para las Celdas de Tarifa Ahora explicamos cómo se pueden incorporar las relatividades en la regresión de Poisson. Como se vio al principio de este capítulo, utilizamos variables indicadoras para tratar con variables categóricas. Por lo tanto, para nuestra aseguradora de automóviles del ejemplo, definimos una variable indicadora para el primer factor de calificación como \\[\\begin{equation} x_1= \\begin{cases} 1 &amp; \\text{ para vehículos de tipo B}, \\\\ 0 &amp; \\text{ en caso contrario}. \\end{cases} \\end{equation}\\] Para el segundo factor de tarificación, empleamos dos variables indicadoras para el grupo de edad, es decir, \\[\\begin{equation} x_2= \\begin{cases} 1 &amp; \\text{para el grupo de edad 2}, \\\\ 0 &amp; \\text{en caso contrario}. \\end{cases} \\end{equation}\\] y \\[\\begin{equation} x_3= \\begin{cases} 1 &amp; \\text{para el grupo de edad3}, \\\\ 0 &amp; \\text{en caso contrario}. \\end{cases} \\end{equation}\\] La tripleta \\((x_1, x_2, x_3)\\) puede determinar de manera efectiva y única cada clase de riesgo. Al observar que las variables indicadoras asociadas con el Tipo A y el grupo de edad 1 se omiten, vemos que la celda de tarifa \\((j, k) = (1,1)\\) juega el papel de la celda base. Hacemos hincapié en que nuestra elección de las tres variables indicadoras anteriores se ha realizado cuidadosamente para que sea coherente con la elección de los niveles base en el modelo de tarifa multiplicativa en la subsección anterior (es decir, \\(f_{11}=1\\) and \\(f_{21}=1\\)). Con las variables indicadoras propuestas, podemos reescribir la tasa de registro (8.19) como \\[\\begin{equation} \\log \\lambda_{}= \\log f_0+ \\log f_{12} \\times x_1 + \\log f_{22} \\times x_2 +\\log f_{23} \\times x_3, \\tag{8.21} \\end{equation}\\] que es idéntico a (8.20) cuando cada valor de la tripleta se aplica como corresponde. Por ejemplo, podemos verificar que la celda de tarifa base \\((j,k)=(1,1)\\) corresponde a \\((x_1, x_2,x_3)=(0, 0, 0)\\), y a su vez produce \\(\\log \\lambda=\\log f_0\\) o \\(\\lambda=f_0\\) en (8.21) según sea necesario. Regresion de Poisson para el modelo de tarificación Bajo esta especificación, consideremos a los \\(n\\) asegurados en la cartera con las características de riesgo del asegurado \\(i\\)-ésimo dadas por un vector de variables explicativas \\(\\mathbf{ x}_i=(x_{i1}, x_{i2},x_{i3})^{\\prime}\\), para \\(i = 1, \\ldots, n\\). Entonces establecemos (8.21) como \\[\\begin{equation} \\log \\lambda_{i}= \\beta_0+ \\beta_1 \\, x_{i1} + \\beta_{2} \\, x_{i2} +\\beta_3 \\, x_{i3}=\\mathbf{ x}^{\\prime}_i\\beta, \\qquad i=1, \\ldots, n, \\end{equation}\\] donde \\(\\beta_0, \\ldots, \\beta_3\\) se pueden asignar a las relatividades de registro correspondientes en (8.21). Ésta es exactamente la misma configuración que en (8.17) excepto por el componente de exposición. Por lo tanto, al incorporar la exposición en cada clase de riesgo, el modelo de regresión de Poisson para este modelo de tarifa multiplicativa finalmente se convierte en \\[\\begin{equation} \\log \\mu_i=\\log \\lambda_{i}+\\log m_i= \\log m_i+ \\beta_0+ \\beta_1 \\, x_{i1} + \\beta_{2} \\, x_{i2} +\\beta_3 \\, x_{i3}=\\log m_i+\\mathbf{ x}^{\\prime}_i\\beta, \\end{equation}\\] para \\(i=1, \\ldots, n\\). Como resultado, las relatividades vienen dadas por \\[\\begin{equation} {f}_0=e^{\\beta_0}, \\quad {f}_{12}=e^{\\beta_1}, \\quad {f}_{22}=e^{\\beta_2} \\quad \\text{and}\\quad {f}_{23}=e^{\\beta_3}, \\tag{8.22} \\end{equation}\\] con \\(f_{11}=1\\) y \\(f_{21}=1\\) de la especificación inicial. Para el conjunto de datos real, \\(\\beta_i\\), \\(i = 0,1, 2, 3\\), se reemplaza con su estimación mle \\(b_i\\) usando el método en el suplemento técnico al final de este capítulo (Sección 8.A). 8.3.4 Ejemplos numéricos Presentamos dos ejemplos numéricos de la regresión de Poisson. En el primer ejemplo, construimos un modelo de regresión de Poisson a partir de la [Tabla 8.2], que es un conjunto de datos de una hipotética compañía de seguro del automóvil. El segundo ejemplo utiliza un conjunto de datos real de una entidad aseguradora con más factores de riesgo. Como nuestro propósito es mostrar cómo se puede usar el modelo de regresión de Poisson bajo una regla de clasificación dada, no nos preocupa la calidad del ajuste del modelo de Poisson en este capítulo. Ejemplo 8.1: Regresión de Poisson para el seguro del automóvil del ejemplo En las últimas subsecciones anteriores, hemos considerado un conjunto de datos de una compañía aseguradora hipotética de automóviles con dos factores de riesgo, como se muestra en la [Tabla 8.2]. Ahora aplicamos el modelo de regresión de Poisson a este conjunto de datos. Como se hizo anteriormente, hemos establecido \\((j, k) = (1,1)\\) como la celda de tarifa base, de modo que \\(f_{11} = f_{21} = 1\\). El resultado de la regresión da las estimaciones de coeficientes siguientes \\((b_0, b_1, b_2, b_3) = (- 2,3359, -0,3004, -0,7837, -1,0655)\\), que a su vez produce las correspondientes relatividades \\[\\begin{equation} \\nonumber {f}_0=0,0967, \\quad {f}_{12}= 0,7405, \\quad {f}_{22}=0,4567 \\quad \\text{y}\\quad {f}_{23}=0,3445. \\end{equation}\\] a partir de la relación dada por (8.22). El programa en R y los resultados son los siguientes Muestral código R &gt; mydat1&lt;- read.csv(&quot;eg1_v1a.csv&quot;) &gt; mydat1 Vtype Agebnd Expsr Claims 1 1 1 89.1 9 2 1 2 208.5 8 3 1 3 155.2 6 4 2 1 19.3 1 5 2 2 360.4 13 6 2 3 276.7 6 &gt; VtypeF &lt;- relevel(factor(Vtype), ref=&quot;1&quot;) # treat Vtype as factors with 1 as base. &gt; AgebndF &lt;- relevel(factor(Agebnd), ref=&quot;1&quot;) # treat Age band as factors. &gt; Pois_reg1 = glm(Claims ~ VtypeF + AgebndF, data = mydat1, family = poisson(link = log), offset = log(Expsr) ) &gt; Pois_reg1 Coefficients: (Intercept) VtypeF2 AgebndF2 AgebndF3 -2.3359 -0.3004 -0.7837 -1.0655 Degrees of Freedom: 5 Total (i.e. Null); 2 Residual Null Deviance: 8.774 Residual Deviance: 0.6514 AIC: 30.37 Ejemplo 8.2. Regresión de Poisson para datos de siniestros en seguros en Singapur Este conjunto de datos real es un subconjunto de los datos utilizados por (Frees and Valdez 2008). Los datos provienen de la Asociación de Seguros Generales de Singapur, una organización que agrupa aseguradoras de no vida en Singapur. Los datos contienen el número de accidentes automovilísticos para \\(n = 7.483\\) pólizas de seguro de auto con varias variables explicativas categóricas y la exposición para cada póliza. Las variables explicativas incluyen cuatro factores de riesgo: el tipo de vehículo asegurado (automóvil (A) u otro (O), denotado por \\(\\tt{Vtype}\\)), la edad del vehículo en años (\\(\\tt{Vage}\\)), el sexo del titular de la póliza (\\(\\tt{Sex}\\)) y la edad del titular de la póliza (en años, agrupados en siete categorías, indicados \\(\\tt{Age}\\)). Según la descripción de los datos, hay varias cosas a recordar antes de construir un modelo. Primero, hay 3.842 pólizas con vehículo tipo A (automóvil) y 3.641 pólizas con otros tipos de vehículos. Sin embargo, la información sobre edad y sexo está disponible solo para las pólizas del vehículo tipo A; Se registra que los conductores de todos los demás tipos de vehículos tienen 21 años de edad o menos con sexo no especificado, excepto en una póliza, lo que indica que no se ha recopilado información del conductor para vehículos que no sean automóviles. Segundo, todos los vehículos tipo A están clasificados como vehículos privados y los demás tipos no. Cuando incluimos estos factores de riesgo, asumimos que todo sexo no especificado es masculino. Como la información sobre la edad solo es aplicable a los vehículos tipo A, configuramos el modelo en consecuencia. Es decir, aplicamos la variable de edad solo a los vehículos del tipo A. También utilizamos cinco franjas de antigüedad del vehículo, simplificando los siete grupos originales, combinando las edades de los vehículos 0, 1 y 2; el intervalo combinado se codifica como nivel 211 en el archivo de datos. Por lo tanto, nuestro modelo de Poisson tiene la siguiente forma explícita: \\[\\begin{align*} \\log \\mu_i= \\mathbf{ x}^{\\prime}_i\\beta+&amp;\\log m_i=\\beta_0+\\beta_1 I(Sex_i=M)+ \\sum_{t=2}^6 \\beta_t\\, I(Vage_i=t) \\\\ &amp;+ \\sum_{t=7}^{13} \\beta_t \\,I(Vtype_i=A)\\times I(Age_i=t-7)+\\log m_i. \\end{align*}\\] El resultado del ajuste se proporciona en la Table 8.3, para la que hacemos varios comentarios. La frecuencia de reclamaciones es mayor para hombres en un 17,3%, cuando otros factores de tarificación se mantienen fijos. Sin embargo, esto puede estar afectado por el hecho de que todo el sexo no especificado se ha asignado como hombre. Con respecto a la edad del vehículo, la frecuencia de reclamaciones disminuye gradualmente a medida que el vehículo envejece, cuando otros factores de tarificación se mantienen fijos. El nivel comienza desde 2 para esta variable pero, nuevamente, la numeración es nominal y no afecta el resultado numérico. La variable de edad del titular de la póliza solo se aplica al vehículo tipo A (automóvil), y no existe una póliza en el primer grupo de edad. Podemos especular que los conductores más jóvenes, menores de 21 años, conducen los automóviles de sus padres en lugar de tener el suyo debido a las altas primas de seguro o las regulaciones relacionadas. La falta de relatividad puede estimarse mediante alguna interpolación o a juicio profesional del actuario. La frecuencia de siniestros es la más baja para las franjas de edad 3 y 4, pero se vuelve sustancialmente más alta para los grupos de mayor edad, un patrón razonable visto en muchos conjuntos de datos de costes en el seguro de automóviles. También observamos que no existe un nivel base en la variable de edad del titular de la póliza, en el sentido de que ninguna relatividad es igual a 1. Esto se debe a que la variable solo es aplicable al tipo de vehículo A. Esto no causa un problema numérico, pero se puede establecer la relatividad básica de la siguiente manera si es necesario para otros fines. Como no hay ninguna póliza en el grupo de edad 0, consideramos el grupo 1 como el caso base. Específicamente, tratamos su relatividad como un producto de 0,918 y 1, donde la primera es la relatividad común (es decir, la reducción de prima común) aplicada a todas las pólizas con vehículo tipo A y la segunda es el valor base para la franja de edad 1. Entonces, la relatividad de la franja de edad 2 puede obtenerse como \\(0,917 = 0,918 \\times 0,999\\), donde 0,999 se entiende como la relatividad para la franja de edad 2. Los grupos de edad restantes pueden tratarse de manera similar. \\[ {\\small \\begin{matrix} \\begin{array}{clcc} \\hline \\text{Factor} &amp; \\text{Nivel} &amp; \\text{Relatividad en la tarifa} &amp; \\text{Nota}\\\\ \\hline\\hline \\text{Valor base} &amp; &amp; 0.167 &amp; f_0\\\\ \\hline \\text{Sexo} &amp; 1 (F) &amp; 1.000 &amp; \\text{Base}\\\\ &amp; 2 (M) &amp; 1.173 &amp;\\\\\\hline \\text{Edad del vehículo} &amp; 2 (0-2\\text{ años}) &amp; 1.000 &amp; \\text{Base}\\\\ &amp; 3 (3-5\\text{ años}) &amp; 0,843 \\\\ &amp; 4 (6-10\\text{ años}) &amp; 0,553 \\\\ &amp; 5 (11-15\\text{ años}) &amp; 0,269 \\\\ &amp; 6 (16+\\text{ años}) &amp; 0,189 &amp;\\\\\\hline \\text{Edad del asegurado} &amp; 0 (0-21) &amp; \\text{N. D.} &amp; \\text{Sin pólizas} \\\\ \\text{(Sólo aplicable a} &amp; 1 (22-25) &amp; 0,918 \\\\ \\text{Tipo de vehículo A)} &amp; 2 (26-35) &amp; 0,917 \\\\ &amp; 3 (36-45) &amp; 0,758 \\\\ &amp; 4 (46-55) &amp; 0,632 \\\\ &amp; 5 (56-65) &amp; 1,102\\\\ &amp; 6 (65+) &amp; 1,179\\\\ \\hline \\hline \\end{array} \\end{matrix} } \\] Table 8.3 : Datos de siniestros en seguros en Singapur Probemos varios ejemplos basados en la [Tabla 8.3]. Supongamos que un titular de póliza masculino de 40 años que posee un vehículo de tipo A de 7 años de edad. La frecuencia de reclamaciones esperada para este titular de póliza viene dada por \\[\\begin{equation} \\lambda=0,167 \\times 1,173 \\times 0,553 \\times 0,758 = 0,082. \\end{equation}\\] Como otro ejemplo, considere a una asegurada de 60 años que posee un vehículo de 3 años del tipo O. La frecuencia de reclamaciones esperada para este asegurado es \\[\\begin{equation} \\lambda=0,167 \\times 1 \\times 0,843 = 0,141. \\end{equation}\\] Tengamos en cuenta que para esta póliza, la variable de grupo de edad no se utiliza ya que el tipo de vehículo no es A. La secuencia de comandos R se proporciona de la siguiente manera. Muestra código R mydat &lt;- read.csv(&quot;SingaporeAuto.csv&quot;, quote = &quot;&quot;, header = TRUE) attach(mydat) # create vehicle type as factor TypeA = 1 * (VehicleType == &quot;A&quot;) table(VehicleType) VtypeF &lt;- as.character(VehicleType) VtypeF[VtypeF != &quot;A&quot;] &lt;- &quot;O&quot; VtypeF = relevel(factor(VtypeF), ref=&quot;A&quot;) # create gender as factor Female = 1 * (SexInsured == &quot;F&quot; ) Sex = as.character(SexInsured) Sex[Sex != &quot;F&quot;] &lt;- &quot;M&quot; SexF = relevel(factor(Sex), ref = &quot;F&quot;) # create driver age as factor AgeCat = pmax(AgeCat - 1, 0) AgeCatF = relevel(factor(AgeCat), ref = &quot;0&quot;) table(AgeCatF) # No policy in the first age band # create vehicle age as factor VAgeCatF = relevel( factor(VAgeCat), ref = &quot;0&quot; ) VAgecat1 = factor(VAgecat1, labels = c(&quot;Vage0-2&quot;, &quot;Vage3-5&quot;, &quot;Vage6-10&quot;, &quot;Vage11-15&quot;, &quot;Vage15+&quot;) ) VAgecat1F = relevel( factor(VAgecat1), ref = &quot;Vage0-2&quot; ) # Poisson reg model Pois_reg2 = glm(Clm_Count ~ SexF + TypeA:AgeCatF + VAgecat1F, offset = LNWEIGHT, poisson(link = log) ) summary(Pois_reg2) # compute relativities exp(Pois_reg2$coefficients) detach(mydat) Como observación final, comentar que la regresión de Poisson no es el único modelo de regresión posible para datos de conteo. En realidad, la distribución de Poisson puede ser restrictiva en el sentido de que tiene un único parámetro y su media y la varianza son siempre iguales. Existen otros modelos de regresión para conteos que permiten una estructura de distribución más flexible, como las regresiones binomiales negativas y las regresiones infladas en cero (ZI); Los detalles de estas regresiones alternativas se pueden encontrar en otros textos enumerados en la siguiente sección. 8.4 Más recursos y colaboradores Más Información y Referencias La regresión de Poisson es un caso especial de una clase de modelo de regresión más general conocido como modelo lineal generalizado (glm). El glm establece un marco de regresión unificado para conjuntos de datos cuando las variables de respuesta son continuas, binarias o discretas. El modelo de regresión lineal clásico con error normal también es miembro del glm. Hay muchos textos estadísticos estándar que tratan sobre el glm, incluido (Peter McCullagh and Nelder 1989). Los textos más accesibles son (Dobson and Barnett 2008), (Agresti 1996) y (Faraway 2016). Para las aplicaciones actuariales y de seguros del glm, consulte (Edward W. Frees 2009a), (De Jong and Heller 2008). Además, (Ohlsson and Johansson 2010) analiza el glm en el contexto de fijación de precios de seguros no vida con análisis de tarifas. Colaboradores Joseph H. T. Kim, Yonsei University, es el autor principal de la versión inicial de este capítulo. Email: jhtkim@yonsei.ac.kr para comentarios del capítulo y sugerencias de mejora. Revisores del capítulo: Chun Yong Chew, Lina Xu, Jeffrey Zheng. Traducción al español: Montserrat Guillen (Universitat de Barcelona) TS 8.A – Estimación de Modelos de Regresión de Poisson Los principios de la estimación de máxima verosimilitud (mle) se presentan en las Secciones 2.4.1 y 3.5, definidos en la Sección 15.2.2, y desarrollados teóricamente en el Capítulo 17. Aquí presentamos el procedimiento mle de la regresión de Poisson para que el lector pueda ver cómo se tratan las variables explicativas para maximizar la función de verosimilitud en el ámbito de la regresión. Máxima Verosimilitud para Datos Individuales En la regresión de Poisson, la media de la distribución de Poisson está determinada por los parámetros \\(\\beta_i\\)’s, como se muestra en (8.17). En esta subsección usamos el método de máxima verosimilitud para estimar estos parámetros. Nuevamente, asumimos que hay \\(n\\) asegurados y el asegurado \\(i\\)-ésimo se caracteriza por \\(\\mathbf{ x}_i=(1, x_{i1}, \\ldots, x_{ik})^{\\prime}\\) con la pérdida observada como una frecuencia \\(y_i\\). Luego, partiendo de (8.16) y @ref(eq: mean-ft-Pois-7), la función log-verosimilitud del vector\\(\\beta=(\\beta_0, \\dots, \\beta_k)\\) viene dada por \\[\\begin{align} \\nonumber \\log L(\\beta) &amp;= l(\\beta)=\\sum^n_{i=1} \\left( -\\mu_i +y_i \\, \\log \\mu_i -\\log y_i! \\right) \\\\ &amp; = \\sum^n_{i=1} \\left( -m_i \\exp(\\mathbf{ x}^{\\prime}_i\\beta) +y_i \\,(\\log m_i+\\mathbf{ x}^{\\prime}_i\\beta) -\\log y_i! \\right) \\tag{8.23} \\end{align}\\] Para obtener la mle de \\(\\beta=(\\beta_0, \\ldots, \\beta_k)^{\\prime}\\), diferenciamos12 \\(l(\\beta)\\) respecto al vector \\(\\beta\\) e igualamos a cero: \\[\\begin{equation} \\frac{\\partial}{\\partial \\beta}l(\\beta)\\Bigg{|}_{\\beta=\\mathbf{b}}=\\sum^n_{i=1} \\left(y_i -m_i \\exp(\\mathbf{ x}^{\\prime}_i \\mathbf{ b}) \\right)\\mathbf{ x}_i=\\mathbf{ 0}. \\tag{8.24} \\end{equation}\\] Solucionando numéricamente este sistema de ecuaciones obtenemos la mle de \\(\\beta\\), denotada como \\(\\mathbf{ b}=(b_0, b_1, \\ldots, b_k)^{\\prime}\\). Es importante ver que, como \\(\\mathbf{ x}_i=(1, x_{i1}, \\ldots, x_{ik})^{\\prime}\\) es un vector columna, la ecuación (8.24) es un sistema con \\(k+1\\) ecuaciones donde ambos lados están escritos como un vector columna de dimensión \\(k+1\\). Si denotamos \\(\\hat{\\mu}_i=m_i \\exp(\\mathbf{ x}^{\\prime}_i \\mathbf{ b})\\), podemos escribir (8.24) como \\[\\begin{equation} \\sum^n_{i=1} \\left(y_i -\\hat{\\mu}_i \\right)\\mathbf{ x}_i=\\mathbf{ 0}. \\end{equation}\\] Dado que la solución \\(\\mathbf{ b}\\) satisface esta ecuación, se deduce que la primera de las \\(k+1\\) ecuaciones, que corresponde al primer elemento constante de \\(\\mathbf{ x}_i\\), implica que \\[\\begin{equation} \\sum^n_{i=1}\\left( y_i -\\hat{\\mu}_i \\right)\\times 1={ 0}, \\end{equation}\\] lo que implica que tenemos \\[\\begin{equation} n^{-1}\\sum_{i=1}^n y_i =\\bar{y}=n^{-1}\\sum_{i=1}^n \\hat{\\mu}_i. \\end{equation}\\] Esta es una propiedad interesante que dice que el promedio de las pérdidas individuales observadas, \\(\\bar{y}\\), es el mismo que el promedio de los valores estimados. Es decir, la media muestral se conserva bajo el modelo de regresión de Poisson ajustado. Estimación por Máxima Verosimilitud con Datos Agrupados Algunas veces los datos no están disponibles a nivel de póliza individual. Por ejemplo, la [Tabla 8.2] proporciona información sobre pérdidas colectivas para cada clase de riesgo después de agrupar pólizas individuales. Cuando este es el caso, \\(y_i\\) y \\(m_i\\), las cantidades necesarias para el cálculo de la mle en (8.24) no están disponibles para cada \\(i\\). Sin embargo, esto no plantea un problema siempre que tengamos los recuentos de pérdidas totales y la exposición total para cada clase de riesgo. Para ver el detalle, supongamos que hay \\(K\\) diferentes clases de riesgo, y además que, en la clase de riesgo \\(k\\)-ésima, tenemos \\(n_k\\) pólizas con la exposición total \\(m_{(k)}\\) y el promedio pérdidas \\(\\bar{y}_{(k)}\\), para \\(k = 1, \\ldots, K\\); el recuento total de pérdidas para la clase de riesgo \\(k\\)-ésima es entonces \\(n_k \\, \\bar {y} _ {(k)}\\). Denotamos el conjunto de índices de las pólizas que pertenecen a la clase \\(k\\)-ésima para \\(C_k\\). Como todas las pólizas en una clase de riesgo dada comparten las mismas características de riesgo, podemos denotar \\(\\mathbf{x} _i = \\mathbf{x} _{(k)}\\) para las pólizas \\(i \\in C_k\\). Con esta notación, podemos reescribir (8.24) como \\[\\begin{align} \\nonumber \\sum^n_{i=1} \\left(y_i -m_i \\exp(\\mathbf{ x}^{\\prime}_i \\mathbf{ b}) \\right)\\mathbf{ x}_i &amp;= \\sum^K_{k=1}\\Big{\\{}\\sum_{i \\in C_k} \\left(y_i -m_i \\exp(\\mathbf{ x}^{\\prime}_i \\mathbf{ b}) \\right)\\mathbf{ x}_i \\Big{\\}} \\\\ \\nonumber &amp; =\\sum^K_{k=1}\\Big{\\{} \\sum_{i \\in C_k} \\left(y_i -m_i \\exp(\\mathbf{ x}^{\\prime}_{(k)} \\mathbf{ b}) \\right)\\mathbf{ x}_{(k)} \\Big{\\}} \\\\ \\nonumber &amp; =\\sum^K_{k=1}\\Big{\\{} \\Big(\\sum_{i \\in C_k}y_i -\\sum_{i \\in C_k}m_i \\exp(\\mathbf{ x}^{\\prime}_{(k)} \\mathbf{ b}) \\Big)\\mathbf{ x}_{(k)} \\Big{\\}} \\\\ &amp; =\\sum^K_{k=1} \\Big(n_k\\, \\bar{y}_{(k)}-m_{(k)} \\exp(\\mathbf{ x}^{\\prime}_{(k)} \\mathbf{ b}) \\Big)\\mathbf{ x}_{(k)} =0. \\tag{8.25} \\end{align}\\] Como \\(n_k \\, \\bar{y}_{(k)}\\) en (8.25) representa el recuento total de pérdidas para la clase de riesgo \\(k\\)-ésima y \\(m_{( k)}\\) es su exposición total, vemos que para la regresión de Poisson la mle de \\(\\mathbf {b}\\) es el misma si usamos los datos individuales o los datos agrupados. Matriz de Información La Sección 17.1 define las matrices de información. Tomando las segundas derivadas en (8.23) proporciona la matriz de información de los estimadores mle, \\[\\begin{equation} \\mathbf{ I}(\\beta)=-\\mathrm{E~}{\\left( \\frac{\\partial^2}{\\partial \\beta\\partial \\beta^{\\prime}}l(\\beta) \\right)}=\\sum^n_{i=1}m_i \\exp(\\mathbf{ x}^{\\prime}_i \\mathbf{ \\beta})\\mathbf{ x}_i \\mathbf{ x}_i^{\\prime}=\\sum^n_{i=1} {\\mu}_i \\mathbf{ x}_i \\mathbf{ x}_i^{\\prime}. \\tag{8.26} \\end{equation}\\] Para conjuntos de datos individuales, \\({\\mu}_i\\) en (8.26) se reemplaza por \\(\\hat{\\mu}_i=m_i \\exp(\\mathbf{ x}^{\\prime}_i \\mathbf{ b})\\) para estimar las varianzas y covarianzas relevantes de los estimadores mle \\(\\mathbf{ b}\\) o sus funciones. Para conjuntos de datos agrupados, tenemos \\[\\begin{equation} \\mathbf{ I}(\\beta)=\\sum^K_{k=1} \\Big{\\{}\\sum_{i \\in C_k}m_i \\exp(\\mathbf{ x}^{\\prime}_i \\mathbf{ \\beta})\\mathbf{ x}_i \\mathbf{ x}_i^{\\prime} \\Big{\\}}=\\sum^K_{k=1} m_{(k)} \\exp(\\mathbf{ x}^{\\prime}_{(k)} \\mathbf{ \\beta})\\mathbf{ x}_{(k)} \\mathbf{ x}_{(k)}^{\\prime}. \\end{equation}\\] Bibliography "],
["C-Credibility.html", "Chapter 9 Experience Rating Using Credibility Theory 9.1 Introduction to Applications of Credibility Theory 9.2 Limited Fluctuation Credibility 9.3 Bühlmann Credibility 9.4 Bühlmann-Straub Credibility 9.5 Bayesian Inference and Bühlmann Credibility 9.6 Estimating Credibility Parameters 9.7 Further Resources and Contributors", " Chapter 9 Experience Rating Using Credibility Theory Chapter Preview. This chapter introduces credibility theory which is an important actuarial tool for estimating pure premiums, frequencies, and severities for individual risks or classes of risks. Credibility theory provides a convenient framework for combining the experience for an individual risk or class with other data to produce more stable and accurate estimates. Several models for calculating credibility estimates will be discussed including limited fluctuation, Bühlmann, Bühlmann-Straub, and nonparametric and semiparametric credibility methods. The chapter will also show a connection between credibility theory and Bayesian estimation which was introduced in Chapter 4. 9.1 Introduction to Applications of Credibility Theory What premium should be charged to provide insurance? The answer depends upon the exposure to the risk of loss. A common method to compute an insurance premium is to rate an insured using a classification rating plan. A classification plan is used to select an insurance rate based on an insured’s rating characteristics such as geographic territory, age, etc. All classification rating plans use a limited set of criteria to group insureds into a “class” and there will be variation in the risk of loss among insureds within the class. An experience rating plan attempts to capture some of the variation in the risk of loss among insureds within a rating class by using the insured’s own loss experience to complement the rate from the classification rating plan. One way to do this is to use a credibility weight \\(Z\\) with \\(0\\leq Z \\leq 1\\) to compute \\[\\begin{equation*} \\hat{R}=Z\\bar{X}+(1-Z)M, \\end{equation*}\\] \\[\\begin{eqnarray*} \\hat{R}&amp;=&amp;\\textrm{credibility weighted rate for risk,}\\\\ \\bar{X}&amp;=&amp;\\textrm{average loss for the risk over a specified time period,}\\\\ M&amp;=&amp;\\textrm{the rate for the classification group, often called the manual rate.}\\\\ \\end{eqnarray*}\\] For a risk whose loss experience is stable from year to year, \\(Z\\) might be close to 1. For a risk whose losses vary widely from year to year, \\(Z\\) may be close to 0. Credibility theory is also used for computing rates for individual classes within a classification rating plan. When classification plan rates are being determined, some or many of the groups may not have sufficient data to produce stable and reliable rates. The actual loss experience for a group will be assigned a credibility weight \\(Z\\) and the complement of credibility \\(1-Z\\) may be given to the average experience for risks across all classes. Or, if a class rating plan is being updated, the complement of credibility may be assigned to the current class rate. Credibility theory can also be applied to the calculation of expected frequencies and severities. Computing numeric values for \\(Z\\) requires analysis and understanding of the data. What are the variances in the number of losses and sizes of losses for risks? What is the variance between expected values across risks? Show Quiz Solution 9.2 Limited Fluctuation Credibility In this section, you learn how to: Calculate full credibility standards for number of claims, average size of claims, and aggregate losses. Learn how the relationship between means and variances of underlying distributions affects full credibility standards. Determine credibility-weight \\(Z\\) using the square-root partial credibility formula. Limited fluctuation credibility, also called “classical credibility”, was given this name because the method explicitly attempts to limit fluctuations in estimates for claim frequencies, severities, or losses. For example, suppose that you want to estimate the expected number of claims \\(N\\) for a group of risks in an insurance rating class. How many risks are needed in the class to ensure that a specified level of accuracy is attained in the estimate? First the question will be considered from the perspective of how many claims are needed. 9.2.1 Full Credibility for Claim Frequency Let \\(N\\) be a random variable representing the number of claims for a group of risks, for example, risks within a particular rating classification. The observed number of claims will be used to estimate \\(\\mu_N=\\mathrm{E}[N]\\), the expected number of claims. How big does \\(\\mu_N\\) need to be to get a good estimate? One way to quantify the accuracy of the estimate would be a statement like: ``The observed value of \\(N\\) should be within 5\\(\\%\\) of \\(\\mu_N\\) at least 90\\(\\%\\) of the time.\" Writing this as a mathematical expression would give \\(\\Pr[0.95\\mu_N\\leq N \\leq1.05\\mu_N] \\geq 0.90\\). Generalizing this statement by letting \\(k\\) replace 5\\(\\%\\) and probability \\(p\\) replace 0.90 gives the equation \\[\\begin{equation} \\Pr[(1-k)\\mu_N\\leq N \\leq(1+k)\\mu_N] \\geq p. \\tag{9.1} \\end{equation}\\] The expected number of claims required for the probability on the left-hand side of (9.1) to equal \\(p\\) is called the full credibility standard. If the expected number of claims is greater than or equal to the full credibility standard then full credibility can be assigned to the data so \\(Z=1\\). Usually the expected value \\(\\mu_N\\) is not known so full credibility will be assigned to the data if the actual observed number of claims \\(n\\) is greater than or equal to the full credibility standard. The \\(k\\) and \\(p\\) values must be selected and the actuary may rely on experience, judgment, and other factors in making the choices. Subtracting \\(\\mu_N\\) from each term in (9.1) and dividing by the standard deviation \\(\\sigma_N\\) of \\(N\\) gives \\[\\begin{equation} \\Pr\\left[\\frac{-k\\mu_N}{\\sigma_N}\\leq \\frac{N-\\mu_N}{\\sigma_N} \\leq \\frac{k\\mu_N}{\\sigma_N}\\right] \\geq p. \\tag{9.2} \\end{equation}\\] In limited fluctuation credibility the standard normal distribution is used to approximate the distribution for \\((N-\\mu_N)/\\sigma_N\\). If \\(N\\) is the sum of many claims from a large group of similar risks and the claims are independent, then the approximation may be reasonable. Let \\(y_p\\) be the value such that \\(\\Pr[-y_p\\leq (N-\\mu_N)/\\sigma_N \\leq y_p]=\\Phi(y_p)-\\Phi(-y_p)=p\\) where \\(\\Phi( )\\) is the cumulative distribution function of the standard normal. Because \\(\\Phi(-y_p)=1-\\Phi(y_p)\\), the equality can be rewritten as \\(2\\Phi(y_p)-1=p\\). Solving for \\(y_p\\) gives \\(y_p=\\Phi^{-1}((p+1)/2)\\) where \\(\\Phi^{-1}( )\\) is the inverse of \\(\\Phi( )\\). Equation (9.2) will be satisfied if \\(k\\mu_N/\\sigma_N \\geq y_p\\) assuming the normal approximation. First we will consider this inequality for the case when \\(N\\) has a Poisson distribution: \\(\\Pr[N=n] = \\lambda^n\\textrm{e}^{-\\lambda}/n!\\). Because \\(\\lambda=\\mu_N=\\sigma_N^2\\) for the Poisson, taking square roots yields \\(\\mu_N^{1/2}=\\sigma_N\\). So, \\(k\\mu_N/\\mu_N^{1/2} \\geq y_p\\) which is equivalent to \\(\\mu_N \\geq (y_p/k)^2\\). Let’s define \\(\\lambda_{kp}\\) to be the value of \\(\\mu_N\\) for which equality holds. Then the full credibility standard for the Poisson distribution is \\[\\begin{equation} \\lambda_{kp} = \\left(\\frac{y_p}{k}\\right)^2 \\textrm{with } y_p=\\Phi^{-1}((p+1)/2). \\tag{9.3} \\end{equation}\\] If the expected number of claims \\(\\mu_N\\) is greater than or equal to \\(\\lambda_{kp}\\) then equation (9.1) is assumed to hold and full credibility can be assigned to the data. As noted previously, because \\(\\mu_N\\) is usually unknown, full credibility is given if the observed number of claims \\(n\\) satisfies \\(n \\geq \\lambda_{kp}.\\) Example 9.2.1. The full credibility standard is set so that the observed number of claims is to be within 5% of the expected value with probability \\(p=0.95\\). If the number of claims has a Poisson distribution find the number of claims needed for full credibility. Show Example Solution Solution Referring to a normal table, \\(y_p=\\Phi^{-1}((p+1)/2)=\\Phi^{-1}((0.95+1)/2)\\)=\\(\\Phi^{-1}(0.975)=1.960\\). Using this value and \\(k=.05\\) then \\(\\lambda_{kp} = (y_p/k)^{2}=(1.960/0.05)^{2}=1,536.64\\). After rounding up the full credibility standard is 1,537. If claims are not Poisson distributed then equation (9.2) does not imply (9.3). Setting the upper bound of \\((N-\\mu_N)/\\sigma_N\\) in (9.2) equal to \\(y_p\\) gives \\(k\\mu_N/\\sigma_N=y_p\\). Squaring both sides and moving everything to the right side except for one of the \\(\\mu_N\\)’s gives \\(\\mu_N=(y_p/k)^2(\\sigma_N^2/\\mu_N)\\). This is the full credibility standard for frequency and will be denoted by \\(n_f\\), \\[\\begin{equation} n_f=\\left(\\frac{y_p}{k}\\right)^2\\left(\\frac{\\sigma_N^2}{\\mu_N}\\right)=\\lambda_{kp}\\left(\\frac{\\sigma_N^2}{\\mu_N}\\right). \\tag{9.4} \\end{equation}\\] This is the same equation as the Poisson full credibility standard except for the \\((\\sigma_N^2/\\mu_N)\\) multiplier. When the claims distribution is Poisson this extra term is one because the variance equals the mean. Example 9.2.2. The full credibility standard is set so that the total number of claims is to be within 5\\(\\%\\) of the observed value with probability \\(p=0.95\\). The number of claims has a negative binomial distribution \\[\\begin{equation*} \\Pr(N=x)={x+r-1\\choose x} \\left(\\frac{1}{1+\\beta}\\right)^r \\left(\\frac{\\beta}{1+\\beta}\\right)^x \\end{equation*}\\] with \\(\\beta=1\\). Calculate the full credibility standard. Show Example Solution Solution From the prior example, \\(\\lambda_{kp} =1,536.64\\). The mean and variance for the negative binomial are \\(\\mathrm{E}(N)=r\\beta\\) and \\(\\mathrm{Var}(N)=r\\beta(1+\\beta)\\) so \\((\\sigma_N^2/\\mu_N)=(r\\beta(1+\\beta)/(r\\beta))=1+\\beta\\) which equals 2 when \\(\\beta=1\\). So, \\(n_f=\\lambda_{kp}(\\sigma_N^2/\\mu_N)=1,536.64(2)=3,073.28\\) and rounding up gives a full credibility standard of 3,074. We see that the negative binomial distribution with \\((\\sigma_N^2/\\mu_N)&gt;1\\) requires more claims for full credibility than a Poisson distribution for the same \\(k\\) and \\(p\\) values. The next example shows that a binomial distribution which has \\((\\sigma_N^2/\\mu_N)&lt;1\\) will need fewer claims for full credibility. Example 9.2.3. The full credibility standard is set so that the total number of claims is to be within 5\\(\\%\\) of the observed value with probability \\(p=0.95\\). The number of claims has a binomial distribution \\[\\begin{equation*} \\Pr(N=x)={m\\choose x}q^x(1-q)^{m-x}. \\end{equation*}\\] Calculate the full credibility standard for \\(q=1/4\\). Show Example Solution Solution From the first example in this section \\(\\lambda_{kp} =1,536.64\\). The mean and variance for a binomial are \\(\\mathrm{E}(N)=mq\\) and \\(\\mathrm{Var}(N)=mq(1-q)\\) so \\((\\sigma_N^2/\\mu_N)=(mq(1-q)/(mq))=1-q\\) which equals 3/4 when \\(q=1/4\\). So, \\(n_f=\\lambda_{kp}(\\sigma_N^2/\\mu_N)=1,536.64(3/4)=1,152.48\\) and rounding up gives a full credibility standard of 1,153. Rather than using expected number of claims to define the full credibility standard, the number of exposures can be used for the full credibility standard. An exposure is a measure of risk. For example, one car insured for a full year would be one car-year. Two cars each insured for exactly one-half year would also result in one car-year. Car-years attempt to quantify exposure to loss. Two car-years would be expected to generate twice as many claims as one car-year if the vehicles have the same risk of loss. To translate a full credibility standard denominated in terms of number of claims to a full credibility standard denominated in exposures one needs a reasonable estimate of the expected number of claims per exposure. Example 9.2.4. The full credibility standard should be selected so that the observed number of claims will be within 5\\(\\%\\) of the expected value with probability \\(p=0.95\\). The number of claims has a Poisson distribution. If one exposure is expected to have about 0.20 claims per year, find the number of exposures needed for full credibility. Show Example Solution Solution With \\(p=0.95\\) and \\(k=.05\\), \\(\\lambda_{kp} = (y_p/k)^{2}=(1.960/0.05)^{2}=1,536.64\\) claims are required for full credibility. The claims frequency rate is 0.20 claims/exposures. To convert the full credibility standard to a standard denominated in exposures the calculation is: (1,536.64 claims)/(0.20 claims/exposures) = 7,683.20 exposures. This can be rounded up to 7,684. Frequency can be defined as the number of claims per exposure. Letting \\(m\\) represent number of exposures then the observed claim frequency is \\(N/m\\) which is used to estimate \\(\\mathrm{E}(N/m)\\): \\[\\begin{equation*} \\Pr[(1-k)\\mathrm{E}(N/m)\\leq N/m \\leq(1+k)\\mathrm{E}(N/m)] \\geq p. \\end{equation*}\\] Because the number of exposures is not a random variable, \\(\\mathrm{E}(N/m)=\\mathrm{E}(N)/m=\\mu_N/m\\) and the prior equation becomes \\[\\begin{equation*} \\Pr\\left[(1-k)\\frac{\\mu_N}{m}\\leq \\frac{N}{m} \\leq(1+k)\\frac{\\mu_N}{m}\\right] \\geq p. \\end{equation*}\\] Multiplying through by \\(m\\) results in equation (9.1) at the beginning of the section. The full credibility standards that were developed for estimating expected number of claims also apply to frequency. 9.2.2 Full Credibility for Aggregate Losses and Pure Premium Aggregate losses are the total of all loss amounts for a risk or group of risks. Letting \\(S\\) represent aggregate losses then \\[\\begin{equation*} S=X_1+X_2+\\cdots+X_N. \\end{equation*}\\] The random variable \\(N\\) represents the number of losses and random variables \\(X_1, X_2,\\ldots,X_N\\) are the individual loss amounts. In this section it is assumed that \\(N\\) is independent of the loss amounts and that \\(X_1, X_2,\\ldots,X_N\\) are iid. The mean and variance of \\(S\\) are \\[\\begin{equation*} \\mu_S=\\mathrm{E}(S)=\\mathrm{E}(N)\\mathrm{E}(X)=\\mu_N\\mu_X\\textrm{ and} \\end{equation*}\\] \\[\\begin{equation*} \\sigma^{2}_S=\\mathrm{Var}(S)=\\mathrm{E}(N)\\mathrm{Var}(X)+[\\mathrm{E}(X)]^{2}\\mathrm{Var}(N)=\\mu_N\\sigma^{2}_X+\\mu^{2}_X\\sigma^{2}_N. \\end{equation*}\\] where \\(X\\) is the amount of a single loss. Observed losses \\(S\\) will be used to estimate expected losses \\(\\mu_S=\\mathrm{E}(S)\\). As with the frequency model in the previous section, the observed losses must be close to the expected losses as quantified in the equation \\[\\begin{equation*} \\Pr[(1-k)\\mu_S\\leq S \\leq(1+k)\\mu_S] \\geq p. \\end{equation*}\\] After subtracting the mean and dividing by the standard deviation, \\[\\begin{equation*} \\Pr\\left[\\frac{-k\\mu_S}{\\sigma_S}\\leq (S-\\mu_S)/\\sigma_S \\leq \\frac{k\\mu_S}{\\sigma_S}\\right] \\geq p \\end{equation*}\\]. As done in the previous section the distribution for \\((S-\\mu_S)/\\sigma_S\\) is assumed to be normal and \\(k\\mu_S/\\sigma_S=y_p=\\Phi^{-1}((p+1)/2)\\). This equation can be rewritten as \\(\\mu_S^2=(y_p/k)^2\\sigma_S^2\\). Using the prior formulas for \\(\\mu_S\\) and \\(\\sigma_{S}^2\\) gives \\((\\mu_N\\mu_X)^2=(y_p/k)^2(\\mu_N\\sigma^{2}_X+\\mu^{2}_X\\sigma^{2}_N)\\). Dividing both sides by \\(\\mu_N\\mu_X^2\\) and reordering terms on the right side results in a full credibility standard \\(n_S\\) for aggregate losses \\[\\begin{equation} n_S=\\left(\\frac{y_p}{k}\\right)^2\\left[\\left(\\frac{\\sigma_N^2}{\\mu_N}\\right)+\\left(\\frac{\\sigma_X}{\\mu_X}\\right)^2\\right]=\\lambda_{kp}\\left[\\left(\\frac{\\sigma_N^2}{\\mu_N}\\right)+\\left(\\frac{\\sigma_X}{\\mu_X}\\right)^2\\right]. \\tag{9.5} \\end{equation}\\] Example 9.2.5. The number of claims has a Poisson distribution. Individual loss amounts are independently and identically distributed with a Type II Pareto distribution \\(F(x)=1-[\\theta/(x+\\theta)]^{\\alpha}\\). The number of claims and loss amounts are independent. If observed aggregate losses should be within 5\\(\\%\\) of the expected value with probability \\(p=0.95\\), how many losses are required for full credibility? Show Example Solution Solution Because the number of claims is Poisson, \\((\\sigma_N^2/\\mu_N)=1\\). The mean of the Pareto is \\(\\mu_X=\\theta/(\\alpha-1)\\) and the variance is \\(\\sigma_X^2=\\theta^{2}\\alpha/[(\\alpha-1)^{2}(\\alpha-2)]\\) so \\((\\sigma_X/\\mu_X)^2=\\alpha/(\\alpha-2)\\). Combining the frequency and severity terms gives \\([(\\sigma_N^2/\\mu_N)+(\\sigma_X/\\mu_X)^2]=2(\\alpha-1)/(\\alpha-2)\\). From a normal table \\(y_p=\\Phi^{-1}((0.95+1)/2)=1.960\\). The full credibility standard is \\(n_S=(1.96/0.05)^{2}[2(\\alpha-1)/(\\alpha-2)]=3,073.28(\\alpha-1)/(\\alpha-2)\\). Suppose \\(\\alpha=3\\) then \\(n_S=6,146.56\\) for a full credibility standard of 6,147. Note that considerably more claims are needed for full credibility for aggregate losses than frequency alone. When the number of claims is Poisson distributed then equation (9.5) can be simplified using \\((\\sigma_N^2/\\mu_N)=1\\). It follows that \\([(\\sigma_N^2/\\mu_N)+(\\sigma_X/\\mu_X)^2]=[1+(\\sigma_X/\\mu_X)^2]=[(\\mu_X^2+\\sigma_X^2)/\\mu_X^2]=\\mathrm{E}(X^2)/\\mathrm{E}(X)^2\\) using the relationship \\(\\mu_X^2+\\sigma_X^2=\\mathrm{E}(X^2)\\). The full credibility standard is \\(n_S=\\lambda_{kp}\\mathrm{E}(X^2)/\\mathrm{E}(X)^2\\). The pure premium \\(PP\\) is equal to aggregate losses \\(S\\) divided by exposures \\(m\\): \\(PP=S/m\\). The full credibility standard for pure premium will require \\[\\begin{equation*} \\Pr\\left[(1-k)\\mu_{PP}\\leq PP \\leq(1+k)\\mu_{PP}\\right] \\geq p. \\end{equation*}\\] The number of exposures \\(m\\) is assumed fixed and not a random variable so \\(\\mu_{PP}=\\mathrm{E}(S/m)=\\mathrm{E}(S)/m=\\mu_S/m\\). \\[\\begin{equation*} \\Pr\\left[(1-k)\\left(\\frac{\\mu_S}{m}\\right)\\leq \\left(\\frac{S}{m}\\right) \\leq(1+k)\\left(\\frac{\\mu_S}{m}\\right)\\right] \\geq p. \\end{equation*}\\] Multiplying through by exposures \\(m\\) returns the bounds for losses \\[\\begin{equation*} \\Pr[(1-k)\\mu_S\\leq S \\leq(1+k)\\mu_S] \\geq p. \\end{equation*}\\] This means that the full credibility standard \\(n_{PP}\\) for the pure premium is the same as that for aggregate losses \\[\\begin{equation*} n_{PP}=n_S=\\lambda_{kp}\\left[\\left(\\frac{\\sigma_N^2}{\\mu_n}\\right)+\\left(\\frac{\\sigma_X}{\\mu_X}\\right)^2\\right]. \\end{equation*}\\] 9.2.3 Full Credibility for Severity Let \\(X\\) be a random variable representing the size of one claim. Claim severity is \\(\\mu_X=\\mathrm{E}(X)\\). Suppose that \\({X_1,X_2, \\ldots, X_n}\\) is a random sample of \\(n\\) claims that will be used to estimate claim severity \\(\\mu_X\\). The claims are assumed to be iid. The average value of the sample is \\[\\begin{equation*} \\bar{X}=\\frac{1}{n}\\left(X_1+X_2+\\cdots+X_n\\right). \\end{equation*}\\] How big does \\(n\\) need to be to get a good estimate? Note that \\(n\\) is not a random variable whereas it is in the aggregate loss model. In Section 9.2.1 the accuracy of an estimator for frequency was defined by requiring that the number of claims lie within a specified interval about the mean number of claims with a specified probability. For severity this requirement is \\[\\begin{equation*} \\Pr[(1-k)\\mu_X\\leq \\bar{X} \\leq(1+k)\\mu_X ]\\geq p \\end{equation*}\\] where \\(k\\) and \\(p\\) need to be specified. Following the steps in Section 9.2.1, the mean claim severity \\(\\mu_X\\) is subtracted from each term and the standard deviation of the claim severity estimator \\(\\sigma_{\\bar{X}}\\) is divided into each term yielding \\[\\begin{equation*} \\Pr\\left[\\frac{-k\\mu_X}{\\sigma_{\\bar{X}}}\\leq (\\bar{X}-\\mu_X)/\\sigma_{\\bar{X}} \\leq \\frac{k\\mu_X}{\\sigma_{\\bar{X}}}\\right] \\geq p \\end{equation*}\\]. As in prior sections, it is assumed that \\((\\bar{X}-\\mu_X)/\\sigma_{\\bar{X}}\\) is approximately normally distributed and the prior equation is satisfied if \\(k\\mu_X/\\sigma_{\\bar{X}}\\geq y_p\\) with \\(y_p=\\Phi^{-1}((p+1)/2)\\). Because \\(\\bar{X}\\) is the average of individual claims \\(X_1, X_2,\\dots, X_n\\), its standard deviation is equal to the standard deviation of an individual claim divided by \\(\\sqrt{n}\\): \\(\\sigma_{\\bar{X}}=\\sigma_X/\\sqrt{n}\\). So, \\(k\\mu_X/(\\sigma_X/\\sqrt{n})\\geq y_p\\) and with a little algebra this can be rewritten as \\(n \\geq (y_p/k)^2(\\sigma_X/\\mu_X)^2\\). The full credibility standard for severity is \\[\\begin{equation} n_X=\\left(\\frac{y_p}{k}\\right)^2\\left(\\frac{\\sigma_X}{\\mu_X}\\right)^2=\\lambda_{kp}\\left(\\frac{\\sigma_X}{\\mu_X}\\right)^2. \\tag{9.6} \\end{equation}\\] Note that the term \\(\\sigma_X/\\mu_X\\) is the coefficient of variation for an individual claim. Even though \\(\\lambda_{kp}\\) is the full credibility standard for frequency given a Poisson distribution, there is no assumption about the distribution for the number of claims. Example 9.2.6. Individual loss amounts are independently and identically distributed with a Type II Pareto distribution \\(F(x)=1-[\\theta/(x+\\theta)]^{\\alpha}\\). How many claims are required for the average severity of observed claims to be within 5\\(\\%\\) of the expected severity with probability \\(p=0.95\\)? Show Example Solution Solution The mean of the Pareto is \\(\\mu_X=\\theta/(\\alpha-1)\\) and the variance is \\(\\sigma_X^2=\\theta^{2}\\alpha/[(\\alpha-1)^{2}(\\alpha-2)]\\) so \\((\\sigma_X/\\mu_X)^2=\\alpha/(\\alpha-2)\\). From a normal table \\(y_p=\\Phi^{-1}((0.95+1)/2)=1.960\\). The full credibility standard is \\(n_X=(1.96/0.05)^{2}[\\alpha/(\\alpha-2)]=1,536.64\\alpha/(\\alpha-2)\\). Suppose \\(\\alpha=3\\) then \\(n_X=4,609.92\\) for a full credibility standard of 4,610. 9.2.4 Partial Credibility In prior sections full credibility standards were calculated for estimating frequency (\\(n_f\\)), pure premium (\\(n_{PP}\\)), and severity (\\(n_X\\)) - in this section these full credibility standards will be denoted by \\(n_{0}\\). In each case the full credibility standard was the expected number of claims required to achieve a defined level of accuracy when using empirical data to estimate an expected value. If the observed number of claims is greater than or equal to the full credibility standard then a full credibility weight \\(Z=1\\) is given to the data. In limited fluctuation credibility, credibility weights \\(Z\\) assigned to data are \\[\\begin{equation*} Z=\\quad \\sqrt{\\frac{n}{n_{0}}} \\quad \\textrm{if} \\quad n &lt; n_{0} \\quad \\textrm{and} \\quad Z=\\quad 1 \\quad \\textrm{for} \\quad n \\geq n_{0} \\end{equation*}\\] where \\(n_0\\) is the full credibility standard. The quantity \\(n\\) is the number of claims for the data that is used to estimate the expected frequency, severity, or pure premium. Example 9.2.7. The number of claims has a Poisson distribution. Individual loss amounts are independently and identically distributed with a Type II Pareto distribution \\(F(x)=1-[\\theta/(x+\\theta)]^{\\alpha}\\). Assume that \\(\\alpha=3\\). The number of claims and loss amounts are independent. The full credibility standard is that the observed pure premium should be within 5\\(\\%\\) of the expected value with probability \\(p=0.95\\). What credibility \\(Z\\) is assigned to a pure premium computed from 1,000 claims? Show Example Solution Solution Because the number of claims is Poisson, \\[ \\frac{\\mathrm{E}(X^2)}{[\\mathrm{E}~(X)]^2} =\\frac{\\sigma_N^2}{\\mu_N}+\\left(\\frac{\\sigma_X}{\\mu_X}\\right)^2. \\] The mean of the Pareto is \\(\\mu_X=\\theta/(\\alpha-1)\\) and the second moment is \\(\\mathrm{E}(X^2)=2\\theta^{2}/[(\\alpha-1)(\\alpha-2)]\\) so \\(\\mathrm{E}(X^2)/[\\mathrm{E}~(X)]^2=2(\\alpha-1)/(\\alpha-2)\\). From a normal table \\(y_p=\\Phi^{-1}((0.95+1)/2)=1.960\\). The full credibility standard is \\[n_{PP}=(1.96/0.05)^{2}[2(\\alpha-1)/(\\alpha-2)]=3,073.28(\\alpha-1)/(\\alpha-2)\\] and if \\(\\alpha=3\\) then \\(n_0=n_{PP}=6,146.56\\) or 6,147 if rounded up. The credibility assigned to 1,000 claims is \\(Z=(1,000/6,147)^{1/2}=0.40\\). Limited fluctuation credibility uses the formula \\(Z=\\sqrt{n/n_0}\\) to limit the fluctuation in the credibility-weighted estimate to match the fluctuation allowed for data with expected claims at the full credibility standard. Variance or standard deviation is used as the measure of fluctuation. Next we show an example to explain why the square-root formula is used. Suppose that average claim severity is being estimated from a sample of size \\(n\\) that is less than the full credibility standard \\(n_0=n_X\\). Applying credibility theory the estimate \\(\\hat{\\mu}_X\\) would be \\[\\begin{equation*} \\hat{\\mu}_X=Z\\bar{X}+(1-Z)M_X \\end{equation*}\\] with \\(\\bar{X}=(X_1+X_2+\\cdots+X_n)/n\\) and \\(iid\\) random variables \\(X_i\\) representing the sizes of individual claims. The complement of credibility is applied to \\(M_X\\) which could be last year’s estimated average severity adjusted for inflation, the average severity for a much larger pool of risks, or some other relevant quantity selected by the actuary. It is assumed that the variance of \\(M_X\\) is zero or negligible. With this assumption \\[\\begin{equation*} \\mathrm{Var}(\\hat{\\mu}_X)=\\mathrm{Var}(Z\\bar{X})=Z^2\\mathrm{Var}(\\bar{X})=\\frac{n}{n_0}\\mathrm{Var}(\\bar{X}). \\end{equation*}\\] Because \\(\\bar{X}=(X_1+X_2+\\cdots+X_n)/n\\) it follows that \\(\\mathrm{Var}(\\bar{X})=\\mathrm{Var}(X_i)/n\\) where random variable \\(X_i\\) is one claim. So, \\[\\begin{equation*} \\mathrm{Var}(\\hat{\\mu}_X)=\\frac{n}{n_0}\\mathrm{Var}(\\bar{X})=\\frac{n}{n_0}\\frac{\\mathrm{Var}(X_i)}{n}=\\frac{\\mathrm{Var}(X_i)}{n_0}. \\end{equation*}\\] The last term is exactly the variance of a sample mean \\(\\bar{X}\\) when the sample size is equal to the full credibility standard \\(n_0=n_X\\). Show Quiz Solution 9.3 Bühlmann Credibility In this section, you learn how to: Compute a credibility-weighted estimate for the expected loss for a risk or group of risks. Determine the credibility \\(Z\\) assigned to observations. Calculate the values required in Bühlmann credibility including the Expected Value of the Process Variance (EPV), Variance of the Hypothetical Means (VHM) and collective mean \\(\\mu\\). Recognize situations when the Bühlmann model is appropriate. A classification rating plan groups policyholders together into classes based on risk characteristics. Although policyholders within a class have similarities, they are not identical and their expected losses will not be exactly the same. An experience rating plan can supplement a class rating plan by credibility weighting an individual policyholder’s loss experience with the class rate to produce a more accurate rate for the policyholder. In the presentation of Buhlmann credibility it is convenient to assign a risk parameter \\(\\theta\\) to each policyholder. Losses \\(X\\) for the policyholder will have a common distribution function \\(F_{\\theta}(x)\\) with mean \\(\\mu(\\theta)=\\mathrm{E}(X|\\theta)\\) and variance \\(\\sigma^2(\\theta)=\\mathrm{Var}(X|\\theta)\\). Losses \\(X\\) can represent pure premiums, aggregate losses, number of claims, claim severities, or some other measure of loss for a period of time, often one year. Risk parameter \\(\\theta\\) may be continuous or discrete and may be multivariate depending on the model. If a policyholder with risk parameter \\(\\theta\\) had losses \\(X_1, \\ldots, X_n\\) during \\(n\\) time periods then the goal is to find E(\\(\\mu(\\theta)|X_1,\\ldots, X_n)\\), the conditional expectation of \\(\\mu(\\theta)\\) given \\(X_1,\\ldots, X_n\\). The Bühlmann credibility-weighted estimate for E(\\(\\mu(\\theta)|X_1,\\ldots, X_n)\\) for the policyholder is \\[\\begin{equation} \\hat{\\mu}(\\theta)=Z\\bar{X}+(1-Z)\\mu \\tag{9.7} \\end{equation}\\] with \\[\\begin{eqnarray*} \\theta&amp;=&amp;\\textrm{a risk parameter that identifies a policyholder&#39;s risk level}\\\\ \\hat{\\mu}(\\theta)&amp;=&amp;\\textrm{estimated expected loss for a policyholder with parameter }\\theta\\\\ &amp; &amp; \\textrm{and loss experience } \\bar{X}\\\\ \\bar{X}&amp;=&amp;(X_1+\\cdots+X_n)/n \\textrm{ is the average of $n$ observations of the policyholder } \\\\ Z&amp;=&amp;\\textrm{credibility assigned to $n$ observations } \\\\ \\mu&amp;=&amp;\\textrm{the expected loss for a randomly chosen policyholder in the class.}\\\\ \\end{eqnarray*}\\] For a selected policyholder, random variables \\(X_j\\) are assumed to be iid for \\(j=1,\\ldots,n\\) because it is assumed that the policyholder’s exposure to loss is not changing through time. The quantity \\(\\bar{X}\\) is the average of \\(n\\) observations and \\(\\mathrm{E}(\\bar{X}|\\theta)=\\mathrm{E}(X_j|\\theta)=\\mu(\\theta)\\). If a policyholder is randomly chosen from the class and there is no loss information about the risk then the expected loss is \\(\\mu=\\mathrm{E}(\\mu(\\theta))\\) where the expectation is taken over all \\(\\theta\\)’s in the class. In this situation \\(Z=0\\) and the expected loss is \\(\\hat\\mu(\\theta)=\\mu\\) for the risk. The quantity \\(\\mu\\) can also be written as \\(\\mu=\\mathrm{E}(X_j)\\) or \\(\\mu=\\mathrm{E}(\\bar{X})\\) and is often called the overall mean or collective mean. Note that E(\\(X_j\\)) is evaluated with the law of total expectation: E(\\(X_j\\))=E(E(\\(X_j|\\theta)\\)). Example 9.3.1. The number of claims \\(X\\) for an insured in a class has a Poisson distribution with mean \\(\\theta&gt;0\\). The risk parameter \\(\\theta\\) is exponentially distributed within the class with pdf \\(f(\\theta)=e^{-\\theta}\\). What is the expected number of claims for an insured chosen at random from the class? Show Example Solution Solution Random variable \\(X\\) is Poisson with parameter \\(\\theta\\) and E\\((X|\\theta)=\\theta\\). The expected number of claims for a randomly chosen insured is \\(\\mu=\\mathrm{E}(\\mu(\\theta))=\\mathrm{E}(\\mathrm{E}(X|\\theta))=\\)E\\((\\theta)=\\int_{0}^{\\infty}\\theta e^{-\\theta} d\\theta=1\\). In the prior example the risk parameter \\(\\theta\\) is a random variable with an exponential distribution. In the next example there are three types of risks and the risk parameter has a discrete distribution. Example 9.3.2. For any risk (policyholder) in a population the number of losses \\(N\\) in a year has a Poisson distribution with parameter \\(\\lambda\\). Individual loss amounts \\(X_i\\) for a risk are independent of \\(N\\) and are iid with Type II Pareto distribution \\(F(x)=1-[\\theta/(x+\\theta)]^{\\alpha}\\). There are three types of risks in the population as follows: \\[\\begin{matrix} \\begin{array}{|c|c|c|c|} \\hline \\text{Risk } &amp; \\text{Percentage} &amp; \\text{Poisson} &amp; \\text{Pareto} \\\\ \\text{Type} &amp; \\text{of Population} &amp; \\text{Parameter} &amp; \\text{Parameters} \\\\ \\hline A &amp; 50\\% &amp; \\lambda=0.5 &amp; \\theta=1000, \\alpha=2.0 \\\\ B &amp; 30\\% &amp; \\lambda=1.0 &amp; \\theta=1500, \\alpha=2.0 \\\\ C &amp; 20\\% &amp; \\lambda=2.0 &amp; \\theta=2000, \\alpha=2.0 \\\\ \\hline \\end{array} \\end{matrix}\\] If a risk is selected at random from the population, what is the expected aggregate loss in a year? Show Example Solution Solution The expected number of claims for a risk is E(\\(N|\\lambda\\))=\\(\\lambda\\). The expected value for a Pareto distributed random variable is E(\\(X | \\theta, \\alpha\\))=\\(\\theta/(\\alpha-1)\\). The expected value of the aggregate loss random variable \\(S=X_1+\\cdots+X_N\\) for a risk with parameters \\(\\lambda\\), \\(\\alpha\\), and \\(\\theta\\) is E(\\(S\\))=E(\\(N\\))E(\\(X\\))=\\(\\lambda\\theta/(\\alpha-1)\\). The expected aggregate loss for a risk of type A is E(\\(S_{\\textrm{A}}\\))=(0.5)(1000)/(2-1)=500. The expected aggregate loss for a risk selected at random from the population is E(\\(S\\))=0.5[(0.5)(1000)]+0.3[(1.0)(1500)]+0.2[(2.0)(2000)]=1500. What is the risk parameter for a risk (policyholder) in the prior example? One could say that the risk parameter has three components \\((\\lambda,\\theta,\\alpha)\\) with possible values (0.5,1000,2.0), (1.0,1500,2.0), and (2.0,2000,2.0) depending on the type of risk. Note that in both of the examples the risk parameter is a random quantity with its own probability distribution. We do not know the value of the risk parameter for a randomly chosen risk. Although formula (9.7) was introduced using experience rating as an example, the Bühlmann credibility model has wider application. Suppose that a rating plan has multiple classes. Credibility formula (9.7) can be used to determine individual class rates. The overall mean \\(\\mu\\) would be the average loss for all classes combined, \\(\\bar{X}\\) would be the experience for the individual class, and \\(\\hat{\\mu}(\\theta)\\) would be the estimated loss for the class. 9.3.1 Credibility Z, EPV, and VHM When computing the credibility estimate \\(\\hat{\\mu}(\\theta)=Z\\bar{X}+(1-Z)\\mu\\), how much weight \\(Z\\) should go to experience \\(\\bar{X}\\) and how much weight \\((1-Z)\\) to the overall mean \\(\\mu\\)? In Bühlmann credibility there are three factors that need to be considered: How much variation is there in a single observation \\(X_j\\) for a selected risk? With \\(\\bar{X}=(X_1+\\cdots+X_n)/n\\) and assuming that the observations are iid conditional on \\(\\theta\\), it follows that Var(\\(\\bar{X}|\\theta)\\)=Var(\\(X_j|\\theta)/n\\). For larger Var(\\(\\bar{X}|\\theta)\\) less credibility weight \\(Z\\) should be given to experience \\(\\bar{X}\\). The Expected Value of the Process Variance, abbreviated EPV, is the expected value of Var(\\(X_j|\\theta\\)) across all risks: \\[\\begin{equation*} EPV=\\mathrm{E}(\\mathrm{Var}(X_j|\\theta)). \\end{equation*}\\] Because Var(\\(\\bar{X}|\\theta)\\)=Var(\\(X_j|\\theta)/n\\) it follows that E(Var(\\(\\bar{X}|\\theta)\\))=EPV/\\(n\\). How homogeneous is the population of risks whose experience was combined to compute the overall mean \\(\\mu\\)? If all the risks are similar in loss potential then more weight \\((1-Z)\\) would be given to the overall mean \\(\\mu\\) because \\(\\mu\\) is the average for a group of similar risks whose means \\(\\mu(\\theta)\\) are not far apart. The homogeneity or heterogeneity of the population is measured by the Variance of the Hypothetical Means with abbreviation VHM: \\[\\begin{equation*} VHM=\\mathrm{Var}(\\mathrm{E}(X_j|\\theta))=\\mathrm{Var}(\\mathrm{E}(\\bar{X}|\\theta)). \\end{equation*}\\] Note that we used \\(\\mathrm{E}(\\bar{X}|\\theta)=\\mathrm{E}(X_j|\\theta)\\) for the second equality. How many observations \\(n\\) were used to compute \\(\\bar{X}\\)? A larger sample would infer a larger \\(Z\\). Example 9.3.3. The number of claims \\(N\\) in a year for a risk in a population has a Poisson distribution with mean \\(\\lambda&gt;0\\). The risk parameter \\(\\lambda\\) is uniformly distributed over the interval \\((0,2)\\). Calculate the EPV and VHM for the population. Show Example Solution Solution Random variable \\(N\\) is Poisson with parameter \\(\\lambda\\) so Var\\((N|\\lambda)=\\lambda\\). The Expected Value of the Process variance is EPV=E(Var(\\(N|\\lambda\\)))=E\\((\\lambda)=\\int_{0}^{2}\\lambda \\frac{1}{2} d\\lambda=1\\). The Variance of the Hypothetical Means is VHM=Var(E(N\\(|\\lambda\\)))= Var(\\(\\lambda\\))=E(\\(\\lambda^2)-(\\mathrm{E}(\\lambda))^2=\\int_{0}^{2}\\lambda^2 \\frac{1}{2} d\\lambda-(1)^2=\\frac{1}{3}\\). The Bühlmann credibility formula includes values for \\(n\\), EPV, and VHM: \\[\\begin{equation} Z=\\frac{n}{n+K} \\quad , \\quad K =\\frac{EPV}{VHM}. \\tag{9.8} \\end{equation}\\] If the VHM increases then \\(Z\\) increases. If the EPV increases then \\(Z\\) gets smaller. Unlike limited fluctuation credibility where \\(Z=1\\) when the expected number of claims is greater than the full credibility standard, \\(Z\\) can approach but not equal 1 as the number of observations \\(n\\) goes to infinity. If you multiply the numerator and denominator of the \\(Z\\) formula by (VHM/\\(n\\)) then \\(Z\\) can be rewritten as \\[\\begin{equation*} Z=\\frac{VHM}{VHM+(EPV/n)} . \\end{equation*}\\] The number of observations \\(n\\) is captured in the term (EPV/\\(n\\)). As shown in bullet (1) at the beginning of the section, E(Var(\\(\\bar{X}|\\theta)\\))=EPV/\\(n\\). As the number of observations get larger, the expected variance of \\(\\bar{X}\\) gets smaller and credibility \\(Z\\) increases so that more weight gets assigned to \\(\\bar{X}\\) in the credibility-weighted estimate \\(\\hat{\\mu}(\\theta)\\). Example 9.3.4. Use the law of total variance to show that Var(\\(\\bar{X}\\)) = VHM + (EPV/n) and derive a formula for \\(Z\\) in terms of \\(\\bar{X}\\). Show Example Solution Solution The quantity Var(\\(\\bar{X}\\)) is called the unconditional variance or the total variance of \\(\\bar{X}\\). The law of total variance says \\[\\begin{equation*} \\mathrm{Var}(\\bar{X})=\\textrm{E(Var}(\\bar{X}|\\theta))+\\textrm{Var(E}(\\bar{X}|\\theta)). \\end{equation*}\\] In bullet (1) at the beginning of this section we showed E(Var(\\(\\bar{X}|\\theta)\\))=EPV/\\(n\\). In the second bullet (2), Var(E(\\(\\bar{X}|\\theta\\)))=VHM. Reordering the right hand side gives Var(\\(\\bar{X}\\))= VHM +(EPV/\\(n\\)). Another way to write the formula for credibility \\(Z\\) is \\(Z\\)=Var(E(\\(\\bar{X}|\\theta\\)))/Var(\\(\\bar{X}\\)). This implies \\((1-Z)\\)=E(Var(\\(\\bar{X}|\\theta\\)))/Var(\\(\\bar{X}\\)). The following long example and solution demonstrate how to compute the credibility-weighted estimate with frequency and severity data. Example 9.3.5. For any risk in a population the number of losses \\(N\\) in a year has a Poisson distribution with parameter \\(\\lambda\\). Individual loss amounts \\(X\\) for a selected risk are independent of \\(N\\) and are iid with exponential distribution \\(F(x)=1-e^{-x/\\beta}\\). There are three types of risks in the population as shown below. A risk was selected at random from the population and all losses were recorded over a five-year period. The total amount of losses over the five-year period was 5,000. Use Bühlmann credibility to estimate the annual expected aggregate loss for the risk. \\[\\begin{matrix} \\begin{array}{|c|c|c|c|} \\hline \\text{Risk } &amp; \\text{Percentage} &amp; \\text{Poisson} &amp; \\text{Exponential} \\\\ \\text{Type} &amp; \\text{of Population} &amp; \\text{Parameter} &amp; \\text{Parameter} \\\\ \\hline A &amp; 50\\% &amp; \\lambda=0.5 &amp; \\beta=1000 \\\\ B &amp; 30\\% &amp; \\lambda=1.0 &amp; \\beta=1500 \\\\ C &amp; 20\\% &amp; \\lambda=2.0 &amp; \\beta=2000 \\\\ \\hline \\end{array} \\end{matrix}\\] Show Example Solution Solution Because individual loss amounts \\(X\\) are exponentially distributed, E(\\(X| \\beta\\))=\\(\\beta\\) and Var(\\(X| \\beta\\))=\\(\\beta^2\\). For aggregate loss \\(S=X_1+\\cdots+X_N\\), the mean is E(\\(S\\))=E(\\(N\\))E(\\(X\\)) and process variance is Var(\\(S\\))=E(\\(N\\))Var(\\(X\\))+[E(\\(X\\))]\\(^2\\)Var(\\(N\\)). With Poisson frequency and exponentially distributed loss amounts, E(\\(S| \\lambda, \\beta\\))=\\(\\lambda\\beta\\) and Var(\\(S| \\lambda, \\beta\\)) = \\(\\lambda\\beta^2+\\beta^2\\lambda=2\\lambda\\beta^2\\). Population mean \\(\\mu\\): Risk means are \\(\\mu\\)(A)=0.5(1000)=500; \\(\\mu\\)(B)=1.0(1500)=1500; \\(\\mu\\)(C)=2.0(2000)=4000; and \\(\\mu\\)=0.50(500)+0.30(1500)+0.20(4000)=1,500. VHM: VHM=\\(0.50(500-1500)^2+0.30(1500-1500)^2+0.20(4000-1500)^2\\)=1,750,000. EPV: Process variances are \\(\\sigma^2(A)=2(0.5)(1000)^2=1,000,000\\); \\(\\sigma^2(B)=2(1.0)(1500)^2=4,500,000\\); \\(\\sigma^2(C)=2(2.0)(2000)^2=16,000,000\\); and EPV=0.50(1,000,000)+0.30(4,500,000)+0.20(16,000,000)=5,050,000. \\(\\mathbf{\\bar{X}}\\): \\(\\bar{X}_5=5,000/5\\)=1,000. \\(\\mathbf{K}\\): \\(K=5,050,000/1,750,000\\)=2.89. \\(\\mathbf{Z}\\): There are five years of observations so \\(n=5\\). \\(Z=5/(5+2.89)\\)=0.63. \\(\\boldsymbol{\\hat{\\mu}(\\theta)}\\): \\(\\hat{\\mu}(\\theta)=0.63(1,000)+(1-0.63)1,500=\\boxed{\\mathbf{1,185.00}}\\). In real world applications of Bühlmann credibility the value of \\(K=EPV/VHM\\) must be estimated. Sometimes a value for \\(K\\) is selected using judgment. A smaller \\(K\\) makes estimator \\(\\hat{\\mu}(\\theta)\\) more responsive to actual experience \\(\\bar{X}\\) whereas a larger \\(K\\) produces a more stable estimate by giving more weight to \\(\\mu\\). Judgment may be used to balance responsiveness and stability. A later section in this chapter will discuss methods for determining \\(K\\) from data. For a policyholder with risk parameter \\(\\theta\\), Bühlmann credibility uses a linear approximation \\(\\hat{\\mu}(\\theta)=Z\\bar{X}+(1-Z)\\mu\\) to estimate E(\\(\\mu(\\theta)|X_1,\\ldots,X_n\\)), the expected loss for the policyholder given prior losses \\(X_1,\\ldots, X_n\\). We can rewrite this as \\(\\hat{\\mu}(\\theta)=a+b\\bar{X}\\) which makes it obvious that the credibility estimate is a linear function of \\(\\bar{X}\\). If E(\\(\\mu(\\theta)|X_1,\\ldots,X_n\\)) is approximated by the linear function \\(a+b\\bar{X}\\) and constants \\(a\\) and \\(b\\) are chosen so that E[(E(\\(\\mu(\\theta)|X_1,\\ldots,X_n)-(a+b\\bar{X}))^2\\)] is minimized, what are \\(a\\) and \\(b\\)? The answer is \\(b=n/(n+K)\\) and \\(a=(1-b)\\mu\\) with \\(K=EPV/VHM\\) and \\(\\mu=E(\\mu(\\theta))\\). More details can be found in references (Bühlmann 1967), (Bühlmann and Gisler 2005), (Klugman, Panjer, and Willmot 2012), and (Tse 2009). Bühlmann credibility is also called least-squares credibility, greatest accuracy credibility, or Bayesian credibility. Show Quiz Solution 9.4 Bühlmann-Straub Credibility In this section, you learn how to: Compute a credibility-weighted estimate for the expected loss for a risk or group of risks using the Bühlmann-Straub model. Determine the credibility \\(Z\\) assigned to observations. Calculate required values including the Expected Value of the Process Variance (EPV), Variance of the Hypothetical Means (VHM) and collective mean \\(\\mu\\). Recognize situations when the Bühlmann-Straub model is appropriate. With standard Bühlmann or least-squares credibility as described in the prior section, losses \\(X_1,\\ldots,X_n\\) arising from a selected policyholder are assumed to be iid. If the subscripts indicate year 1, year 2 and so on up to year \\(n\\), then the iid assumption means that the policyholder has the same exposure to loss every year. For commercial insurance this assumption is frequently violated. Consider a commercial policyholder that uses a fleet of vehicles in its business. In year 1 there are \\(m_1\\) vehicles in the fleet, \\(m_2\\) vehicles in year 2, .., and \\(m_n\\) vehicles in year \\(n\\). The exposure to loss from ownership and use of this fleet is not constant from year to year. The annual losses for the fleet are not iid. Define \\(Y_{jk}\\) to be the loss for the \\(k^{th}\\) vehicle in the fleet for year \\(j\\). Then, the total losses for the fleet in year \\(j\\) are \\(Y_{j1}+\\cdots+Y_{jm_j}\\) where we are adding up the losses for each of the \\(m_j\\) vehicles. In the Bühlmann-Straub model it is assumed that random variables \\(Y_{jk}\\) are iid across all vehicles and years for the policyholder. With this assumption the means E(\\(Y_{jk}|\\theta)=\\mu(\\theta)\\) and variances Var(\\(Y_{jk}|\\theta)=\\sigma^2(\\theta)\\) are the same for all vehicles and years. The quantity \\(\\mu(\\theta)\\) is the expected loss and \\(\\sigma^2(\\theta)\\) is the variance in the loss for one year for one vehicle for a policyholder with risk parameter \\(\\theta\\). If \\(X_j\\) is the average loss per unit of exposure in year \\(j\\), \\(X_j=(Y_{j1}+\\cdots+Y_{jm_j})/m_j\\), then E(\\(X_j|\\theta)=\\mu(\\theta)\\) and Var(\\(X_j|\\theta)=\\sigma^2(\\theta)/m_j\\) for policyholder with risk parameter \\(\\theta\\). Note that we used the fact that the \\(Y_{jk}\\) are iid for a given policyholder. The average loss per vehicle for the entire \\(n\\)-year period is \\[\\begin{equation*} \\bar{X}= \\frac{1}{m} \\sum_{j=1}^{n} m_j X_{j} \\quad , \\quad m=\\sum_{j=1}^{n} m_j. \\end{equation*}\\] It follows that E\\((\\bar{X}|\\theta)=\\mu(\\theta)\\) and Var\\((\\bar{X}|\\theta)=\\sigma^2(\\theta)/m\\) where \\(\\mu(\\theta)\\) and \\(\\sigma^2(\\theta)\\) are the mean and variance for a single vehicle for one year for the policyholder. Example 9.4.1. Prove that Var\\((\\bar{X}|\\theta)=\\sigma^2(\\theta)/m\\) for a risk with risk parameter \\(\\theta\\). Show Example Solution Solution \\[\\begin{eqnarray*} \\mathrm{Var}(\\bar{X}|\\theta)&amp;=&amp;\\mathrm{Var}\\left(\\frac{1}{m} \\sum_{j=1}^{n} m_j X_j|\\theta \\right)\\\\ &amp;=&amp;\\frac{1}{m^2}\\sum_{j=1}^{n} \\mathrm{Var}(m_j X_{j}|\\theta)=\\frac{1}{m^2}\\sum_{j=1}^{n} m_j^2 \\mathrm{Var}(X_j|\\theta)\\\\ &amp;=&amp;\\frac{1}{m^2}\\sum_{j=1}^{n} m_j^2 (\\sigma^2(\\theta)/m_j)=\\frac{\\sigma^2(\\theta)}{m^2}\\sum_{j=1}^{n} m_j=\\sigma^2(\\theta)/m.\\\\ \\end{eqnarray*}\\] The Buhlmann-Straub credibility estimate is: \\[\\begin{equation}\\hat{\\mu}(\\theta)=Z\\bar{X}+(1-Z)\\mu \\tag{9.9} \\end{equation}\\] with \\[\\begin{eqnarray*} \\theta&amp;=&amp;\\textrm{a risk parameter that identifies a policyholder&#39;s risk level}\\\\ \\hat{\\mu}(\\theta)&amp;=&amp;\\textrm{estimated expected loss for one exposure for the policyholder}\\\\ &amp; &amp; \\textrm{with loss experience } \\bar{X}\\\\ \\bar{X}&amp;=&amp; \\frac{1}{m} \\sum_{j=1}^{n} m_j X_j \\textrm{ is the average loss per exposure for $m$ exposures.}\\\\ &amp; &amp; \\textrm{$X_j$ is the average loss per exposure and $m_j$ is the number of exposures in year $j$.} \\\\ Z&amp;=&amp;\\textrm{credibility assigned to $m$ exposures } \\\\ \\mu&amp;=&amp;\\textrm{expected loss for one exposure for randomly chosen}\\\\ &amp; &amp; \\textrm{ policyholder from population.}\\\\ \\end{eqnarray*}\\] Note that \\(\\hat{\\mu}(\\theta)\\) is the estimator for the expected loss for one exposure. If the policyholder has \\(m_j\\) exposures then the expected loss is \\(m_j\\hat{\\mu}(\\theta)\\). In an example in the prior section it was shown that \\(Z\\)=Var(E(\\(\\bar{X}|\\theta\\)))/Var(\\(\\bar{X}\\)) where \\(\\bar{X}\\) is the average loss for \\(n\\) observations. In equation (9.9) the \\(\\bar{X}\\) is the average loss for \\(m\\) exposures and the same \\(Z\\) formula can be used: \\[ Z=\\frac{\\mathrm{Var}(\\mathrm{E}(\\bar{X}|\\theta))}{\\mathrm{Var}(\\bar{X})}= \\frac{\\mathrm{Var}(\\mathrm{E}(\\bar{X}|\\theta))}{\\mathrm{E}(\\mathrm{Var}(\\bar{X}|\\theta))+\\mathrm{Var}(\\mathrm{E}(\\bar{X}|\\theta))}. \\] The denominator was expanded using the law of total variance. As noted above \\(\\mathrm{E}(\\bar{X}|\\theta)=\\mu(\\theta)\\) so \\(\\mathrm{Var}(\\mathrm{E}(\\bar{X}|\\theta))=\\mathrm{Var}(\\mu(\\theta))=VHM\\). Because Var\\((\\bar{X}|\\theta)=\\sigma^2(\\theta)/m\\) it follows that E(Var(\\(\\bar{X}|\\theta\\)))=E(\\(\\sigma^2(\\theta))/m\\)=EPV/m. Making these substitutions and a little algebra gives \\[\\begin{equation} Z=\\frac{m}{m+K} \\quad , \\quad K =\\frac{EPV}{VHM}. \\tag{9.10} \\end{equation}\\] This is the same \\(Z\\) as for Bühlmann credibility except number of exposures \\(m\\) replaces number of years or observations \\(n\\). Example 9.4.2. A commercial automobile policyholder had the following exposures and claims over a three-year period: \\[\\begin{matrix} \\begin{array}{|c|c|c|} \\hline \\text{Year} &amp; \\text{Number of Vehicles} &amp; \\text{Number of Claims} \\\\ \\hline 1 &amp; 9 &amp; 5 \\\\ 2 &amp; 12 &amp; 4 \\\\ 3 &amp; 15 &amp; 4 \\\\ \\hline \\end{array} \\end{matrix}\\] The number of claims in a year for each vehicle in the policyholder’s fleet is Poisson distributed with the same mean (parameter) \\(\\lambda\\). Parameter \\(\\lambda\\) is distributed among the policyholders in the population with pdf \\(f(\\lambda)=6\\lambda(1-\\lambda)\\) with \\(0&lt;\\lambda&lt;1\\). The policyholder has 18 vehicles in its fleet in year 4. Use Bühlmann-Straub credibility to estimate the expected number of policyholder claims in year 4. Show Example Solution Solution The expected number of claims for one vehicle for a randomly chosen policyholder is \\(\\mu=\\mathrm{E}(\\lambda)=\\int_{0}^{1} \\lambda[6\\lambda(1-\\lambda)] d\\lambda=1/2\\). The average number of claims per vehicle for the policyholder is \\(\\bar{X}\\)=13/36. The Expected Value of the Process Variance for a single vehicle is EPV=E(\\(\\lambda)=1/2\\). The Variance of the Hypothetical Means across policyholders is VHM=Var(\\(\\lambda\\))=E(\\(\\lambda^2\\))-\\((\\mathrm{E}(\\lambda))^2=\\int_{0}^{1} \\lambda^2[6\\lambda(1-\\lambda)] d\\lambda-(1/2)^2=(3/10)-(1/4)=(6/20)-(5/20)=1/20\\). So, \\(K\\)=EPV/VHM=(1/2)/(1/20)=10. The number of exposures in the experience period is \\(m=9+12+15=36\\). The credibility is \\(Z=36/(36+10)=18/23\\). The credibility-weighted estimate for the number of claims for one vehicle is \\(\\hat{\\mu}(\\theta)=Z\\bar{X}+(1-Z)\\mu\\)=(18/23)(13/36)+(5/23)(1/2)=9/23. With 18 vehicles in the fleet in year 4 the expected number of claims is 18(9/23)=162/23=7.04 . 9.5 Bayesian Inference and Bühlmann Credibility In this section, you learn how to: Use Bayes Theorem to determine a formula for the expected loss of a risk given a likelihood and prior distribution. Determine the posterior distributions for the Gamma-Poisson and Beta-Binomial Bayesian models and compute expected values. Understand the connection between the Bühlmann and Bayesian estimates for the Gamma-Poisson and Beta-Binomial models. Section 4.4 reviews Bayesian inference and it is assumed that the reader is familiar with that material. The reader is also advised to read the Bühlmann credibility section in this chapter. This section will compare Bayesian inference with Bühlmann credibility and show connections between the two models. A risk with risk parameter \\(\\theta\\) has expected loss \\(\\mu(\\theta)=E(X|\\theta)\\) with random variable \\(X\\) representing pure premium, aggregate loss, number of claims, claim severity, or some other measure of loss during a period of time. If the risk has \\(n\\) losses \\(X_1,\\ldots, X_n\\) during n separate periods of time, then these losses are assumed to be \\(iid\\) for the policyholder and \\(\\mu(\\theta)=E(X_i|\\theta)\\) for \\(i=1,..,n\\). If the risk had \\(n\\) losses \\(x_1,\\ldots, x_n\\) then E(\\(\\mu(\\theta)|x_1,\\ldots, x_n)\\) is the conditional expectation of \\(\\mu(\\theta)\\). The Bühlmann credibility formula \\(\\hat{\\mu}(\\theta)=Z\\bar{X}+(1-Z)\\mu\\) is a linear function of \\(\\bar{X}=(x_1+\\cdots+x_n)/n\\) used to estimate \\(E(\\mu(\\theta)|x_1,\\ldots,x_n)\\). The expectation \\(E(\\mu(\\theta)|x_1,\\ldots,x_n)\\) can be calculated from the conditional density function \\(f(x|\\theta)\\) and the posterior distribution \\(\\pi(\\theta|x_1,\\ldots,x_n)\\): \\[\\begin{eqnarray*} \\mathrm{E}(\\mu(\\theta)|x_1,\\ldots,x_n)&amp;=&amp;\\int \\mu(\\theta) \\pi(\\theta|x_1,\\ldots,x_n) d\\theta \\\\ \\mu(\\theta)&amp;=&amp;\\mathrm{E}(X|\\theta)=\\int xf(x|\\theta) dx .\\\\ \\end{eqnarray*}\\] The posterior distribution comes from Bayes theorem \\[\\begin{equation*} \\pi(\\theta|x_1,\\ldots,x_n)=\\frac{\\prod_{j=1}^{n} f(x_j|\\theta)}{f(x_1,\\ldots,x_n)}\\pi({\\theta}). \\end{equation*}\\] The conditional density function \\(f(x|\\theta)\\) and the prior distribution \\(\\pi(\\theta)\\) must be specified. The numerator \\(\\prod_{j=1}^{n} f(x_j|\\theta)\\) on the right-hand side is called the likelihood. The denominator \\(f(x_1,\\ldots,x_n)\\) is the joint density function for \\(n\\) losses \\(x_1,\\ldots,x_n\\). 9.5.1 Gamma-Poisson Model In the Gamma-Poisson model the number of claims \\(X\\) has a Poisson distribution Pr(\\(X=x|\\lambda)=\\lambda^xe^{-\\lambda}/x!\\) for a risk with risk parameter \\(\\lambda\\). The prior distribution for \\(\\lambda\\) is gamma with \\(\\pi(\\lambda)=\\beta^\\alpha\\lambda^{\\alpha-1}e^{-\\beta\\lambda}/\\Gamma(\\alpha)\\). (Note that a rate parameter \\(\\beta\\) is being used in the gamma distribution rather than a scale parameter.) The mean of the gamma is E(\\(\\lambda)=\\alpha/\\beta\\) and the variance is Var(\\(\\lambda)=\\alpha/\\beta^2\\). In this section we will assume that \\(\\lambda\\) is the expected number of claims per year though we could have chosen another time interval. If a risk is selected at random from the population then the expected number of claims in a year is E(\\(N\\))=E(E(\\(N|\\lambda\\)))=E(\\(\\lambda\\))=\\(\\alpha/\\beta\\). If we had no observations for the selected risk then the expected number of claims for the risk is \\(\\alpha/\\beta\\). During \\(n\\) years the following number of claims by year was observed for the randomly selected risk: \\(x_1,\\ldots,x_n\\). From Bayes theorem the posterior distribution is \\[\\begin{equation*} \\pi(\\lambda|x_1,\\ldots,x_n)=\\frac{\\prod_{j=1}^{n} (\\lambda^{x_j}e^{-\\lambda}/x_j!)}{\\Pr(X_1=x_1,\\ldots,X_n=x_n)}\\beta^\\alpha\\lambda^{\\alpha-1}e^{-\\beta\\lambda}/\\Gamma(\\alpha). \\end{equation*}\\] Combining terms that have a \\(\\lambda\\) and putting all other terms into constant \\(C\\) gives \\[\\begin{equation*} \\pi(\\lambda|x_1,\\ldots,x_n)=C\\lambda^{(\\alpha+\\sum_{j=1}^{n}x_j)-1}e^{-(\\beta+n)\\lambda}. \\end{equation*}\\] This is a gamma distribution with parameters \\(\\alpha&#39;=\\alpha+\\sum_{j=1}^{n}x_j\\) and \\(\\beta&#39;=\\beta+n\\). The constant must be \\(C={\\beta&#39;}^{\\alpha&#39;}/\\Gamma(\\alpha&#39;)\\) so that \\(\\int_{0}^{\\infty}\\pi(\\lambda|x_1,\\ldots,x_n) d\\lambda=1\\) though we do not need to know \\(C\\). As explained in chapter four the gamma distribution is a conjugate prior for the Poisson distribution so the posterior distribution is also gamma. Because the posterior distribution is gamma the expected number of claims for the selected risk is \\[\\begin{equation*} \\mathrm{E}(\\lambda|x_1,\\ldots,x_n) = \\frac{\\alpha+\\sum_{j=1}^{n}x_j}{\\beta+n}=\\frac{\\alpha + \\textrm{number of claims}}{\\beta+\\textrm{number of years}}. \\end{equation*}\\] This formula is slightly different from chapter four because parameter \\(\\beta\\) is multiplied by \\(\\lambda\\) in the exponential of the gamma pdf whereas in chapter four \\(\\lambda\\) is divided by parameter \\(\\theta\\). We have chosen this form for the exponential to simplify the equation for the expected number of claims. Now we will compute the Bühlmann credibility estimate for the Gamma-Poisson model. The variance for a Poisson distribution with parameter \\(\\lambda\\) is \\(\\lambda\\) so EPV=E(Var(\\(X|\\lambda\\)))=E(\\(\\lambda\\))=\\(\\alpha/\\beta\\). The mean number of claims per year for the risk is \\(\\lambda\\) so VHM=Var(E(\\(X|\\lambda\\)))=Var(\\(\\lambda\\))=\\(\\alpha/\\beta^2\\). The credibility parameter is \\(K\\)=EPV/VHM=\\((\\alpha/\\beta)/(\\alpha/\\beta^2)=\\beta\\). The overall mean is E(E(\\(X|\\lambda\\)))=E(\\(\\lambda\\))=\\(\\alpha/\\beta\\). The sample mean is \\(\\bar{X}=(\\sum_{j=1}^{n}x_j)/n\\). The credibility-weighted estimate for the expected number of claims for the risk is \\[\\begin{equation*} \\hat{\\mu}=\\frac{n}{n+\\beta}\\frac{\\sum_{j=1}^{n}x_j}{n} +(1-\\frac{n}{n+\\beta})\\frac{\\alpha}{\\beta}=\\frac{\\alpha+\\sum_{j=1}^{n}x_j}{\\beta+n}. \\end{equation*}\\] For the Gamma-Poisson model the Bühlmann credibility estimate matches the Bayesian analysis result. 9.5.2 Beta-Binomial Model The Beta-Binomial model is useful for modeling the probability of an event. Assume that random variable \\(X\\) is the number of successes in \\(n\\) trials and that \\(X\\) has a binomial distribution Pr(\\(X=x|p)=\\binom{n}{x}p^x(1-p)^{n-x}\\). In the Beta-Binomial model the prior distribution for probability \\(p\\) is a beta distribution with pdf \\[\\begin{equation*} \\pi(p)=\\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}p^{\\alpha-1}(1-p)^{\\beta-1} , \\quad 0&lt;p&lt;1, \\alpha&gt;0, \\beta&gt;0. \\end{equation*}\\] The posterior distribution for \\(p\\) given an outcome of \\(x\\) successes in \\(n\\) trials is \\[\\begin{equation*} \\pi(p|x)=\\frac{\\binom{n}{x}p^x(1-p)^{n-x}}{\\Pr(x)}\\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}p^{\\alpha-1}(1-p)^{\\beta-1}. \\end{equation*}\\] Combining terms that have a \\(p\\) and putting everything else into the constant \\(C\\) yields \\[\\begin{equation*} \\pi(p| x)=Cp^{\\alpha+x-1}(1-p)^{\\beta+(n-x)-1}. \\end{equation*}\\] This is a beta distribution with new parameters \\(\\alpha^\\prime=\\alpha+x\\) and \\(\\beta^\\prime=\\beta+(n-x)\\). The constant must be \\[\\begin{equation*} C=\\frac{\\Gamma(\\alpha+\\beta+n)}{\\Gamma(\\alpha+x)\\Gamma(\\beta+n-x)}. \\end{equation*}\\] The mean for the beta distribution with parameters \\(\\alpha\\) and \\(\\beta\\) is E(\\(p)=\\alpha/(\\alpha+\\beta)\\). Given \\(x\\) successes in \\(n\\) trials in the Beta-Binomial model the mean of the posterior distribution is \\[\\begin{equation*} E(p|x)=\\frac{\\alpha+x}{\\alpha+\\beta+n}. \\end{equation*}\\] As the number of trials \\(n\\) and successes \\(x\\) increase, the expected value of \\(p\\) approaches \\(x/n\\). The Bühlmann credibility estimate for E(\\(p|x\\)) is exactly as the same as the Bayesian estimate as demonstrated in the following example. Example 9.5.1 The probability that a coin toss will yield heads is \\(p\\). The prior distribution for probability \\(p\\) is beta with parameters \\(\\alpha\\) and \\(\\beta\\). On \\(n\\) tosses of the coin there were exactly \\(x\\) heads. Use Bühlmann credibility to estimate the expected value of \\(p\\). Show Example Solution Solution Define random variables \\(Y_j\\) such that \\(Y_j=1\\) if the \\(j^{th}\\) coin toss is heads and \\(Y_j=0\\) if tails for \\(j=1,\\ldots, n\\). Random variables \\(Y_j\\) are iid conditional on \\(p\\) with Pr\\([Y=1|p]=p\\) and Pr\\([Y=0|p]=1-p\\) The number of heads in \\(n\\) tosses can be represented by the random variable \\(X=Y_1+\\cdots+Y_n\\). We want to estimate \\(p=E[Y_j]\\) using Bühlmann credibility: \\(\\hat{p} = Z\\bar{Y} +(1-Z)\\mu\\). The overall mean is \\(\\mu=E(E(Y_j|p))=E(p)=\\alpha/(\\alpha+\\beta)\\). The sample mean is \\(\\bar{y}=x/n\\). The credibility is \\(Z=n/(n+K)\\) and K=EPV/VHM. With Var\\((Y_j|p)=p(1-p)\\) it follows that EPV=E(Var\\((Y_j|p)\\))=E(\\(p(1-p)\\)). Because E\\((Y_j|p)=p\\) then VHM=Var\\((E(Y_j|p))\\)=Var(\\(p\\)). For the beta distribution \\[\\begin{equation*} \\mathrm{E}(p)=\\frac{\\alpha}{\\alpha+\\beta}, \\mathrm{E}(p^2)=\\frac{\\alpha(\\alpha+1)}{(\\alpha+\\beta)(\\alpha+\\beta+1)}, \\textrm{ and } \\mathrm{Var}(p)=\\frac{\\alpha\\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}. \\end{equation*}\\] Parameter \\(K\\)=EPV/VHM=[E(\\(p\\))-E(\\(p^2\\))]/Var(\\(p\\)). With some algebra this reduces to \\(K=\\alpha+\\beta\\). The Bühlmann credibility-weighted estimate is \\[\\begin{align*} \\hat{p} &amp;= \\frac{n}{n+\\alpha+\\beta}\\left(\\frac{x}{n}\\right)+\\left(1-\\frac{n}{n+\\alpha+\\beta}\\right)\\frac{\\alpha}{\\alpha+\\beta} \\\\ \\hat{p} &amp; =\\frac{\\alpha+x}{\\alpha+\\beta+n}\\\\ \\end{align*}\\] which is the same as the Bayesian posterior mean. 9.5.3 Exact Credibility As demonstrated in the prior section, the Bühlmann credibility estimates for the Gamma-Poisson and Beta-Binomial models exactly match the Bayesian analysis results. The term exact credibility is applied in these situations. Exact credibility may occur if the probability distribution for \\(X_j\\) is in the linear exponential family and the prior distribution is a conjugate prior. Besides these two models, examples of exact credibility also include Gamma-Exponential and Normal-Normal models. It is also noteworthy that if the conditional mean E\\((\\mu(\\theta)|X_1,...,X_n)\\) is linear in the past observations, then the Bühlmann credibility estimate will coincide with the Bayesian estimate. More information about exact credibility can be found in (Bühlmann and Gisler 2005), (Klugman, Panjer, and Willmot 2012), and (Tse 2009). 9.6 Estimating Credibility Parameters In this section, you learn how to: Perform nonparametric estimation with the Bühlmann and Bühlmann-Straub credibility models. Identify situations when semiparametric estimation is appropriate. Use data to approximate the EPV and VHM. Balance credibility-weighted estimates. The examples in this chapter have provided assumptions for calculating credibility parameters. In actual practice the actuary must use real world data and judgment to determine credibility parameters. 9.6.1 Full Credibility Standard for Limited Fluctuation Credibility Limited-fluctuation credibility requires a full credibility standard. The general formula for aggregate losses or pure premium, as obtained in formula (9.5), is \\[\\begin{equation*} n_S=\\left(\\frac{y_p}{k}\\right)^2\\left[\\left(\\frac{\\sigma_N^2}{\\mu_N}\\right)+\\left(\\frac{\\sigma_X}{\\mu_X}\\right)^2\\right] \\end{equation*}\\] with \\(N\\) representing number of claims and \\(X\\) the size of claims. If one assumes \\(\\sigma_X=0\\) then the full credibility standard for frequency results. If \\(\\sigma_N=0\\) then the full credibility formula for severity follows. Probability \\(p\\) and \\(k\\) value are often selected using judgment and experience. In practice it is often assumed that the number of claims is Poisson distributed so that \\(\\sigma_N^2/\\mu_N=1\\). In this case the formula can be simplified to \\[\\begin{equation*} n_S=\\left(\\frac{y_p}{k}\\right)^2\\left[\\frac{\\mathrm{E}(X^2)}{(\\mathrm{E}(X))^2}\\right]. \\end{equation*}\\] An empirical mean and second moment for the sizes of individual claim losses can be computed from past data, if available. 9.6.2 Nonparametric Estimation for Bühlmann and Bühlmann-Straub Models Bayesian analysis as described previously requires assumptions about a prior distribution and likelihood. It is possible to produce estimates without these assumptions and these methods are often referred to as empirical Bayes methods. Bühlmann and Bühlmann-Straub credibility with parameters estimated from the data are included in the category of empirical Bayes methods. Bühlmann Model First we will address the simpler Bühlmann model. Assume that there are \\(r\\) risks in a population. For risk \\(i\\) with risk parameter \\(\\theta_i\\) the losses for \\(n\\) periods are \\(X_{i1},\\ldots, X_{in}\\). The losses for a given risk are iid across periods as assumed in the Bühlmann model. For risk \\(i\\) the sample mean is \\(\\bar{X}_i=\\sum_{j=1}^{n}X_{ij}/n\\) and the unbiased sample process variance is \\(s_i^2=\\sum_{j=1}^{n}(X_{ij}-\\bar{X}_i)^2/(n-1)\\). An unbiased estimator for the EPV can be calculated by taking the average of \\(s_i^2\\) for the \\(r\\) risks in the population: \\[\\begin{equation} \\widehat{EPV}=\\frac{1}{r}\\sum_{i=1}^{r} s_i^2 = \\frac{1}{r(n-1)} \\sum_{i=1}^{r} \\sum_{j=1}^{n}(X_{ij}-\\bar{X}_i)^2 . \\tag{9.11} \\end{equation}\\] The individual risk means \\(\\bar{X}_i\\) for \\(i=1,\\ldots, r\\) can be used to estimate the VHM. An unbiased estimator of Var(\\(\\bar{X}_i\\)) is \\[\\begin{equation*} \\widehat{\\mathrm{Var}}(\\bar{X}_i)=\\frac{1}{r-1} \\sum_{i=1}^{r}(\\bar{X}_i-\\bar{X})^2 \\textrm{ and } \\bar{X}=\\frac{1}{r}\\sum_{i=1}^{r} \\bar{X}_i, \\end{equation*}\\] but Var(\\(\\bar{X}_i\\)) is not the VHM. The total variance formula or unconditional variance formula is \\[\\begin{equation*} \\mathrm{Var}(\\bar{X}_i)=\\textrm{E(Var}(\\bar{X}_i|\\Theta=\\theta_i))+\\textrm{Var(E}(\\bar{X}_i|\\Theta=\\theta_i)). \\end{equation*}\\] The VHM is the second term on the right because \\(\\mu(\\theta_i)=\\mathrm{E}(\\bar{X}_i|\\Theta=\\theta_i)\\) is the hypothetical mean for risk \\(i\\). So, \\[\\begin{equation*} VHM=\\textrm{Var(E}(\\mu(\\theta_i)) = \\mathrm{Var}(\\bar{X}_i) - \\textrm{E(Var}(\\bar{X}_i|\\Theta=\\theta_i)). \\end{equation*}\\] As discussed previously in Section 9.3.1, EPV/n = E(Var(\\(\\bar{X}_i|\\Theta=\\theta_i\\))) and using the above estimators gives an unbiased estimator for the VHM: \\[\\begin{equation} \\widehat{VHM} = \\frac{1}{r-1} \\sum_{i=1}^{r}(\\bar{X}_i-\\bar{X})^2 - \\frac{\\widehat{EPV}}{n} . \\tag{9.12} \\end{equation}\\] Although the expected loss for a risk with parameter \\(\\theta_i\\) is \\(\\mu(\\theta_i)\\)=E(\\(\\bar{X}_i|\\Theta=\\theta_i\\)), the variance of the sample mean \\(\\bar{X}_i\\) is greater than or equal to the variance of the hypothetical means: Var(\\(\\bar{X}_i)\\geq\\)Var(\\(\\mu(\\theta_i)\\)). The variance in the sample means Var(\\(\\bar{X}_i\\)) includes both the variance in the hypothetical means plus a process variance term. In some cases formula (9.12) can produce a negative value for \\(\\widehat{VHM}\\) because of the subtraction of \\(\\widehat{EPV}/n\\), but a variance cannot be negative. The process variance within risks is so large that it overwhelms the measurement of the variance in means between risks. In this case we cannot use this method to determine the values needed for Bühlmann credibility. Example 9.6.1. Two policyholders had claims over a three-year period as shown in the table below. Estimate the expected number of claims for each policyholder using Bühlmann credibility and calculating necessary parameters from the data. \\[\\begin{matrix} \\begin{array}{|c|c|c|} \\hline \\text{Year} &amp; \\text{Risk A} &amp; \\text{Risk B} \\\\ \\hline 1 &amp; 0 &amp; 2 \\\\ 2 &amp; 1 &amp; 1 \\\\ 3 &amp; 0 &amp; 2 \\\\ \\hline \\end{array} \\end{matrix}\\] Show Example Solution Solution \\(\\bar{x}_A=\\frac{1}{3}(0+1+0)=\\frac{1}{3}\\), \\(\\bar{x}_B=\\frac{1}{3}(2+1+2)=\\frac{5}{3}\\) \\(\\bar{x}=\\frac{1}{2}(\\frac{1}{3}+\\frac{5}{3})=1\\) \\(s_A^2=\\frac{1}{3-1}\\left[(0-\\frac{1}{3})^2+(1-\\frac{1}{3})^2+(0-\\frac{1}{3})^2\\right]=\\frac{1}{3}\\) \\(s_B^2=\\frac{1}{3-1}\\left[(2-\\frac{5}{3})^2+(1-\\frac{5}{3})^2+(2-\\frac{5}{3})^2\\right]=\\frac{1}{3}\\) \\(\\widehat{EPV}=\\frac{1}{2}\\left(\\frac{1}{3}+\\frac{1}{3}\\right)=\\frac{1}{3}\\) \\(\\widehat{VHM}=\\frac{1}{2-1}\\left[(\\frac{1}{3}-1)^2+(\\frac{5}{3}-1)^2\\right]-\\frac{1/3}{3}=\\frac{7}{9}\\) \\(K=\\frac{1/3}{7/9}=\\frac{3}{7}\\) \\(Z=\\frac{3}{3+(3/7))}=\\frac{7}{8}\\) \\(\\hat{\\mu}_A=\\frac{7}{8}\\left(\\frac{1}{3}\\right)+(1-\\frac{7}{8})1=\\frac{5}{12}\\) \\(\\hat{\\mu}_B=\\frac{7}{8}\\left(\\frac{5}{3}\\right)+(1-\\frac{7}{8})1=\\frac{19}{12}\\) Example 9.6.2. Two policyholders had claims over a three-year period as shown in the table below. Calculate the nonparametric estimate for the VHM. \\[\\begin{matrix} \\begin{array}{|c|c|c|} \\hline \\text{Year} &amp; \\text{Risk A} &amp; \\text{Risk B} \\\\ \\hline 1 &amp; 3 &amp; 3 \\\\ 2 &amp; 0 &amp; 0 \\\\ 3 &amp; 0 &amp; 3 \\\\ \\hline \\end{array} \\end{matrix}\\] Show Example Solution Solution \\(\\bar{x}_A=\\frac{1}{3}(3+0+0)=1\\), \\(\\bar{x}_B=\\frac{1}{3}(3+0+3)=2\\) \\(\\bar{x}=\\frac{1}{2}(1+2)=\\frac{3}{2}\\) \\(s_A^2=\\frac{1}{3-1}\\left[(3-1)^2+(0-1)^2+(0-1)^2\\right]=3\\) \\(s_B^2=\\frac{1}{3-1}\\left[(3-2)^2+(0-2)^2+(3-2)^2\\right]=3\\) \\(\\widehat{EPV}=\\frac{1}{2}(3+3)=3\\) \\(\\widehat{VHM}=\\frac{1}{2-1}\\left[(1-\\frac{3}{2})^2+(2-\\frac{3}{2})^2\\right]-\\frac{3}{3}=-\\frac{1}{2}.\\) The process variance is so large that it is not possible to estimate the VHM. Bühlmann-Straub Model Empirical formulas for EPV and VHM in the Bühlmann-Straub model are more complicated because a risk’s number of exposures can change from one period to another. Also, the number of experience periods does not have to be constant across the population. First some definitions: \\(X_{ij}\\) is the losses per exposure for risk \\(i\\) in period \\(j\\). Losses can refer to number of claims or amount of loss. There are \\(r\\) risks so \\(i=1,\\ldots,r\\). \\(n_i\\) is the number of observation periods for risk \\(i\\) \\(m_{ij}\\) is the number of exposures for risk \\(i\\) in period \\(j\\) for \\(j=1,\\ldots,n_i\\) Risk \\(i\\) with risk parameter \\(\\theta_i\\) has \\(m_{ij}\\) exposures in period \\(j\\) which means that the losses per exposure random variable can be written as \\(X_{ij}=(Y_{i1}+\\cdots+Y_{im_{ij}})/m_{ij}\\). Random variable \\(Y_{ik}\\) is the loss for one exposure. For risk \\(i\\) losses \\(Y_{ik}\\) are iid with mean E(\\(Y_{ik}\\))=\\(\\mu(\\theta_i)\\) and process variance Var(\\(Y_{ik}\\))=\\(\\sigma^2(\\theta_i)\\). It follows that Var(\\(X_{ij})\\)=\\(\\sigma^2(\\theta_i)/m_{ij}\\). Two more important definitions are: \\(\\bar{X}_i=\\frac{1}{m_i}\\sum_{j=1}^{n_i} m_{ij}X_{ij}\\) with \\(m_i = \\sum_{j=1}^{n_i} m_{ij}\\). \\(\\bar{X}_i\\) is the average loss per exposure for risk \\(i\\) for all observation periods combined. \\(\\bar{X}=\\frac{1}{m}\\sum_{i=1}^{r} m_i \\bar{X}_i\\) with \\(m=\\sum_{i=1}^r m_i\\). \\(\\bar{X}\\) is the average loss per exposure for all risks for all observation periods combined. An unbiased estimator for the process variance \\(\\sigma^2(\\theta_i)\\) of one exposure for risk \\(i\\) is \\[\\begin{equation*} {s_i}^2=\\frac{\\sum_{j=1}^{n_i} m_{ij}(X_{ij}-\\bar{X}_i)^2}{n_i-1}. \\end{equation*}\\] The weights \\(m_{ij}\\) are applied to the squared differences because the \\(X_{ij}\\) are the averages of \\(m_{ij}\\) exposures. The weighted average of the sample variances \\({s_i}^2\\) for each risk \\(i\\) in the population with weights proportional to the number of \\((n_i-1)\\) observation periods will produce the expected value of the process variance (EPV) estimate \\[\\begin{equation*} \\widehat{EPV}=\\frac{\\sum_{i=1}^r (n_i-1){s_i}^2}{\\sum_{i=1}^r (n_i-1)}=\\frac{\\sum_{i=1}^r \\sum_{j=1}^{n_i} m_{ij}(X_{ij}-\\bar{X}_i)^2}{\\sum_{i=1}^r (n_i-1)}. \\end{equation*}\\] The quantity \\(\\widehat{EPV}\\) is an unbiased estimator for the expected value of the process variance of one exposure for a risk chosen at random from the population. To calculate an estimator for the variance in the hypothetical means (VHM) the squared differences of the individual risk sample means \\(\\bar{X}_i\\) and population mean \\(\\bar{X}\\) are used. An unbiased estimator for the VHM is \\[\\begin{equation*} \\widehat{VHM}=\\frac{\\sum_{i=1}^r m_i(\\bar{X}_i-\\bar{X})^2 - (r-1)\\widehat{EPV}}{m-\\frac{1}{m}\\sum_{i=1}^r m_i^2}. \\end{equation*}\\] This complicated formula is necessary because of the varying number of exposures. Proofs that the EPV and VHM estimators shown above are unbiased can be found in several references mentioned at the end of this chapter including (Bühlmann and Gisler 2005), (Klugman, Panjer, and Willmot 2012), and (Tse 2009). Example 9.6.3. Two policyholders had claims shown in the table below. Estimate the expected number of claims per vehicle for each policyholder using Bühlmann-Straub credibility and calculating parameters from the data. \\[\\begin{matrix} \\begin{array}{|c|c|c|c|c|c|} \\hline \\text{Policyholder} &amp; &amp; \\text{Year 1} &amp; \\text{Year 2} &amp; \\text{Year 3} &amp; \\text{Year 4} \\\\ \\hline \\text{A} &amp; \\text{Number of claims} &amp; 0 &amp; 2 &amp; 2 &amp; 3 \\\\ \\hline \\text{A} &amp; \\text{Insured vehicles} &amp; 1 &amp; 2 &amp; 2 &amp; 2\\\\ \\hline &amp; &amp; &amp; &amp; &amp; \\\\ \\hline \\text{B} &amp; \\text{Number of claims} &amp; 0 &amp; 0 &amp; 1 &amp; 2\\\\ \\hline \\text{B} &amp; \\text{Insured vehicles} &amp; 0 &amp; 2 &amp; 3 &amp; 4\\\\ \\hline \\end{array} \\end{matrix}\\] Show Example Solution Solution \\(\\bar{x}_A=\\frac{0+2+2+3}{1+2+2+2}=1\\) \\(\\bar{x}_B=\\frac{0+1+2}{2+3+4}=\\frac{1}{3}\\) \\(\\bar{x}=\\frac{7(1)+9(1/3)}{7+9}=\\frac{5}{8}\\) \\(s_A^2=\\frac{1}{4-1}\\left[1(0-1)^2+2(1-1)^2+2(1-1)^2+2(\\frac{3}{2}-1)^2\\right]=\\frac{1}{2 }\\) \\(s_B^2=\\frac{1}{3-1}\\left[2(0-\\frac{1}{3})^2+3(\\frac{1}{3}-\\frac{1}{3})^2+4(\\frac{1}{2}-\\frac{1}{3})^2\\right]=\\frac{1}{6}\\) \\(\\widehat{EPV}=\\left[3\\left(\\frac{1}{2}\\right)+2\\left(\\frac{1}{6}\\right)\\right]/(3+2)=\\frac{11}{30}=0.3667\\) \\(\\widehat{VHM}=\\left[(7(1-\\frac{5}{8})^2+9(\\frac{1}{3}-\\frac{5}{8})^2-(2-1)\\frac{11}{30}\\right]/\\left[16-\\left(\\frac{1}{16}\\right)(7^2+9^2)\\right]=0.1757\\) \\(K=\\frac{0.3667}{0.1757}=2.0871\\) \\(m_A=7\\), \\(m_B=9\\) \\(Z_A=\\frac{7}{7+2.0871}=0.7703\\), \\(Z_B=\\frac{9}{9+2.0871}=0.8118\\) \\(\\hat{\\mu}_A=0.7703(1)+(1-0.7703)(5/8)=0.9139\\) \\(\\hat{\\mu}_B=0.8118(1/3)+(1-0.8118)(5/8)=0.3882\\) 9.6.3 Semiparametric Estimation for Bühlmann and Bühlmann-Straub Models In the prior section on nonparametric estimation, there were no assumptions about the distribution of the losses per exposure \\(X_{ij}\\). Assuming that the \\(X_{ij}\\) have a particular distribution and using properties of the distribution along with the data to determine credibility parameters is referred to as semiparametric estimation. An example of semiparametric estimation would be the assumption of a Poisson distribution when estimating claim frequencies. The Poisson distribution has the property that the mean and variance are identical and this property can simplify calculations. The following simple example comes from the prior section but now includes a Poisson assumption about claim frequencies. Example 9.6.4. Two policyholders had claims over a three-year period as shown in the table below. Assume that the number of claims for each risk has a Poisson distribution. Estimate the expected number of claims for each policyholder using Bühlmann credibility and calculating necessary parameters from the data. \\[\\begin{matrix} \\begin{array}{|c|c|c|} \\hline \\text{Year} &amp; \\text{Risk A} &amp; \\text{Risk B} \\\\ \\hline 1 &amp; 0 &amp; 2 \\\\ 2 &amp; 1 &amp; 1 \\\\ 3 &amp; 0 &amp; 2 \\\\ \\hline \\end{array} \\end{matrix}\\] Show Example Solution Solution \\(\\bar{x}_A=\\frac{1}{3}(0+1+0)=\\frac{1}{3}\\), \\(\\bar{x}_B=\\frac{1}{3}(2+1+2)=\\frac{5}{3}\\) \\(\\bar{x}=\\frac{1}{2}(\\frac{1}{3}+\\frac{5}{3})=1\\) With Poisson assumption the estimated variance for risk A is \\(\\hat\\sigma_A^2=\\bar{x}_A=\\frac{1}{3}\\) Similarly, \\(\\hat\\sigma_B^2=\\bar{x}_B=\\frac{5}{3}\\) \\(\\widehat{EPV}=\\frac{1}{2}(\\frac{1}{3})+\\frac{1}{2}(\\frac{5}{3})=1\\). This is also \\(\\bar{x}\\) because of Poisson assumption. \\(\\widehat{VHM}=\\frac{1}{2-1}\\left[(\\frac{1}{3}-1)^2+(\\frac{5}{3}-1)^2\\right]-\\frac{1}{3}=\\frac{5}{9}\\) \\(K=\\frac{1}{5/9}=\\frac{9}{5}\\) \\(Z_A=Z_B=\\frac{3}{3+(9/5)}=\\frac{5}{8}\\) \\(\\hat{\\mu}_A=\\frac{5}{8}\\left(\\frac{1}{3}\\right)+(1-\\frac{5}{8})1=\\frac{7}{12}\\) \\(\\hat{\\mu}_B=\\frac{5}{8}\\left(\\frac{5}{3}\\right)+(1-\\frac{5}{8})1=\\frac{17}{12}.\\) Although we assumed that the number of claims for each risk was Poisson distributed in the prior example, we did not need this additional assumption because there was enough information to use nonparametric estimation. In fact, the Poisson assumption might not be appropriate because for risk B the sample mean is not equal to the sample variance: \\(\\bar{x}_B=\\frac{5}{3}\\neq s_B^2=\\frac{1}{3}\\). The following example is commonly used to demonstrate a situation where semiparametric estimation is needed. There is insufficient information for nonparametric estimation but with the Poisson assumption, estimates can be calculated. Example 9.6.5. A portfolio of 2,000 policyholders generated the following claims profile during a five-year period: \\[\\begin{matrix} \\begin{array}{|c|c|} \\hline \\text{Number of Claims} &amp; \\\\ \\text{In 5 Years} &amp; \\text{Number of policies}\\\\ \\hline 0 &amp; 923 \\\\ 1 &amp; 682 \\\\ 2 &amp; 249 \\\\ 3 &amp; 70 \\\\ 4 &amp; 51 \\\\ 5 &amp; 25 \\\\ \\hline \\end{array} \\end{matrix}\\] In your model you assume that the number of claims for each policyholder has a Poisson distribution and that a policyholder’s expected number of claims is constant through time. Use Bühlmann credibility to estimate the annual expected number of claims for policyholders with 3 claims during the five-year period. Show Example Solution Solution Let \\(\\theta_i\\) be the risk parameter for the \\(i^{th}\\) risk in the portfolio with mean \\(\\mu(\\theta_i)\\) and variance \\(\\sigma^2(\\theta_i)\\). With the Poisson assumption \\(\\mu(\\theta_i)=\\sigma^2(\\theta_i)\\). The expected value of the process variance is EPV=E(\\(\\sigma^2(\\theta_i)\\)) where the expectation is taken across all risks in the population. Because of the Poisson assumption for all risks it follows that EPV=E(\\(\\sigma^2(\\theta_i)\\))=E(\\(\\mu(\\theta_i)\\)). An estimate for the annual expected number of claims is \\(\\hat{\\mu}(\\theta_i)\\)= (observed number of claims)/5. This can also serve as the estimate for the expected value of the process variance for a risk. Weighting the process variance estimates (or means) by the number of policies in each group gives the estimators \\[\\begin{equation*} \\widehat{EPV}=\\bar{x}=\\frac{923(0)+682(1)+249(2)+70(3)+51(4)+25(5)}{(5)(2000)}=0.1719. \\end{equation*}\\] Using the formula ((9.12)), the VHM estimator is \\[\\begin{eqnarray*} \\widehat{VHM}&amp;=&amp;\\frac{1}{2000-1}[923(0-0.1719)^2+682(0.20-0.1719)^2+249(0.40-0.1719)^2\\\\ &amp; &amp;+70(0.60-0.1719)^2+51(0.80-0.1719)^2+25(1-0.1719)^2]-\\frac{0.1719}{5}\\\\ &amp;=&amp; 0.0111\\\\ \\hat{K} &amp;=&amp; \\widehat{EPV}/\\widehat{VHM}=0.1719/0.0111=15.49\\\\ \\hat{Z} &amp;=&amp; \\frac{5}{5+15.49}=0.2440\\\\ \\hat{\\mu}_{3 \\textrm{ claims}}&amp; = &amp; 0.2440(3/5)+(1-0.2440)0.1719=0.2764 .\\\\ \\end{eqnarray*}\\] 9.6.4 Balancing Credibility Estimators The credibility weighted model \\(\\hat{\\mu}(\\theta_i)=Z_i\\bar{X}_i+(1-Z_i)\\bar{X}\\), where \\(\\bar{X}_i\\) is the loss per exposure for risk \\(i\\) and \\(\\bar{X}\\) is loss per exposure for the population, can be used to estimate the expected loss for risk \\(i\\). The overall mean is \\(\\bar{X}=\\sum_{i=1}^r(m_i/m) \\bar{X}_i\\) where \\(m_i\\) and \\(m\\) are number of exposures for risk \\(i\\) and population, respectively. For the credibility weighted estimators to be in balance we want \\[\\begin{equation*} \\bar{X}=\\sum_{i=1}^r(m_i/m) \\bar{X}_i=\\sum_{i=1}^r(m_i/m) \\hat{\\mu}(\\theta_i). \\end{equation*}\\] If this equation is satisfied then the estimated losses for each risk will add up to the population total, an important goal in ratemaking, but this may not happen if \\(\\bar{X}\\) is used for the complement of credibility. In order to find a complement of credibility that will bring the credibility-weighted estimators into balance we will set \\(\\hat{\\mu}\\) as the complement of credibility and analyze the following equation: \\[\\begin{equation*} \\sum_{i=1}^r(m_i/m) \\bar{X}_i=\\sum_{i=1}^r(m_i/m) (Z_i\\bar{X}_i+(1-Z_i)\\hat{\\mu}) . \\end{equation*}\\] A little algebra gives \\[\\begin{equation*} \\sum_{i=1}^r m_i \\bar{X}_i=\\sum_{i=1}^r m_i Z_i\\bar{X}_i + \\hat{\\mu}\\sum_{i=1}^r m_i(1-Z_i), \\end{equation*}\\] and \\[\\begin{equation*} \\hat{\\mu}=\\frac{\\sum_{i=1}^r m_i(1-Z_i)\\bar{X}_i}{\\sum_{i=1}^r m_i(1-Z_i)}. \\end{equation*}\\] Using this value for \\(\\hat{\\mu}\\) will bring the credibility weighted estimators into balance. If credibilities \\(Z_i\\) were computed using the Bühlmann-Straub model, then \\(Z_i=m_i/(m_i+K)\\). The prior formula can be simplified using the following relationship \\[\\begin{equation*} m_i(1-Z_i)=m_i\\left(1-\\frac{m_i}{m_i+K}\\right)=m_i\\left(\\frac{(m_i+K)-m_i}{m_i+K}\\right)=KZ_i . \\end{equation*}\\] Therefore, a complement of credibility that will bring the credibility-weighed estimators into balance with the overall mean loss per exposure is \\[\\begin{equation*} \\hat{\\mu}=\\frac{\\sum_{i=1}^r Z_i \\bar{X}_i}{\\sum_{i=1}^r Z_i}. \\end{equation*}\\] Example 9.6.6. An example from the nonparametric Bühlmann-Straub section had the following data for two risks. Find the complement of credibility \\(\\hat{\\mu}\\) that will produce credibility-weighted estimates that are in balance. \\[\\begin{matrix} \\begin{array}{|c|c|c|c|c|c|} \\hline \\text{Policyholder} &amp; &amp; \\text{Year 1} &amp; \\text{Year 2} &amp; \\text{Year 3} &amp; \\text{Year 4} \\\\ \\hline \\text{A} &amp; \\text{Number of claims} &amp; 0 &amp; 2 &amp; 2 &amp; 3 \\\\ \\hline \\text{A} &amp; \\text{Insured vehicles} &amp; 1 &amp; 2 &amp; 2 &amp; 2\\\\ \\hline &amp; &amp; &amp; &amp; &amp; \\\\ \\hline \\text{B} &amp; \\text{Number of claims} &amp; 0 &amp; 0 &amp; 1 &amp; 2\\\\ \\hline \\text{B} &amp; \\text{Insured vehicles} &amp; 0 &amp; 2 &amp; 3 &amp; 4\\\\ \\hline \\end{array} \\end{matrix}\\] Show Example Solution Solution The credibilities from the prior example are \\(Z_A=\\frac{7}{7+2.0871}=0.7703\\) and \\(Z_B=\\frac{9}{9+2.0871}=0.8118\\). The sample means are \\(\\bar{x}_A=1\\) and \\(\\bar{x}_B=1/3\\). The balanced complement of credibility is \\[\\begin{equation*} \\hat{\\mu}=\\frac{0.7703(1)+0.8118(1/3)}{0.7703+0.8118}=0.6579. \\end{equation*}\\] The updated credibility estimates are \\(\\hat{\\mu}_A=0.7703(1)+(1-0.7703)(.6579)=0.9214\\) versus the previous 0.9139 and \\(\\hat{\\mu}_B=0.8118(1/3)+(1-0.8118)(.6579)=0.3944\\) versus the previous 0.3882. Checking the balance on the new estimators: (7/16)(0.9214)+(9/16)(0.3944)=0.6250. This exactly matches \\(\\bar{X}=10/16=0.6250\\). Show Quiz Solution 9.7 Further Resources and Contributors Exercises Here are a set of exercises that guide the viewer through some of the theoretical foundations of Loss Data Analytics. Each tutorial is based on one or more questions from the professional actuarial examinations, typically the Society of Actuaries Exam C. Credibility Guided Tutorials Contributors Gary Dean, Ball State University is the author of the initial version of this chapter. Email: cgdean@bsu.edu for chapter comments and suggested improvements. Chapter reviewers include: Liang (Jason) Hong, Ambrose Lo, Ranee Thiagarajah, Hongjuan Zhou. Bibliography "],
["C-PortMgt.html", "Chapter 10 Gestión de Carteras de Seguros incluyendo Reaseguro 10.1 Introducción a las Carteras de Seguros 10.2 Colas de las Distribuciones 10.3 Medidas de Riesgo 10.4 Reaseguro 10.5 Recursos y Colaboradores adicionales", " Chapter 10 Gestión de Carteras de Seguros incluyendo Reaseguro Contenido. Una cartera de seguros es simplemente un conjunto de contratos de seguros. Para ayudar a gestionar la incertidumbre de la cartera, este capítulo cuantifica coberturas inusualmente extremas examinando las colas de la distribución, cuantifica el riesgo global introduciendo indicadores conocidos como medidas de riesgo, y analiza las opciones de repartir el riesgo de la cartera a través del reaseguro, la contratación de cobertura de seguro por la propia entidad aseguradora. 10.1 Introducción a las Carteras de Seguros La mayoría de nuestros análisis en los capítulos previos se han realizado a nivel de contrato, definido como un acuerdo entre el tomador y el asegurador. Los aseguradores tienen, y gestionan, carterasuna colección de contratos que son simplemente conjuntos de pólizas. Como en otras áreas financieras, existen elecciones sobre los procesos de gestión que se producen solo a nivel de cartera. Por ejemplo, las decisiones estratégicas no ocurren a nivel de contrato. Se producen en la sala de reuniones, donde los gestores revisan los datos disponibles y posiblemente pongan en marcha nuevas estrategias. Desde la perspectiva de la cartera, los aseguradores quieren planear su capacidad, establecer políticas de gestión, y equilibrar el mix de productos que se distribuyen para aumentar los ingresos mientras se controla la volatilidad. Conceptualmente, uno puede pensar en una compañía de seguros como nada más que un conjunto, o cartera, de contratos de seguros. En el Capítulo 5 se ha aprendido sobre la modelización de carteras de seguros como la suma de contratos individuales, teniendo en cuenta hipótesis de independencia entre los contratos. Teniendo en cuenta su importancia, este capítulo se centra directamente en las distribuciones de carteras. Las carteras de seguros representan las obligaciones de los aseguradores y, por ello, se está particularmente interesado en las probabilidades de grandes riesgos, dado que ellos representan grandes obligaciones o coberturas extraordinarias. Para formalizar este concepto se introduce el concepto de distribución de colas pesadas en la Sección 10.2. Las carteras de seguros representan las obligaciones de la compañía y por ello los aseguradores mantienen una cantidad equivalente de activos para cumplir con dichas obligaciones. Las Medidas de riesgo, introducidas en la Sección 10.3, resumen la distribución de la cartera de seguros y son usadas para cuantificar la cantidad de activos que un asegurador necesita tener para cumplir con sus obligaciones. En la Sección 3.4 se aprendieron mecanismos que los tomadores usan para repartir riesgos como franquicias y límites de cobertura. De la misma forma, los aseguradores usan mecanismos similares para repartir los riesgos de cartera. Compran protecciones del riesgo mediante el reaseguro, una compañía de seguros para los aseguradores. Este reparto del riesgo de cartera de seguros se describe en la Sección ??. 10.2 Colas de las Distribuciones En esta sección, se aprende como: Describir una distribución de cola pesada intuitivamente. Clasificar la pesadez de las colas de una distribución basada en los momentos. Comparar las colas de dos distribuciones. En 1998 cayó lluvia helada en el este de Ontario, al suroeste de Canadá, durante seis días. El suceso supuso el doble de precipitaciones experimentadas en la zona en cualquier tormenta de hielo anterior, y provocó una catástrofe que derivó en más de 840,000 reclamaciones de seguros. Esta cifra es un 20\\(\\%\\) superior a los siniestros causados por el Huracán Andrew – uno de los mayores desastres naturales en la historia de Norteamérica. La catástrofe supuso aproximadamente 1.44 miles de millones de dólares Canadienses en acuerdos de seguros lo que representa la mayor cantidad para pérdidas en la historia de Canadá. Este no es un ejemplo aislado – sucesos catastróficos similares que causaron pérdidas extremas para el seguro son los Huracanes Harvey y Sandy, el terremoto y tsunami japonès de 2011, y otros. En el contexto asegurador, las pérdidas muy grandes y poco frecuentes que afectan a las carteras convirtiéndose en siniestros representan habitualmente la mayor parte de las indemnizaciones pagadas por las compañías aseguradoras. Dichas pérdidas, también llamadas ‘extremas’, son modelizadas cuantitativamente mediante las colas de las distribuciones de probabilidad asociadas. Desde el punto de vista de la modelización cuantitativa, confiar en modelos probabilísticos que no recogen bien el comportamiento de las colas puede resultar desalentador. Por ejemplo, los periodos de crisis financera pueden aparecer con mayor frecuencia de loesperado, y las pérdidas en seguros pueden producirse con mayor severidad. Por tanto, el estudio del comportamiento probabilístico en las colas de los modelos actuariales es de suma importancia en el contexto moderno de la gestión cuantitativa del riesgo. Por esta razón, esta sección se dedica a la introduccción de unas pocas nociones matemáticas que caracterizan el peso de la cola de variables aleatorias (v.a.). La aplicación de esas nociones será útil en la construcción y selección de modelos apropiados con las propiedades matemáticas deseadas en las colas, que serán adecuadas para el alcance de determinados objetivos. Formalmente, se define \\(X\\) como las obligaciones (aleatorias) que pueden derivarse de un conjunto (cartera) de pólizas de seguros. Se está especialmente interesado en estudiar la cola derecha de la distribución de \\(X\\), que representa la ocurrencia de grandes pérdidas. Informalmente, una v.a. se define como de cola pesada si las probabilidades altas se asignan a los valores grandes. Destacar que esto no significa que las funciones de densidad/masa de probabilidad vayan creciendo cuando el valor de v.a. tienda a infinito. De hecho para una v.a. continua, la pdffunción de densidad de probabilidad/pmffunción de masa de probabilidad debe disminuir en el infinito para garantizar que la probabilidad total es igual a uno. En cambio, lo que preocupa es la tasa de decrecimiento de la función de probabilidad. Es más probable que se produzcan resultados no deseados en carteras de seguros descritas por una v.a. de pérdidas con cola (derecha) pesada. El peso de la cola puede ser un concepto absoluto o relativo. Específicamente, desde el primer punto de vista, se puede considerar que una v.a. es de cola pesada si se cumplen ciertas propiedades matemáticas de la distribución de probabilidad. Desde el segundo punto de vista, se puede decir que la cola de una distribución es más pesada que la otra si algunas medidas de cola son mayores/menores. Se han propuesto diferentes enfoques cuantitativos para clasificar y comparar el peso de las colas. Entre ellos, la función de supervivenciaUno menos la función de distribución. Proporciona la probabilidad de que la v.a. supere un determinado valor sirve como base de análisis. A continuación, se introducen dos métodos de clasificación de colas simples pero muy utilizados, basados en el comportamiento de la función de supervivencia de \\(X\\). 10.2.1 Clasificación Basada en los Momentos Una forma de clasificar el peso de la cola de una distribución es evaluando la existencia de momentos ordinarios o respecto al origen. Ya que nuestro mayor interés recae en las colas derechas de las distribuciones, de ahora en adelante se asume que la obligación o pérdida v.a. \\(X\\) es positiva. Al principio, el momento ordinario \\(k-\\)th de una v.a. \\(X\\) continua, introducido en la Sección 3.1, puede calcularse como \\[\\begin{eqnarray*} \\mu_k&#39; &amp;=&amp; k \\int_0^{\\infty} x^{k-1} S(x) dx, \\\\ \\end{eqnarray*}\\] donde \\(S(\\cdot)\\) es la función de supervivencia de \\(X\\). Esta expresión pone de manifiesto que la existencia de los momentos ordinarios depende del comportamiento asintótico de la función de supervivencia en el infinito. Dicho de otro modo, cuanto más rápido tiende a cero la función de supervivencia, mayor será el orden del momento finito (k) que la v.a. asociada posee. Se puede interpretar \\(k^{\\ast}\\) como el mayor valor de k para que el momento sea finito. Formalmente, se define \\(k^{\\ast}:=\\sup\\{k &gt; 0:\\mu_k&#39;&lt;\\infty \\}\\), donde \\(sup\\) representa el elemento supremo. Esta observación nos conduce al método de clasificación del peso de las colas basado en los momentos, que se define formalmente a continuación. Definición 10.1. Consideremos una variable aleatoria de pérdidas positiva \\(X\\). Si todos los momentos ordinarios positivos existen, llámemosle el máximo orden del momento finito \\(k^{\\ast}=\\infty\\), entonces \\(X\\) se denomina de cola ligera en base al método de los momentos. Si \\(k^{\\ast} &lt; \\infty\\), entonces \\(X\\) se denomina de cola pesada en base al método de los momentos. Además, para dos variables aleatorias de pérdidas positivas \\(X_1\\) y \\(X_2\\) con máximos órdenes del momento \\(k^{\\ast}_1\\) y \\(k^{\\ast}_2\\) respectivamente, se dice que \\(X_1\\) tiene una cola (derecha) más pesada que \\(X_2\\) si \\(k^{\\ast}_1\\leq k^{\\ast}_2\\). La primera parte de la Definición 10.1 es un concepto absoluto de peso de cola, mientras que la segunda parte es un concepto relativo de peso de cola que compara las colas (derechas) entre dos distribuciones. A continuación, se presentan unos cuantos ejemplos que ilustran las aplicaciones del método basado en los momentos para comparar el peso de las colas. Ejemplo 10.1.1. Naturaleza de la cola ligera de la distribución gamma. Sea \\(X\\sim gamma(\\alpha,\\theta)\\), con \\(\\alpha&gt;0\\) y \\(\\theta&gt;0\\), entonces para todo \\(k&gt;0\\), demuestra que \\(\\mu_k&#39; &lt; \\infty\\). Muestra solución del ejemplo Solución. \\[\\begin{eqnarray*} \\mu_k&#39; &amp;=&amp; \\int_0^{\\infty} x^k \\frac{x^{\\alpha-1} e^{-x/\\theta}}{\\Gamma(\\alpha) \\theta^{\\alpha}} dx \\\\ &amp;=&amp; \\int_0^{\\infty} (y\\theta)^k \\frac{(y\\theta)^{\\alpha-1} e^{-y}}{\\Gamma(\\alpha) \\theta^{\\alpha}} \\theta dy \\\\ &amp;=&amp; \\frac{\\theta^k}{\\Gamma(\\alpha)} \\Gamma(\\alpha+k) &lt; \\infty. \\end{eqnarray*}\\] Dado que todos los momentos positivos existen, por tanto, \\(k^{\\ast}=\\infty\\), de acuerdo con el método de clasificación basado en los momentos de la Definición 10.1, la distribución gamma es de cola ligera. Ejemplo 10.1.2. Naturaleza de la cola ligera de la distribución Weibull. Sea \\(X\\sim Weibull(\\theta,\\tau)\\), con \\(\\theta&gt;0\\) y \\(\\tau&gt;0\\), entonces para todo \\(k&gt;0\\), demuestra que \\(\\mu_k&#39; &lt; \\infty\\). Muestra solución del ejemplo Solución. \\[\\begin{eqnarray*} \\mu_k&#39; &amp;=&amp; \\int_0^{\\infty} x^k \\frac{\\tau x^{\\tau-1} }{\\theta^{\\tau}} e^{-(x/\\theta)^{\\tau}}dx \\\\ &amp;=&amp; \\int_0^{\\infty} \\frac{ y^{k/\\tau} }{\\theta^{\\tau}} e^{-y/\\theta^{\\tau}}dy \\\\ &amp;=&amp; \\theta^{k} \\Gamma(1+k/\\tau) &lt; \\infty. \\end{eqnarray*}\\] De nuevo, debido a la existencia de todos los momentos positivos, la distribution Weibull es de cola ligera. Las distribuciones gamma y Weibull se utilizan ampliamente en la práctica actuarial. Las aplicaciones de estas dos distribuciones son extensas e incluyen, entre otras, la modelización de la severidad de los siniestros de seguros, la evaluación de solvencia, reservas, la aproximación del riesgo agregado o conjunto, e ingeniería de fiabilidad y análisis de errores o fallos. Hasta ahora se han visto dos ejemplos de aplicación del método basado en los momentos para analizar distribuciones de cola ligera. A continuación se presenta un ejemplo de cola pesada. Ejemplo 10.1.3. Naturaleza de la cola pesada de la distribución de pareto. Sea \\(X\\sim Pareto(\\alpha,\\theta)\\), con \\(\\alpha&gt;0\\) y \\(\\theta&gt;0\\), entonces para \\(k&gt;0\\) \\[\\begin{eqnarray*} \\mu_k^{&#39;} &amp;=&amp; \\int_0^{\\infty} x^k \\frac{\\alpha \\theta^{\\alpha}}{(x+\\theta)^{\\alpha+1}} dx \\\\ &amp;=&amp; \\alpha \\theta^{\\alpha} \\int_{\\theta}^{\\infty} (y-\\theta)^k {y^{-(\\alpha+1)}} dy. \\end{eqnarray*}\\] Se considera una integración similar: \\[\\begin{eqnarray*} g_k:=\\int_{\\theta}^{\\infty} {y^{k-\\alpha-1}} dy=\\left\\{ \\begin{array}{ll} &lt;\\infty, &amp; \\hbox{for } k&lt;\\alpha;\\\\ =\\infty, &amp; \\hbox{for } k\\geq \\alpha. \\end{array} \\right. \\end{eqnarray*}\\] Mientras tanto, \\[\\lim_{y\\rightarrow \\infty} \\frac{(y-\\theta)^k {y^{-(\\alpha+1)}}}{y^{k-\\alpha-1}}=\\lim_{y\\rightarrow \\infty} (1-\\theta/y)^{k}=1.\\] La aplicación del teorema de comparación de límites para integrales impropias indica que \\(\\mu_k&#39;\\) es finita si y solo si \\(g_k\\) es finita. Por tanto se puede concluir que los momentos ordinarios de una rv Pareto existen solo hasta \\(k&lt;\\alpha\\), es decir, \\(k^{\\ast}=\\alpha\\), y de este modo la distribución es de cola pesada. Aún más, el máximo orden del momento finito depende solo del parámetro de forma \\(\\alpha\\) y es una función creciente de \\(\\alpha\\). En otras palabras, en base al método de los momentos, el peso de la cola de una v.a. Pareto cambia únicamente en función de \\(\\alpha\\) – cuanto más pequeño es el valor de \\(\\alpha\\), más fuerte es el peso de la cola. Dado que \\(k^{\\ast}&lt;\\infty\\), la cola de una distribución de Pareto es más pesada que la de las distribuciones gamma y Weibull. Se concluye esta sección con una discusión abierta sobre las limitaciones del método basado en los momentos. A pesar de su implementación sencilla y de su interpretación intuitiva, existen determinadas situaciones en las que la aplicación del método basado en los momentos no es factible. Primero, en el caso de los modelos probabilísticos más complejos, el \\(k\\)-th momento ordinario puede no ser simple de derivar, y de este modo, la identificación del máximo orden del momento finito puede convertirse en un desafío. Segundo, el método basado en los momentos no cumple bien con el cuerpo principal de la teoría de la cola pesada definido en la literatura. Específicamente, la existencia de las funciones generadoras de momentos es sin duda el método más popular para clasificar la cola pesada frente a la cola ligera dentro de la comunidad de los actuarios académicos. Sin embargo, para algunas v.a. como la v.a. lognormal, sus funciones generadoras de momentos no existen, incluso cuando todos los momentos positivos son finitos. En esos casos, las aplicaciones de los métodos basados en los momentos pueden conduir a diferentes evaluaciones del peso de la cola. Tercero, cuando se necesita comparar el peso de la cola entre dos distribuciones de cola ligera para las cuales existen todos los momentos positivos, el método basado en los momentos no es informativo (ver, por ejemplo, Ejemplos 10.1.1 y 10.1.2). 10.2.2 Comparación basada en el comportamiento de colas con límites Para resolver las dificultades anteriormente comentadas en relación al uso del método de clasificación basado en los momentos, una aproximación alternativa para comparar el peso de las colas es estudiar directamente los límites de las funciones de supervivencia. Definición 10.2. Para dos v.a. \\(X\\) e \\(Y\\), sea \\[ \\gamma:=\\lim_{t\\rightarrow \\infty}\\frac{S_X(t)}{S_Y(t)}. \\] Se dice que \\(X\\) tiene una cola derecha más pesada que \\(Y\\) si \\(\\gamma=\\infty\\); \\(X\\) e \\(Y\\) son proporcionalmente equivalentes en la cola derecha si \\(\\gamma =c\\in \\mathbf{R}_+\\); \\(X\\) tiene una cola derecha más ligera que \\(Y\\) si \\(\\gamma=0\\). Ejemplo 10.1.4. Comparación de las distribuciones Pareto y Weibull. Sea \\(X\\sim Pareto(\\alpha, \\theta)\\) e \\(Y\\sim Weibull(\\tau, \\theta)\\), para \\(\\alpha&gt;0\\), \\(\\tau&gt;0\\), y \\(\\theta&gt;0\\). Demostrar que la distribución Pareto tiene una cola derecha más pesada que la Weibull. Muestra solución del ejemplo Solución. \\[\\begin{eqnarray*} \\lim_{t\\rightarrow \\infty}\\frac{S_X(t)}{S_Y(t)} &amp;=&amp; \\lim_{t\\rightarrow \\infty}\\frac{(1+t/\\theta)^{-\\alpha}}{\\exp\\{-(t/\\theta)^{\\tau}\\}} \\\\ &amp;=&amp; \\lim_{t\\rightarrow \\infty}\\frac{\\exp\\{t/\\theta^{\\tau} \\}}{(1+t^{1/\\tau}/\\theta)^{\\alpha}} \\\\ &amp;=&amp; \\lim_{t\\rightarrow \\infty}\\frac{\\sum_{i=0}^{\\infty}\\left(\\frac{t}{\\theta^{\\tau}}\\right)^{i}/i!}{(1+t^{1/\\tau}/\\theta)^{\\alpha}}\\\\ &amp;=&amp; \\lim_{t\\rightarrow \\infty} \\sum_{i=0}^{\\infty} \\left(t^{-i/\\alpha}+\\frac{t^{(1/\\tau-i/\\alpha)}}{\\theta} \\right)^{-\\alpha}/\\theta^{\\tau i}i!\\\\ &amp;=&amp; \\infty. \\end{eqnarray*}\\] Por tanto, la distribución de Pareto tiene una cola más pesada que la distribución Weibull. Se puede observar que las exponenciales tienden a infinito más rápido que las polinómicas, por tanto, el límite antes mencionado debe ser infinito. Para algunas distribuciones para las que las funciones de supervivencia no admiten expresiones explícitas, se puede encontrar la siguiente fórmula alternativa: \\[\\begin{eqnarray*} \\lim_{t\\to \\infty} \\frac{S_X(t)}{S_Y(t)} &amp;=&amp; \\lim_{t \\to \\infty} \\frac{S_X^{&#39;}(t)}{S_Y^{&#39;}(t)} \\\\ &amp;=&amp; \\lim_{t \\to \\infty} \\frac{-f_X(t)}{-f_Y(t)}\\\\ &amp;=&amp; \\lim_{t\\to \\infty} \\frac{f_X(t)}{f_Y(t)}. \\end{eqnarray*}\\] dado que existen las funciones de densidad. Ejemplo 10.1.5. Comparación de las distribuciones Pareto y gamma. Sea \\(X\\sim Pareto(\\alpha, \\theta)\\) e \\(Y\\sim gamma(\\alpha, \\theta)\\), para \\(\\alpha&gt;0\\) y \\(\\theta&gt;0\\). Demostrar que la Pareto tiene una cola derecha más pesada que la gamma. Muestra solución del ejemplo Solución. \\[\\begin{eqnarray*} \\lim_{t\\to \\infty} \\frac{f_{X}(t)}{f_{Y}(t)} &amp;=&amp; \\lim_{t \\to \\infty} \\frac{\\alpha \\theta^{\\alpha} (t+ \\theta)^{-\\alpha-1}}{t^{\\tau-1} e^{-t/\\lambda} \\lambda^{-\\tau} \\Gamma(\\tau)^{-1}} \\\\ &amp;\\propto&amp; \\lim_{t\\to \\infty} \\frac{e^{t/\\lambda}}{(t+\\theta)^{\\alpha+1} t^{\\tau-1}} \\\\ &amp;=&amp; \\infty, \\end{eqnarray*}\\] Dado que las exponenciales tienden a infinito más rápido que las polinómicas. 10.3 Medidas de Riesgo En esta sección, se aprende como: Definir la idea de coherencia y determinar si una medida de riesgo es o no coherente. Definir el valor en riesgo y calcular este valor para una distribución dada. Definir la cola del valor en riesgo y calcular este valor para una distribución dada. En la sección previa, se estudian dos métodos para clasificar el peso de las colas de la distribución. Se puede afirmar que el riesgo asociado con una distribución es más peligroso que otros(asintóticamente)si la cola es más pesada. Sin embargo, saber que un riesgo es más peligroso (asintóticamente) que otros puede no ser suficiente a nivel informativo para una gestión de riesgos sofisticada, y adicionalmente, se puede estar interesado en cuantificar cuanto más lo es. De hecho, la magnitud del riesgo asociada con una distribución dada de pérdidas es un input fundamental para muchas aplicaciones de seguros, tales como la tarificación actuarial, el cálculo de reservas, el diseño de coberturas, la supervisión regulatoria de seguros, y otras. 10.3.1 Medidas de Riesgo Coherentes Para comparar la magnitud del riesgo de una forma conveniente, se busca una función que represente la v.a. pérdida en un valor numérico indicativo del nivel de riesgo, denominada medida de riesgouna medida que resume el riesgo, o incertidumbre, de una distribución. A nivel matemático, la medida de riesgo simplemente resume la función de distribución de una v.a. mediante un solo número. Dos medidas de riesgo sencillas son la media \\(\\mathrm{E}[X]\\) y la desviación estándar \\(\\mathrm{SD}(X)=\\sqrt{\\mathrm{Var}(X)}\\). Otros ejemplos clásicos de medidas de riesgo incluyen el principio de desviación estándar \\[\\begin{equation} H_{\\mathrm{SD}}(X):=\\mathrm{E}[X]+\\alpha \\mathrm{SD}(X),\\text{ para } \\alpha\\geq 0, \\tag{10.1} \\end{equation}\\] y el principio de varianza \\[ H_{\\mathrm{Var}}(X):=\\mathrm{E}[X]+\\alpha \\mathrm{Var}(X),\\text{ para } \\alpha\\geq 0. \\] Es sencillo comprobar que todas las funciones antes mencionadas son medidas de riesgo en las que se introduce la v.a. pérdida y las funciones generan un valor numérico. Sin embargo, la función \\(H^{\\ast}(X):=\\alpha X^{\\beta}\\) para cualquier valor real \\(\\alpha,\\beta\\neq 0\\), no es una medida de riesgo porque \\(H^{\\ast}\\) produce otra v.a. en lugar de un único valor numérico. Como las medidas de riesgo son medidas escalares que tienen como objetivo utilizar un único valor numérico para describir la naturaleza estocástica de la v.a. pérdidas, no debería sorprendernos que no haya ninguna medida de riesgo que pueda capturar toda la información de riesgo de las v.a. asociadas. Por tanto, al buscar medidas de riesgo útiles, es importante tener en cuenta que las medidas deben ser al menos fácilmente interpretables; convenientemente computables; y capaces de reflejar la información más crítica sobre el riesgo que sustenta la distribución de pérdidas. En la literatura se han desarrollado varias medidas de riesgo. Desafortunadamente, no hay una mejor medida de riesgo que pueda superar a las demás, y la selección de la medida de riesgo adecuada depende principalmente de lo que se esté analizando. En este sentido, es necesario subrayar que riesgo es un concepto subjetivo, y por tanto, incluso delante del mismo problema, existen enfoques alternativos para su evaluación. Sin embargo, en aplicaciones de gestión de riesgos, existe un amplio consenso en el hecho de que las medidas de riesgo utilizadas desde un punto de vista económico deben cumplir cuatro axiomas principales que se describen con detalle a continuación. Las medidas de riesgo que satisfacen estos axiomas se denominan medidas de riesgo coherentesuna medida de riesgo que es subaditiva, monótona, tiene homgeneidad positiva, y es invariante a desplazamientos . Consideramos a continuación una medida de riesgo \\(H(\\cdot)\\), de forma que \\(H\\) es una medida de riesgo coherente si se satisfacen los siguientes axiomas. Axioma 1. Subaditividad: \\(H(X+Y)\\leq H(X)+H(Y)\\). La implicación económica de este axioma es que existen beneficios de diversificación si se combinan diferentes riesgos. Axioma 2. Monotonicidad: si \\(\\Pr[X\\leq Y]=1\\), entonces \\(H(X)\\leq H(Y)\\). Destacar que \\(X\\) e \\(Y\\) son v.a. que representan pérdidas, la implicación económica subyacente es que las pérdidas más altas conducen esencialmente a un mayor nivel de riesgo. Axioma 3. Homogeneidad positiva: \\(H(cX)=cH(X)\\) para cualquier constante positiva \\(c\\). Una implicación económica posible de este axioma es que la medida de riesgo debe ser independiente de las unidades monetarias en las que se mide el riesgo. Por ejemplo, sea \\(c\\) el tipo de cambio entre los dólares estadounidenses y canadienses, entonces el riesgo de pérdidas aleatorias medidas en dólares estadounidenses (es decir, X) y dólares canadienses (es decir, cX) debe ser diferente solo en términos del tipo de cambio \\(c\\) (es decir, \\(cH(x)=H(cX)\\)). Axioma 4. Invarianza a los desplazamientos: \\(H(X+c)=H(X)+c\\) para cualquier constante positiva \\(c\\). Si la constante \\(c\\) se interpreta como un efectivo libre de riesgo, este axioma indica que no se crea riesgo adicional al añadir liquidez a una cartera de seguros, y añadir un capital libre de riesgo de cuantía \\(c\\) puede reducir solo el riesgo en la misma cantidad. Verificar las propiedades coherentes para algunas medidas de riesgo puede ser bastante sencillo, pero a veces puede complicarse. Por ejemplo, es sencillo comprobar que la media es una medida de riesgo coherente. Ejemplo. La Media es una Medida de Riesgo Coherente. Para cualquier par de v.a. \\(X\\) e \\(Y\\) con medias finitas y la constante \\(c&gt;0\\), validación de la subaditividad: \\(\\mathrm{E}[X+Y]=\\mathrm{E}[X]+\\mathrm{E}[Y]\\); validación de la monotonicidad: si \\(\\Pr[X\\leq Y]=1\\), entonces \\(\\mathrm{E}[X]\\leq \\mathrm{E}[Y]\\); validación de homogeneidad positiva: \\(\\mathrm{E}[cX]=c\\mathrm{E}[X]\\); validación de invarianza a los desplazamientos: \\(\\mathrm{E}[X+c]=\\mathrm{E}[X]+c\\) Con un poco más de esfuerzo, se puede determinar lo siguiente. Ejemplo. La Desviación Estándar no es una Medida de Riesgo Coherente. Mostrar verificación del ejemplo La desviación estándar no es una medida de riesgo coherente. De forma específica, se puede comprobar que la desviación estándar satisface validación de la subaditividad: \\[\\begin{eqnarray*} \\mathrm{SD}[X+Y]&amp;=&amp;\\sqrt{\\mathrm{Var}(X)+\\mathrm{Var}(Y)+2\\mathrm{Cov}(X,Y)}\\\\ &amp;\\leq&amp; \\sqrt{\\mathrm{SD}(X)^2+\\mathrm{SD}(Y)^2+2\\mathrm{SD}(X)\\mathrm{SD}(Y)}\\\\ &amp;=&amp; \\mathrm{SD}(X)+\\mathrm{SD}(Y); \\end{eqnarray*}\\] validación de la homogeneidad positiva: \\(\\mathrm{SD}[cX]=c~\\mathrm{SD}[X]\\). Sin embargo, la desviación estándar no cumple con la propiedad de la invarianza ante desplazamientos dado que para cualquier constante positiva \\(c\\), \\[ \\mathrm{SD}(X+c)=\\mathrm{SD}(X)&lt;\\mathrm{SD}(X)+c. \\] Además, la desviación estándar tampoco satisface la propiedad de monotonicidad. Para demostrarlo, se consideran las dos v.a. siguientes: \\[\\begin{eqnarray} X=\\left\\{ \\begin{array}{ll} 0, &amp; \\hbox{con probabilidad $0.25$;} \\\\ 4, &amp; \\hbox{con probabilidad $0.75$,} \\end{array} \\right. \\tag{10.2} \\end{eqnarray}\\] e \\(Y\\) es una v.a. tal que \\[\\begin{eqnarray} \\Pr[Y = 4] = 1. \\tag{10.3} \\end{eqnarray}\\] Es fácil comprobar que \\(\\Pr[X\\leq Y]=1\\), pero \\(\\mathrm{SD}(X)=\\sqrt{4^2\\cdot 0.25\\cdot 0.75}=\\sqrt{3}&gt;\\mathrm{SD}(Y)=0\\). Hasta ahora se ha comprobado que \\(\\mathrm{E}[\\cdot]\\) es una medida de riesgo coherente, pero no \\(\\mathrm{SD}(\\cdot)\\). Se procede ahora a estudiar la propiedad de coherencia para el principio de desviación estándar (10.1) que es una combinación linear de medidas de riesgo coherentes y no coherentes. Ejemplo. El Principio de Desviación Estándar (10.1) es una Medida de Riesgo Coherente. Mostrar verificación del ejemplo Con este fin, para una \\(\\alpha&gt;0\\) dada, comprobamos los cuatro axiomas para \\(H_{\\mathrm{SD}}(X+Y)\\) uno por uno: validación de subaditividad: \\[\\begin{eqnarray*} H_{\\mathrm{SD}}(X+Y) &amp;=&amp; \\mathrm{E}[X+Y]+\\alpha \\mathrm{SD}(X+Y) \\\\ &amp;\\leq&amp; \\mathrm{E}[X]+\\mathrm{E}[Y]+\\alpha [\\mathrm{SD}(X) +\\mathrm{SD}(Y)]\\\\ &amp;=&amp; H_{\\mathrm{SD}}(X)+ H_{\\mathrm{SD}}(Y); \\end{eqnarray*}\\] validación de homogeneidad positiva: \\[ H_{\\mathrm{SD}}(cX)=c\\mathrm{E}[X]+c\\alpha\\mathrm{SD}(X)=cH_{\\mathrm{SD}}(X); \\] validación de invarianza en los desplazamientos: \\[ H_{\\mathrm{SD}}(X+c)=\\mathrm{E}[X]+c+\\alpha\\mathrm{SD}(X)=H_{\\mathrm{SD}}(X)+c. \\] Solo queda por verificar la propiedad de monotonicidad, que puede cumplirse o no dependiendo del valor de \\(\\alpha\\). Para analizarlo, se considera de nuevo (10.2) y (10.3) donde \\(\\Pr[X\\leq Y]=1\\). Sea \\(\\alpha=0.1\\cdot \\sqrt{3}\\), entonces \\(H_{\\mathrm{SD}}(X)=3+0.3=3.3&lt; H_{\\mathrm{SD}}(Y)=4\\) y se cumple la condición de monotonicidad. Por otro lado, sea \\(\\alpha=\\sqrt{3}\\), entonces \\(H_{\\mathrm{SD}}(X)=3+3=6&gt; H_{\\mathrm{SD}}(Y)=4\\) y la condición de monotinicidad no se satisface. De forma más precisa, estableciendo \\[ H_{\\mathrm{SD}}(X) = 3+\\alpha\\sqrt{3} \\leq4= H_{\\mathrm{SD}}(Y), \\] Se observa que la condición de monotonicidad se satisface solo para \\(0\\leq\\alpha\\leq 1/\\sqrt{3}\\), y de este modo el principio de desviación estándar \\(H_{\\mathrm{SD}}\\) es coherente. Este resultado es muy intuitivo ya que el principio de desviación estándar \\(H_{\\mathrm{SD}}\\) es una combinación lineal de dos medidas de riesgo de las cuales una es coherente y la otra no lo es. Si \\(\\alpha\\leq 1/\\sqrt{3}\\), entonces la medida coherente domina a la no coherente, y de este modo la medida resultante \\(H_{\\mathrm{SD}}\\) es coherente y viceversa. Destacar que dicha conclusión no puede generalizarse a cualquier par de v.a. \\(X\\) e \\(Y\\). La literatura sobre medidas de riesgo ha crecido rápidamente en popularidad e importancia. En las dos secciones siguientes, se introducen dos índices que han ganado mucho interés recientemente entre teóricos, empíricos y reguladores. Son las medidas denominadas Valor en Riesgo (VaR) y Cola del Valor en Riesgo (TVaR). La racionalidad económica detrás de estas dos medidas de riesgo es similar a la de los métodos de clasificación de colas introducidos en la sección anterior, con las que se espera captar el riesgo de pérdidas extremas representadas por las colas de la distribución. 10.3.2 Valor en Riesgo En la Sección 4.1.1.3, se define el cuantil de una distribución. Se presenta ahora una caso especial de éste y se ofrece una definición formal del valor en riesgouna medida de riesgo basada en la función cuantílica, o VaR. Definición 10.3. Se considera la variable aleatoria pérdidas en seguros \\(X\\). La medida valor en riesgo de \\(X\\) con un nivel de confianza \\(q\\in (0,1)\\) se formula como \\[\\begin{eqnarray} VaR_q[X]:=\\inf\\{x:F_X(x)\\geq q\\}. \\tag{10.4} \\end{eqnarray}\\] Aquí, \\(inf\\) es el operador ínfimo de modo que la medida VaR proporciona el valor más pequeño de \\(X\\) tal que la cdffunción de distribución acumulada asociada supera o iguala a \\(q\\). Así es como debemos interpretar el VaR en el contexto de las aplicaciones actuariales. El VaR es una medida de la pérdida probable ‘máxima’ para un cartera/producto de seguros o una inversión con riesgo produciéndose \\(q\\times 100\\%\\) veces, a lo largo de un periodo de tiempo específico (típicamente, un año). Por ejemplo, sea \\(X\\) la v.a. pérdida anual para un producto de seguros, \\(VaR_{0,95}[X]=100\\) millones de dólares significa que hay un \\(5\\%\\) de probabilidad de que la pérdida supere 100 millones en un año dado. Debido a esta interpretación tan relevante, el VaR se ha convertido en una medida estándar en la medición de riesgos financieros y aseguradores desde 1990. Los conglomerados financieros, los reguladores, y los académicos usan a menudo el VaR para medir riesgos de capital, garantizar el cumplimiento de las reglas regulatorias, y divulgar las posiciones financieras. A continuación, se presentan unos cuantos ejemplos sobre el cálculo del VaR. Ejemplo 10.2.1. VaR para la distribución exponencial. Se considera una v.a. pérdidas en seguros \\(X\\sim Exp(\\theta)\\) para \\(\\theta&gt;0\\), entonces la cdf de \\(X\\) viene dada por \\[ F_X(x)=1-e^{-x/\\theta}, \\text{ para } x&gt;0. \\] Obtener una expresión cerrada para el VaR. Mostrar Solución de Ejemplo Solución. Dado que la distribución exponencial es una distribución continua, el valor más pequeño tal que la cdf excede o iguala a \\(q \\in (0,1)\\) debe ser el valor \\(x_q\\) que satisface \\[ q=F_X(x_q)=1-\\exp\\{-x_q/\\theta \\}. \\] De este modo \\[ VaR_q[X]=F_X^{-1}(q)=-\\theta[\\log(1-q)]. \\] El resultado presentado en el Ejemplo 10.2.1 puede generalizarse a cualquier v.a. continua con una cdf estrictamente creciente. Específicamente, el VaR de cualquier v.a continua es simplemente la inversa de la correspondiente cdf. Se considera otro ejemplo de una v.a. continua desde el infinito negativo hasta el infinito positivo. Ejemplo 10.2.2. VaR para la distribución normal. Se considera una v.a. pérdida en seguros \\(X\\sim Normal(\\mu,\\sigma^2)\\) con \\(\\sigma&gt;0\\). En este caso, se pueden interpretar los valores negativos de \\(X\\) como beneficio o ingreso. Obtener una expresión cerrada para el VaR. Mostrar Solución de Ejemplo Solución. Como la distribución normal es una distribución continua, el VaR de \\(X\\) debe satisfacer \\[\\begin{eqnarray*} q &amp;=&amp; F_X(VaR_q[X])\\\\ &amp;=&amp;\\Pr\\left[(X-\\mu)/\\sigma\\leq (VaR_q[X]-\\mu)/\\sigma\\right]\\\\ &amp;=&amp;\\Phi((VaR_q[X]-\\mu)/\\sigma). \\end{eqnarray*}\\] Por tanto, se tiene \\[ VaR_q[X]=\\Phi^{-1}(q)\\ \\sigma+\\mu. \\] En muchas aplicaciones de seguros se tiene que trabajar con transformaciones de v.a.. Por ejemplo, en el Ejemplo 10.2.2, la v.a. pérdida \\(X\\sim Normal(\\mu, \\sigma^2)\\) puede interpretarse como una transformación lineal de una normal estándar v.a. \\(Z\\sim Normal(0,1)\\), denominada \\(X=Z\\sigma+\\mu\\). Estableciendo \\(\\mu=0\\) y \\(\\sigma=1\\), es directo comprobar que \\(VaR_q[Z]=\\Phi^{-1}(q).\\) Un resultado relevante obtenido a partir del Ejemplo 10.2.2 es que el VaR de una transformación lineal de las v.a. normales es equivalente a la transformación lineal del VaR de las v.a. originales. Este resultado se puede generalizar a cualquier v.a. siempre y cuando las transformaciones sean estrictamente crecientes. Ejemplo 10.2.3. VaR para variables transformadas. Se considera una v.a. pérdida de seguros \\(Y\\sim lognormal(\\mu,\\sigma^2)\\), para \\(\\mu\\in \\mathbf{R}\\) y \\(\\sigma&gt;0\\). Obtener una expresión para el \\(VaR\\) de \\(Y\\) en función de la inversa normal estándar cdf. Mostrar Solución de Ejemplo Solución. Señalar que \\(\\log Y\\sim Normal(\\mu,\\sigma^2)\\), o de forma equivalente sea \\(X\\sim Normal(\\mu,\\sigma^2)\\), entonces \\(Y\\overset{d}{=}e^{X}\\) que es una transformación estrictamente creciente. Aquí, la notación `\\(\\overset{d}{=}\\)’ significa igualdad en la distribución. El VaR de \\(Y\\) viene dado de esta forma por la transformación exponencial del VaR de \\(X\\). Precisamente, para \\(q\\in (0,1)\\), \\[ VaR_{q}[Y]= e^{VaR_q[X]}=\\exp\\{\\Phi^{-1}(q)\\ \\sigma+\\mu\\}. \\] Hasta ahora se han visto una serie de ejemplos sobre el VaR para v.a. continuas. Se presenta ahora un ejemplo sobre el VaR de una v.a. discreta. Ejemplo 10.2.4. VaR para una variable aleatoria discreta. Se considera una v.a. pérdida en seguros con la siguiente distribución de probabilidad: \\[ {\\small \\Pr[X=x]=\\left\\{ \\begin{array}{ll} 1, &amp; \\hbox{con probabilidad $0,75$} \\\\ 3, &amp; \\hbox{con probabilidad $0,20$} \\\\ 4, &amp; \\hbox{con probabilidad $0,05$.} \\end{array} \\right. } \\] Determina el VaR para \\(q = 0,6, 0,9, 0,95, 0,95001\\). Mostrar Solución de Ejemplo Solución. La correspondiente cdf de \\(X\\) es \\[ F_X(x)=\\left\\{ \\begin{array}{ll} 0, &amp; \\hbox{ $x&lt;1$;} \\\\ 0,75, &amp; \\hbox{ $1\\leq x&lt;3$;} \\\\ 0,95, &amp; \\hbox{ $3\\leq x&lt;4$;} \\\\ 1, &amp; \\hbox{ $4\\leq x$.} \\end{array} \\right. \\] A partir de la definición del VaR, tenemos que \\(VaR_{0,6}[X]=1\\); \\(VaR_{0,9}[X]=3\\); \\(VaR_{0,95}[X]=3\\); \\(VaR_{0,950001}[X]=4\\). Se concluye esta subsección con una discusión abierta sobre la medida del VaR. Algunas ventajas de utilizar el VaR incluyen proporciona una interpretación práctica y sencilla; es relativamente sencillo de calcular para muchas funciones de distribución de forma cerrada; no se requieren supuestos adicionales para el cálculo del VaR. Por otro lado, las limitaciones del VaR pueden ser particularmente pronunciadas para algunas prácticas de gestión de riesgos. Algunas de ellas pueden ser: la selección del nivel de confianza \\(q\\in (0,1)\\) es muy subjetiva, mientras el VaR puede ser muy sensible a la elección de \\(q\\) (por ejemplo, en el Ejemplo 10.2.4, \\(VaR_{0,95}[X]=3\\) y \\(VaR_{0,950001}[X]=4\\)); los escenarios/información de pérdidas que están por encima del \\((1-p)\\times 100\\%\\) peor suceso, están completamente descuidados; el VaR no es una medida de riesgo coherente (específicamente, el VaR no satisface el axioma de subaditividad, lo que significa que los beneficios de la diversificación pueden no quedar suficientemente reflejados). 10.3.3 Cola del Valor en Riesgo Recalcar que el VaR representa \\((1-p)\\times100\\%\\) la máxima pérdida. Como se mencionó en la sección previa, uno de los mayores inconvenientes del VaR es que no refleja las pérdidas extremas que se producen más allá del \\((1-p)\\times100\\%\\) peor escenario. Con fines ilustrativos, se considera el siguiente ejemplo poco realista pero inspirador. Ejemplo 10.2.5. Se consideran dos v.a. de pérdidas \\(X\\sim Uniform [0,100]\\), e \\(Y\\sim Exp(31,71)\\). Se usa el VaR al \\(95\\%\\) de nivel de confianza para medir el riesgo de \\(X\\) e \\(Y\\). Mediante cálculos simples (ver, también, Ejemplo 10.2.1), \\[ VaR_{0,95}[X]=VaR_{0,95}[Y]=95, \\] y de ese modo estas dos distribuciones de pérdidas tienen el mismo nivel de riesgo según el \\(VaR_{0,95}\\). Sin embargo, está claro que \\(Y\\) tiene mayor riesgo que \\(X\\) si las pérdidas extremas son más preocupantes ya que \\(X\\) está limitada por arriba mientras que \\(Y\\) no lo está. La simple cuantificación del riesgo mediante el uso del VaR a un nivel de confianza específico podría ser engañosa y no reflejar la verdadera naturaleza del riesgo. Para remediarlo, fue propuesta la Cola del Valor en Riesgo (TVaR) para medir las pérdidas extremas que están por encima de un nivel dado del VaR como una media. Se presenta a continuación la definición del TVaR. Para simplificar, nos vamos a limitar a las v.a. positivas continuas, que se utilizan con más frecuencia en el contexto de la gestión de riesgos de seguros. Se remite al lector interesado a Hardy (2006) para una discusión más completa del TVaR para v.a. discretas y continuas. Definición 10.4. Dado \\(q\\in (0,1)\\), la cola del valor en riesgoel valor esperado de un riesgo dado que el riesgo excede el valor en riesgo de una v.a. (continua) \\(X\\) se define como \\[\\begin{eqnarray*} TVaR_q[X] &amp;:=&amp; \\mathrm{E}[X|X&gt;VaR_q[X]], \\end{eqnarray*}\\] dado que el valor esperado existe. Teniendo en cuenta la Definición 10.4, el cálculo del TVaR típicamente consta de dos partes - el VaR y la media de pérdidas que están por encima del VaR. El TVaR se puede calcular por medio de fórmulas. Se considera una v.a. \\(X\\) positiva continua, por conveniencia notacional, escrita de ahora en adelante \\(\\pi_q:=VaR_q[X]\\). Por definición, el TVaR puede calcularse vía \\[\\begin{eqnarray} TVaR_{q}[X]=\\frac{1}{(1-q)}\\int_{\\pi_q}^{\\infty}xf_X(x)dx. \\tag{10.5} \\end{eqnarray}\\] Ejemplo 10.2.6. TVaR para una distribución normal. Se considera una v.a. pérdida de seguros \\(X\\sim Normal (\\mu,\\sigma^2)\\) con \\(\\mu\\in \\mathbf{R}\\) y \\(\\sigma&gt;0\\). Obtener una expresión para el TVaR. Mostrar Solución de Ejemplo Solución. Sea \\(Z\\) la v.a. normal estándar. Para \\(q\\in(0,1)\\), el TVaR de \\(X\\) puede calcularse como \\[\\begin{eqnarray*} TVaR_q[X] &amp;=&amp; \\mathrm{E}[X|X&gt;VaR_q[X]]\\\\ &amp;=&amp;\\mathrm{E}[\\sigma Z+\\mu|\\sigma Z+\\mu&gt;VaR_q[X]]\\\\ &amp;=&amp; \\sigma\\mathrm{E}[Z|Z&gt;(VaR_q[X]-\\mu)/\\sigma]+\\mu\\\\ &amp;\\overset{(1)}{=}&amp; \\sigma\\mathrm{E}[Z|Z&gt;VaR_q[Z]]+\\mu, \\end{eqnarray*}\\] donde `\\(\\overset{(1)}{=}\\)’ debido a los resultados presentados en el Ejemplo 10.2.2. A continuación, se estudia \\(TVaR_q[Z]=\\mathrm{E}[Z|Z&gt;VaR_q[Z]]\\). Sea \\(\\omega(q)=(\\Phi^{-1}(q))^2/2\\), se tiene \\[\\begin{eqnarray*} (1-q)\\ TVaR_q[Z] &amp;=&amp; \\int_{\\Phi^{-1}(q)}^{\\infty} z \\frac{1}{\\sqrt{2\\pi}} e^{-z^2/2}dz\\\\ &amp;=&amp; \\int_{\\omega(q)}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} e^{-x}dx\\\\ &amp;=&amp; \\frac{1}{\\sqrt{2\\pi}} e^{-\\omega(q)}\\\\ &amp;=&amp; \\phi(\\Phi^{-1}(q)). \\end{eqnarray*}\\] De este modo, \\[ TVaR_q[X]=\\sigma\\frac{\\phi(\\Phi^{-1}(q))}{1-q}+\\mu. \\] Se mencionó anteriormente en la subsección previa que el VaR de una función estrictamente creciente de una v.a. es igual a la función VaR de la v.a. original. Como consecuencia de los resultados del Ejemplo 10.2.6, se puede demostrar que el TVaR de una v.a. transformación lineal estrictamente creciente es igual a la función VaR de la v.a. original. Esto es debido a la propiedad de linealidad de los valores esperados. Sin embargo, el resultado anterior no puede extenderse a funciones no lineales. El siguiente caso de v.a. lognormales sirve como ejemplo. Ejemplo 10.2.7. TVaR de una distribución lognormal. Se considera una v.a. de pérdidas de seguros \\(X\\sim lognormal (\\mu,\\sigma^2)\\), con \\(\\sigma&gt;0\\). Demuestra que \\[\\begin{eqnarray*} TVaR_q[X] &amp;=&amp; \\frac{e^{\\mu+\\sigma^2/2}}{(1-q)} \\Phi(\\Phi^{-1}(q)-\\sigma). \\end{eqnarray*}\\] Mostrar Solución de Ejemplo Solución. Recordar que la pdf de una distribución lognormal se formula como \\[ f_X(x)=\\frac{1}{\\sigma\\sqrt{2\\pi} x}\\exp\\{-(\\ln x-\\mu )^2/2\\sigma^2 \\}, \\text{ para } x&gt;0. \\] Dado que \\(q\\in(0,1)\\), entonces el TVaR de \\(X\\) se puede calcular como \\[\\begin{eqnarray} TVaR_q[X] &amp;=&amp; \\frac{1}{(1-q)} \\int_{\\pi_q}^{\\infty} x f_X(x)dx \\nonumber\\\\ &amp;=&amp;\\frac{1}{(1-q)} \\int_{\\pi_q}^{\\infty} \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left\\{ -\\frac{(\\log x-\\mu)^2}{2\\sigma^2} \\right\\}dx\\nonumber\\\\ &amp;\\overset{(1)}{=}&amp;\\frac{1}{(1-q)} \\int_{\\omega(q)}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} e^{ -\\frac{1}{2}w^2+\\sigma w+\\mu}dw\\nonumber\\\\ &amp;=&amp;\\frac{e^{\\mu+\\sigma^2/2}}{(1-q)} \\int_{\\omega(q)}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} e^{ -\\frac{1}{2}(w-\\sigma)^2}dw\\nonumber\\\\ &amp;=&amp;\\frac{e^{\\mu+\\sigma^2/2}}{(1-q)} \\Phi(\\omega(q)-\\sigma), \\tag{10.6} \\end{eqnarray}\\] donde \\(\\overset{(1)}{=}\\) aplicando un cambio de variable \\(w=(\\log x-\\mu)/\\sigma\\), y \\(\\omega(q)=(\\log \\pi_q-\\mu)/\\sigma\\). Recordando la fórmula del VaR para la v.a. lognormal presentada en el Ejemplo 10.2.2, se puede simplificar la expresión (10.6) en \\[\\begin{eqnarray*} TVaR_q[X] &amp;=&amp; \\frac{e^{\\mu+\\sigma^2/2}}{(1-q)} \\Phi(\\Phi^{-1}(q)-\\sigma). \\end{eqnarray*}\\] De forma clara, el TVaR de una v.a. lognormal no es la exponencial del TVaR de una v.a. normal. Cuando las funciones de distribución son más fáciles de trabajar, se puede aplicar la integración por partes para reescribir la ecuación (10.5) como \\[\\begin{eqnarray*} TVaR_{q}[X]&amp;=&amp;\\left[-x S_X(x)\\big |_{\\pi_q}^{\\infty}+\\int_{\\pi_q}^{\\infty}S_X(x)dx\\right]\\frac{1}{(1-q)}\\\\ &amp;=&amp; \\pi_q +\\frac{1}{(1-q)}\\int_{\\pi_q}^{\\infty}S_X(x)dx. \\end{eqnarray*}\\] Ejemplo 10.2.8. TVaR de una distribución exponencial. Se considera una v.a. pérdida de seguros \\(X\\sim Exp(\\theta)\\) para \\(\\theta&gt;0\\). Obtener una expresión para el TVaR. Mostrar Solución de Ejemplo Solución. Se ha visto en la subsección previa que \\[ \\pi_q=-\\theta[\\log(1-q)]. \\] Consideremos ahora el TVaR: \\[\\begin{eqnarray*} TVaR_q[X] &amp;=&amp; \\pi_q+\\int_{\\pi_q}^{\\infty} e^{-x/\\theta}dx/(1-q)\\\\ &amp;=&amp; \\pi_q+\\theta e^{-\\pi_q/\\theta}/(1-q)\\\\ &amp;=&amp; \\pi_q+\\theta. \\end{eqnarray*}\\] Puede ser también provechoso expresar el TVaR en términos de valores esperados limitados. Específicamente tenemos \\[\\begin{eqnarray} TVaR_q[X] &amp;=&amp; \\int_{\\pi_q}^{\\infty} (x-\\pi_q+\\pi_q)f_X(x)dx/(1-q) \\nonumber\\\\ &amp;=&amp; \\pi_q+\\frac{1}{(1-q)}\\int_{\\pi_q}^{\\infty} (x-\\pi_q)f_X(x)dx\\nonumber\\\\ &amp;=&amp; \\pi_q+e_X(\\pi_q)\\nonumber\\\\ &amp;=&amp; \\pi_q +\\frac{\\left({\\mathrm{E}[X]-\\mathrm{E}[X\\wedge\\pi_q]}\\right)}{(1-q)}, \\tag{10.7} \\end{eqnarray}\\] donde \\(e_X(d):=\\mathrm{E}[X-d|X&gt;d]\\) para \\(d&gt;0\\) indica la función de exceso de pérdida media . Para muchas de las distribuciones paramétricas comúnmente usadas, las fórmulas para calcular \\(\\mathrm{E}[X]\\) y \\(\\mathrm{E}[X\\wedge\\pi_q]\\) pueden ser encontradas en una tabla de distribuciones. Ejemplo 10.2.9. TVaR de la distribución Pareto. Se considera una v.a. de pérdida \\(X\\sim Pareto(\\theta,\\alpha)\\) con \\(\\theta&gt;0\\) y \\(\\alpha&gt;0\\). La cdf de \\(X\\) viene dada por \\[ F_X(x)=1-\\left(\\frac{\\theta}{\\theta+x} \\right)^{\\alpha}, \\text{ para } x&gt;0 . \\] Estableciendo \\(q\\in (0,1)\\) y siendo \\(F_X(\\pi_q)=q\\), fácilmente se obtiene \\[\\begin{eqnarray} \\pi_q=\\theta\\left[(1-q)^{-1/\\alpha}-1 \\right]. \\tag{10.8} \\end{eqnarray}\\] De acuerdo a la tabla de distribuciones facilitada en la Sociedad de Actuarios, se sabe que \\[ \\mathrm{E}[X]=\\frac{\\theta}{\\alpha-1}, \\] y \\[ \\mathrm{E}[X\\wedge \\pi_q]=\\frac{\\theta}{\\alpha-1}\\left[ 1-\\left(\\frac{\\theta}{\\theta+\\pi_q}\\right)^{\\alpha-1} \\right]. \\] Recordando la ecuación (10.7) se tiene \\[\\begin{eqnarray*} TVaR_q[X] &amp;=&amp; \\pi_q+\\frac{\\theta}{\\alpha-1} \\frac{(\\theta/(\\theta+\\pi_q))^{\\alpha-1}} {(\\theta/(\\theta+\\pi_q))^{\\alpha}}\\\\ &amp;=&amp;\\pi_q +\\frac{\\theta}{\\alpha-1}\\left( \\frac{\\pi_q+\\theta}{\\theta} \\right)\\\\ &amp;=&amp; \\pi_q+\\frac{\\pi_q+\\theta}{\\alpha-1}, \\end{eqnarray*}\\] donde \\(\\pi_q\\) viene dada por (10.8). A partir de un cambio de variables, se puede también reescribir la ecuación (10.5) como \\[\\begin{eqnarray} TVaR_{q}[X] &amp;=&amp; \\frac{1}{(1-q)}\\int_{q}^{1} VaR_{\\alpha}[X]\\ d\\alpha. \\tag{10.9} \\end{eqnarray}\\] Lo que esta fórmula alternativa (10.9) indica es que el TVaR es de hecho la media del \\(VaR_{\\alpha}[X]\\) con un nivel de confianza variable \\(\\alpha\\in [q,1]\\). Por tanto, el TVaR resuelve efectivamente la mayoría de las limitaciones del VaR señaladas en la subsección previa. Primero, debido al efecto promedio, el TVaR puede ser menos sensible al cambio del nivel de confianza comparado con el VaR. Segundo, todas las pérdidas extremas que están por encima de \\((1-q)\\times 100\\%\\) representando los peores sucesos probables son tenidas en cuenta. En este sentido, es fácil ver que para cualquier \\(q\\in (0,1)\\) \\[ TVaR_q[X]\\geq VaR_q[X]. \\] Tercero y tal vez de forma más relevante, el TVaR es una medida de riesgo coherente y de este modo es capaz de capturar de modo más acertado los efectos de la diversificación de la cartera de seguros. En este caso, no se formula el objetivo de proporcionar la demostración de la característica coherente para el TVaR, que se considera técnicamente cambiante. 10.4 Reaseguro En esta sección, se aprende como: Definir tipos básicos de reaseguro incluyendo el proporcional, cuota- parte, no-proporcional, stop-loss, exceso de pérdida, y excedente. Interpretar la optimalidad de la cuota para los reaseguradores y calcular los acuerdos óptimos de repartos de cuotas. Interpretar la optimalidad del stop-loss para los aseguradores. Interpretar y calcular los límites óptimos de retención de exceso de pérdidas. Recordar que reaseguroseguro comprado por un asegurador es simplemente el seguro comprado por un asegurador. El seguro comprado por no-aseguradores se conoce algunas veces como seguro primarioseguro comprado por un no-asegurador para distinguirlo del reaseguro. El reaseguro difiere de un seguro personal comprado por los individuos, como el seguro de automóviles o el seguro del hogar, en la flexibilidad del contrato. Al igual que los seguros comprados por las grandes empresas, los programas de reaseguro suelen adaptarse mucho al comprador. Por el contrario, los compradores de seguros personales normalmente no pueden negociar los términos del contrato aunque pueden tener una variedad de diferentes opciones (contratos) para elegir. Los dos tipos más amplios de reaseguro son el proporcional y el no-proporcional. Un contrato de reaseguro proporcional un acuerdo entre un reasegurador y una compañía cedente (también conocida como reasegurada) en el cual el reasegurador asume un porcentaje dado de pérdidas y primas es un acuerdo entre un reasegurador y una compañía cedenteuna compañía que compra reaseguro (también conocida como reasegurada) (también conocida como la reasegurada) en el cual el reasegurador asume un porcentaje dado de pérdidas y primas. Un contrato de reaseguro se conoce también como un acuerdoun contrato de reaseguro. Los acuerdos no-proporcionales son simplemente todo lo demás. Como ejemplos de acuerdos no-proporcionales, este capítulo se centra en stop-lossbajo un acuerdo stop-loss, el asegurador establece un nivel de retención y paga siniestros hasta ese nivel con el reasegurador pagando el exceso y ,exceso de pérdida bajo un contrato de exceso de pérdida, el asegurador establece un nivel de retención para cada siniestro y paga indemnizaciones inferiores a dicho nivel mientras que el reasegurador paga el exceso contratado. Para todos los tipos de acuerdos, se divide el riesgo total \\(X\\) entre la porción que asume el reasegurador, \\(Y_{reasegurador}\\), y el retenido por el asegurador, \\(Y_{asegurador}\\), es decir, \\(X= Y_{asegurador}+Y_{reasegurador}\\). La estructura matemática de un contrato de reaseguro básico es la misma que la considerada en las modificacions de cobertura para seguros personales analizados en el Capítulo 3. Para un reaseguro proporcional, la transformación \\(Y_{asegurador} = c X\\) es idéntica a un ajuste de coaseguro en un seguro personal. Para un reaseguro stop-loss, la transformación \\(Y_{reasegurador} = \\max(0,X-M)\\) es la misma que el pago de un asegurador con una franquicia \\(M\\) e \\(Y_{asegurador} = \\min(X,M) = X \\wedge M\\) es equivalente a lo que un tomador paga con una franquicia \\(M\\). Para aplicaciones matemáticas prácticas, en los seguros personales el foco está generalmente en los valores esperados como el ingrediente principal usado en tarificación. Por el contrario, en reaseguro el foco está en la distribución completa del riesgo, dado que los valores extremos son la principal preocupación de la estabilidad financera del asegurador y del reasegurador. Esta sección describe los fundamentos y cuestiones más básicas de los acuerdos de reaseguro: Sección 10.4.1 para el reaseguro proporcional y Sección 10.4.2 para el reaseguro no-proporcional. La Sección 10.4.3 da una pincelada a los contratos más complejos. 10.4.1 Reaseguro Proporcional El ejemplo más sencillo de contratos proporcionales se denominacuota parteUn acuerdo proporcional donde el reasegurador recibe un porcentaje determinado de la prima por la cartera de negocio reasegurado y paga un porcentaje de las pérdidas, incluyendo los gastos asignados de ajuste de pérdidas. El reasegurador puede también pagar a la compañía cedente una comisión de cesión diseñada para reflejar las diferencias en los gastos incurridos en la suscripción.. En un contrato de cuota parte, el reasegurador recibe un porcentaje determinado, digamos el 50%, de la prima por la cartera de negocio reasegurado. A cambio, el reasegurador paga el 50% de las pérdidas, incluidos los gastos asignados de ajuste de pérdidas. El reasegurador también paga a la compañía cedente una comisión de cesión diseñada para reflejar las diferencias en los gastos de suscripción incurridos. Las cantidades pagadas por el asegurador de directo y el reasegurador se resumen como \\[ Y_{asegurador} = c X \\ \\ \\text{y} \\ \\ \\ Y_{reasegurador} = (1-c) X, \\] donde \\(c\\in (0,1)\\) representa la proporción retenida por el asegurador. Destacar que \\(Y_{asegurador}+Y_{reasegurador}=X\\). Ejemplo 10.3.1. Distribución de pérdidas bajo un contrato cuota parte. Para tener en cuenta una idea sobre el efecto de un contrato cuota parte en la distribución de pérdidas, se presenta a continuación una demostración breve en R usando simulación. Tener en cuenta las formas relativas de las distribuciones de las pérdidas totales, la parte retenida (del asegurador), y la parte del reasegurador. Mostrar el Código R set.seed(2018) theta = 1000 alpha = 3 nSim = 10000 library(actuar) X &lt;- rpareto(nSim, shape = alpha, scale = theta) par(mfrow=c(1,3)) plot(density(X), xlim=c(0,3*theta), ylim=c(0,0.008), main=&quot;Total Loss&quot;, xlab=&quot;Losses&quot;) plot(density(0.75*X), xlim=c(0,3*theta), ylim=c(0,0.008), main=&quot;Insurer (75%)&quot;, xlab=&quot;Losses&quot;) plot(density(0.25*X), xlim=c(0,3*theta), ylim=c(0,0.008), main=&quot;Reinsurer (25%)&quot;, xlab=&quot;Losses&quot;) 10.4.1.1 El Cuota Parte es deseable para los Reaseguradores El contrato cuota parte es particularmente deseable para el reasegurador. Para entenderlo, supongamos que un asegurador y un reasegurador desean firmar un contrato para repartir las pérdidas totales \\(X\\) tal que \\[Y_{asegurador}=g(X) \\ \\ \\ \\text{y} \\ \\ \\ \\ Y_{reasegurador}=X-g(X),\\] para alguna función genérica \\(g(\\cdot)\\) (conocida como la función retención). Supongamos además que el asegurador solo se preoucupa por la variabilidad de los siniestros retenidos y es indiferente a la elección de \\(g\\) siempre que \\(Var(Y_{asegurador})\\) sea la misma e igual, digamos, \\(Q\\). Entonces, el siguiente resultado demuestra que el contrato de reaseguro de cuota parte minimiza la incertidumbre del reasegurador medida por \\(Var(Y_{reasegurador})\\). Proposición. Se supone que \\(Var(Y_{asegurador})=Q.\\) Entonces, \\(Var ((1-c)X) \\le Var(g(X))\\) para todo \\(g(.)\\), donde \\(c=Q/Var(X)\\). Mostrar la Justificación de la Proposición Demostración de la Proposición. Donde \\(Y_{reasegurador} = X - Y_{asegurador}\\) y la ley de la variación total \\[ \\begin{array}{ll} Var (Y_{reasegurador}) &amp;= Var (X-Y_{asegurador}) \\\\ &amp;= Var (X) + Var (Y_{asegurador}) - 2 Cov (X,Y_{asegurador}) \\\\ &amp;=Var (X) + Q - 2 Corr (X,Y_{asegurador}) \\times \\sqrt{Q} \\sqrt{Var (X)} \\end{array} \\] En esta expresión, vemos que \\(Q\\) y \\(Var(X)\\) no cambian con la elección de \\(g\\). De este modo, se puede minimizar \\(Var (Y_{reasegurador})\\) maximizando la correlación \\(Corr (X,Y_{asegurador})\\). Si se usa un contrato de reaseguro cuota parte, entonces \\(Corr (X,Y_{asegurador})=Corr (X,(1-c)X)=1\\), la máxima correlación posible. Esto muestra la proposición. \\(\\Box\\)` La propuesta es intuitivamente atractiva – con un contrato de cuota parte, el reasegurador comparte la responsabilidad para siniestros muy grandes en la cola de la distribución. Esto contrasta con los acuerdos no proporcionales donde los reaseguradores se responsabilizan de las grandes reclamaciones. 10.4.1.2 Optimizando los Contratos Cuota Parte para Aseguradores Ahora se asumen \\(n\\) riesgos en la cartera, \\(X_1, \\ldots, X_n,\\) tal que la suma de la cartera es \\(X= X_1 + \\cdots + X_n\\). Por simplicidad, nos centramos en el caso de riesgos independientes. Se considera una variación del contrato básico de cuota parte donde la cantidad retenida por el asegurador puede variar con cada riesgo, digamos \\(c_i\\). De este modo, la parte que el asegurador asume del riesgo de la cartera es \\(Y_{asegurador} = \\sum_{i=1}^n c_i X_i\\). ¿Cuál es la mejor elección de las partes \\(c_i\\)? Para formalizar esta pregunta, tratamos de encontrar aquellos valores de \\(c_i\\) que minimizan \\(Var (Y_{asegurador})\\) teniendo en cuenta la restricción de que \\(E (Y_{asegurador}) = K.\\) El requisito de que \\(E (Y_{asegurador}) = K\\) sugiere que los aseguradores prefieren retener un ingreso como mínimo de la cantidad de la constante \\(K\\). Sujeto a esta restricción sobre el ingreso, el asegurador prefiere minimizar la incertidumbre de los riesgos retenidos medida por la varianza. Mostrar las Proporciones de Retención Óptimas Las Proporciones de Retención Óptimas La minimización de \\(Var(Y_{asegurador})\\) sujeta a \\(E(Y_{asegurador}) = K\\) es un problema de optimización restringida – se puede usar el método de los multiplicadores de Lagrange, una técnica de cálculo, para resolverlo. Para ello, se define el Lagrangiano \\[ \\begin{array}{ll} L &amp;= Var (Y_{asegurador}) - \\lambda (E (Y_{asegurador}) - K) \\\\ &amp;= \\sum_{i=1}^n c_i^2 ~Var(X_i) - \\lambda (\\sum_{i=1}^n c_i ~E(X_i) - K) \\end{array} \\] Calculando la derivada parcial respecto a \\(\\lambda\\) y fijándola igual a cero simplemente significa que se fuerza la restricción, \\(E(Y_{asegurador}) = K\\), y se tienen que elegir las proporciones \\(c_i\\) para satisfacer esta restricción. Además, obteniendo la derivada parcial respecto a cada proporción \\(c_i\\) se obtiene \\[ \\frac{\\partial}{\\partial c_i} L = 2 c_i ~Var(X_i) - \\lambda ~E(X_i) = 0 \\] Tal que \\[ c_i = \\frac{\\lambda}{2} \\frac{E(X_i)}{Var(X_i)} . \\] Con la restricción, se puede determinar \\(\\lambda\\) como la solución de \\[ \\begin{array}{ll} K &amp;= \\sum_{i=1}^3 c_i \\mathrm{E}(X_i) \\\\ &amp;= \\frac{\\lambda}{2} \\sum_{i=1}^3 \\frac{\\mathrm{E}(X_i)^2}{Var(X_i)} \\end{array} \\] Y usar este valor de \\(\\lambda\\) para determinar las proporciones. Desde el punto de vista matemático, se observa que la constante para el riesgo \\(i\\)th, \\(c_i\\) es proporcional a \\(\\frac{E(X_i)}{Var (X_i)}\\). Esto es intuitivamente interesante. Si el resto permanece igual, un mayor ingreso medido por \\(E (X_i)\\) significa un valor más alto de \\(c_i\\). De la misma forma, un mayor grado de incertidumbre medido por \\(Var(X_i)\\)significa un menor valor de \\(c_i\\). El factor de escala proporcional se determina por el requisito de ingreso \\(E(Y_{asegurador}) = K\\). El siguiente ejemplo ayuda a entender esta relación. Ejemplo 10.3.2. Tres riesgos Pareto. Se consideran tres riesgos que siguen una distribución de Pareto. Generar un gráfico, y el código necesario, que proporcionan valores de \\(c_1\\), \\(c_2\\), y \\(c_3\\) para un ingreso determinado \\(K\\). Observar si esos valores aumentan linealmente con \\(K\\). Mostrar un Ejemplo con Tres Riesgos Pareto theta1 = 1000; theta2 = 2000; theta3 = 3000; alpha1 = 3; alpha2 = 3; alpha3 = 4; library(actuar) propnfct &lt;- function(alpha,theta){ mu &lt;- mpareto(shape=alpha, scale=theta, order=1) var &lt;- mpareto(shape=alpha, scale=theta, order=2) - mu^2 mu/var } temp &lt;- propnfct(alpha1, theta1)*mpareto(shape=alpha1, scale=theta1, order=1)+ propnfct(alpha2, theta2)*mpareto(shape=alpha2, scale=theta2, order=1)+ propnfct(alpha3, theta3)*mpareto(shape=alpha3, scale=theta3, order=1) KVec &lt;- seq(100, 2500, length.out=20) Lambdavec &lt;- 2*KVec/temp c1 &lt;- propnfct(alpha1, theta1) c2 &lt;- propnfct(alpha2, theta2) c3 &lt;- propnfct(alpha3, theta3) c1Vec &lt;- c2Vec &lt;- c3Vec &lt;- 0*KVec for (j in 1:20) { c1Vec[j] &lt;- (Lambdavec[j]/2) * propnfct(alpha1, theta1) c2Vec[j] &lt;- (Lambdavec[j]/2) * propnfct(alpha2, theta2) c3Vec[j] &lt;- (Lambdavec[j]/2) * propnfct(alpha3, theta3) } plot(KVec, c1Vec, type=&quot;l&quot;, ylab=&quot;proportion&quot;, xlab=&quot;required revenue (K)&quot;, ylim=c(0,1)) lines(KVec, c2Vec) lines(KVec, c3Vec) text(1200,0.80, expression(c[1])) text(2000,0.75, expression(c[2])) text(1500,0.30, expression(c[3])) 10.4.2 Reaseguro No-Proporcional 10.4.2.1 La Optimalidad del Seguro Stop-Loss Bajo un contrato stop-loss, el asegurador establece un nivel de retención \\(M (&gt;0)\\) y paga en su totalidad los siniestros para los que \\(X \\le M\\). Además, para los siniestros con \\(X &gt; M\\), el asegurador de directo paga \\(M\\) y el reasegurador para la cantidad restante \\(X-M\\). De este modo, el asegurador retiene una cantidad \\(M\\) del riesgo. Resumiendo, las cantidades pagadas por el asegurador de directo y el reasegurador son \\[ Y_{asegurador} = \\begin{cases} X &amp; \\text{for } X \\le M\\\\ M &amp; \\text{for } X &gt;M \\\\ \\end{cases} \\ \\ \\ \\ = \\min(X,M) = X \\wedge M \\] y \\[ Y_{reasegurador} = \\begin{cases} 0 &amp; \\text{for } X \\le M\\\\ X- M &amp; \\text{for } X &gt;M \\\\ \\end{cases} \\ \\ \\ \\ = \\max(0,X-M) . \\] Como antes, notar que \\(Y_{asegurador}+Y_{reasegurador}=X\\). El tipo de contrato stop-loss es particularmente deseable para el asegurador. Similar a lo visto anteriormente, se supone que un asegurador y un reasegurador desean establecer un contrato tal que \\(Y_{asegurador}=g(X)\\) e \\(Y_{reasegurador}=X-g(X)\\) para alguna función de retención genérica \\(g(\\cdot)\\). Se supone además que el asegurador solo se encarga de la variabilidad de los siniestros retenidos y es indiferente respecto a la elección de \\(g\\) siempre que la \\(Var(Y_{asegurador})\\) pueda ser minimizada. De nuevo, se impone la restricción de que \\(E(Y_{asegurador}) = K\\); el asegurador tiene que retener un ingreso \\(K\\). Sujeto a esta restricción de ingreso, el asegurador desea minimizar la incertidumbre de los riesgos retenidos (medida por la varianza). Entonces, se obtiene el siguiente resultado que indica que el acuerdo de reaseguro stop-loss minimiza la incertidumbre del reasegurador medida por \\(Var(Y_{reasegurador})\\). Proposición. Se supone que \\(E(Y_{asegurador})=K.\\) Entonces, \\(Var (X \\wedge M) \\le Var(g(X))\\) para todo \\(g(.)\\), donde \\(M\\) es tal que \\(E(X \\wedge M)=K\\). Mostrar la Justificación de la Proposición Demostración de la Proposición. Añadir y restar una constante \\(M\\) y generar el cuadrado \\[ \\begin{array}{ll} Var(g(X)) &amp;= E (g(X) - K)^2 = E (g(X) -M +M- K)^2 \\\\ &amp;= E (g(X) -M)^2 + (M- K)^2 +2 E (g(X) -M)(M- K) \\\\ &amp;= E (g(X) -M)^2 - (M- K)^2 , \\end{array} \\] Porque \\(E(g(X))= K.\\) Ahora, para cualquier función de retención, se tiene \\(g(X) \\le X\\), es decir, los siniestros retenidos por el asegurador son menores o iguales que el total de los siniestros. Usando la notación \\(g_{SL}(X) = X \\wedge M\\) para los seguros stop-loss, se tiene \\[ \\begin{array}{ll} M- g_{SL}(X) &amp;= M-(X \\wedge M) \\\\ &amp;= (M-X) \\wedge 0 \\\\ &amp;\\le (M-g(X)) \\wedge 0 . \\end{array} \\] Elevando al cuadrado cada parte se tiene \\[(M- g_{SL}(X))^2 \\le (M-g(X))^2 \\wedge 0 \\le (M-g(X))^2.\\] Volviendo a la expresión de la varianza, \\[ \\begin{array}{ll} Var(g_{SL}(X)) &amp;= E (g_{SL}(X) -M)^2 - (M- K)^2 \\\\ &amp;\\le E (g(X) -M)^2 - (M- K)^2 = Var(g(X)) , \\end{array} \\] para cualquier función de retención \\(g\\). Esto demuestra la proposición. \\(\\Box\\)` La proposición es intuitivamente interesante – con el seguro stop-loss, el reasegurador es responsable de los siniestros muy grandes en la cola de la distribución, no el asegurador. 10.4.2.2 Exceso de Pérdida Una forma cerrada de reaseguro no-proporcional es la cobertura exceso de pérdida Bajo un acuerdo de exceso de pérdida, el asegurador establece un nivel de retención para cada siniestro y paga indemnizaciones inferiores a dicho nivel con el reasegurador pagando el exceso. Bajo este contrato, se asume que el riesgo total \\(X\\) puede entenderse como una composición de \\(n\\) riesgos separados \\(X_1, \\ldots, X_n\\) y que cada uno de esos riesgos están sujetos a un límite superior, digamos, \\(M_i\\). De este modo el asegurador retiene \\[ Y_{i,asegurador} = X_i \\wedge M_i \\ \\ \\ \\ Y_{asegurador} = \\sum_{i=1}^n Y_{i,asegurador} \\] y el reasegurador es responsable del exceso, \\(Y_{reasegurador}=X - Y_{asegurador}\\). Los límites de retención pueden variar según el riesgo o pueden ser los mismos para todos los riesgos, \\(M_i =M\\), para todo \\(i\\). 10.4.2.3 Elección Óptima de los Límites de Retención para Exceso de Pérdidas ¿Cuál es la mejor elección de los límites de retención del exceso de pérdidas \\(M_i\\)? Para formalizar esta pregunta, se propone encontrar aquellos valores de \\(M_i\\) que minimizan \\(Var(Y_{asegurador})\\) sujetos a la restricción de que \\(E(Y_{asegurador}) = K.\\) Sujeto a esta restricción de ingresos, el asegurador desea minimizar la incertidumbre de los riesgos retenidos (medidos por la varianza). Mostrar las Proporciones de Retención Óptimas Los Límites de Retención Óptimos Minimizar \\(Var(Y_{asegurador})\\) sujeto a \\(E(Y_{asegurador}) = K\\) es un problema de optimización restringida – se puede usar el método de los multiplicadores de Lagrange, una técnica de cálculo, para resolverlo. Como antes, se define el Lagrangiano \\[ \\begin{array}{ll} L &amp;= Var (Y_{asegurador}) - \\lambda (E(Y_{asegurador}) - K) \\\\ &amp;= \\sum_{i=1}^n ~Var (X_i \\wedge M_i) - \\lambda (\\sum_{i=1}^n ~E(X_i \\wedge M_i)- K). \\end{array} \\] En primer lugar se presentan las relaciones \\[ E(X \\wedge M) = \\int_0^M ~(1- F(x))dx \\] y \\[ E(X \\wedge M)^2 = 2\\int_0^M ~x(1- F(x))dx. \\] Calculando la derivada parcial respecto a \\(\\lambda\\) y fijándola igual a cero simplemente significa que se fuerza la restricción, \\(E(Y_{asegurador}) = K\\), y se han de elegir los límites \\(M_i\\) para satisfacer dicha restricción. Además, calculando la derivada parcial respecto a cada límite \\(M_i\\) se obtiene \\[ \\begin{array}{ll} \\frac{\\partial}{\\partial M_i} L &amp;= \\frac{\\partial}{\\partial M_i} ~Var(X_i \\wedge M_i) - \\lambda \\frac{\\partial}{\\partial M_i} ~E(X_i \\wedge M_i) \\\\ &amp;= \\frac{\\partial}{\\partial M_i} \\left(E(X_i \\wedge M_i)^2 -(E(X_i \\wedge M_i))^2\\right) - \\lambda (1-F_i(M_i)) \\\\ &amp;= 2 M_i (1-F_i(M_i)) - 2 E(X_i \\wedge M_i) (1-F_i(M_i))- \\lambda (1-F_i(M_i)). \\end{array} \\] Estableciendo \\(\\frac{\\partial}{\\partial M_i} L =0\\) y resolviendo para \\(\\lambda\\), se obtiene \\[ \\lambda = 2 (M_i - E(X_i \\wedge M_i)) . \\] Desde el punto de vista matemático se obtiene que el límite de retención menos los siniestros esperados por el asegurador, \\(M_i - E(X_i \\wedge M_i)\\), es el mismo para todos los riesgos. Esto es intuitivamente interesante. Ejemplo 10.3.3. Exceso de pérdidas para tres riesgos de Pareto . Se consideran tres riesgos que siguen una distribución de Pareto, cada uno definido por un set diferente de parámetros (de forma que son independientes pero no-idénticos). Demostrar numéricamente que los límites óptimos de retención \\(M_1\\), \\(M_2\\), y \\(M_3\\) calulados como los límites de retención menos los siniestros esperados por el asegurador, \\(M_i - E(X_i \\wedge M_i)\\), son los mismos para todos los riesgos, como se demuestra teóricamente. Además, comparar gráficamente la distribución de todos los riesgos con la de los retenidos por el asegurador y el reasegurador. Mostrar un Ejemplo con Tres Riesgos Pareto Primero se optimiza el Lagrangiano usando el paquete R alabama para Algoritmo de Minimización de la Barrera Adaptativa del Lagrangiano Aumentado. theta1 = 1000;theta2 = 2000;theta3 = 3000; alpha1 = 3; alpha2 = 3; alpha3 = 4; Pmin &lt;- 2000 library(actuar) VarFct &lt;- function(M){ M1=M[1];M2=M[2];M3=M[3] mu1 &lt;- levpareto(limit=M1,shape=alpha1, scale=theta1, order=1) var1 &lt;- levpareto(limit=M1,shape=alpha1, scale=theta1, order=2)-mu1^2 mu2 &lt;- levpareto(limit=M2,shape=alpha2, scale=theta2, order=1) var2 &lt;- levpareto(limit=M2,shape=alpha2, scale=theta2, order=2)-mu2^2 mu3 &lt;- levpareto(limit=M3,shape=alpha3, scale=theta3, order=1) var3 &lt;- levpareto(limit=M3,shape=alpha3, scale=theta3, order=2)-mu3^2 varFct &lt;- var1 +var2+var3 meanFct &lt;- mu1+mu2+mu3 c(meanFct,varFct) } f &lt;- function(M){VarFct(M)[2]} h &lt;- function(M){VarFct(M)[1] - Pmin} library(alabama) par0=rep(1000,3) op &lt;- auglag(par=par0,fn=f,hin=h,control.outer=list(trace=FALSE)) Los límites de retención óptimos \\(M_1\\), \\(M_2\\), y \\(M_3\\) calculados como los límites de retención menos los siniestros esperados del asegurador, \\(M_i - E(X_i \\wedge M_i)\\), son los mismos para todos los riesgos, como se ha derivado teóricamente. M1star = op$par[1];M2star = op$par[2];M3star = op$par[3] M1star -levpareto(M1star,shape=alpha1, scale=theta1,order=1) [1] 1344.135 M2star -levpareto(M2star,shape=alpha2, scale=theta2,order=1) [1] 1344.133 M3star -levpareto(M3star,shape=alpha3, scale=theta3,order=1) [1] 1344.133 Gráficamente se compara la distribución de los riesgos totales con los retenidos por el asegurador y el reasegurador. set.seed(2018) nSim = 10000 library(actuar) Y1 &lt;- rpareto(nSim, shape = alpha1, scale = theta1) Y2 &lt;- rpareto(nSim, shape = alpha2, scale = theta2) Y3 &lt;- rpareto(nSim, shape = alpha3, scale = theta3) YTotal &lt;- Y1 + Y2 + Y3 Yinsur &lt;- pmin(Y1,M1star)+pmin(Y2,M2star)+pmin(Y3,M3star) Yreinsur &lt;- YTotal - Yinsur par(mfrow=c(1,3)) plot(density(YTotal), xlim=c(0,10000), main=&quot;Total Loss&quot;, xlab=&quot;Losses&quot;) plot(density(Yinsur), xlim=c(0,10000), main=&quot;Insurer&quot;, xlab=&quot;Losses&quot;) plot(density(Yreinsur), xlim=c(0,10000), main=&quot;Reinsurer&quot;, xlab=&quot;Losses&quot;) 10.4.3 Acuerdos de Reaseguro Adicionales 10.4.3.1 Acuerdo Surplus Share Proportional Treaty Otro acuerdo proporcional es el denominado surplus shareUn acuerdo de reaseguro proporcional que es frecuente en seguros de daños comerciales. Un acuerdo surplus share permite al reasegurado limitar su exposición en un determinado riesgo a una cantidad dada (el pleno de retención). El reasegurador asume una parte del riesgo en proporción a la cantidad que el valor asegurado excede el pleno de retención, hasta un límite dado (expresado como un múltiplo del pleno de retención, o número de plenos).; este tipo de contratos es frecuente en seguros de daños comerciales. Un acuerdo surplus share permite al reasegurado limitar su exposición a un determinado riesgo a una cantidad dada (el pleno de retención). El reasegurador asume una parte del riesgo en proporción a la cantidad que el valor asegurado excede el pleno de retención, hasta un límite dado (expresado como un múltiplo del pleno de retención, o número de plenos). Por ejemplo, sea el pleno de retención $100,000 y el límite 4 veces el pleno ($400,000). Entonces, si \\(X\\) es la pérdida, la parte del reasegurador es \\(\\min(400000, (X-100000)_+)\\). 10.4.3.2 Layers de cobertura Se pueden extender los acuerdos de reaseguro no-proporcionales stop-loss introduiendo partes adicionales al contrato. Por ejemplo, en lugar de simplemente un asegurador y un reasegurador o un asegurador y un tomador, pensar en una situación con las tres partes, tomador, asegurador, y reasegurador, los cuales se ponen de acuerdo en como repartir el riesgo. De forma más general, se consideran \\(k\\) partes. Si \\(k=3\\), podria tratarse de un asegurador y dos reaseguradores diferentes. Ejemplo 10.3.4. Layers de cobertura para tres partes. Se supone que hay \\(k=3\\) partes. La primera parte es responsable de los siniestros hasta 100, la segunda es responsable de los siniestros entre 100 y 3000, y la tercera es responsable de los siniestros por encima de 3000. Si hay cuatro siniestros de cuantías 50, 600, 1800 y 4000, entonces estarían repartidos entre las partes de la forma: Layer Siniestro 1 Siniestro 2 Siniestro 3 Siniestro 4 Total (0, 100] 50 100 100 100 350 (100, 3000] 0 500 1700 2900 5100 (3000, $ ty$) 0 0 0 1000 1000 Total 50 600 1800 4000 6450 Para considerar la situación general con \\(k\\) grupos, se divide la línea de los reales positivos en \\(k\\) intervalos usando los puntos de corte \\[0 = M_0 &lt; M_1 &lt; \\cdots &lt; M_{k-1} &lt; M_k = \\infty.\\] Observar que el intervalo \\(j\\)th es \\((M_{j-1}, M_j]\\). Ahora sea \\(Y_j\\) la cuantía de riesgo compartida por la parte \\(j\\)th. Para ilustrarlo, si una pérdida \\(x\\) es tal que \\(M_{j-1} &lt;x \\le M_j\\), entonces \\[\\left(\\begin{array}{c} Y_1\\\\ Y_2 \\\\ \\vdots \\\\ Y_j \\\\Y_{j+1} \\\\ \\vdots \\\\Y_k \\end{array}\\right) =\\left(\\begin{array}{c} M_1-M_0 \\\\ M_2-M_1 \\\\ \\vdots \\\\ x-M_{j-1} \\\\ 0 \\\\ \\vdots \\\\0 \\end{array}\\right)\\] De forma más clara, podemos escribir \\[Y_j = \\min(X,M_j) - \\min(X,M_{j-1}) .\\] Con la expresión \\(Y_j = \\min(X,M_j) - \\min(X,M_{j-1})\\), se observa que la parte \\(j\\)th es responsable de los siniestros en el intervalo \\((M_{j-1}, M_j].\\) Con esto, es fàcil comprobar que \\(X = Y_1 + Y_2 + \\cdots + Y_k.\\) Como se destaca en el siguiente ejemplo, también se puede remarcar que las partes no necesitan ser diferentes. Ejemplo 10.3.5. - Suponer que un tomador es responsable de los primeros 500 y todos los siniestros en exceso de 100.000. El asegurador coge siniestros entre 100 y 100.000. - Entonces, se deberían usar \\(M_1 = 100\\), \\(M_2 =100000\\). - El tomador es responsable de \\(Y_1 =\\min(X,100)\\) y \\(Y_3 = X - \\min(X,100000) = \\max(0, X-100000)\\). Para saber más, consultar en Wisconsin Property Fund site un ejemplo de layers de reaseguro. 10.4.3.3 Ejemplo de Gestión de Cartera Pueden encontrarse muchas otras variaciones de los contratos originales. Para tener más ilustraciones, se considera lo siguiente. Ejemplo. 10.3.6. Gestión de carteras. Tú eres el jefe de riesgos de una empresa de telecomunicaciones. Tu empresa tiene varios riesgos de daños y responsabilidad. Se considera: \\(X_1\\) - edificios, modelizados por medio de una distribución gamma de media 200 y parámetro de escala 100. \\(X_2\\) - vehículos a motor, modelizados usando una distribución gamma con media 400 y parámetro de escala 200. \\(X_3\\) - responsabilidad de directores y ejecutivos, modelizada usando una distribución de Pareto con media 1000 y parámetro de escala 1000. \\(X_4\\) - ciberriesgos, modelizados usando una distribución de Pareto con media 1000 y parámetro de escala 2000. Se describe el riesgo total como \\[X = X_1 + X_2 + X_3 + X_4 .\\] Por simplicidad, se asume que esos riesgos son independientes. Para controlar el riesgo, se contrata algún tipo de cobertura aseguradora. Se puede preferir controlar internamente pequeñas cantidades relacionades con edificios y vehículos a motor, hasta \\(M_1\\) y \\(M_2\\), respectivamente. Se recurre al seguro para cubrir todos los demás riesgos. Específicamente, la parte del asegurador es \\[ Y_{asegurador} = (X_1 - M_1)_+ + (X_2 - M_2)_+ + X_3 + X_4 ,\\] De forma que tu riesgo retenido es \\(Y_{retenido}= X- Y_{asegurador} =\\) \\(\\min(X_1,M_1) + \\min(X_2,M_2)\\). Usando franquicias \\(M_1=\\) 100 y \\(M_2=\\) 200: Determinar de la cuantía esperada por siniestro (i)la retenida, (ii) la aceptada por el asegurador, y (iii) la cuantía total. Determinar los percentiles 80, 90, 95, y 99 para (i) la parte retenida, (ii) la parte aceptada por el asegurador, y (iii) la cuantía total. Comparar las distribuciones graficando las densidades para (i) la parte retenida, (ii) la aceptada por el asegurador, y (iii) la cuantía total. Mostrar Solución al Ejemplo con Código R En preparación, se adjunta el código necesario para establecer los parámetros. # Para la distribución gamma, usar alpha1 &lt;- 2; theta1 &lt;- 100 alpha2 &lt;- 2; theta2 &lt;- 200 # Para la distribución de Pareto, usar alpha3 &lt;- 2; theta3 &lt;- 1000 alpha4 &lt;- 3; theta4 &lt;- 2000 # Límites M1 &lt;- 100 M2 &lt;- 200 Con estos parámetros, se pueden simular acaecimientos de los riesgos de la cartera. # Simular los riesgos nSim &lt;- 10000 #número de simulaciones set.seed(2017) #establecer la seed para reproducir el trabajo X1 &lt;- rgamma(nSim,alpha1,scale = theta1) X2 &lt;- rgamma(nSim,alpha2,scale = theta2) # Para la Distribución de Pareto, usar library(actuar) X3 &lt;- rpareto(nSim,scale=theta3,shape=alpha3) X4 &lt;- rpareto(nSim,scale=theta4,shape=alpha4) # Riesgos de Cartera X &lt;- X1 + X2 + X3 + X4 Yretenido &lt;- pmin(X1,M1) + pmin(X2,M2) Yasegurador &lt;- X - Yretenido (a) Aquí está el código para las cantidades esperadas por siniestro. # Cantidades esperadas por siniestro ExpVec &lt;- t(as.matrix(c(mean(Yretenido),mean(Yasegurador),mean(X)))) colnames(ExpVec) &lt;- c(&quot;Retenido&quot;, &quot;Asegurador&quot;,&quot;Total&quot;) round(ExpVec,digits=2) Retenido Asegurador Total [1,] 269.05 5274.41 5543.46 (b) Aquí está el código para los cuantiles. # Cuantiles quantMat &lt;- rbind( quantile(Yretenido, probs=c(0.80, 0.90, 0.95, 0.99)), quantile(Yasegurador, probs=c(0.80, 0.90, 0.95, 0.99)), quantile(X , probs=c(0.80, 0.90, 0.95, 0.99))) rownames(quantMat) &lt;- c(&quot;Retenido&quot;, &quot;Asegurador&quot;,&quot;Total&quot;) round(quantMat,digits=2) 80% 90% 95% 99% Retenido 300.00 300.00 300.00 300.00 Asegurador 6075.67 7399.80 9172.69 14859.02 Total 6351.35 7675.04 9464.20 15159.02 (c) Aquí está el código para los gráficos de densidades del riesgo retenido, del asegurador y el total de riesgo de cartera. par(mfrow=c(1,3)) plot(density(Yretenido), xlim=c(0,500), main=&quot;Riesgo de Cartera Retenido&quot;, xlab=&quot;Pérdida (Tener en cuenta la escala horizontal diferente)&quot;, ylab = &quot;Densidad (Tener en cuenta la diferente escala vertical)&quot;) plot(density(Yasegurador), xlim=c(0,15000), main=&quot;Riesgo de Cartera del Asegurador&quot;, xlab=&quot;Pérdida&quot;) plot(density(X), xlim=c(0,15000), main=&quot;Riesgo Total de Cartera&quot;, xlab=&quot;Pérdida&quot;) 10.5 Recursos y Colaboradores adicionales Edward W. (Jed) Frees, University of Wisconsin-Madison, y Jianxi Su, Purdue University son los autores principales de la versión inicial de este capítulo. Email: jfrees@bus.wisc.edu y/o jianxi@purdue.edu para comentarios sobre el capítulo y mejoras sugeridas. Revisores del Capítulo: Fei Huang, Hirokazu (Iwahiro) Iwasawa, Peng Shi, Ping Wang, Chengguo Weng. Traducción al español: Mercedes Ayuso (Universitat de Barcelona) Algunos de los ejemplos de este capítulo se tomaron de Clark (1996), Klugman, Panjer, and Willmot (2012), y Bahnemann (2015). Estas referencias proporcionan excelentes Fuentes para discusiones adicionales y ejemplos. Bibliography "],
["C-LossReserves.html", "Chapter 11 Provisiones 11.1 Motivación 11.2 Datos de provisiones 11.3 Chain-Ladder 11.4 GLMs y Bootstrap para provisiones 11.5 Recursos adicionales y contribuciones", " Chapter 11 Provisiones Vista previa del capítulo. Este capítulo introduce las provisiones (también conocidas como reservas por pérdidas) para seguros de propiedad y accidentes (P&amp;C, según sus siglas en inglés, o generales, no-vida). En particular, el capítulo presenta algunas herramientas analíticas básicas esenciales para evaluar las reservas de una cartera de productos de seguros de P&amp;C. En primer lugar, la Sección 11.1 motiva la necesidad de las provisiones. Después la Sección 11.2 estudia las fuentes de datos disponibles e introduce algunas notaciones formales para enfocar las provisiones como un desafío de predicción. A continuación, la sección 11.3 cubre el método de chain-ladder y el modelo de chain-ladder con distribución libre de Mack. La sección 11.4 finalmente desarrolla un enfoque totalmente estocástico para determinar la reserva pendiente con modelos lineales generalizados (GLMs, según sus siglas en inglés), incluyendo la técnica de bootstrapping para obtener una distribución predictiva de la reserva pendiente a través de la simulación. 11.1 Motivación Nuestro punto de partida es la vida de un siniestro en un seguro de P&amp;C. La figura 11.1 muestra el desarrollo del siniestro a lo largo del tiempo e identifica los eventos de interés: Figure 11.1: Vida o run-off de un siniestro El evento asegurado o accidente ocurre en el momento \\(t_{occ}\\). Este siniestro es reportado a la compañía de seguros en el momento \\(t_{rep}\\), después de un cierto tiempo de demora. Si la compañía de seguros acepta la reclamación presentada, realizará diferentes pagos para reembolsar la pérdida financiera del titular de la póliza. En este ejemplo, la compañía de seguros compensa la pérdida sufrida con pagos por pérdidas en los momentos \\(t_1\\), \\(t_2\\) u \\(t_3\\). Finalmente, la reclamación se liquida o cierra en el momento \\(t_{set}\\). A menudo las reclamaciones no se liquidan inmediatamente debido a la presencia de una demora en la presentación de la reclamación, un retraso en el proceso de liquidación o ambos. El retraso en la notificación es el tiempo que transcurre entre la ocurrencia del evento asegurado y la notificación de este evento a la compañía de seguros. El tiempo entre la notificación y la liquidación de una reclamación se conoce como la demora en la liquidación. Por ejemplo, es muy intuitivo que una reclamación por daños materiales se resuelve más rápidamente que una reclamación por lesiones corporales que impliquen un tipo de lesión compleja. Las reclamaciones cerradas pueden reabrirse debido a nuevos acontecimientos, por ejemplo, una lesión que requiere un tratamiento adicional. En conjunto, el desarrollo del siniestro requiere un tiempo. La presencia de este retraso en la tramitación de un siniestro obliga al asegurador a disponer de capital para liquidar estas reclamaciones en el futuro. 11.1.1 Siniestros cerrados, IBNR, y RBNS Basándonos en el estado de la liquidación de la reclamación, distinguimos tres tipos de siniestros en los libros de una compañía de seguros. El primer tipo de siniestro es una reclamación cerrada. Para estos siniestros se ha observado el desarrollo completo. Con la línea roja de la figura 11.2 que indica el momento presente, todos los eventos del desarrollo del siniestro tienen lugar antes del momento presente. Por lo tanto, estos eventos se observan en el momento actual. Por comodidad, asumiremos que una reclamación cerrada no puede reabrirse. Figure 11.2: Vida de un siniestro cerrado Un siniestro RBNS ha sido comunicado pero no está completamente liquidado (Reported But Not Settled) en el momento actual o en el momento de la evaluación, es decir, el momento en que las provisiones deben ser calculadas y reservadas por el asegurador. La ocurrencia, la notificación y posiblemente algunos pagos tienen lugar antes del momento presente, pero el cierre del siniestro ocurre en el futuro, más allá del momento presente. Figure 11.3: Vida de un siniestro RBNS Un siniestro IBNR ha ocurrido en el pasado pero aún no ha sido comunicado (Incurred But Not yet Reported). El evento asegurado ocurrió, pero la compañía de seguros aún no está al tanto del siniestro asociado. Esta reclamación se comunicará en el futuro y su desarrollo completo (desde la comunicación hasta la liquidación) tendrá lugar en el futuro. Figure 11.4: Vida de un siniestro IBNR Las compañías de seguros provisionarán el capital para cumplir con sus responsabilidades futuras con respecto a los siniestros tanto RBNS como IBNR. El desarrollo futuro de tales siniestros es incierto y se utilizarán técnicas de modelización predictiva para calcular las reservas adecuadas, a partir de los datos históricos de desarrollo observados en siniestros similares. 11.1.2 ¿Por qué reservar? El ciclo de producción invertido del mercado de los seguros y la dinámica de los siniestros que se muestra en la sección 11.1.1 motivan la necesidad de reservar y el diseño de herramientas de modelización predictiva para estimar las reservas. En los seguros, los ingresos por primas preceden a los costes. Un asegurador cobrará una prima a un cliente, antes de saber realmente cómo de costosa será la póliza o el contrato de seguro. En la industria manufacturera normalmente no es así y el fabricante sabe - antes de vender un producto - cuál fue el coste de producción de este producto. En un momento de evaluación específico \\(\\tau\\) el asegurador predecirá sus responsabilidades pendientes con respecto a los contratos vendidos en el pasado. Esta es la reserva de siniestros o reserva para pérdidas; es el capital necesario para liquidar los siniestros abiertos de exposiciones pasadas. Es un elemento muy importante en el balance del asegurador, más concretamente en el pasivo de este balance. 11.2 Datos de provisiones 11.2.1 De Micro a Macro Ahora analizamos los datos disponibles para estimar la reserva pendiente de una cartera de contratos P&amp;C. Las compañías de seguros suelen registrar los datos sobre el desarrollo de un siniestro individual como se muestra en la línea de tiempo a la izquierda de la figura 11.5. Nos referimos a los datos registrados a este nivel como datos granulares o de micro-nivel. Típicamente, un actuario agrega la información registrada sobre la evolución individual de los siniestros para todas las reclamaciones de una cartera. Esta agregación da lugar a datos estructurados en un formato triangular como se muestra en la parte derecha de la figura 11.5. Estos datos se denominan datos agregados o a nivel macro porque cada celda del triángulo muestra la información obtenida al agregar el desarrollo de múltiples reclamaciones. Figure 11.5: De datos granulares a triángulo de desarrollo La visualización triangular utilizada en la provisión por pérdidas se llama triángulo run-off o de desarrollo. En el eje vertical el triángulo enumera los años de accidente o de ocurrencia durante los cuales se sigue una cartera. Los pagos provisionados para un siniestro específico están conectados con el año durante el cual ocurrió el evento asegurado. En el eje horizontal se indica el retraso en el pago desde la ocurrencia del evento asegurado. 11.2.2 Triángulos de desarrollo Un primer ejemplo de un triángulo de desarrollo con pagos incrementales se muestra en la Figura ?? (tomada de Wüthrich and Merz (2008), Tabla 2.2, también utilizada en Wüthrich and Merz (2015), Tabla 1.4). Los años de los accidentes (o años de ocurrencia) se muestran en el eje vertical y van desde 2004 hasta 2013. Se refieren al año durante el cual ocurrió el evento asegurado. El eje horizontal indica el retraso en el pago en años desde la ocurrencia del evento asegurado. 0 retraso se utiliza para los pagos realizados en el año de ocurrencia del accidente o evento asegurado. Un año de retraso se utiliza para los pagos realizados en el año posterior a la ocurrencia del accidente. Figure 11.6: Triángulo de Desarrollo con datos de pagos incrementales. Fuente: Wüthrich and Merz (2008), Tabla 2.2. Por ejemplo, la celda \\((2004, 0)\\) del triángulo anterior muestra el número \\(5947\\), la cantidad total pagada en el año 2004 por todas los siniestros ocurridos en el año 2004. Por lo tanto, es la cantidad total pagada con 0 años de retraso en todas las reclamaciones que ocurrieron en el año 2004. De manera similar, el número de la celda \\((2012,1)\\) muestra el total de \\(2357,9\\) pagados en el año 2013 por todos los siniestros que ocurrieron en el año 2012. Figure 11.7: Triángulo de desarrollo con datos de pago acumulados. Fuente: Wüthrich and Merz (2008), Tabla 2.2. Mientras que el triángulo de la Figura 11.6 muestra los datos de pago incremental, la Figura 11.7 muestra la misma información en formato acumulado. Ahora, la celda \\((2004,1)\\) muestra la cantidad total pagada hasta la demora de pago 1 para todos los siniestros que ocurrieron en el año 2004. Por lo tanto, es la suma de la cantidad pagada en 2004 y la cantidad pagada en 2005 por los accidentes que ocurrieron en 2004. Se pueden utilizar diferentes datos en triángulos de desarrollo como los que se muestran en la Figura 11.6 y en la Figura 11.7. Dependiendo del tipo de datos utilizados, el triángulo se utilizará para estimar diferentes cantidades. Por ejemplo, en el formato incremental una celda puede mostrar: los pagos de los siniestros, como explicado antes el número de reclamaciones que se produjeron en un año específico y que se notificaron con cierto retraso, cuando el objetivo es estimar el número de siniestros IBNR la variación en las cantidades incurridas, donde las cantidades incurridas de los siniestros son la suma de los siniestros pagados acumulados y las estimaciones individuales. La estimación individual es la estimación del tramitador de los siniestros sobre la cantidad pendiente de pago de un siniestro. En el formato acumulado una celda puede mostrar: la cantidad pagada acumulada, según lo explicado antes el número total de siniestros de un año de ocurrencia, notificados hasta un determinado retraso las cantidades incurridas de los siniestros. Es posible que se disponga de otras fuentes de información, por ejemplo, covariables (como el tipo de siniestros), información externa (como inflación, cambios regulatorios). La mayoría de los métodos de provisión de siniestros diseñados para los triángulos de desarrollo se basan más bien en una sola fuente de información, aunque algunas contribuciones recientes se centran en el uso de datos más detallados para la provisión de pérdidas. 11.2.3 Notación de provisiones Triángulos de desarrollo Para formalizar lo mostrado en las figuras 11.6 y 11.7, permitimos que \\(i\\) se refiera al año de ocurrencia o accidente, el año en que ocurrió el evento asegurado. En nuestra anotación el primer año de accidente considerado en la cartera se denota con 1 y el último año de accidente, el más reciente, se denota con \\(I\\). De la misma forma, \\(j\\) se refiere al año de retraso de pago o desarrollo, donde un retraso igual a 0 corresponde al año de accidente. La figura 11.8 muestra un triángulo en el que se considera el mismo número de años en la dirección vertical y en la horizontal, por lo que \\(j\\) va desde 0 hasta \\(J = I-1\\). Figure 11.8: Notación matemática para un triángulo de desarrollo. Fuente: Wüthrich and Merz (2008) La variable aleatoria \\(X_{ij}\\) denota las reclamaciones incrementales pagadas en el período de desarrollo \\(j\\) de los siniestros del año de accidente \\(i\\). Por lo tanto, \\(X_{ij}\\) es la cantidad total pagada en el año de desarrollo \\(j\\) por todos los siniestros que ocurrieron en el año de ocurrencia \\(i\\). Estas cuantías se pagan realmente en el año contable o natural \\(i+j\\). Desde un punto de vista acumulado, \\(C_{ij}\\) es la cantidad acumulada pagada hasta (e incluyendo) el año de desarrollo \\(j\\) por los accidentes ocurridos en el año \\(i\\). Al final, se paga una cantidad total de \\(C_{iJ}\\) en el último año de desarrollo \\(J\\) por los siniestros ocurridos en el año de accidente \\(i\\). En este capítulo el tiempo se expresa en años, aunque también se pueden utilizar otras unidades de tiempo, por ejemplo, semestres o trimestres. Provisión por pérdidas En el momento de la evaluación \\(\\tau\\), se han observado los datos del triángulo superior, mientras que el triángulo inferior tiene que predecirse. Aquí, el momento de la evaluación es el final del año del accidente \\(I\\) lo que implica que una celda \\((i,j)\\) con \\(i+j \\leq I\\) se observa, y una celda \\((i,j)\\) con \\(i+j &gt; I\\) pertenece al futuro y tiene que ser predicha. Así, para un triángulo de desarrollo acumulado, el objetivo de un método de provisión de pérdidas es predecir \\(C_{i,I-1}\\), la cantidad última por los siniestros para el año de ocurrencia \\(i\\), correspondiente al período final de desarrollo \\(I-1\\) en la Figura 11.7. Asumimos que - más allá de este período - no habrá más pagos, aunque este supuesto puede relajarse. Dado que \\(C_{i,I-1}\\) es acumulado, incluye tanto una parte observada como una parte que debe predecirse. Por lo tanto, la provisión por pagos pendientes para el año de accidente \\(i\\) es \\[\\begin{eqnarray*} \\mathcal{R}^{(0)}_{i} = \\sum_{\\ell=I-i+1}^{I-1} X_{i\\ell} = C_{i,I}-C_{i,I-i}. \\end{eqnarray*}\\] Expresamos la reserva como una suma de datos incrementales, \\(X_{i\\ell}\\), o como la diferencia entre datos acumulados. En este último caso, la cantidad pendiente es la cantidad acumulada final \\(C_{i,I}\\) menos la cantidad acumulada observada más reciente \\(C_{i,I-i}\\). Siguiendo a Wüthrich and Merz (2015), la anotación \\(\\mathcal{R}^{(0)}_{i}\\) se refiere a la reserva para el año de ocurrencia \\(i\\) donde \\(i=1,\\ldots,I\\). El superíndice \\((0)\\) se refiere a la evaluación de la reserva en el momento actual, digamos \\(\\tau = 0\\). Entendemos que \\(\\tau = 0\\) al final del año de ocurrencia \\(I\\), el año calendario más reciente para el que se observan y registran los datos. 11.2.4 Código R para resumir datos de provisión de pérdidas Usamos el paquete ChainLadder (Gesmann et al. 2019) para importar triángulos de desarrollo en R y para explorar las tendencias presentes en estos triángulos. La viñeta del paquete documenta muy bien sus funciones para trabajar con datos triangulares. Primero, exploramos dos formas de importar un triángulo. Datos con formato extenso El conjunto de datos triangle_W_M_long.txt almacena el triángulo de desarrollo acumulado de Wüthrich and Merz (2008) (Tabla 2.2) en formato largo. Es decir, cada celda del triángulo es una fila de este conjunto de datos, y se almacenan tres características: la cuantía del pago (acumulado, en este ejemplo), el año de ocurrencia (\\(i\\)) y el retraso del pago (\\(j\\)). Importamos el archivo .txt y almacenamos el conjunto de datos resultante como my_triangle_long: Código R para importar datos de texto my_triangle_long &lt;- read.table(&quot;Data/triangle_W_M_long.txt&quot;, header = TRUE) head(my_triangle_long) payment origin dev 1 5946975 2004 0 2 9668212 2004 1 3 10563929 2004 2 4 10771690 2004 3 5 10978394 2004 4 6 11040518 2004 5 Usamos la función as.triangle del paquete ChainLadder para transformar el conjunto de datos en formato triangular. El objeto resultante my_triangle ahora es de tipo triangle. Código R para la transformación en formato triangular my_triangle &lt;- as.triangle(my_triangle_long, origin = &quot;origin&quot;, dev = &quot;dev&quot;, value = &quot;payment&quot;) str(my_triangle) &#39;triangle&#39; int [1:10, 1:10] 5946975 6346756 6269090 5863015 5778885 6184793 5600184 5288066 5290793 5675568 ... - attr(*, &quot;dimnames&quot;)=List of 2 ..$ origin: chr [1:10] &quot;2004&quot; &quot;2005&quot; &quot;2006&quot; &quot;2007&quot; ... ..$ dev : chr [1:10] &quot;0&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; ... Mostramos el triángulo y reconocemos los números (en miles) de la figura 11.7. Las celdas en el triángulo inferior se indican como valores ausentes (not available), NA. Código R para mostrar datos triangulares round(my_triangle/1000, digits = 0) dev origin 0 1 2 3 4 5 6 7 8 9 2004 5947 9668 10564 10772 10978 11041 11106 11121 11132 11148 2005 6347 9593 10316 10468 10536 10573 10625 10637 10648 NA 2006 6269 9245 10092 10355 10508 10573 10627 10636 NA NA 2007 5863 8546 9269 9459 9592 9681 9724 NA NA NA 2008 5779 8524 9178 9451 9682 9787 NA NA NA NA 2009 6185 9013 9586 9831 9936 NA NA NA NA NA 2010 5600 8493 9057 9282 NA NA NA NA NA NA 2011 5288 7728 8256 NA NA NA NA NA NA NA 2012 5291 7649 NA NA NA NA NA NA NA NA 2013 5676 NA NA NA NA NA NA NA NA NA Datos en formato triangular Alternativamente, el triángulo puede ser almacenado en un archivo .csv con los años de ocurrencia en las filas y los años de desarrollo en las celdas de la columna. Importamos este archivo .csv y transformamos my_triangle_csv resultante en una matriz. Código R para importar datos triangulares my_triangle_csv &lt;- read.csv2(&quot;Data/triangle_W_M.csv&quot;, header = FALSE) my_triangle_matrix &lt;- as.matrix(my_triangle_csv) dimnames(my_triangle_matrix) &lt;- list(origin = 2004 : 2013, dev = 0:(ncol(my_triangle_matrix)-1)) Inspeccionamos el triángulo: Código R para mostrar datos triangulares my_triangle &lt;- as.triangle(my_triangle_matrix) round(my_triangle/1000, digits = 0) dev origin 0 1 2 3 4 5 6 7 8 9 2004 5947 9668 10564 10772 10978 11041 11106 11121 11132 11148 2005 6347 9593 10316 10468 10536 10573 10625 10637 10648 NA 2006 6269 9245 10092 10355 10508 10573 10627 10636 NA NA 2007 5863 8546 9269 9459 9592 9681 9724 NA NA NA 2008 5779 8524 9178 9451 9682 9787 NA NA NA NA 2009 6185 9013 9586 9831 9936 NA NA NA NA NA 2010 5600 8493 9057 9282 NA NA NA NA NA NA 2011 5288 7728 8256 NA NA NA NA NA NA NA 2012 5291 7649 NA NA NA NA NA NA NA NA 2013 5676 NA NA NA NA NA NA NA NA NA De acumulado a incremental y viceversa Las funciones de R cum2incr() y incr2cum() nos permiten pasar de datos acumulados a incrementales, y viceversa, de una manera fácil. Código R para pasar de visualización de datos acumulados a incrementales my_triangle_incr &lt;- cum2incr(my_triangle) round(my_triangle_incr/1000, digits = 0) dev origin 0 1 2 3 4 5 6 7 8 9 2004 5947 3721 896 208 207 62 66 15 11 16 2005 6347 3246 723 152 68 37 53 11 12 NA 2006 6269 2976 847 263 153 65 54 9 NA NA 2007 5863 2683 723 191 133 88 43 NA NA NA 2008 5779 2745 654 273 230 105 NA NA NA NA 2009 6185 2828 573 245 105 NA NA NA NA NA 2010 5600 2893 563 226 NA NA NA NA NA NA 2011 5288 2440 528 NA NA NA NA NA NA NA 2012 5291 2358 NA NA NA NA NA NA NA NA 2013 5676 NA NA NA NA NA NA NA NA NA Reconocemos el triángulo incremental de la figura 11.6. Visualización de triángulos Para explorar la evolución de los pagos acumulados por año de ocurrencia, la figura 11.9 muestra my_triangle usando la función plot disponible para los objetos de tipo triangle en el paquete ChainLadder. Cada línea de este gráfico muestra un año de ocurrencia (de 2004 a 2013, etiquetado como 1 a 10). Los períodos de desarrollo se etiquetan de 1 a 10 (en lugar de 0 a 9, como se usó anteriormente). plot(my_triangle) Figure 11.9: Desarrollo del siniestro por año de ocurrencia Alternativamente, el argumento lattice crea un gráfico por año de ocurrencia. plot(my_triangle, lattice = TRUE) En lugar de graficar el triángulo acumulado guardado en my_triangle, podemos graficar el triángulo de desarollo incremental. plot(my_triangle_incr) plot(my_triangle_incr, lattice = TRUE) 11.3 Chain-Ladder El método más utilizado para estimar las reservas por pagos pendientes es el llamado método chain-ladder. Los orígenes de este método no están claros pero se afianzó firmemente en aplicaciones prácticas a principios de los 70, Taylor (1986). Como se mostrará, el nombre se refiere al encadenamiento (chain) de una secuencia de factores (desarrollo año a año) en una escalera (ladder) de factores; las pérdidas inmaduras suben hacia la madurez cuando se multiplican por esta concatenación de ratios, de ahí la descripción de método chain-ladder. Empezaremos explorando el método chain-ladder en su versión determinista o algorítmica, por lo tanto sin hacer ninguna suposición estocástica. Luego describiremos el modelo chain-ladder de distribución libre de Mack. 11.3.1 Chain-Ladder Determinista El método chain-ladder determinista se centra en el triángulo de desarrollo en forma acumulada. Recordemos que una celda \\((i,j)\\) en este triángulo muestra la cantidad acumulada pagada hasta el período de desarrollo \\(j\\) por siniestros que ocurrieron en el año \\(i\\). El método chain-ladder asume que los factores de desarrollo \\(f_j\\) (también llamados factores edad-a-edad, ratios de enlace o factores chain-ladder) existen de tal manera que \\[ C_{i,j+1} = f_j \\times C_{i,j}. \\] Por tanto, el factor de desarrollo indica cómo la cantidad acumulada en el año de desarrollo \\(j\\) crece hasta la cantidad acumulada en el año \\(j+1\\). Destacamos la cantidad acumulada en el período 0 en azul y la cantidad acumulada en el período 1 en rojo en la Figura 11.10 tomada de Wüthrich and Merz (2008) (Tabla 2.2, también utilizada en Wüthrich and Merz (2015), Tabla 1.4). Figure 11.10: Triángulo de desarrollo con datos de pagos acumulados que muestra la cantidad acumulada en el período 0 en azul y la cantidad acumulada en el período 1 en rojo. Fuente: Wüthrich and Merz (2008), Tabla 2.2. El método chain-ladder presenta una forma intuitiva para estimar o calcular estos factores de desarrollo. Dado que el primer factor de desarrollo \\(f_0\\) describe el desarrollo de la cantidad acumulada de los siniestros desde el período de desarrollo 0 hasta el período de desarrollo 1, se puede estimar como la proporción de las cantidades acumuladas en rojo y las cantidades acumuladas en azul, resaltadas en la Figura 11.10. En notación matemática obtenemos entonces la siguiente estimación \\(\\hat{f}_0^{CL}\\) para el primer factor de desarrollo \\(f_0\\), dadas las observaciones \\(\\mathcal{D}_I\\): \\[ \\hat{f}^{CL}_{\\color{magenta}{0}} = \\frac{\\sum_{i=1}^{10-\\color{magenta}{0}-1} \\color{red}{C_{i,\\color{magenta}{0}+1}}}{\\sum_{i=1}^{10-\\color{magenta}{0}-1} \\color{blue}{C_{i\\color{magenta}{0}}}}= 1,4925. \\] Cabe señalar que el índice \\(i\\), utilizado en las sumas del numerador y el denominador, va desde el primer período de ocurrencia (1) hasta el último período de ocurrencia (9) para el que se observan ambos períodos de desarrollo 0 y 1. Como tal, este factor de desarrollo mide cómo los datos en azul crecen hasta los datos en rojo, promediados a través de todos los períodos de ocurrencia para los cuales se observan ambos períodos. El método chain-ladder utiliza entonces este estimador del factor de desarrollo para predecir la cantidad acumulada \\(C_{10,1}\\) (es decir, la cantidad acumulada pagada hasta el año de desarrollo 1 inclusive por los accidentes ocurridos en el año 10). Esta predicción se obtiene multiplicando la cantidad acumulada de siniestros más reciente observada para el período de ocurrencia 10 (es decir, \\(C_{10,0}\\) con el período de desarrollo 0) por el factor de desarrollo estimado \\(\\hat{f}^{CL}_0\\): \\[ \\hat{C}_{10, 1} = C_{10,0} \\cdot \\hat{f}^{CL}_0 = 5.676\\cdot 1,4925=8.471. \\] Siguiendo este razonamiento, se puede estimar el próximo factor de desarrollo \\(f_1\\). Dado que \\(f_1\\) captura el desarrollo del período 1 al período 2, puede ser estimado como la proporción de los números en rojo y los números en azul como se resalta en la Figura 11.11. Figure 11.11: Triángulo de desarrollo con datos de pago acumulado que muestra la cantidad acumulada en el período 1 en azul y la cantidad acumulada en el período 2 en rojo. Fuente: Wüthrich and Merz (2008), Tabla 2.2. La notación matemática de la estimación de \\(\\hat{f}_1^{CL}\\) para el siguiente factor de desarrollo \\(f_1\\), dadas las observaciones \\(\\mathcal{D}_I\\), es igual: \\[ \\hat{f}^{CL}_{\\color{magenta}{1}} = \\frac{\\sum_{i=1}^{10-\\color{magenta}{1}-1} \\color{red}{C_{i,\\color{magenta}{1}+1}}}{\\sum_{i=1}^{10-\\color{magenta}{1}-1} \\color{blue}{C_{i\\color{magenta}{1}}}}=1,0778. \\] Por consiguiente, este factor mide cómo la cantidad acumulada pagada en el período de desarrollo 1 crece hasta el período 2, promediada en todos los períodos de ocurrencia en los que se observan ambos períodos. El índice \\(i\\) va ahora del período 1 al 8, ya que estos son los períodos de ocurrencia para los que se observan ambos períodos de desarrollo 1 y 2. Esta estimación del segundo factor de desarrollo se utiliza entonces para predecir las casillas que faltan y no se observan en el período de desarrollo 2: \\[ \\begin{array}{rl} \\hat{C}_{10,2} &amp;= C_{10,0} \\cdot \\hat{f}^{CL}_0 \\cdot \\hat{f}_1^{CL} = \\hat{C}_{10,1} \\cdot \\hat{f}_1^{CL} = 8471 \\cdot 1,0778 = 9130 \\\\ \\hat{C}_{9,2} &amp;= C_{9,1} \\cdot \\hat{f}^{CL}_1 = 7649 \\cdot 1,0778 = 8244. \\end{array} \\] Note que para \\(\\hat{C}_{10,2}\\) realmente se usa la estimación \\(\\hat{C}_{10,1}\\) y se multiplica por el factor de desarrollo estimado \\(\\hat{f}_1^{CL}\\). Continuamos de manera análoga y obtenemos las siguientes predicciones, mostradas en cursiva en la Figura 11.12: Figure 11.12: Triángulo de desarollo con datos de pago acumulados que incluyen predicciones en cursiva. Fuente: (Wüthrich and Merz 2008), Tabla 2.2. Eventualmente se necesita estimar los valores de la columna final. El último factor de desarrollo \\(f_8\\) mide el crecimiento desde el período de desarrollo 8 al período de desarrollo 9 en el triángulo. Como sólo en la primera fila del triángulo se han observado ambas celdas, este último factor se estima como la relación entre el valor en rojo y el valor en azul en la Figura 11.13. Figure 11.13: Triángulo de desarollo con datos de pago acumulado en los que se destaca la cantidad acumulada en el período 8 en azul y la cantidad acumulada en el período 9 en rojo. Fuente: (Wüthrich and Merz 2008), Tabla 2.2. Dadas las observaciones \\(\\mathcal{D}_I\\), este factor estimado es igual a: \\[ \\hat{f}^{CL}_{\\color{magenta}{8}} = \\frac{\\sum_{i=1}^{10-\\color{magenta}{8}-1} \\color{red}{C_{i,\\color{magenta}{8}+1}}}{\\sum_{i=1}^{10-\\color{magenta}{8}-1} \\color{blue}{C_{i\\color{magenta}{8}}}}=1,001. \\] Frecuentemente este último factor de desarrollo es cercano a 1 y por lo tanto los flujos de caja pagados en el período final de desarrollo son menores. Utilizando esta estimación del factor de desarrollo, podemos ahora estimar los costes de los siniestros acumulados que faltan en la columna multiplicando los valores del año de desarrollo 8 con este factor. La notación matemática general para las predicciones chain-ladder para el triángulo inferior (\\(i+j&gt;I\\)) es la siguiente: \\[ \\begin{array}{rl} \\hat{C}_{ij}^{CL} &amp;= C_{i,I-i} \\cdot \\prod_{l=I-i}^{j-1} \\hat{f}_l^{CL} \\\\ \\hat{f}_j^{CL} &amp;= \\frac{\\sum_{i=1}^{I-j-1} C_{i,j+1}}{\\sum_{i=1}^{I-j-1} C_{ij}}, \\end{array} \\] donde \\(C_{i,I-i}\\) está en la última diagonal observada. Es evidente que una suposición importante del método chain-ladder es que los desarrollos proporcionales de siniestros de un período de desarrollo a otro son similares para todos los años de ocurrencia. Esto da como resultado la siguiente Figura 11.14: Figure 11.14: Triángulo de desarrollo con datos de pagos acumulados en el que se incluyen las predicciones en cursiva. Fuente: Wüthrich and Merz (2008), Tabla 2.2. Las cifras de la última columna muestran las estimaciones de las cantidades finales de los siniestros. La estimación de la cantidad pendiente \\(\\hat{\\mathcal{R}}_i^{CL}\\) para un particular año de ocurrencia \\(i=I-J+1,\\ldots, I\\) viene dada por la diferencia entre la cantidad última y la cantidad acumulada observada en la diagonal más reciente: \\[ \\hat{\\mathcal{R}}_i^{CL} =\\hat{C}_{iJ}^{CL}-C_{i,I-i}. \\] Esta es la estimación chain-ladder de la provisión necesaria para cumplir con las responsabilidades futuras con respecto a los siniestros que ocurrieron en este período de ocurrencia en particular. Estas reservas por período de ocurrencia y para el total sumado de todos los períodos de ocurrencia se resumen en la Figura 11.15. Figure 11.15: Reservas por período de ocurrencia y para el total 11.3.2 Modelo Chain-ladder de distribución libre de Mack En esta etapa, el método tradicional chain-ladder proporciona un estimador puntual \\(\\hat{C}^{CL}_{iJ}\\) para el pronóstico de \\(C_{iJ}\\), usando la información \\(\\mathcal{D}_I\\). Dado que el método de chain-ladder es un algoritmo puramente determinista e intuitivamente natural para completar un triángulo de desarrollo, no se puede determinar cómo de fiable es el estimador puntual ni modelizar la variación de los pagos futuros. Para responder a tales preguntas se necesita un modelo estocástico subyacente que reproduzca las estimaciones de las provisiones chain-ladder. En esta sección nos centraremos en el modelo chain-ladder de distribución libre como modelo estocástico subyacente, introducido en Mack (1993). Este método nos permite estimar los errores estándar de las predicciones chain-ladder. En la siguiente sección 11.4, se utilizan modelos lineales generalizados para desarrollar un enfoque totalmente estocástico para predecir la reserva pendiente. En el enfoque de Mack se mantienen las siguientes condiciones (sin asumir una distribución): Los siniestros acumulados \\((C_{ij})_{j=0,\\ldots,J}\\) son independientes a lo largo de diferentes periodos de ocurrencia \\(i\\). Existen constantes fijas \\(f_0, \\ldots, f_{J-1}\\) y \\(\\sigma^2_0,\\ldots, \\sigma^2_{J-1}\\) tal que para todo \\(i=1,\\ldots, I\\) y \\(j=0,\\ldots,J-1\\): \\[ \\begin{array}{rl} E[C_{i,j+1}|C_{i0},\\ldots,C_{ij}] &amp;= f_j \\cdot C_{ij} \\\\ \\text{Var}(C_{i,j+1}|C_{ij}) &amp;= \\sigma^2_j \\cdot C_{ij}. \\end{array} \\] Esto significa que los siniestros acumulados \\((C_{ij})_{j=0,\\ldots,J}\\) son procesos de Markov (en los períodos de desarrollo \\(j\\)) y por lo tanto el futuro sólo depende del presente. Con estos supuestos, el valor esperado de la cantidad de pagos final \\(C_{i,J}\\), dados los datos disponibles en el triángulo superior, es la cantidad acumulada en la diagonal más reciente (\\(C_{i, I-1}\\)) multiplicada por los factores de desarrollo apropiados \\(f_j\\). En notación matemática obtenemos para los factores de desarrollo conocidos \\(f_j\\) y las observaciones \\(\\mathcal{D}_I\\): \\[ E[C_{iJ}|\\mathcal{D}_I] = C_{i,I-i} \\prod_{j=I-i}^{J-1} f_j. \\] Esto es exactamente lo que hace el método de chain-ladder determinista, como se explica en la sección 11.3.1. En la práctica, los factores de desarrollo no se conocen y necesitan ser estimados a partir de los datos que están disponibles en el triángulo superior. En el enfoque de Mack obtenemos exactamente la misma expresión para estimar los factores de desarrollo \\(f_j\\) en el tiempo \\(I\\) que en el algoritmo determinista de chain-ladder: \\[ \\hat{f}_j^{CL} =\\frac{\\sum_{j=1}^{I-j-1} C_{i,j+1}}{\\sum_{i=1}^{I-j-1} C_{ij}}. \\] Las predicciones para las celdas del triángulo inferior (es decir, para las celdas \\(C_{i,j}\\) donde \\(i+j&gt;I\\)) se obtienen entonces reemplazando los factores desconocidos \\(f_j\\) por sus correspondientes estimaciones \\(\\hat{f}_j^{CL}\\): \\[ \\hat{C}^{CL}_{ij} = C_{i,I-i}\\prod_{l=I-i}^{j-1} \\hat{f}_l^{CL}. \\] Para cuantificar el error de predicción de las predicciones de chain-ladder, Mack también introdujo parámetros de varianza \\(\\sigma^2_j\\). Para comprender mejor la estimación de estos parámetros de varianza, se introducen los llamados factores de desarrollo individual \\(f_{i,j}\\) (que son específicos del período de ocurrencia \\(i\\)): \\[ f_{i,j} = \\frac{C_{i,j+1}}{C_{ij}}. \\] Estos factores de desarrollo individuales también describen cómo la cantidad acumulada crece desde el período \\(j\\) hasta el período \\(j+1\\), pero consideran la proporción de sólo dos celdas (en lugar de tomar la proporción de dos sumas sobre todos los períodos de ocurrencia disponibles). Obsérvese que los factores de desarrollo pueden escribirse como un promedio ponderado de los factores de desarrollo individual: \\[ \\hat{f}_j^{CL} = \\sum_{i=1}^{I-j-1} \\frac{C_{ij}}{\\sum_{i=1}^{I-j-1} C_{ij}} f_{i,j}, \\] donde los pesos son iguales a los siniestros acumulados \\(C_{ij}\\). Estimemos ahora los parámetros de varianza \\(\\sigma^2\\) escribiendo el supuesto de la varianza de Mack de manera equivalente. Primero, la varianza de la relación de \\(C_{i,j+1}\\) y \\(c_{i,j}\\) condicionada a \\(C_{i,0},\\ldots, C_{i,j}\\) es proporcional a la inversa de \\(C_{i,j}\\): \\[ \\text{Var}[C_{i,j+1}/C_{ij}|C_{i0},\\ldots,C_{ij}] ~ \\propto ~ \\frac{1}{C_{ij}}. \\] Esto tiene la estructura de mínimos cuadrados ponderados donde los pesos son la inversa de la variabilidad de una respuesta. Por lo tanto, una variable de respuesta más volátil o imprecisa tendrá menos peso. Los \\(C_{i,j}\\) juegan el papel de los pesos. Usando el parámetro de varianza desconocida \\(\\sigma^2_j\\) esta suposición de varianza puede escribirse como: \\[ \\text{Var}[C_{i,j+1}|C_{i0},\\ldots,C_{ij}] = \\sigma^2_j \\cdot C_{ij}, \\] La conexión con los mínimos cuadrados ponderados nos conduce directamente a una estimación insesgada del parámetro de varianza desconocida \\(\\sigma^2_j\\) en forma de suma ponderada de residuos al cuadrado: \\[ \\hat{\\sigma}^2_j = \\frac{1}{I-j-2}\\sum_{i=1}^{I-j-1} C_{ij}\\left(\\frac{C_{i,j+1}}{C_{ij}}-\\hat{f}_j^{CL}\\right)^2. \\] Los pesos son de nuevo iguales a \\(C_{i,j}\\) y los residuos son las diferencias entre las ratios \\(C_{i,j+1}/C_{i,j}\\) y los factores de desarrollo individual. Ahora tenemos todos los ingredientes necesarios para calibrar el modelo chain-ladder de distribución libre con los datos. El siguiente paso es analizar la incertidumbre de la predicción y el error de predicción. Aquí usamos el predictor de chain-ladder donde reemplazamos los factores de desarrollo desconocidos con sus estimadores: \\[ \\hat{C}_{iJ}^{CL} = C_{i,I-i} \\prod_{l=I-i}^{J-1} \\hat{f}_l^{CL} \\] Utilizamos esta expresión como estimador de la esperanza condicional de la cantidad de pagos final (dado el triángulo superior observado) o como predictor de la cantidad de pagos final como variable aleatoria (dado el triángulo superior observado). En estadística, la medida más simple para analizar la incertidumbre que viene con una estimación puntual o predicción es el Error Cuadrado Medio de Predicción (MSEP, según sus siglas en inglés). Aquí consideramos un MSEP condicional, condicionado a los datos observados en el triángulo superior: \\[ MSEP_{C_{iJ}|\\mathcal{D}_I}\\left(\\hat{C}_{iJ}^{CL}\\right) = E\\left[\\left(C_{iJ}-\\hat{C}_{iJ}^{CL}\\right)^2|\\mathcal{D}_I\\right]. \\] El MSEP condicional mide: la distancia entre el (verdadero) coste final \\(C_{iJ}\\) y su predictor chain-ladder \\(\\hat{C}_{iJ}^{CL}\\) en el tiempo \\(I\\), y la incertidumbre total de la predicción sobre la totalidad del desarrollo del coste nominal final \\(C_{iJ}\\). No se considera ni el valor del tiempo del dinero, ni margen de riesgo ni ninguna dinámica en los desarrollos. El MSEP de la estimación de la cantidad final de siniestros acumulada es igual al MSEP que mide la distancia cuadrada entre la provisión verdadera y la estimada: \\[ \\begin{array}{rl} MSEP_{\\hat{\\mathcal{R}}^{I}_{i}|\\mathcal{D}_I}(\\hat{\\mathcal{R}}^{I}_i) &amp;= E[(\\hat{\\mathcal{R}}^I_i-\\mathcal{R}^I_i)^2|\\mathcal{D}_I] \\\\ &amp;= E[(\\hat{C}^{CL}_{iJ}-C_{iJ})^2|\\mathcal{D}_I] = MSEP(\\hat{C}_{iJ}). \\end{array} \\] La razón de esta equivalencia es el hecho de que la provisión es el coste último de los siniestros menos el coste de los siniestros observado más reciente. Este último se observa y usa en \\(\\mathcal{R}^I_i\\) y \\(\\hat{\\mathcal{R}}^I_i\\). Es interesante descomponer este MSEP en un componente que capture la varianza del proceso y un componente que capture la varianza de la estimación de los parámetros: \\[ \\begin{array}{rl} MSEP_{C_{iJ|\\mathcal{D}_I}}\\left(\\hat{C}_{iJ}^{CL}\\right) &amp;= E\\left[ \\left( C_{iJ} - \\hat{C}_{iJ} \\right)^2 | \\mathcal{D}_I\\right] \\\\ &amp;= \\text{Var}(C_{iJ}|\\mathcal{D}_I) + \\left( E[C_{iJ}|\\mathcal{D}_I]-\\hat{C}_{iJ}^{CL} \\right)^2 \\\\ &amp;= \\color{magenta}{\\text{varianza del proceso}} + \\color{magenta}{\\text{ varianza de la estimación de los parámetros}}, \\end{array} \\] para un \\(\\mathcal{D}_I\\) medible estimador/predictor de \\(\\hat{C}_{iJ}\\). El componente de la varianza del proceso captura la volatilidad o incertidumbre en la variable aleatoria \\(C_{i,J}\\) y la varianza de la estimación del parámetro mide el error que surge al sustituir los factores de desarrollo desconocidos \\(f_j\\) por sus valores estimados. Este resultado se deriva inmediatamente de la siguiente igualdad sobre la varianza de una variable aleatoria desplazada \\(X\\) donde el desplazamiento \\(a\\) es determinístico: \\[ E(X-a)^2 = \\text{Var}(X)+\\left[EX-a\\right]^2. \\] Aplicado a la expresión del MSEP se trata a \\(\\hat{C}_{i,J}\\) como fijo porque se trabaja condicionalmente en los datos del triángulo superior y \\(\\hat{C}_{i,J}\\) sólo usa la información de este triángulo superior. Mack (1993) derivó la importante fórmula para el MSEP condicional en el modelo chain-ladder de distribución libre para un único período de ocurrencia \\(i\\): \\[ \\widehat{MSEP_{C_{iJ}|\\mathcal{D}_I}} = \\left(\\hat{C}_{iJ}^{CL}\\right)^2 \\sum_{j=I-i}^{J-1} \\left[ \\frac{\\hat{\\sigma}_j^2}{(\\hat{f}_j^{CL})^2} \\left(\\frac{1}{\\hat{C}^{CL}_{ij}}+\\frac{1}{\\sum_{n=1}^{I-j-1}C_{nj}}\\right)\\right]. \\] Para la derivación de esta fórmula popular, nos remitimos a su artículo. Nótese que es una estimación del MSEP ya que los parámetros desconocidos \\(f_j\\) y \\(\\sigma_j\\) necesitan ser estimados y el error de estimación no puede calcularse explícitamente. Mack también derivó una fórmula para el MSEP para la provisión total, a través de todos los períodos de ocurrencia: \\[ \\begin{array}{ll} \\widehat{MSEP_{\\sum_{i=1}^I \\hat{C}^{CL}_{iJ}}}\\left( \\sum_{i=1}^I \\hat{C}^{CL}_{iJ} \\right) \\\\ \\ \\ \\ \\ \\ \\sum_{i=1}^I \\widehat{MSEP_{C_{iJ}|\\mathcal{D}_I}}\\left( \\hat{C}^{CL}_{iJ} \\right) \\color{blue}{+2 \\sum_{1\\leq i&lt; k \\leq I} \\hat{C}_{iJ}^{CL} \\hat{C}_{kJ}^{CL} \\sum_{j=I-i}^{J-1} \\frac{ \\hat{\\sigma}_j^2/\\left( \\hat{f}_j^{\\text{CL}} \\right)^2 }{ \\sum_{n=1}^{I-j-1} C_{nj} }}. \\end{array} \\] El resultado es la suma de los MSEP por período de ocurrencia más un término de covarianza. Este término de covarianza se suma porque los MSEPs para diferentes períodos de ocurrencia \\(i\\) utilizan los mismos estimadores \\(\\hat{f}_j^{CL}\\) de los parámetros \\(f_j\\) para diferentes años de accidentes \\(i\\). 11.3.3 Código R para las predicciones Chain-Ladder Usamos el objeto my_triangle de tipo triangle que se creó en la sección 11.2.4. El modelo chain-ladder de distribución libre de Mack (1993) está implementado en el paquete ChainLadder (Gesmann et al. 2019) (como una forma especial de mínimos cuadrados ponderados) y puede ser aplicado en los datos my_triangle para predecir las cuantías de los siniestros pendientes y para estimar el error estándar de estas predicciones. Código R para las predicciones del modelo Mack CL &lt;- MackChainLadder(my_triangle) CL MackChainLadder(Triangle = my_triangle) Latest Dev.To.Date Ultimate IBNR Mack.S.E CV(IBNR) 2004 11,148,124 1.000 11,148,124 0 0 NaN 2005 10,648,192 0.999 10,663,318 15,126 716 0.0474 2006 10,635,751 0.998 10,662,008 26,257 1,131 0.0431 2007 9,724,068 0.996 9,758,606 34,538 3,121 0.0904 2008 9,786,916 0.991 9,872,218 85,302 7,654 0.0897 2009 9,935,753 0.984 10,092,247 156,494 33,347 0.2131 2010 9,282,022 0.970 9,568,143 286,121 73,469 0.2568 2011 8,256,211 0.948 8,705,378 449,167 85,400 0.1901 2012 7,648,729 0.880 8,691,971 1,043,242 134,338 0.1288 2013 5,675,568 0.590 9,626,383 3,950,815 410,818 0.1040 Totals Latest: 92,741,334.00 Dev: 0.94 Ultimate: 98,788,397.77 IBNR: 6,047,063.77 Mack.S.E 462,977.83 CV(IBNR): 0.08 round(summary(CL)$Totals) Totals Latest: 92741334 Dev: 1 Ultimate: 98788398 IBNR: 6047064 Mack S.E.: 462978 CV(IBNR): 0 Los factores de desarrollo se obtienen de la siguiente manera: round(CL$f,digits = 4) [1] 1.4925 1.0778 1.0229 1.0148 1.0070 1.0051 1.0011 1.0010 1.0014 1.0000 También podemos obtener el triángulo de desarrollo completo (incluyendo las predicciones). Código R para el triángulo completo modelo de Mack CL$FullTriangle dev origin 0 1 2 3 4 5 6 7 2004 5946975 9668212 10563929 10771690 10978394 11040518 11106331 11121181 2005 6346756 9593162 10316383 10468180 10536004 10572608 10625360 10636546 2006 6269090 9245313 10092366 10355134 10507837 10573282 10626827 10635751 2007 5863015 8546239 9268771 9459424 9592399 9680740 9724068 9734574 2008 5778885 8524114 9178009 9451404 9681692 9786916 9837277 9847905 2009 6184793 9013132 9585897 9830796 9935753 10005044 10056528 10067393 2010 5600184 8493391 9056505 9282022 9419776 9485469 9534279 9544579 2011 5288066 7728169 8256211 8445057 8570389 8630159 8674567 8683939 2012 5290793 7648729 8243496 8432051 8557190 8616868 8661208 8670566 2013 5675568 8470989 9129696 9338521 9477113 9543206 9592313 9602676 dev origin 8 9 2004 11132310 11148124 2005 10648192 10663318 2006 10646884 10662008 2007 9744764 9758606 2008 9858214 9872218 2009 10077931 10092247 2010 9554570 9568143 2011 8693029 8705378 2012 8679642 8691971 2013 9612728 9626383 La MSEP para la reserva total a través de todos los períodos de ocurrencia se obtiene como: CL$Total.Mack.S.E^2 9 214348469061 Se deben validar los supuestos de Mack comprobando que no hay tendencias en los gráficos de los residuos. Los últimos cuatro gráficos que obtenemos con el siguiente comando muestran respectivamente los residuos estandarizados frente a los valores ajustados, el período de origen, el período de calendario y el período de desarrollo. plot(CL) El gráfico superior izquierdo es un gráfico de barras de la última posición de los siniestros más el IBNR y el error estándar de Mack por período de ocurrencia. El gráfico superior derecho muestra los patrones de desarrollo predichos para todos los períodos de ocurrencia (comenzando con 1 para el período de ocurrencia más antiguo). Al establecer el argumento lattice=TRUE se obtiene un gráfico del desarrollo, incluyendo la predicción y los errores estándar estimados por período de ocurrencia: plot(CL, lattice=TRUE) 11.4 GLMs y Bootstrap para provisiones ** Esta sección se está escribiendo y aún no está completa ni editada. Os mostramos una idea de lo que será la versión final.** Esta sección cubre los modelos de regresión para analizar los triángulos de desarrollo. Cuando se analizan los datos de un triángulo de desarrollo con un modelo de regresión, se dispone de los instrumentos estándar para la construcción, estimación y predicción del modelo. Usando estas herramientas somos capaces de ir más allá de la estimación puntual y el error estándar como se deriva en la Sección 11.3. Más específicamente, construimos un modelo lineal generalizado (GLM) para los pagos incrementales \\(X_{ij}\\) en la Figura 11.6. Mientras que el método de chain-ladder funciona con datos acumulados, los GLM asumen que las variables de respuesta son independientes y por lo tanto trabajan con triángulos de desarrollo incrementales. 11.4.1 Especificación del modelo Suponemos que \\(X_{ij}\\) denota el pago incremental en la celda \\((i,j)\\) del triángulo de desarrollo. Asumimos que los \\(X_{ij}\\) son independientes con una densidad \\(f(x_{ij};\\theta_{ij},\\phi)\\) de la familia exponencial de distribuciones. Identificamos \\(\\mu_{ij}=E[X_{ij}]\\) el valor esperado de la celda \\(X_{ij}\\) \\(\\phi\\) el parámetro de dispersion y \\(\\text{Var}[X_{ij}]=\\phi \\cdot V(\\mu_{ij})\\), donde \\(V(.)\\) es la función varianza. \\(\\eta_{ij}\\) el predictor lineal tal \\(\\eta_{ij}=g(\\mu_{ij})\\) con \\(g\\) la función enlace. Las distribuciones de la familia exponencial y sus funciones de enlace por defecto se enumeran en http://stat.ethz.ch/R-manual/R-patched/library/stats/html/family.html. Ahora analizamos tres GLM específicos ampliamente utilizados para la reserva de pérdidas. Primero, el modelo de regresión de Poisson fue introducido en la sección 8.2. En este modelo, asumimos que \\(X_{ij}\\) tiene una distribución de Poisson con el parámetro \\[ \\mu_{ij} = \\pi_i \\cdot \\gamma_j, \\] una estructura cruzada que capta un efecto multiplicador del año de ocurrencia \\(i\\) y el período de desarrollo \\(j\\). La estructura del modelo propuesto no es identificable sin una restricción adicional en los parámetros, por ejemplo \\(\\sum_{j=0}^J \\gamma_j=1\\). Esta restricción da una interpretación explícita a \\(\\pi_i\\) (con \\(i=1,\\ldots,I\\)) como la medida de exposición o volumen para el año de ocurrencia \\(i\\) y \\(\\gamma_j\\) como la fracción del volumen total pagado con retraso \\(j\\). Sin embargo, cuando se calibran los GLM en R, las restricciones alternativas como \\(\\pi_1=1\\) o \\(\\gamma_1=1\\), o una reparametrización donde \\(\\mu_{ij} = \\exp{(\\mu+\\alpha_i+\\beta_j)}\\) son más fáciles de implementar. Continuamos con esta última especificación, incluyendo \\(\\alpha_1 = \\beta_0 = 0\\), denominadas restricciones de esquina. Este GLM trata el año de ocurrencia y el retraso de pago como variables categóricas y ajusta un parámetro por nivel, junto a una constante \\(\\mu\\). Las restricciones de esquina establecen que el efecto del primer nivel de una variable factorial sea igual a cero. La distribución de Poisson es particularmente útil para un triángulo de desarrollo con número de siniestros comunicados, a menudo utilizado en la estimación del número de siniestros IBNR (véase la sección 11.2). En segundo lugar, una interesante modificación del modelo básico de regresión de Poisson es el modelo de regresión de Poisson sobredisperso donde \\(Z_{ij}\\) tiene una distribución de Poisson con parámetro \\(\\mu_{ij}/\\phi\\) y \\[ \\begin{array}{rl} X_{ij} &amp;\\sim \\phi \\cdot Z_{ij} \\\\ \\mu_{ij} &amp;= \\exp{(\\mu + \\alpha_i + \\beta_j)}. \\end{array} \\] De este modo, \\(X_{ij}\\) tiene la misma especificación para la media que en el modelo básico de regresión de Poisson, pero ahora \\[ \\text{Var}[X_{ij}] = \\phi^2 \\cdot \\text{Var}[Z_{ij}] = \\phi \\cdot \\exp{(\\mu + \\alpha_i + \\beta_j)}. \\] Esta construcción permite la subdispersión (cuando \\(\\phi &lt;1\\)) y la sobredispersión (con \\(\\phi&gt;1\\)). Dado que \\(X_{ij}\\) ya no sigue una distribución conocida, este enfoque se denomina cuasiprobabilidad. Es particularmente útil para modelar un triángulo de desarrollo con pagos incrementales, ya que éstos normalmente muestran sobredispersión. En tercer lugar, el modelo de regresión gamma es adecuado para modelizar un triángulo de desarrollo con pagos de siniestros. Recordemos la sección 3.2.1 (véase también el capítulo del apéndice 18) con parámetros \\(\\alpha\\) y \\(\\theta\\). A partir de aquí, reparametrizamos y definimos un nuevo parámetro \\(\\mu = \\alpha \\cdot \\theta\\) mientras se mantiene el parámetro de escala \\(\\theta\\). Además, se asume que \\(X_{ij}\\) tiene una distribución gamma y se permite que \\(\\mu\\) varíe con \\(ij\\) de tal manera que \\[ \\mu_{ij} = \\exp{(\\mu + \\alpha_i + \\beta_j)}. \\] 11.4.2 Estimación y predicción del modelo Se estiman los parámetros de regresión \\(\\mu\\), \\(\\alpha_i\\) y \\(\\beta_j\\) en los GLM propuestos. En R está disponible la función glm para estimar estos parámetros a través de la estimación por máxima verosimilitud (mle) o cuasi-verosimilitud (en el caso de Poisson sobredisperso). Teniendo disponibles las estimaciones de los parámetros \\(\\hat{\\mu}\\), \\(\\hat{\\alpha}_i\\) y \\(\\hat{\\beta}_j\\), se obtiene una estimación puntual para cada celda del triángulo superior \\[ \\hat{X}_{ij} =\\hat{E[X_{ij}]} = \\exp{(\\hat{\\mu}+\\hat{\\alpha}_i+\\hat{\\beta}_j)},\\ \\text{con}\\ i+j\\leq I. \\] Similarly, a cell in the lower triangle will be predicted as De manera similar, se puede predecir una celda en el triángulo inferior como \\[ \\hat{X}_{ij} = \\hat{E[X_{ij}]} = \\exp{(\\hat{\\mu}+\\hat{\\alpha}_i+\\hat{\\beta}_j)},\\ \\text{con}\\ i+j&gt; I. \\] Luego se suman las estimaciones específicas de cada celda para obtener estimaciones puntuales de las reservas pendientes (por año de ocurrencia \\(i\\) o la provisión total). Combinando las observaciones del triángulo superior con sus estimaciones puntuales, podemos obtener residuos adecuadamente definidos y usarlos para la inspección de los residuos. 11.4.3 Bootstrap 11.5 Recursos adicionales y contribuciones Colaboradores Katrien Antonio, KU Leuven y University of Amsterdam, Jan Beirlant, KU Leuven, y Tim Veerdonck, University of Antwerp, son los autores principals de la version inicial de este capítulo. Email: katrien.antonio@kuleuven.be para comentarios y posibles mejoras del capítulo. Traducción al español: Miguel Santolino (Universitat de Barcelona) Lecturas adicionales y referencias Como se muestra en la Figura 11.1, cronogramas y visualizaciones similares se discuten (entre otros) en Wüthrich and Merz (2008), Antonio and Plat (2014) y Wüthrich and Merz (2015). Con el tiempo los actuarios comenzaron a pensar en posibles modelos subyacentes. Aquí mencionamos algunas contribuciones importantes: Kremer (1982): ANOVA de dos factores Kremer (1984), Mack (1991): modelo Poisson Mack (1993): modelo chain-ladder de distribución-libre Renshaw (1989); Renshaw and Verrall (1998): modelo Poisson sobredisperso Gisler (2006); Gisler and Wüthrich (2008); Bühlmann et al. (2009): modelo chain-ladder bayesiano. Los diversos modelos estocásticos propuestos en la literatura actuarial se basan en diferentes supuestos y tienen diferentes propiedades, pero tienen en común que proporcionan exactamente las estimaciones de la provisión chain-ladder. Para más información también nos referimos a Mack and Venter (2000) y a la interesante discusión que se publicó en el ASTIN Bulletin: Journal of the International Actuarial Association en 2006 (Venter 2006). Para leer más sobre las familias exponenciales y los modelos lineales generalizados, ver, por ejemplo, P. McCullagh and Nelder (1989) y Wüthrich and Merz (2008). Nos referimos a (Kremer 1982), (Renshaw and Verrall 1998) y (England and Verrall 2002), y a los resúmenes en (Taylor 2000), (Wüthrich and Merz 2008) y (Wüthrich and Merz 2015) para más detalles sobre los GLM analizamos. XXX presenta supuestos distributivos y especificaciones alternativas del predictor lineal. Bibliography "],
["C-BonusMalus.html", "Chapter 12 Experience Rating using Bonus-Malus 12.1 Introduction 12.2 NCD System in Several Countries 12.3 BMS and Markov Chain Model 12.4 BMS and Stationary Distribution 12.5 BMS and Premium Rating", " Chapter 12 Experience Rating using Bonus-Malus This chapter is being written and is not yet complete nor edited. It is here to give you a flavor of what will be in the final version. 12.1 Introduction Bonus-malus system, which is used interchangeably as “no-fault discount”, “merit rating”, “experience rating” or “no-claim discount” in different countries, is based on penalizing insureds who are responsible for one or more claims by a premium surcharge, and awarding insureds with a premium discount if they do not have any claims. Insurers use bonus-malus systems for two main purposes; to encourage drivers to drive more carefully in a year without any claims, and to ensure insureds to pay premiums proportional to their risks based on their claims experience. No Claim Discount (NCD) system is an experience rating system commonly used in motor insurance. It represents an attempt to categorize insureds into homogeneous groups who pay premiums based on their claims experience. Depending on the rules in the scheme, new policyholders may be required to pay full premium initially, and obtain discounts in the future years as a results of claim-free years. An NCD system rewards policyholders for not making any claims during a year, or in other words, it grants a bonus to a careful driver. This bonus principle may affect policy holders’ decisions whether to claim or not to claim, especially when involving accidents with slight damages, which is known as ‘hunger for bonus’ phenomenon. The option of ‘hunger for bonus’ under an NCD system may reduce insurers’ claim costs, and may be able to offset the expected decrease in premium income. 12.2 NCD System in Several Countries 12.2.1 NCD System in Malaysia Before the liberalization of Motor Tariff on 1st July 2017, the rating of motor insurance in Malaysia was governed by Motor Tariff. Under the tariff, the rate charged should not be lower than the rates specified under the classes of risks, to ensure that the price competition among insurers will not go below the country’s economic level. The basic rating factors considered were scope of insurance, cubic capacity of vehicle and estimated value of vehicle (or sum insured, whichever is lower). Under the Motor Tariff, the final premium to be paid is adjusted by the policyholder’s claim experience, or equivalently, his NCD entitlement. Effective on 1st July 2017, the premium rates for motor insurance are liberalized, or de-tariffed. The pricing of premium is now determined by individual insurers and takaful operators, and the consumers are able to enjoy a wider choice of motor insurance products at competitive prices. Since tariff liberalization encourages innovation and competition among insurers and takaful operators, the premiums are based on broader risk factors other than the two rating factors specified in the Motor Tariff, i.e. sum insured and cubic capacity of vehicle. Other rating factors may be defined in the risk profile of an insured, such as age of vehicle, age of driver, safety and security features of vehicle, geographical location of vehicle and traffic offences of driver. As different insurers and takaful operators have different ways of defining the risk profile of an insured, the price of a policy may differ from one insurer to another. However, the NCD structure from the Motor Tariff remains ‘unchanged’ and continue to exist, and is ‘transferable’ from one insurer, or from one takaful operator, to another. The discounts in the Malaysian NCD system are divided into six classes, starting from the initial class of 0% discount, followed by classes of 25%, 30%, 38.3%, 45% and 55% discounts. Table 1 provides the classes of NCD system in Malaysia. A claim-free year indicates that a policyholder is entitled to move one-step forward to the next discount class, such as from a 0% discount to a 25% discount in the renewal year. If a policyholder is already at the highest class, which is at a 55% discount, a claim-free year indicates that the policyholder remains in the same class. On the other hand, if one or more claims are made within the year, the NCD will be forfeited and the policyholder has to start at 0% discount in the renewal year. In other words, the policyholder has to pay a full premium for the next year’s renewal premium, regardless of his current class of NCD. For an illustration purpose, Figure 12.1 shows the transition diagram for the NCD classes under the Malaysian Motor Tariff. The transition starts at class 0, and increase one by one if an insured has a no-claim year. If an insured has one or more claims within the year, the current class automatically returns to class 0. \\[ \\begin{matrix} \\text{Table 1: Classes of NCD (Malaysia)}\\\\ \\begin{array}{*{20}c} \\hline \\text{Classes (claim-free years)} &amp; \\text{Discounts}\\\\ \\hline\\\\ {0} &amp; {0}\\\\ {1} &amp; {25}\\\\ {2} &amp; {30}\\\\ {3} &amp; {38.33}\\\\ {4} &amp; {45}\\\\ {5\\text{ and above}} &amp; {55}\\\\\\\\ \\hline \\end{array} \\end{matrix} \\] Figure 12.1: Transition diagram for NCD classes (Malaysia) 12.2.2 NCD System in Other Countries The NCD system in Brazil are subdivided into seven classes, with the following premium levels (Lemaire 1998): 100, 90, 85, 80, 75, 70, and 65. These premium levels are also equivalent to the following discount classes: 0%, 10%, 15%, 20%, 25%, 30% and 45%. New policyholders have to start at 0% discount, or at level 100, and a claim-free year indicates that a policyholder can move forward at a one-class discount. If one or more claims incurred within the year, the policyholder has to move backward, also at a one-class discount. Table 2 and Figure 12.2 respectively show the classes and the transition diagram for the NCD system in Brazil. \\[ \\begin{matrix} \\text{Table 2: Classes of NCD (Brazil)}\\\\ \\begin{array}{*{20}c} \\hline \\text{Classes (claim-free years)} &amp; \\text{Discounts}\\\\ \\hline\\\\ {0} &amp; {0}\\\\ {1} &amp; {10}\\\\ {2} &amp; {15}\\\\ {3} &amp; {20}\\\\ {4} &amp; {25}\\\\ {5} &amp; {30}\\\\ {6\\text{ and above}} &amp; {45}\\\\\\\\ \\hline \\end{array} \\end{matrix} \\] Figure 12.2: Transition diagram for NCD classes (Brazil) The NCD system in Switzerland, which is implemented in 1990, are subdivided into twenty-two classes, with the following premium levels: 270, 250, 230, 215, 200, 185, 170, 155, 140, 130, 120, 110, 100, 90, 80, 75, 70, 65, 60, 55, 50 and 45 (Lemaire and Zi 1994). These levels are also equivalent to the following loadings: 170%, 150%, 130%, 115%, 100%, 85%, 70%, 55%, 40%, 30%, 20%, and 10%, and the following discounts: 0%, 10%, 20%, 25%, 30%, 35%, 40%, 45%, 50% and 55%. New policyholders have to start at 170% loading, or at 270 premium level, and a claim-free year indicates that a policyholder can move one-class forward. If one or more claims incurred within the year, the policyholder has to move four-classes backwards. Table 3 and Figure 12.3 respectively show the classes and the transition diagram for the NCD system in Switzerland. \\[ \\begin{matrix} \\text{Table 3: Classes of NCD (Switzerland)}\\\\ \\begin{array}{*{20}c} \\hline \\text{Classes} &amp; \\text{Loadings} &amp; \\text{Classes} &amp; \\text{Discounts}\\\\ \\text{(claim-free years)} &amp; &amp; \\text{(claim-free years)} &amp; \\\\ \\hline\\\\ {0} &amp; {170} &amp; {12} &amp; {0}\\\\ {1} &amp; {150} &amp; {13} &amp; {10}\\\\ {2} &amp; {130} &amp; {14} &amp; {20}\\\\ {3} &amp; {115} &amp; {15} &amp; {25}\\\\ {4} &amp; {100} &amp; {16} &amp; {30}\\\\ {5} &amp; {85} &amp; {17} &amp; {35}\\\\ {6} &amp; {70} &amp; {18} &amp; {40}\\\\ {7} &amp; {55} &amp; {19} &amp; {45}\\\\ {8} &amp; {40} &amp; {20} &amp; {50}\\\\ {9} &amp; {30} &amp; {21 \\text{ and above}} &amp; {55}\\\\ {10} &amp; {20} &amp;&amp; \\\\ {11} &amp; {10} &amp;&amp; \\\\\\\\ \\hline \\end{array} \\end{matrix} \\] Figure 12.3: Transition diagram for NCD classes (Switzerland) 12.3 BMS and Markov Chain Model A BMS, or an NCD system, can be represented by a discrete time parameter Markov chain. Under this model, the state space consists of classes of bonus-malus, and the state (or class) is assumed to shift randomly from year to year. Therefore, it is important to know a brief description on two elements; a stochastic process that has a Markov property, and a discrete time Markov chain. Definition: A stochastic process has a Markov property if the probability distribution of future states, conditional on both past and present states, depends only upon the present state and not on the sequence of events that preceded it. Definition: A discrete time Markov chain is a stochastic process that can be parameterized by empirically estimating the transition probabilities between discrete states. 12.3.1 Transition Probability The randomness of the transition of the NCD classes is governed by the transition probability in a given year. The definition of a transition probability is provided here to understand the use of the probability for representing the transition of the NCD classes. Definition: The transition probability from state \\(i\\) (at time \\(n\\)) to state \\(j\\) (at time \\(n + 1\\)) is called a one-step transition probability, and is denoted by \\(p_{ij} = Pr (X_{n + 1} = j|X_n = i)\\), \\(i = 1,2,...,k\\), \\(j = 1,2,...,k\\). The transition probabilities can be represented by a \\(k \\times k\\) matrix. Assuming a homogeneous Markov process, a k-state Markov chain can be represented by a matrix of transition probabilities \\({\\bf P}\\): \\[ {\\bf P} = \\left[ {\\begin{array}{*{20}c} p_{11} &amp; p_{12} &amp; \\ldots &amp; &amp; &amp; p_{1k} \\\\ p_{21} &amp; p_{22} &amp; \\ldots &amp; &amp; &amp; p_{2k} \\\\ \\vdots &amp; \\ddots &amp; &amp; &amp; &amp; \\vdots \\\\ &amp; &amp; &amp; &amp; &amp; \\\\ &amp; &amp; &amp; &amp; &amp; \\\\ p_{k1} &amp; p_{k2} &amp; \\cdots &amp; &amp; &amp; p_{kk} \\end{array} } \\right]. \\] Each row of the transition matrix represents the transition of flowing out of state, whereas each column represents the transition of flowing into the state. The cumulative transitions of flowing out of state must equal 1, or each row of the matrix must sum to 1, i.e. \\(\\sum\\limits_j p_{ij} = 1\\). All probabilities must also be non-negative (since they are probabilities), i.e. \\(p_{ij} \\ge 0\\). Consider the Malaysian NCD system. Under this system, let the random variable \\(X_t\\) denotes the class of NCD at time \\(t\\) and takes the values in a state space \\(\\bf{S}\\), where \\({\\bf S} = \\{0,1,...,5\\}\\). Therefore, the probability of a no-claim year is equal to the probability of transition from state \\(i\\) to state \\(j\\), which is \\(p_{ij}\\), \\(i = 0,1,2,...,5\\), \\(j = 0,1,2,...,5\\). If an insured has one or more claims within the year, the probability of transitioning back to state 0 is represented by \\(p_{i0}\\), which is also equivalent to \\(1 - {p_{ij}}.\\) Therefore, there are only two transition probabilities in each row; the probability of advancing to the next state, \\(p_{ij},\\) and the probability of returning back to state zero, \\(p_{i0} = 1 - p_{ij}\\). In terms of transition probabilities, the Malaysian NCD system can be represented by the following \\((6 \\times 6)\\) transition matrix: \\[ {\\bf P} = \\left[ {\\begin{array}{*{20}c} p_{00}&amp;p_{01}&amp;0&amp;0&amp;0&amp;0\\\\ p_{10}&amp;0&amp;p_{12}&amp;0&amp;0&amp;0\\\\ p_{20}&amp;0&amp;0&amp;p_{23}&amp;0&amp;0\\\\ p_{30}&amp;0&amp;0&amp;0&amp;p_{34}&amp;0\\\\ p_{40}&amp;0&amp;0&amp;0&amp;0&amp;p_{45}\\\\ p_{50}&amp;0&amp;0&amp;0&amp;0&amp;p_{55} \\end{array} }\\right] = \\left[ {\\begin{array}{*{20}c} {1 - p_{01}}&amp;p_{01}&amp;0&amp;0&amp;0&amp;0\\\\ {1 - p_{12}}&amp;0&amp;p_{12}&amp;0&amp;0&amp;0\\\\ {1 - p_{23}}&amp;0&amp;0&amp;p_{23}&amp;0&amp;0\\\\ {1 - p_{34}}&amp;0&amp;0&amp;0&amp;p_{34}&amp;0\\\\ {1 - p_{45}}&amp;0&amp;0&amp;0&amp;0&amp;p_{45}\\\\ {1 - p_{55}}&amp;0&amp;0&amp;0&amp;0&amp;p_{55} \\end{array} }\\right] \\] Example 1 Provide the transition matrix for the NCD system in Brazil. Solution Based on the NCD classes and the transition diagram shown respectively in Table 2 and Figure 12.2, the probability of a no-claim year is equal to the probability of moving one-class forward, whereas the probability of having one or more claims within the year is equal to the probability of moving one-class backward. Therefore, each row can contain two or more transition probabilities; one probability for advancing to the next state, and one or more probabilities for moving one-class backwards. The transition matrix is: \\[ {\\bf P} = \\left[ {\\begin{array}{*{20}{c}} {1 - p_{01}}&amp;p_{01}&amp;0&amp;0&amp;0&amp;0&amp;0\\\\ {1 - p_{12}}&amp;0&amp;p_{12}&amp;0&amp;0&amp;0&amp;0\\\\ {1 - \\sum\\limits_j p_{2j}}&amp;p_{21}&amp;0&amp;p_{23}&amp;0&amp;0&amp;0\\\\ {1 - \\sum\\limits_j p_{3j}}&amp;p_{31}&amp;p_{32}&amp;0&amp;p_{34}&amp;0&amp;0\\\\\\ {1 - \\sum\\limits_j p_{4j}}&amp;p_{41}&amp;p_{42}&amp;p_{43}&amp;0&amp;p_{45}&amp;0\\\\ {1 - \\sum\\limits_j p_{5j}}&amp;p_{51}&amp;p_{52}&amp;p_{53}&amp;p_{54}&amp;0&amp;p_{56}\\\\ {1 - \\sum\\limits_j p_{6j}}&amp;p_{61}&amp;p_{62}&amp;p_{63}&amp;p_{64}&amp;p_{65}&amp;p_{66} \\end{array} } \\right] \\] Example 2 Provide the transition matrix for the NCD system in Switzerland. Solution From Table 3 and Figure 12.3, the probability of a no-claim year is equal to the probability of moving one-class forward, whereas the probability of having one or more claims within the year is equal to the probability of moving four-classes backward. The transition matrix is: \\[ \\begin{matrix} \\left| {\\begin{array}{*{12}{c}} 1 - {p_{01}} &amp; p_{01} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots\\\\ 1 - {p_{12}} &amp; 0 &amp; p_{12} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots\\\\ 1 - {p_{23}} &amp; 0 &amp; 0 &amp; p_{23} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots\\\\ 1 - {p_{34}} &amp; 0 &amp; 0 &amp; 0 &amp; p_{34} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots\\\\ 1 - {p_{45}} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; p_{45} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots\\\\ 1 - \\sum\\limits_j {p_{5j}} &amp; p_{51} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; p_{56} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots\\\\ 1 - \\sum\\limits_j {p_{6j}} &amp; 0 &amp; p_{62} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; p_{67} &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots\\\\ 1 - \\sum\\limits_j {p_{7j}} &amp; 0 &amp; 0 &amp; p_{73} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; p_{78} &amp; 0 &amp; 0 &amp; \\cdots\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots\\\\ 1 - \\sum\\limits_j {p_{19,j}} &amp; 0 &amp; 0 &amp; p_{19,3} &amp; 0 &amp; 0 &amp; 0 &amp; p_{19,7} &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots\\\\ 1 - \\sum\\limits_j {p_{20,j}} &amp; 0 &amp; 0 &amp; 0 &amp; p_{20,4} &amp; 0 &amp; 0 &amp; 0 &amp; p_{20,8} &amp; 0 &amp; 0 &amp; \\cdots\\\\ 1 - \\sum\\limits_j {p_{21,j}} &amp; p_{21,1} &amp; 0 &amp; 0 &amp; 0 &amp; p_{21,5} &amp; 0 &amp; 0 &amp; 0 &amp; p_{21,9} &amp; 0 &amp; \\cdots \\end{array}} \\right| \\end{matrix} \\] 12.4 BMS and Stationary Distribution 12.4.1 Stationary Distribution It is important to note that the transition matrix represents the transition probabilities of the NCD classes in one year. If we are interested in the distribution of the transition in the long run (which may take several years), the stationary probability can be used. Several definitions and properties are provided here to understand the use of a Markov chain model for representing the stationary distribution of the NCD transitions. However, students are encouraged to refer to textbooks on Markov Chain and stochastic processes available in the literature for a more comprehensive knowledge on the related subjects. Definition: A Markov chain is said to be irreducible if it is possible to move to any state from any other state. Definition: A state \\(i\\) has period \\(k\\) if any return to state \\(i\\) must occur in multiples of \\(k\\) time steps. If \\(k = 1\\), then the state is said to be aperiodic. Definition: A state \\(i\\) is said to be transient if, given that we start in state \\(i\\), there is a non-zero probability that we will never return to \\(i\\). State \\(i\\) is recurrent (or persistent) if it is not transient. A state \\(i\\) is positive recurrent if the mean recurrent time (or expected return time) is finite. Definition: A state \\(i\\) is said to be ergodic if it is aperiodic and positive recurrent. In other words, a state \\(i\\) is ergodic if it is recurrent, has a period of one (aperiodic), and has finite mean recurrence time. If all states in an irreducible Markov chain are ergodic, then the chain is said to be ergodic. Definition: Let \\(p_{ij}^{(n)} = \\Pr ({X_n} = j\\|{X_0} = i)\\) be the probability of transition from state \\(i\\) to state \\(j\\) in \\(n\\) time steps. The n-step transition probabilities for a stationary Markov chain satisfy the Chapman–Kolmogorov equation: \\[p_{ij}^{(n)} = \\sum\\limits_r {p_{ir}^{(k)}p_{rj}^{(n - k)}}\\] for any \\(k\\), where \\(0 &lt; k &lt; n\\). Definition: If a Markov chain is stationary, then the vector \\({\\bf{\\pi }}\\) is called a stationary distribution (or invariant measure) if it satisfies: \\[0 \\le {\\pi _j} \\le 1\\] \\[\\sum\\limits_j {{\\pi _j}} = 1,\\] \\[{\\pi_j} = \\sum\\limits_i {\\pi_i}p_{ij}\\]. In terms of vectors and matrices, a stationary distribution \\({\\bf{\\pi }}\\) is a row vector, whose entries are non-negative and sum to one, that is unchanged by the operation: \\({\\bf{\\pi P}} = {\\bf{\\pi }}\\). If a Markov chain is stationary, then the transition matrix \\({\\bf{P}}\\) is the same after each step, so that the \\(k\\)-step transition probability can be computed as the \\(k\\)-th power of the transition matrix, \\({{\\bf{P}}^k}.\\) From the definitions and properties above, a BMS forms a regular Markov chain if all of its states (NCD classes) are ergodic, and the chain is not cyclic (or irreversible). The row vector, \\({\\bf{\\pi }}\\), which is also the left eigenvector of the transition matrix, is a stationary distribution defined by \\(0 \\le {\\pi _j} \\le 1\\) and \\(\\sum\\limits_j {{\\pi_j}} = 1\\). Example 3 Find the stationary distribution for the NCD system in Malaysia assuming that the probability of a no-claim year for all NCD classes are \\({p_0}\\). Solution The transition matrix can be re-written as: The stationary distribution can be calculated using \\({\\pi _j} = \\sum\\limits_i {\\pi _i}p_{ij}\\). The solutions are: \\[ \\begin{array}{l} {\\pi _0} = \\sum\\limits_i {\\pi_i}p_{i0} = (1 - {p_0})\\sum\\limits_i {{\\pi _i}} = 1 - {p_0}\\\\\\\\ {\\pi _1} = \\sum\\limits_i {\\pi _i}p_{i1} = {\\pi_0}{p_{01}} = (1 - {p_0}){p_0}\\\\\\\\ {\\pi _2} = \\sum\\limits_i {\\pi _i}p_{i2} = {\\pi _1}{p_{12}} = (1 - {p_0}){p_0}^2\\\\\\\\ {\\pi _3} = \\sum\\limits_i {\\pi _i}p_{i3} = {\\pi _2}{p_{23}} = (1 - {p_0}){p_0}^3\\\\\\\\ {\\pi _4} = \\sum\\limits_i {\\pi _i}p_{i4} = {\\pi _3}{p_{34}} = (1 - {p_0}){p_0}^4\\\\\\\\ {\\pi _5} = \\sum\\limits_i {\\pi _i}p_{i5} = {\\pi _4}{p_{45}} + {\\pi _5}{p_{55}} = (1 - {p_0}){p_0}^5 + {\\pi _5}{p_0}\\\\\\\\ \\therefore {\\pi _5} = \\frac{(1 - {p_0}){p_0}^5}{{(1 - {p_0})}} = {p_0}^5 \\end{array} \\] The stationary distribution (or steady state condition) shown in Example 3 represents the asymptotic distribution of the NCD system, or the distribution in the long run. As an example, assuming that the probability of a no-claim year is \\(p_0 = 0.90,\\) the stationary probabilities are: \\[ \\begin{array}{l} {\\pi _0} = 1 - {p_0} = 0.1000\\\\\\\\ {\\pi _1} = (1 - {p_0}){p_0} = 0.0900\\\\\\\\ {\\pi _2} = (1 - {p_0}){p_0}^2 = 0.0810\\\\\\\\ {\\pi _3} = (1 - {p_0}){p_0}^3 = 0.0729\\\\\\\\ {\\pi _4} = (1 - {p_0}){p_0}^4 = 0.0656\\\\\\\\ {\\pi _5} = {p_0}^5 = 0.5905 \\end{array} \\] In other words, \\({\\pi_0} = 0.10\\) indicates that 10% of insureds will eventually belong to class 0 (or zero claim-free years), \\({\\pi _1} = 0.09\\) indicates that 9% of insureds will eventually belong to class 1 (or one claim-free year), and so forth, until \\({\\pi _5} = 0.59\\), which indicates that 59% of insureds will eventually belong to class 5 (or five successive claim-free years). 12.4.2 R Program for Stationary Distribution We can use the left eigenvector of a transition matrix to calculate the stationary distribution. The following R program can be used to calculate the left eigenvector: #create transition matrix entries=c(0.1,0.9,0,0,0,0, + 0.1,0,0.9,0,0,0, + 0.1,0,0,0.9,0,0, + 0.1,0,0,0,0.9,0, + 0.1,0,0,0,0,0.9, + 0.1,0,0,0,0,0.9) TP=matrix(entries,nrow=6,byrow=TRUE) TP ## [,1] [,2] [,3] [,4] [,5] [,6] ## [1,] 0.1 0.9 0.0 0.0 0.0 0.0 ## [2,] 0.1 0.0 0.9 0.0 0.0 0.0 ## [3,] 0.1 0.0 0.0 0.9 0.0 0.0 ## [4,] 0.1 0.0 0.0 0.0 0.9 0.0 ## [5,] 0.1 0.0 0.0 0.0 0.0 0.9 ## [6,] 0.1 0.0 0.0 0.0 0.0 0.9 #calculate left eigenvector #hint -- left eigenvector is the same as right eigenvector of transpose of transition matrix eigen(t(TP)) ## eigen() decomposition ## $values ## [1] 1.0000000000+0.0000000000i -0.0004880382+0.0003546725i ## [3] -0.0004880382-0.0003546725i 0.0001865015+0.0005736028i ## [5] 0.0001865015-0.0005736028i 0.0006030733+0.0000000000i ## ## $vectors ## [,1] [,2] ## [1,] 0.1615936+0i 0.00000000000011546+0.0000000000000838874i ## [2,] 0.1454342+0i -0.00000000006591101-0.0000000002025976972i ## [3,] 0.1308908+0i -0.00000009813867774+0.0000003022936262135i ## [4,] 0.1178017+0i 0.00038354290934278-0.0002787325538732070i ## [5,] 0.1060216+0i -0.70729837066103896+0.0000000000000000000i ## [6,] 0.9541940+0i 0.70691492595616912+0.0002784304627608034i ## [,3] ## [1,] 0.00000000000011546-0.0000000000000838874i ## [2,] -0.00000000006591101+0.0000000002025976972i ## [3,] -0.00000009813867774-0.0000003022936262135i ## [4,] 0.00038354290934278+0.0002787325538732070i ## [5,] -0.70729837066103896+0.0000000000000000000i ## [6,] 0.70691492595616912-0.0002784304627608034i ## [,4] ## [1,] -0.0000000000000440003+0.0000000000001357099i ## [2,] 0.0000000001723292683+0.0000000001248792837i ## [3,] 0.0000002567150759536-0.0000001869214542640i ## [4,] -0.0001468014877601952-0.0004505247500856750i ## [5,] -0.7070333538878578183+0.0004507115465249567i ## [6,] 0.7071798984882565753+0.0000000000000000000i ## [,5] [,6] ## [1,] -0.0000000000000440003-0.0000000000001357099i 0.0000000000001426323+0i ## [2,] 0.0000000001723292683-0.0000000001248792837i 0.0000000002126778891+0i ## [3,] 0.0000002567150759536+0.0000001869214542640i 0.0000003173909504803+0i ## [4,] -0.0001468014877601952+0.0004505247500856750i 0.0004736602551468477+0i ## [5,] -0.7070333538878578183-0.0004507115465249567i 0.7068696732221422252+0i ## [6,] 0.7071798984882565753+0.0000000000000000000i -0.7073436510810596767+0i #divide entry of first column by sum of elements, so that entries sum to 1 #provide answers in 4 decimal places round(eigen(t(TP))$vectors[,1]/sum(eigen(t(TP))$vectors[,1]),4) ## [1] 0.1000+0i 0.0900+0i 0.0810+0i 0.0729+0i 0.0656+0i 0.5905+0i Example 4 Find the stationary distribution for the NCD system in Brazil assuming that the number of successive years of claims is Poisson distributed with parameter \\(\\lambda = 0.10\\). Solution Under the Poisson distribution, the probability of \\(k\\) successive years of claims is \\(p_k = \\frac{e^{ - 0.1}{(0.1)}^k}{{k!}},{\\rm{ }}k = 0,1,2,.....\\) The transition matrix is: \\[ {\\small {\\bf{P}} = \\left[ {\\begin{array}{*{20}{c}} {1 - {p_0}}&amp;{{p_0}}&amp;0&amp;0&amp;0&amp;0&amp;0\\\\\\\\ {1 - {p_0}}&amp;0&amp;{{p_0}}&amp;0&amp;0&amp;0&amp;0\\\\\\\\ {1 -\\sum\\limits_i {{p_i}} }&amp;{{p_1}}&amp;0&amp;{{p_0}}&amp;0&amp;0&amp;0\\\\\\\\ {1 -\\sum\\limits_i {{p_i}} }&amp;{{p_2}}&amp;{{p_1}}&amp;0&amp;{{p_0}}&amp;0&amp;0\\\\\\\\ {1 - \\sum\\limits_i {{p_i}}}&amp;{{p_3}}&amp;{{p_2}}&amp;{{p_1}}&amp;0&amp;{{p_0}}&amp;0\\\\\\\\ {1 - \\sum\\limits_i{{p_i}} }&amp;{{p_4}}&amp;{{p_3}}&amp;{{p_2}}&amp;{{p_1}}&amp;0&amp;{{p_0}}\\\\\\\\ {1 - \\sum\\limits_i {{p_i}}}&amp;{{p_5}}&amp;{{p_4}}&amp;{{p_3}}&amp;{{p_2}}&amp;{{p_1}}&amp;{{p_0}} \\end{array}} \\right] = \\left[ {\\begin{array}{*{20}{c}} {0.0952}&amp;{0.9048}&amp;0&amp;0&amp;0&amp;0&amp;0\\\\\\\\ {0.0952}&amp;0&amp;{0.9048}&amp;0&amp;0&amp;0&amp;0\\\\\\\\ {0.0047}&amp;{0.0905}&amp;0&amp;{0.9048}&amp;0&amp;0&amp;0\\\\\\\\ {0.0002}&amp;{0.0045}&amp;{0.0905}&amp;0&amp;{0.9048}&amp;0&amp;0\\\\\\\\ {0.0000}&amp;{0.0002}&amp;{0.0045}&amp;{0.0905}&amp;0&amp;{0.9048}&amp;0\\\\\\\\ {0.0000}&amp;{0.0000}&amp;{0.0002}&amp;{0.0045}&amp;{0.0905}&amp;0&amp;{0.9048}\\\\\\\\ {0.0000}&amp;{0.0000}&amp;{0.0000}&amp;{0.0002}&amp;{0.0045}&amp;{0.0905}&amp;{0.9048} \\end{array}}\\right]} \\] Using R program, the stationary probabilities are: \\[ \\left[ {\\begin{array}{*{20}{c}} {{\\pi _0}}\\\\\\\\ {{\\pi_1}}\\\\\\\\ {{\\pi _2}}\\\\\\\\ {{\\pi _3}}\\\\\\\\ {{\\pi _4}}\\\\\\\\ {{\\pi_5}}\\\\\\\\ {{\\pi _6}} \\end{array}} \\right] = \\left[ {\\begin{array}{*{20}{c}} {0.0000}\\\\\\\\ {0.0000}\\\\\\\\ {0.0003}\\\\\\\\ {0.0022}\\\\\\\\ {0.0145}\\\\\\\\ {0.0936}\\\\\\\\ {0.8894} \\end{array}} \\right] \\] The probabilities indicate that 89% of insureds will eventually belong to class 6 (six successive claim-free years), 9% of insureds will eventually belong to class 5 (five successive claim-free years), and 1.5% of insureds will eventually belong to class 4 (four successive claim-free years). Other classes, after combined, have less than 1% of insureds. Example 5 Using the results from Example 4, find the final premium under the steady state condition assuming that the premium prior to implementing the NCD is \\(m.\\) Solution Using the stationary probabilities from Example 4, the stationary final premium is: \\[ \\begin{array}{l} = \\sum\\limits_j \\text{(premium)} \\times \\text{(proportion in class } j \\text{ in the long run)} \\times \\text{(1 - NCD in class } j)\\\\\\\\ = m[{\\pi _0}(1) + {\\pi _1}(1 - 0.9) + {\\pi _2}(1 - 0.15) + \\ldots + {\\pi _6}(1 - 0.35)]\\\\\\\\ = m[0 + 0 + (0.0003)(0.85) + \\ldots + (0.8894)(0.65)]\\\\\\\\ = 0.6565m \\end{array} \\] The results indicate that the final premium reduce from m to 0.6565m in the long run (under steady state condition or stationary condition) if the NCD is considered. 12.4.3 Premium Evolution Sometimes we are interested to observe the evolution of the mean premium after \\(n\\) years (or \\(n\\) steps). Under the NCD system, the n-step transition probability, \\(p_{ij}^{(n)}\\), can be used to observe the evolution of the mean premium. A definition on n-step transition probabaility \\(p_{ij}^{(n)}\\) is provided here to understand the use of the probability for observing the evolution of the mean premium. Definition: Let \\(p_{ij} = \\Pr ({X_{n + 1}} = j|{X_n} = i)\\) be a one-step transition probability from state \\(i\\) to state \\(j\\), and \\(p_{ij}^{(n)} = \\Pr ({X_n} = j|{X_0} = i)\\), \\(n = 1,2,...\\), be an n-step transition probability from state \\(i\\) to state \\(j\\). The probability \\(p_{ij}^{(n)}\\) can be obtained using the \\(n\\)th power of transition matrix \\({\\bf{P}}\\), which is \\({\\bf{P}^n}.\\) Example 6 Observe the premiums in 20 years under the NCD system in Malaysia, assuming that the probability of claims is Poisson distributed with parameter \\(\\lambda = 0.10\\) and the premium prior to implementing the NCD is \\(m = 100\\). Solution Under the Malaysian NCD, we use the Poisson probability, \\(p_k = \\frac{e^{ - 0.1}{(0.1)}^k}{k!}\\), only for \\(k = 0,1.\\) Therefore, the transition matrix in the first year is: \\[ {\\bf{P}^{(1)}} = \\left[{\\begin{array}{*{20}{c}} {0.0952}&amp;{0.9048}&amp;0&amp;0&amp;0&amp;0\\\\\\\\ {0.0952}&amp;0&amp;{0.9048}&amp;0&amp;0&amp;0\\\\\\\\ {0.0952}&amp;0&amp;0&amp;{0.9048}&amp;0&amp;0\\\\\\\\ {0.0952}&amp;0&amp;0&amp;0&amp;{0.9048}&amp;0\\\\\\\\ {0.0952}&amp;0&amp;0&amp;0&amp;0&amp;{0.9048}\\\\\\\\ {0.0952}&amp;0&amp;0&amp;0&amp;0&amp;{0.9048} \\end{array}} \\right] \\] The premium in the first year, after implementing the NCD, is: \\[ \\begin{aligned} &amp;= \\sum\\limits_j \\text{(premium)} \\times \\text{(average proportion in class } j) \\times \\text{(1 - NCD in class }j) \\\\ &amp;= m\\left[ \\frac{\\sum\\limits_i {p_{i0}}}{6}{(1)} + \\frac{\\sum\\limits_i {p_{i1}}}{6}{(1 - 0.25)} + \\ldots + \\frac{\\sum\\limits_i {p_{i5}}}{6}{(1 - 0.55)} \\right]\\\\ &amp;= 100[0.0952(1) + 0.1508(0.75) + \\cdots + 0.3016(0.45)]\\\\ &amp;= 62.55. \\end{aligned} \\] Using similar steps, the premium in the \\(n\\)-th year for \\(n = 1,2,...,20\\) can be observed. From R program, the premiums in 20 years are: 62.55, 59.87, 58.06, 57.06, 56.58, 56.58, 56.58, 56.58, 56.58, 56.58, 56.58, 56.58, 56.58, 56.58, 56.58, 56.58, 56.58, 56.58, 56.58, 56.58. 12.4.4 R Program for Premium Evolution The following R program can be used to find the premium in the n-th year and the premiums in 20 years under the NCD system in Malaysia (to find the solution in Example 6). #create transition matrix entries=c(0.0952,0.9048,0,0,0,0, + 0.0952,0,0.9048,0,0,0, + 0.0952,0,0,0.9048,0,0, + 0.0952,0,0,0,0.9048,0, + 0.0952,0,0,0,0,0.9048, + 0.0952,0,0,0,0,0.9048) TP=matrix(entries,nrow=6,byrow=TRUE) TP ## [,1] [,2] [,3] [,4] [,5] [,6] ## [1,] 0.0952 0.9048 0.0000 0.0000 0.0000 0.0000 ## [2,] 0.0952 0.0000 0.9048 0.0000 0.0000 0.0000 ## [3,] 0.0952 0.0000 0.0000 0.9048 0.0000 0.0000 ## [4,] 0.0952 0.0000 0.0000 0.0000 0.9048 0.0000 ## [5,] 0.0952 0.0000 0.0000 0.0000 0.0000 0.9048 ## [6,] 0.0952 0.0000 0.0000 0.0000 0.0000 0.9048 #create function for nth power of square matrix powA = function(n) { if (n==1) return (TP) if (n==2) return (TP%*%TP) if (n&gt;2) return ( TP%*%powA(n-1)) } #example for n=3 powA(3) ## [,1] [,2] [,3] [,4] [,5] [,6] ## [1,] 0.0952 0.08613696 0.07793672 0.7407263 0.0000000 0.0000000 ## [2,] 0.0952 0.08613696 0.07793672 0.0000000 0.7407263 0.0000000 ## [3,] 0.0952 0.08613696 0.07793672 0.0000000 0.0000000 0.7407263 ## [4,] 0.0952 0.08613696 0.07793672 0.0000000 0.0000000 0.7407263 ## [5,] 0.0952 0.08613696 0.07793672 0.0000000 0.0000000 0.7407263 ## [6,] 0.0952 0.08613696 0.07793672 0.0000000 0.0000000 0.7407263 #define NCD percentage NCD=c(1,.75,.7,.6167,.55,.45) #create function for premium in nth year p=numeric(0) prem=function(n){ for (j in 1:length(NCD)) p[j]=mean(powA(n)[,j]) + 100*sum(p*NCD)} #example for n=3 prem(3) ## [1] 58.06106 #provide premiums for 20 years premium=numeric(0) for (n in 1:20) premium[n]=prem(n) round(premium,2) ## [1] 62.55 59.87 58.06 57.06 56.58 56.58 56.58 56.58 56.58 56.58 56.58 56.58 ## [13] 56.58 56.58 56.58 56.58 56.58 56.58 56.58 56.58 Example 7 Observe the premiums in 20 years under the NCD system in Brazil, assuming that the probability of \\(k\\) successive years of claims is \\(p_k = \\frac{e^{ - 0.1}{(0.1)}^k}{{k!}},{\\rm{ }}k = 0,1,2,.....\\), and the premium prior to implementing the NCD is \\(m = 100\\). Solution The transition matrix for the NCD system in Brazil is: \\[ {\\bf P} = \\left[ {\\begin{array}{*{20}{c}} {0.0952}&amp;{0.9048}&amp;0&amp;0&amp;0&amp;0&amp;0\\\\\\\\ {0.0952}&amp;0&amp;{0.9048}&amp;0&amp;0&amp;0&amp;0\\\\\\\\ {0.0047}&amp;{0.0905}&amp;0&amp;{0.9048}&amp;0&amp;0&amp;0\\\\\\\\ {0.0002}&amp;{0.0045}&amp;{0.0905}&amp;0&amp;{0.9048}&amp;0&amp;0\\\\\\\\ {0.0000}&amp;{0.0002}&amp;{0.0045}&amp;{0.0905}&amp;0&amp;{0.9048}&amp;0\\\\\\\\ {0.0000}&amp;{0.0000}&amp;{0.0002}&amp;{0.0045}&amp;{0.0905}&amp;0&amp;{0.9048}\\\\\\\\ {0.0000}&amp;{0.0000}&amp;{0.0000}&amp;{0.0002}&amp;{0.0045}&amp;{0.0905}&amp;{0.9048} \\end{array}} \\right] \\] Using R program the premiums in 20 years are: 76.69, 73.76, 71.31, 69.38, 67.92, 66.93, 66.40, 66.05, 65.88, 65.78, 65.72, 65.69, 65.67, 65.66, 65.66, 65.66, 65.66, 65.65, 65.65, 65.65. The results in Examples 6-7 allow us to observe the evolution of premium for the NCD systems in Malaysia and Brazil assuming that the number of successive years of claims is Poisson distributed with parameter \\(\\lambda = 0.10\\), and the premium prior to implementing the NCD is \\(m = 100\\). The evolutions of premiums for both countries are provided in Table 4, and are shown graphically in Figure 12.4. \\[ \\begin{matrix} \\text{Table 4: Evolution of premium (Malaysia and Brazil)}\\\\ \\begin{array}{*{20}c} \\hline \\text{year} &amp; \\text{premium} &amp; \\text{premium} &amp; \\text{year} &amp; \\text{premium} &amp; \\text{premium} &amp; \\\\ &amp; \\text{Malaysia} &amp; \\text{Brazil} &amp; &amp; \\text{Malaysia} &amp; \\text{Brazil} \\\\ \\hline\\\\ 0 &amp; 100 &amp; 100 &amp; 11 &amp; 56.58 &amp; 65.72 \\\\ 1 &amp; 62.55 &amp; 76.69 &amp; 12 &amp; 56.58 &amp; 65.69 \\\\ 2 &amp; 59.87 &amp; 73.76 &amp; 13 &amp; 56.58 &amp; 65.67 \\\\ 3 &amp; 58.06 &amp; 71.31 &amp; 14 &amp; 56.58 &amp; 65.66 \\\\ 4 &amp; 57.06 &amp; 69.38 &amp; 15 &amp; 56.58 &amp; 65.66 \\\\ 5 &amp; 56.58 &amp; 67.92 &amp; 16 &amp; 56.58 &amp; 65.66 \\\\ 6 &amp; 56.58 &amp; 66.93 &amp; 17 &amp; 56.58 &amp; 65.66 \\\\ 7 &amp; 56.58 &amp; 66.40 &amp; 18 &amp; 56.58 &amp; 65.65 \\\\ 8 &amp; 56.58 &amp; 66.05 &amp; 19 &amp; 56.58 &amp; 65.65 \\\\ 9 &amp; 56.58 &amp; 65.88 &amp; 20 &amp; 56.58 &amp; 65.65 \\\\\\\\ \\hline \\end{array} \\end{matrix} \\] Figure 12.4: Evolution of premium (Malaysia and Brazil) 12.4.5 Convergence Rate Sometimes we are interested to know the variation between the probability in the n-th year, \\(p_{ij}^{(n)}\\), and the stationary probability, \\(\\pi _j\\). The variation between the probabilities can be measured using: \\[\\left| {average(p_{ij}^{(n)}) - {\\pi _j}} \\right|\\]. Therefore, the total variation can be measured by the sum of variation in all classes: \\[\\sum\\limits_j {\\left| {average(p_{ij}^{(n)}) - {\\pi _j}} \\right|}\\]. The total variation is also called the convergence rate because it measures the convergence rate after \\(n\\) years (or \\(n\\) transitions). Example 8 Provide the total variations (convergence rate) in 20 years under the NCD system in Malaysia, assuming that the probability of claims is Poisson distributed with parameter \\(\\lambda = 0.10\\). Solution Using R program, the stationary probabilities are: \\[ \\left[ {\\begin{array}{*{20}{c}} {{\\pi _0}}\\\\\\\\{{\\pi_1}}\\\\\\\\{{\\pi _2}}\\\\\\\\ {{\\pi _3}}\\\\\\\\{{\\pi _4}}\\\\\\\\{{\\pi_5}} \\end{array}} \\right] = \\left[ {\\begin{array}{*{20}{c}} {0.0952}\\\\\\\\{0.0861}\\\\\\\\{0.0779}\\\\\\\\ {0.0705}\\\\\\\\{0.0638}\\\\\\\\{0.6064} \\end{array}} \\right] \\] The transition matrix in the first year is: \\[ {\\bf{P}}^{(1)} = \\left[ {\\begin{array}{*{20}{c}} {0.0952}&amp;{0.9048}&amp;0&amp;0&amp;0&amp;0\\\\\\\\ {0.0952}&amp;0&amp;{0.9048}&amp;0&amp;0&amp;0\\\\\\\\ {0.0952}&amp;0&amp;0&amp;{0.9048}&amp;0&amp;0\\\\\\\\ {0.0952}&amp;0&amp;0&amp;0&amp;{0.9048}&amp;0\\\\\\\\ {0.0952}&amp;0&amp;0&amp;0&amp;0&amp;{0.9048}\\\\\\\\ {0.0952}&amp;0&amp;0&amp;0&amp;0&amp;{0.9048} \\end{array}} \\right] \\] The variation can be computed as: \\[ \\begin{array}{l} \\left| {\\sum\\limits_i {\\frac{p_{i0}^{}}{6}} - {\\pi _0}} \\right| = 0\\\\\\\\ \\left|{\\sum\\limits_i {\\frac{p_{i1}^{}}{6}} - {\\pi _1}} \\right| = 0.0647\\\\\\\\ \\vdots \\\\\\\\ \\left| {\\sum\\limits_i \\frac{p_{i5}}{6} - {\\pi _5}} \\right| = .3048 \\end{array} \\] Therefore, the total variation in the first year is \\(\\sum\\limits_j {\\left| {\\sum\\limits_i {\\frac{p_{ij}}{6} - {\\pi _j}} } \\right|} = 0.6096\\). Using R program, the total variations (or convergence rate) in 20 years are: 0.6096, 0.3941, 0.2252, 0.0958, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0. 12.4.6 R Program for Convergence Rate The following R program can be used to calculate the total variation in the \\(n\\)th year, and the total variations (convergence rates) in 20 years under the NCD system in Malaysia (the solution in Example 8). #transition matrix TP ## [,1] [,2] [,3] [,4] [,5] [,6] ## [1,] 0.0952 0.9048 0.0000 0.0000 0.0000 0.0000 ## [2,] 0.0952 0.0000 0.9048 0.0000 0.0000 0.0000 ## [3,] 0.0952 0.0000 0.0000 0.9048 0.0000 0.0000 ## [4,] 0.0952 0.0000 0.0000 0.0000 0.9048 0.0000 ## [5,] 0.0952 0.0000 0.0000 0.0000 0.0000 0.9048 ## [6,] 0.0952 0.0000 0.0000 0.0000 0.0000 0.9048 # stationary probability SP=eigen(t(TP))$vectors[,1]/sum(eigen(t(TP))$vectors[,1]) SP ## [1] 0.09520000+0i 0.08613696+0i 0.07793672+0i 0.07051715+0i 0.06380391+0i ## [6] 0.60640526+0i #create function for total variation in nth year TV=function(n) {dif=numeric(0) for (j in 1:length(SP)) dif[j]=abs(mean(powA(n)[,j])-SP[j]) + sum(dif)} #example for n=1 TV(1) ## [1] 0.6096105 #provide total variations (convergence rate) in 20 years tot.var=numeric(0) for (n in 1:20) tot.var[n]=TV(n) round(tot.var,4) ## [1] 0.6096 0.3941 0.2252 0.0958 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 ## [11] 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 Example 9 Provide the total variations (or convergence rate) in 20 years under the NCD system in Brazil, assuming that the number of successive years of claims is distributed as Poisson with parameter \\(\\lambda = 0.10\\) Solution Using R program, the total variations (or convergence rates) in 20 years for the NCD system in Brazil are: 1.2617, 1.0536, 0.8465, 0.6412, 0.4362, 0.2316, 0.1531, 0.0747, 0.0480, 0.0232, 0.0145, 0.0071, 0.0043, 0.0021, 0.0013, 0.0006, 0.0004, 0.0002, 0.0001, 0.0001. Examples 8-9 provide the degree of convergence for two different BMS (two different countries). The Malaysian BMS reaches full stationary only after four years, while the BMS in Brazil takes a longer period. As mentioned in Lemaire (1998), a more sophisticated BMS would converge more slowly, and is considered as a drawback as it takes a longer period to stabilize. The main objective of a BMS is to separate the good drivers from the bad drivers, and thus, it is desirable to have a classification process that can be finalized (or stabilized) as soon as possible. 12.5 BMS and Premium Rating 12.5.1 Premium Rating Premium rating is the process of establishing premium rates in an insurance system, or other risk transfer mechanisms. The process involves a number of considerations such as statistical methods, marketing goals, competition and legal restrictions. Premium rating should fulfill four basic objectives generally agreed among the actuaries; producing ‘fair’ premium rates whereby high risks insureds pay higher premium and vice versa, providing sufficient funds for paying incurred losses and expenses, providing adequate margin for adverse deviation, and producing reasonable returns to insurers. Before we discuss the application of BMS in premium rating, a brief discussion of the Poisson and negative binomial regression models are provided here. The Poisson regression has been widely used for fitting count (or frequency) data in insurance area. The negative binomial regression model can be used for fitting count (or frequency) data with overdispersion, which is a situation when the variance is larger than the mean. However, students are encouraged to refer to textbooks on GLMs or regression models available in the literature for a more comprehensive knowledge on the related subjects. 12.5.2 Frequency Model – Poisson and Negative Binomial Regressions Let \\({({Y_1},{Y_2},...,{Y_n})^T}\\) be the vector of count random variables and \\(n\\) be the sample size. The probability mass function (p.m.f.) for Poisson regression model is, \\[\\Pr ({Y_i} = {y_i}) \\begin{array}{*{20}{c}} = \\frac{{{\\exp(- {\\mu _i})}{\\mu _i}^{y_i}}}{y_i{!}}&amp;{y_i = 0,1,...} \\end{array} \\] with mean and variance \\(E({Y_i}) = Var({Y_i}) = {\\mu _i}\\). To take into account non-negative values, the mean, or the fitted value, is assumed to follow a log link, \\(E({Y_i}) = {\\mu _i} = \\exp ({\\bf x}_{\\bf i}{\\bf &#39;\\beta })\\), where \\({\\bf{x}}_{\\bf i}\\) denotes the vector of explanatory variables and \\({\\bf \\beta}\\) is the vector of regression parameters. The maximum likelihood estimates can be obtained by maximizing the log likelihood. The p.m.f. for negative binomial regression model is, \\[ \\Pr ({Y_i} = {y_i}) = \\frac{{\\Gamma ({y_i} + v)}}{y_i{!}\\Gamma (v)} \\left( \\frac{v}{v + {\\mu _i}} \\right)^v \\left( \\frac{\\mu _i}{v + {\\mu _i}} \\right)^{y_i},{y_i} = 0,1,2,..., \\] where the mean is \\(E({Y_i}) = {\\mu _i}\\), the variance is \\(Var({Y_i}) = {\\mu _i}(1 + {v^{ - 1}}{\\mu _i}) = {\\mu _i}(1 + a{\\mu _i})\\), and \\({v^{ - 1}} = a\\) denotes the dispersion parameter. The NB regression model reduce to the Poisson regression model in the limit as \\(a \\to 0\\), and display overdispersion when \\(a &gt; 0\\). The mean can also be assumed to follow the log link, \\(E({Y_i}) = {\\mu _i} = \\exp ({{\\bf x}_{\\bf i}{\\bf{&#39;\\beta }}})\\), and the maximum likelihood estimates can be obtained by maximizing the log likelihood. 12.5.3 Premium Rating with Bonus-Malus Data Under this section, we will consider the statistical approach of obtaining premium rates using count data (frequency data) that provides bonus-malus information on the risk profiles of the insureds. Example 10 Consider the Canadian private automobile liability insurance data from Bailey and Simon (1960). The data provides information on the number of claims incurred and exposures (expressed in terms of number of earned car years). The data is classified into two rating factors; merit rating and class rating. Altogether, there are twenty \\((4 \\times 5)\\) cross-classified rating classes of claim frequencies (20 count data). Table 5 provides the description of the two rating factors. It can be seen that merit rating provides information on the number of accident-free years, and thus, the information can be used as bonus-malus information. Using the Canadian automobile insurance data: Fit the count data using Poisson regression model. Calculate the premium assuming that the claim severity is 1000 for all rating classes. Build a simple premium table, and suggest the percentage of discounts (or loadings) for the premiums if the BMS is to be considered. \\[ \\begin{matrix} \\text{Table 5: Rating factors (Canadian data)}\\\\ \\begin{array}{*{20}c} \\hline \\text{Merit} &amp; \\text{Class}\\\\ \\hline\\\\ \\text{A = licensed, accident-free ≥ 3 years } &amp; \\text{1 = pleasure, no male operator &lt; 25 } \\\\ \\text{X = licensed, accident-free 2 years } &amp; \\text{2 = pleasure, non-principal male operator &lt; 25 } \\\\ \\text{Y = licensed, accident-free 1 year } &amp; \\text{3 = business use } \\\\ \\text{B = others} &amp; \\text{4 = unmarried owner / principal operator &lt; 25} \\\\ &amp; \\text{5 = married owner / principal operator &lt; 25 } \\\\\\\\ \\hline \\end{array} \\end{matrix} \\] Solution Table 6 provides the parameter estimates (and standard errors) for the Poisson regression model which is fitted to the count data. The premiums are calculated by multiplying the fitted frequencies with the claim severities. The fitted frequency is obtained by dividing the fitted count with the exposure. The fitted count, \\(E({Y_i}) = {\\mu _i} = {\\hat y_i}\\), is the fitted value obtained from the Poisson regression model. The premiums for all rating classes, are shown in Table 7. Let the premium classified under merit B be the base premium. The premium relativities and the percentage of discounts for each rating class can be calculated, and the values are shown in Table 8. A simple premium table, which provides the percentage of discounts based on the number of accident-free years, can be constructed and is shown in Table 9. The discounts can be suggested for implementing the BMS. \\[ \\begin{matrix} \\text{Table 6: Poisson regression model (Canadian data)}\\\\ \\begin{array}{*{20}c} \\hline \\text{Regression parameter} &amp; \\text{est.} &amp; \\text{std. error} &amp; p\\text{ -value} \\\\ \\hline\\\\ \\text{Intercept} &amp; {-2.53} &amp; {0.00} &amp; {0.00} \\\\ \\text{Class 2} &amp; {0.30} &amp; {0.01} &amp; {0.00} \\\\ \\text{Class 3} &amp; {0.47} &amp; {0.01} &amp; {0.00} \\\\ \\text{Class 4} &amp; {0.53} &amp; {0.01} &amp; {0.00} \\\\ \\text{Class 5} &amp; {0.22} &amp; {0.01} &amp; {0.00} \\\\ \\text{Merit X} &amp; {0.27} &amp; {0.01} &amp; {0.00} \\\\ \\text{Merit Y} &amp; {0.36} &amp; {0.01} &amp; {0.00} \\\\ \\text{Merit B} &amp; {0.49} &amp; {0.00} &amp; {0.00} \\\\ &amp; &amp; &amp; \\\\ \\text{Log }L &amp; {-394.96} &amp; &amp; \\\\\\\\ \\hline \\end{array} \\end{matrix} \\] \\[ \\begin{matrix} \\text{Table 7: Fitted count, fitted frequency and premium (Canadian data)}\\\\ \\begin{array}{*{20}c} \\hline \\text{Class} &amp; \\text{Merit} &amp; &amp; &amp; \\text{Fitted frequency} &amp; \\text{Premium} \\\\ \\text{rating} &amp; \\text{rating} &amp; \\text{Fitted count} &amp; \\text{Exposure} &amp; \\text{(count/exposure)} &amp; \\text{(frequency x 1000)}\\\\ \\hline\\\\ 1 &amp; \\text{A} &amp; 219950 &amp; 2757520 &amp; 0.08 &amp; 80 \\\\ 1 &amp; \\text{X} &amp; 13688 &amp; 130706 &amp; 0.1 &amp; 105 \\\\ 1 &amp; \\text{Y} &amp; 18608 &amp; 163544 &amp; 0.11 &amp; 114 \\\\ 1 &amp; \\text{B} &amp; 35773 &amp; 273944 &amp; 0.13 &amp; 131 \\\\ 2 &amp; \\text{A} &amp; 14052 &amp; 130535 &amp; 0.11 &amp; 108 \\\\ 2 &amp; \\text{X} &amp; 1022 &amp; 7233 &amp; 0.14 &amp; 141 \\\\ 2 &amp; \\text{Y} &amp; 1494 &amp; 9726 &amp; 0.15 &amp; 154 \\\\ 2 &amp; \\text{B} &amp; 3790 &amp; 21504 &amp; 0.18 &amp; 176 \\\\ 3 &amp; \\text{A} &amp; 31547 &amp; 247424 &amp; 0.13 &amp; 128 \\\\ 3 &amp; \\text{X} &amp; 2656 &amp; 15868 &amp; 0.17 &amp; 167 \\\\ 3 &amp; \\text{Y} &amp; 3705 &amp; 20369 &amp; 0.18 &amp; 182 \\\\ 3 &amp; \\text{B} &amp; 7862 &amp; 37666 &amp; 0.21 &amp; 209 \\\\ 4 &amp; \\text{A} &amp; 21170 &amp; 156871 &amp; 0.13 &amp; 135 \\\\ 4 &amp; \\text{X} &amp; 3137 &amp; 17707 &amp; 0.18 &amp; 177 \\\\ 4 &amp; \\text{Y} &amp; 4060 &amp; 21089 &amp; 0.19 &amp; 193 \\\\ 4 &amp; \\text{B} &amp; 12534 &amp; 56730 &amp; 0.22 &amp; 221 \\\\ 5 &amp; \\text{A} &amp; 6346 &amp; 64130 &amp; 0.1 &amp; 99 \\\\ 5 &amp; \\text{X} &amp; 525 &amp; 4039 &amp; 0.13 &amp; 130 \\\\ 5 &amp; \\text{Y} &amp; 687 &amp; 4869 &amp; 0.14 &amp; 141 \\\\ 5 &amp; \\text{B} &amp; 1393 &amp; 8601 &amp; 0.16 &amp; 162 \\\\\\\\ \\hline \\end{array} \\end{matrix} \\] \\[ \\begin{matrix} \\text{Table 8: Premium relativities (Canadian data)}\\\\ \\begin{array}{*{20}c} \\hline \\text{Class} &amp; \\text{Merit} &amp; \\text{Premium} &amp; \\text{Premium relativity} &amp; \\text{Discount} \\\\ \\hline\\\\ 1 &amp; \\text{A} &amp; 80 &amp; 0.61 &amp; 39 \\\\ &amp; \\text{X} &amp; 105 &amp; 0.80 &amp; 20 \\\\ &amp; \\text{Y} &amp; 114 &amp; 0.87 &amp; 13 \\\\ &amp; \\text{B} &amp; 131 &amp; 1.00 &amp; 0 \\\\ 2 &amp; \\text{A} &amp; 108 &amp; 0.61 &amp; 39 \\\\ &amp; \\text{X} &amp; 141 &amp; 0.80 &amp; 20 \\\\ &amp; \\text{Y} &amp; 154 &amp; 0.88 &amp; 13 \\\\ &amp; \\text{B} &amp; 176 &amp; 1.00 &amp; 0 \\\\ 3 &amp; \\text{A} &amp; 128 &amp; 0.61 &amp; 39 \\\\ &amp; \\text{X} &amp; 167 &amp; 0.80 &amp; 20 \\\\ &amp; \\text{Y} &amp; 182 &amp; 0.87 &amp; 13 \\\\ &amp; \\text{B} &amp; 209 &amp; 1.00 &amp; 0 \\\\ 4 &amp; \\text{A} &amp; 135 &amp; 0.61 &amp; 39 \\\\ &amp; \\text{X} &amp; 177 &amp; 0.80 &amp; 20 \\\\ &amp; \\text{Y} &amp; 193 &amp; 0.87 &amp; 13 \\\\ &amp; \\text{B} &amp; 221 &amp; 1.00 &amp; 0 \\\\ 5 &amp; \\text{A} &amp; 99 &amp; 0.61 &amp; 39 \\\\ &amp; \\text{X} &amp; 130 &amp; 0.80 &amp; 20 \\\\ &amp; \\text{Y} &amp; 141 &amp; 0.87 &amp; 13 \\\\ &amp; \\text{B} &amp; 162 &amp; 1.00 &amp; 0 \\\\\\\\ \\hline \\end{array} \\end{matrix}\\] \\[ \\begin{matrix} \\text{Table 9: Premium rates and BMS (Canadian data)}\\\\ \\begin{array}{*{20}c} \\hline \\text{Class} &amp; \\text{Premium} &amp; \\text{Years of} &amp; \\text{Discount for} \\\\ &amp; &amp; \\text{accident-free} &amp; \\text{bonus-malus }\\\\ \\hline\\\\ 1 &amp; 131 &amp; {3+} &amp; 39 \\\\ &amp; &amp; 2 &amp; 20 \\\\ &amp; &amp; 1 &amp; 13 \\\\ &amp; &amp; 0 &amp; 0 \\\\ 2 &amp; 176 &amp; {3+} &amp; 39 \\\\ &amp; &amp; 2 &amp; 20 \\\\ &amp; &amp; 1 &amp; 13 \\\\ &amp; &amp; 0 &amp; 0 \\\\ 3 &amp; 209 &amp; {3+} &amp; 39 \\\\ &amp; &amp; 2 &amp; 20 \\\\ &amp; &amp; 1 &amp; 13 \\\\ &amp; &amp; 0 &amp; 0 \\\\ 4 &amp; 221 &amp; {3+} &amp; 39 \\\\ &amp; &amp; 2 &amp; 20 \\\\ &amp; &amp; 1 &amp; 13 \\\\ &amp; &amp; 0 &amp; 0 \\\\ 5 &amp; 162 &amp; {3+} &amp; 39 \\\\ &amp; &amp; 2 &amp; 20 \\\\ &amp; &amp; 1 &amp; 13 \\\\ &amp; &amp; 0 &amp; 0 \\\\\\\\ \\hline \\end{array} \\end{matrix}\\] 12.5.4 Premium Rating without Bonus-Malus Data Under this section, we will consider the statistical approach of obtaining premium rates using count data that does not provide bonus-malus information on the risk profiles of the insureds. Example 11 The dataset for private car Own Damage (OD) claim count in Malaysia (Zamani and Ismail 2012, Ismail and Zamani 2013) is considered here. The data is based on 1.01 million private car policies for a three-year period of 2001-2003. The exposures are expressed in car-year units. Table 10 shows the rating factors for the claim count data. Altogether, there are \\(5 \\times 5 \\times 5 \\times 5 = 625\\) cross-classified rating classes of claim frequencies (625 count data). However, the number of rating classes (sample size) reduces to 547 after excluding count data with zero exposure. It can be seen from the description in Table 10 that the data does not provide information on the number of claim-free years (bonus-malus information). Using the Malaysian private car insurance data: Fit the count data using Poisson and negative binomial regression models. Compare both models and suggest a preferred model for the data. Calculate the premium assuming that the claim severity is MYR 1000 (Ringgit Malaysia) for all rating classes. Build a premium table, assuming that the NCD is to be implemented. \\[ \\begin{matrix} \\text{Table 10: Rating factors (Malaysian data)}\\\\ \\begin{array}{*{20}c} \\hline \\text{Rating factors} &amp; \\text{Description} \\\\ \\hline\\\\ \\text{Vehicle age} &amp; \\text{0-1 year } \\\\ &amp; \\text{2-3 years} \\\\ &amp; \\text{4-5 years} \\\\ &amp; \\text{6-7 years} \\\\ &amp; \\text{8+ years} \\\\ \\text{Vehicle c.c.} &amp; \\text{0-1000} \\\\ &amp; \\text{1001-1300} \\\\ &amp; \\text{1301-1500} \\\\ &amp; \\text{1501-1800} \\\\ &amp; \\text{1801+} \\\\ \\text{Vehicle make} &amp; \\text{Local type 1} \\\\ &amp; \\text{Local type 2} \\\\ &amp; \\text{Foreign type 1} \\\\ &amp; \\text{Foreign type 2} \\\\ &amp; \\text{Foreign type 3} \\\\ \\text{Location} &amp; \\text{North} \\\\ &amp; \\text{East} \\\\ &amp; \\text{Central} \\\\ &amp; \\text{South} \\\\ &amp; \\text{East Malaysia} \\\\\\\\ \\hline \\end{array} \\end{matrix} \\] Solution Table 11 shows the parameter estimates (and standard errors) for the fitted Poisson and negative binomial regression models. The results indicate that the regression parameters of all models have similar estimates. The likelihood ratio for testing overdispersion between the Poisson and the NB models is 2844.14, indicating that the data is overdispersed and the NB is a better model. The AIC and BIC also indicate that the NB is a better model. Table 12 shows the parameter estimates (and standard errors) for the fitted negative binomial regression model with significant covariates (covariates with \\(p\\)-values larger than 0.10 are excluded). The NB model in Table 12 is suggested as the preferred model for the data. The premiums are calculated by multiplying the fitted frequencies with the claim severities. The premiums for the first 25 rating classes (vehicle age: 0-1 year and vehicle make: local-type 1) are shown in Table 13. The Malaysian NCD system have six discount classes (0%, 25%, 30%, 38.3%, 45% and 55%) for 0, 1, 2, 3, 4 and 5+ claim-free years. The final premium rates should be ‘inflated’ accordingly to take into account the NCD (discount entitlement) of each insured. We can use the stationary distribution to approximate the proportion of insureds in each NCD class (in the long run). Assume that the probability of a no-claim year for all NCD classes is 0.90. The stationary probabilities are (from Example 3): \\[ {\\pi_0} = 0.1000,\\rm{ }{\\pi _1} = 0.0900,\\rm{ }{\\pi _2} = 0.0810,\\rm{ }{\\pi _3} = 0.0729,\\rm{ }{\\pi _4} = 0.0656,\\rm{ }{\\pi _5} = 0.5905 \\] which indicates that 10% of insureds eventually belong to class 0 (zero claim-free years), 9% of insureds eventually belong to class 1 (one claim-free year), and so forth, until 59% of insureds eventually belong to class 5 (or five successive claim-free years). After implementing the NCD, the premium (in the long run) will be reduced (on average) by the following factor: \\[ \\begin{array}{l} = \\sum\\limits_j \\text{(proportion of insureds in class }j)\\text{(1 - NCD in class }j) \\\\\\\\ = (0.1000)(1) + (0.0900)(1 - 0.25) + ... + (0.5905)(1 - 0.55)\\\\\\\\ = {0}{.570962} \\end{array} \\] Therefore, the final premiums (after adjusting for the NCD) should be inflated by \\(1 \\div 0.57 = 1.75\\). A premium table can be constructed based on the factor (1.75). The final premiums for the first 5 rating classes are shown in Table 14, and can be suggested for implementing the NCD. \\[ \\begin{matrix} \\text{Table 11: Poisson and negative binomial regression models (Malaysian data)}\\\\ \\begin{array}{*{20}c} \\hline \\text{Parameters} &amp; \\text{Poisson} &amp; \\text{Poisson} &amp; \\text{NB} &amp; \\text{NB} \\\\ &amp; \\text{Est.} &amp; {p}\\text{ -value} &amp; \\text{Est.} &amp; {p}\\text{ -value} \\\\ \\hline\\\\ \\text{Intercept} &amp; {-3.04} &amp; {0.00} &amp; -3.17 &amp; 0.00 \\\\ \\text{2-3 year} &amp; {0.51} &amp; {0.00} &amp; 0.57 &amp; 0.00 \\\\ \\text{4-5 year} &amp; {0.52} &amp; {0.00} &amp; 0.52 &amp; 0.00 \\\\ \\text{6-7 year} &amp; {0.43} &amp; {0.00} &amp; 0.40 &amp; 0.00 \\\\ \\text{8+ year} &amp; {0.24} &amp; {0.00} &amp; 0.28 &amp; 0.00 \\\\ \\text{1001-1300 cc} &amp; {-0.31} &amp; {0.00} &amp; -0.14 &amp; 0.00 \\\\ \\text{1301-1500 cc} &amp; {-0.16} &amp; {0.00} &amp; 0.08 &amp; 0.16 \\\\ \\text{1501-1800 cc} &amp; {0.14} &amp; {0.00} &amp; 0.25 &amp; 0.00 \\\\ \\text{1801+ cc} &amp; {0.12} &amp; {0.00} &amp; 0.34 &amp; 0.00 \\\\ \\text{Local type 2} &amp; {-0.46} &amp; {0.00} &amp; -0.30 &amp; 0.00 \\\\ \\text{Foreign type 1} &amp; {-0.21} &amp; {0.00} &amp; -0.31 &amp; 0.00 \\\\ \\text{Foreign type 2} &amp; {0.18} &amp; {0.00} &amp; 0.31 &amp; 0.00 \\\\ \\text{Foreign type 3} &amp; {-0.02} &amp; {0.43} &amp; -0.16 &amp; 0.04 \\\\ \\text{East} &amp; {0.35} &amp; {0.00} &amp; 0.30 &amp; 0.00 \\\\ \\text{Central} &amp; {0.32} &amp; {0.00} &amp; 0.31 &amp; 0.00 \\\\ \\text{South} &amp; {0.26} &amp; {0.00} &amp; 0.36 &amp; 0.00 \\\\ \\text{East Malaysia} &amp; {0.13} &amp; {0.00} &amp; 0.11 &amp; 0.08 \\\\ {a} &amp; {-} &amp; {-} &amp; 0.13 &amp; 0.00 \\\\ &amp; &amp; &amp; &amp; \\\\ \\text{Log likelihood} &amp; &amp; {-3,613.39} &amp; &amp; -2191.32 \\\\ \\text{AIC} &amp; &amp; {7,260.79} &amp; &amp; 4418.65 \\\\ \\text{BIC} &amp; &amp; {7,333.96} &amp; &amp; 4496.13 \\\\\\\\ \\hline \\end{array} \\end{matrix} \\] \\[ \\begin{matrix} \\text{Table 12: Negative binomial regression model with significant covariates (Malaysian data)}\\\\ \\begin{array}{*{20}c} \\hline \\text{Parameters} &amp; \\text{Est.} &amp; p\\text{ -value}\\\\ \\hline \\\\ \\text{Intercept} &amp; {-3.14} &amp; {0.00}\\\\ \\text{2-3 year} &amp; {0.58} &amp; {0.00}\\\\ \\text{4-5 year} &amp; {0.53} &amp; {0.00}\\\\ \\text{6-7 year} &amp; {0.41} &amp; {0.00}\\\\ \\text{8+ year} &amp; {0.29} &amp; {0.00}\\\\ \\text{1001-1300 cc} &amp; {-0.17} &amp; {0.00}\\\\ \\text{1501-1800 cc} &amp; {0.23} &amp; {0.00}\\\\ \\text{1801+ cc} &amp; {0.32} &amp; {0.00}\\\\ \\text{Local type 2} &amp; {-0.32} &amp; {0.00}\\\\ \\text{Foreign type 1} &amp; {-0.31} &amp; {0.00}\\\\ \\text{Foreign type 2} &amp; {0.31} &amp; {0.00}\\\\ \\text{Foreign type 3} &amp; {-0.18} &amp; {0.02}\\\\ \\text{East} &amp; {0.30} &amp; {0.00}\\\\ \\text{Central} &amp; {0.31} &amp; {0.00}\\\\ \\text{South} &amp; {0.36} &amp; {0.00}\\\\ \\text{East Malaysia} &amp; {0.11} &amp; {0.08}\\\\ \\alpha\\,\\text{(dispersion)} &amp; {0.13} &amp; {0.00}\\\\\\\\ \\text{Log likelihood} &amp; &amp; {-2192.34}\\\\ \\text{AIC} &amp; &amp; {4418.68}\\\\ \\text{BIC} &amp; &amp; {4491.85}\\\\\\\\ \\hline \\end{array} \\end{matrix} \\] \\[ \\begin{matrix} \\text{Table 13: Premium rates (Malaysian data)}\\\\ \\begin{array}{*{20}c} \\hline \\text{Vehicle} &amp; \\text{Vehicle} &amp; \\text{Vehicle} &amp; \\text{location} &amp; \\text{exposure} &amp; \\text{Fitted} &amp; \\text{Premium}\\\\ \\text{year} &amp; \\text{cc} &amp; \\text{make} &amp; &amp; &amp; \\text{count} &amp; \\left(\\frac{fitted\\,count}{exposure} \\times 1000 \\right)\\\\ \\hline\\\\ 0-1\\,\\text{year} &amp; {0-1000} &amp; \\text{local-1} &amp; \\text{north} &amp; {34} &amp; {1} &amp; {29}\\\\ &amp; &amp; &amp; \\text{east} &amp; {11} &amp; {1} &amp; {91}\\\\ &amp; &amp; &amp; \\text{central} &amp; {184} &amp; {11} &amp; {60}\\\\ &amp; &amp; &amp; \\text{south} &amp; {14} &amp; {1} &amp; {71}\\\\ &amp; &amp; &amp; \\text{east Msia} &amp; {22} &amp; {1} &amp; {45}\\\\ &amp; &amp; \\text{local-2} &amp; \\text{north} &amp; {17881} &amp; {562} &amp; {31}\\\\ &amp; &amp; &amp; \\text{east} &amp; {7581} &amp; {322} &amp; {42}\\\\ &amp; &amp; &amp; \\text{central} &amp; {19699} &amp; {844} &amp; {43}\\\\ &amp; &amp; &amp; \\text{south} &amp; {8268} &amp; {371} &amp; {45}\\\\ &amp; &amp; &amp; \\text{east Msia} &amp; {12229} &amp; {429} &amp; {35}\\\\ &amp; &amp; \\text{foreign-1} &amp; \\text{north} &amp; {241} &amp; {8} &amp; {33}\\\\ &amp; &amp; &amp; \\text{east} &amp; {44} &amp; {2} &amp; {45}\\\\ &amp; &amp; &amp; \\text{central} &amp; {254} &amp; {11} &amp; {43}\\\\ &amp; &amp; &amp; \\text{south} &amp; {35} &amp; {2} &amp; {57}\\\\ &amp; &amp; &amp; \\text{east Msia} &amp; {113} &amp; {4} &amp; {35}\\\\ &amp; &amp; \\text{foreign-2} &amp; \\text{north} &amp; {64} &amp; {4} &amp; {63}\\\\ &amp; &amp; &amp; \\text{east} &amp; {7} &amp; {1} &amp; {143}\\\\ &amp; &amp; &amp; \\text{central} &amp; {164} &amp; {13} &amp; {79}\\\\ &amp; &amp; &amp; \\text{south} &amp; {23} &amp; {2} &amp; {87}\\\\ &amp; &amp; &amp; \\text{east Msia} &amp; {45} &amp; {1} &amp; {67}\\\\ &amp; &amp; \\text{foreign-3} &amp; \\text{north} &amp; {7512} &amp; {274} &amp; {36}\\\\ &amp; &amp; &amp; \\text{east} &amp; {2747} &amp; {135} &amp; {49}\\\\ &amp; &amp; &amp; \\text{central} &amp; {15551} &amp; {774} &amp; {50}\\\\ &amp; &amp; &amp; \\text{south} &amp; {7408} &amp; {387} &amp; {52}\\\\ &amp; &amp; &amp; \\text{east Msia} &amp; {6740} &amp; {274} &amp; {41}\\\\\\\\ \\hline \\end{array} \\end{matrix} \\] \\[ \\begin{matrix} \\text{Table 14: Premium, final premium and NCD (Malaysian data)}\\\\ \\begin{array}{*{20}c} \\hline \\text{Vehicle} &amp; \\text{Vehicle} &amp; \\text{Vehicle} &amp; \\text{location} &amp; \\text{Premium} &amp; \\text{Final} &amp; \\text{Years of} &amp; \\text{NCD}\\\\ \\text{year} &amp; \\text{cc} &amp; \\text{make} &amp; &amp; &amp; \\text{Premium} &amp; \\text{claim-free} &amp; \\left( \\% \\right)\\\\ &amp; &amp; &amp; &amp; &amp; \\left( \\text{premium} \\times \\text{1.75}\\right) &amp; &amp; \\\\ \\hline\\\\ 0-1\\,\\text{year} &amp; {0-1000} &amp; \\text{local-1} &amp; \\text{north} &amp; {29} &amp; {51} &amp; {5+} &amp; {55}\\\\ &amp; &amp; &amp; &amp; &amp; &amp; {4} &amp; {45}\\\\ &amp; &amp; &amp; &amp; &amp; &amp; {3} &amp; {38.33}\\\\ &amp; &amp; &amp; &amp; &amp; &amp; {2} &amp; {30}\\\\ &amp; &amp; &amp; &amp; &amp; &amp; {1} &amp; {25}\\\\ &amp; &amp; &amp; &amp; &amp; &amp; {0} &amp; {0}\\\\ &amp; &amp; &amp; \\text{east} &amp; {91} &amp; {159} &amp; {0} &amp; {55}\\\\ &amp; &amp; &amp; &amp; &amp; &amp; {1} &amp; {45}\\\\ &amp; &amp; &amp; &amp; &amp; &amp; {2} &amp; {38.33}\\\\ &amp; &amp; &amp; &amp; &amp; &amp; {3} &amp; {30}\\\\ &amp; &amp; &amp; &amp; &amp; &amp; {4} &amp; {25}\\\\ &amp; &amp; &amp; &amp; &amp; &amp; {5+} &amp; {0}\\\\ &amp; &amp; &amp; \\text{central} &amp; {60} &amp; {105} &amp; {0} &amp; {55}\\\\ &amp; &amp; &amp; &amp; &amp; &amp; {1} &amp; {45}\\\\ &amp; &amp; &amp; &amp; &amp; &amp; {2} &amp; {38.33}\\\\ &amp; &amp; &amp; &amp; &amp; &amp; {3} &amp; {30}\\\\ &amp; &amp; &amp; &amp; &amp; &amp; {4} &amp; {25}\\\\ &amp; &amp; &amp; &amp; &amp; &amp; {5+} &amp; {0}\\\\ &amp; &amp; &amp; \\text{south} &amp; {71} &amp; {125} &amp; {0} &amp; {55}\\\\ &amp; &amp; &amp; &amp; &amp; &amp; {1} &amp; {45}\\\\ &amp; &amp; &amp; &amp; &amp; &amp; {2} &amp; {38.33}\\\\ &amp; &amp; &amp; &amp; &amp; &amp; {3} &amp; {30}\\\\ &amp; &amp; &amp; &amp; &amp; &amp; {4} &amp; {25}\\\\ &amp; &amp; &amp; &amp; &amp; &amp; {5+} &amp; {0}\\\\ &amp; &amp; &amp; \\text{east Msia} &amp; {45} &amp; {80} &amp; {0} &amp; {55}\\\\ &amp; &amp; &amp; &amp; &amp; &amp; {1} &amp; {45}\\\\ &amp; &amp; &amp; &amp; &amp; &amp; {2} &amp; {38.33}\\\\ &amp; &amp; &amp; &amp; &amp; &amp; {3} &amp; {30}\\\\ &amp; &amp; &amp; &amp; &amp; &amp; {4} &amp; {25}\\\\ &amp; &amp; &amp; &amp; &amp; &amp; {5+} &amp; {0}\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; &amp; \\vdots &amp; \\vdots &amp; \\vdots\\\\\\\\ \\hline \\end{array} \\end{matrix} \\] FURTHER READING AND REFERENCES: Aitkin, M., Anderson, D., Francis, B., Hinde, J. 1990. Statistical Modelling in GLIM. New York: Oxford University Press. Ajne, B. 1975. A note on the multiplicative ratemaking model. ASTIN Bulletin 8(2): 144-153. Anderson, D., Feldblum, S., Modlin, C., Schirmacher, D., Schirmacher, E., Thandi, N. 2004. A practitioner's guide to Generalized Linear Models. Casualty Actuarial Society Discussion Paper Program 1-115. Bailey, R.A. 1963. Insurance rates with minimum bias. Proceedings of the Casualty Actuarial Society 50(93): 4-14. Bailey, R.A., Simon, L.J. 1960. Two studies in automobile insurance ratemaking. ASTIN Bulletin 49(1): 192-217. Bichsel, F. 1964. Erfahrungs-Tarifierung in der Motorfahrzeug-halfplichtversicherung. Milleilungen der Vereinigung Schweizerischer Versicherungsmathematiker 119-129. Boucher, J.P., Denuit, M., Guillen, M. 2007. Risk classification for claim count: a comparative analysis of various zero-inflated mixed Poisson and hurdle models. North American Actuarial Journal 11(4): 110-131. Brockmann, M.J., Wright, T.S. 1992. Statistical motor rating: making effective use of your data. Journal of the Institute of Actuaries 119(3): 457-543. Brown, R.L. 1988. Minimum bias with generalized linear models. Proceedings of the Casualty Actuarial Society 75(143): 187-217. Bühlmann, H. 1964. Optimale Prämienstufen systeme. Milleilungen der Vereinigung Schweizerischer Versicherungsmathematiker 193-213. Cameron, A.C., Trivedi, P.K. 1986. Econometric models based on count data: comparisons and applications of some estimators and tests. Journal of Applied Econometrics 1: 29-53. Cameron, A.C., Trivedi, P.K. 1998. Regression Analysis of Count Data. New York: Cambridge University Press. Chamberlain, C. 1980. Relativity pricing through analysis of variance. Casualty Actuarial Society Discussion Paper Program 4-24. Corlier, F., Lemaire, J., &amp; Muhokolo, D. (1979). Simulation of an automobile portfolio. The Geneva Papers on Risk and Insurance Theory 4:40-46. Coutts, S.M. 1984. Motor insurance rating, an actuarial approach. Journal of the Institute of Actuaries 111: 87-148. Delaporte, P. 1965. Tarification du risque individuel d’accidents par la prime modelil ée sur le risqué. ASTIN Bulletin 3: 251-271. Denuit, M., Marechal, X., Pitrebois, S., Walhin, J.F. 2007. Actuarial Modeling of Claim Counts: Risk Classification, Credibility and Bonus-Malus Systems. John Wiley and Sons: England. Dionne, G., &amp; Vanasse, C. (1989). A generalization of automobile insurance rating models: the negative binomial distribution with a regression component. ASTIN Bullettin 19(2): 199-212. Frangos, N. E., Vrontos, S. D. 2001. Design of optimal bonus-malus systems with a frequency and severity component on an individual basis in automobile insurance. ASTIN Bulletin 31(1): 1-22. Harrington, S.E. 1986. Estimation and testing for functional form in pure premium regression models. ASTIN Bulletin 16: 31-43. Hastings, N.A.J. 1976. Optimal claiming on vehicle insurance. Operational Research Quarterly 27: 805-813. Hilbe, J. 2007. Negative Binomial Regression. Cambridge, UK: Cambridge University Press. Ismail, N., Jemain, A.A. 2005. Bridging minimum bias and maximum likelihood methods through weighted equation. Casualty Actuarial Society Forum Spring: 367-394. Ismail, N., Jemain, A.A. 2007. Handling overdispersion with negative binomial and generalized Poisson regression models. Casualty Actuarial Society Forum Winter: 103-158. Ismail, N., Zamani, H. 2013. Estimation of claim count data using negative binomial, generalized Poisson, zero-inflated negative binomial and zero-inflated generalized Poisson regression models. Casualty Actuarial Society E-Forum Spring: 1-29. Jung, J. 1968. On automobile insurance ratemaking. ASTIN Bulletin 5(1): 41-48. Kolderman, J., Volgenant, A. 1985. Optimal claiming in an automobile insurance system with bonus-malus structure. Journal of the Operational Research Society 36: 239-247. Lawless, J.F. 1987. Negative binomial and mixed Poisson regression. Canadian Journal of Statistics 15(3): 209-225. Lemaire, J. 1976. Driver versus company, optimal behaviour of the policy holder. Scandinavian Actuarial Journal 59: 209-219. Lemaire, J. 1977. La soif du bonus. ASTIN Bulletin 9: 181-190. Lemaire, J. 1979. How to define a Bonus-Malus system with an exponential utility function. ASTIN Bulletin 10: 274-282. Lemaire, J., Zi, H.M. 1994. A comparative analysis of 30 Bonus-Malus systems. ASTIN Bulletin 24: 287-309. Lemaire, J. 1998. Bonus-Malus systems: The European and Asian approach to merit-rating. North American Actuarial Journal 2(1): 26-38. Loimaranta, K. 1972. Some asymptotic properties of bonus systems. ASTIN Bulletin 6: 233-245. McCullagh, P., Nelder, J.A. 1989. Generalized Linear Models (2nd Edition). Chapman and Hall: London. Morillo, I., Bermúdez, L. 2003. Bonus–malus system using an exponential loss function with an inverse Gaussian distribution. Insurance: Mathematics and Economics 33: 49-57. Pitrebois, S., Denuit, M., Walhin, J.F. 2003. Fitting the Belgian Bonus-Malus system. Belgian Actuarial Bulletin 3(1): 58-62. Renshaw, A.E., 1994. Modelling the claims process in the presence of covariates. ASTIN Bulletin 24(2): 265-285. Tremblay, L. 1992. Using the Poisson inverse Gaussian in Bonus-Malus systems. ASTIN Bulletin 22(1): 97-106. Vepsäläinen, S. 1972. Applications to a theory of bonus systems. ASTIN Bulletin 6: 212-221. Walhin, J. F., Paris, J. 1999. Using mixed Poisson processes in connection with Bonus-Malus systems. ASTIN Bulletin 29(1): 81-99. Winkelmann, R. 2008. Econometric Analysis of Count Data. Heidelberg: Springer Verlag. Zamani, H., Ismail, N. 2012. Functional form for the generalized Poisson regression model. Communications in Statistics (Theory and Methods) 41(20): 3666–3675. "],
["C-DataSystems.html", "Chapter 13 Data and Systems 13.1 Data 13.2 Data Analysis Preliminaries 13.3 Data Analysis Techniques 13.4 Some R Functions 13.5 Summary 13.6 Further Resources and Contributors", " Chapter 13 Data and Systems Chapter Preview. This chapter covers the learning areas on data and systems outlined in the IAA (International Actuarial Association) Education Syllabus published in September 2015. This chapter is organized into three major parts: data, data analysis, and data analysis techniques. The first part introduces data basics such as data types, data structures, data storages, and data sources. The second part discusses the process and various aspects of data analysis. The third part presents some commonly used techniques for data analysis. 13.1 Data 13.1.1 Data Types and Sources In terms of how data are collected, data can be divided into two types (Hox and Boeije 2005): primary data and secondary data. Primary data are original data that are collected for a specific research problem. Secondary data are data originally collected for a different purpose and reused for another research problem. A major advantage of using primary data is that the theoretical constructs, the research design, and the data collection strategy can be tailored to the underlying research question to ensure that the data collected indeed help to solve the problem. A disadvantage of using primary data is that data collection can be costly and time-consuming. Using secondary data has the advantage of lower cost and faster access to relevant information. However, using secondary data may not be optimal for the research question under consideration. In terms of the degree of organization of the data, data can be also divided into two types (Inmon and Linstedt 2014; O’Leary 2013; Hashem et al. 2015; Abdullah and Ahmad 2013; Pries and Dunnigan 2015): structured data and unstructured data. Structured data have a predictable and regularly occurring format. In contrast, unstructured data are unpredictable and have no structure that is recognizable to a computer. Structured data consist of records, attributes, keys, and indices and are typically managed by a database management system (DBMS) such as IBM DB2, Oracle, MySQL, and Microsoft SQL Server. As a result, most units of structured data can be located quickly and easily. Unstructured data have many different forms and variations. One common form of unstructured data is text. Accessing unstructured data is clumsy. To find a given unit of data in a long text, for example, sequentially search is usually performed. In terms of how the data are measured, data can be classified as qualitative or quantitative. Qualitative data are data about qualities, which cannot be actually measured. As a result, qualitative data are extremely varied in nature and include interviews, documents, and artifacts (Miles, Hberman, and Sdana 2014). Quantitative data are data about quantities, which can be measured numerically with numbers. In terms of the level of measurement, quantitative data can be further classified as nominal, ordinal, interval, or ratio (Gan 2011). Nominal data, also called categorical data, are discrete data without a natural ordering. Ordinal data are discrete data with a natural order. Interval data are continuous data with a specific order and equal intervals. Ratio data are interval data with a natural zero. There exist a number of data sources. First, data can be obtained from university-based researchers who collect primary data. Second, data can be obtained from organizations that are set up for the purpose of releasing secondary data for general research community. Third, data can be obtained from national and regional statistical institutes that collect data. Finally, companies have corporate data that can be obtained for research purpose. While it might be difficult to obtain data to address a specific research problem or answer a business question, it is relatively easy to obtain data to test a model or an algorithm for data analysis. In the modern era, readers can obtain datasets from the Internet easily. The following is a list of some websites to obtain real-world data: UCI Machine Learning Repository This website (url: http://archive.ics.uci.edu/ml/index.php) maintains more than 400 datasets that can be used to test machine learning algorithms. Kaggle The Kaggle website (url: https://www.kaggle.com/) include real-world datasets used for data science competition. Readers can download data from Kaggle by registering an account. DrivenData DrivenData aims at bringing cutting-edge practices in data science to solve some of the world’s biggest social challenges. In its website (url: https://www.drivendata.org/), readers can participate data science competitions and download datasets. Analytics Vidhya This website (url: https://datahack.analyticsvidhya.com/contest/all/) allows you to participate and download datasets from practice problems and hackathon problems. KDD Cup KDD Cup is the annual Data Mining and Knowledge Discovery competition organized by ACM Special Interest Group on Knowledge Discovery and Data Mining. This website (url: http://www.kdd.org/kdd-cup) contains the datasets used in past KDD Cup competitions since 1997. U.S. Government’s open data This website (url: https://www.data.gov/) contains about 200,000 datasets covering a wide range of areas including climate, education, energy, and finance. AWS Public Datasets In this website (url: https://aws.amazon.com/datasets/), Amazon provides a centralized repository of public datasets, including some huge datasets. 13.1.2 Data Structures and Storage As mentioned in the previous subsection, there are structured data as well as unstructured data. Structured data are highly organized data and usually have the following tabular format: \\[ \\begin{matrix} \\begin{array}{lllll} \\hline &amp; V_1 &amp; V_2 &amp; \\cdots &amp; V_d \\ \\\\\\hline \\textbf{x}_1 &amp; x_{11} &amp; x_{12} &amp; \\cdots &amp; x_{1d} \\\\ \\textbf{x}_2 &amp; x_{21} &amp; x_{22} &amp; \\cdots &amp; x_{2d} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\cdots &amp; \\vdots \\\\ \\textbf{x}_n &amp; x_{n1} &amp; x_{n2} &amp; \\cdots &amp; x_{nd} \\\\ \\hline \\end{array} \\end{matrix} \\] In other words, structured data can be organized into a table consists of rows and columns. Typically, each row represents a record and each column represents an attribute. A table can be decomposed into several tables that can be stored in a relational database such as the Microsoft SQL Server. The SQL (Structured Query Language) can be used to access and modify the data easily and efficiently. Unstructured data do not follow a regular format (Abdullah and Ahmad 2013). Examples of unstructured data include documents, videos, and audio files. Most of the data we encounter are unstructured data. In fact, the term ``big data’’ was coined to reflect this fact. Traditional relational databases cannot meet the challenges on the varieties and scales brought by massive unstructured data nowadays. NoSQL databases have been used to store massive unstructured data. There are three main NoSQL databases (Chen et al. 2014): key-value databases, column-oriented databases, and document-oriented databases. Key-value databases use a simple data model and store data according to key-values. Modern key-value databases have higher expandability and smaller query response time than relational databases. Examples of key-value databases include Dynamo used by Amazon and Voldemort used by LinkedIn. Column-oriented databases store and process data according to columns rather than rows. The columns and rows are segmented in multiple nodes to achieve expandability. Examples of column-oriented databases include BigTable developed by Google and Cassandra developed by FaceBook. Document databases are designed to support more complex data forms than those stored in key-value databases. Examples of document databases include MongoDB, SimpleDB, and CouchDB. MongoDB is an open-source document-oriented database that stores documents as binary objects. SimpleDB is a distributed NoSQL database used by Amazon. CouchDB is another open-source document-oriented database. 13.1.3 Data Quality Accurate data are essential to useful data analysis. The lack of accurate data may lead to significant costs to organizations in areas such as correction activities, lost customers, missed opportunities, and incorrect decisions (Olson 2003). Data has quality if it satisfies its intended use, that is, the data is accurate, timely, relevant, complete, understood, and trusted (Olson 2003). As a result, we first need to know the specification of the intended uses and then judge the suitability for those uses in order to assess the quality of the data. Unintended uses of data can arise from a variety of reasons and lead to serious problems. Accuracy is the single most important component of high-quality data. Accurate data have the following properties (Olson 2003): The data elements are not missing and have valid values. The values of the data elements are in the right ranges and have the right representations. Inaccurate data arise from different sources. In particular, the following areas are common areas where inaccurate data occur: Initial data entry. Mistakes (including deliberate errors) and system errors can occur during the initial data entry. Flawed data entry processes can result in inaccurate data. Data decay. Data decay, also known as data degradation, refers to the gradual corruption of computer data due to an accumulation of non-critical failures in a storage device. Data moving and restructuring. Inaccurate data can also arise from data extracting, cleaning, transforming, loading, or integrating. Data using. Faulty reporting and lack of understanding can lead to inaccurate data. Reverification and analysis are two approaches to find inaccurate data elements. The first approach is done by people, who manually check every data element by going back to the original source of the data. The second approach is done by software with the skills of an analyst to search through data to find possible inaccurate data elements. To ensure that the data elements are 100% accurate, we must use reverification. However, reverification can be time-consuming and may not be possible for some data. Analytical techniques can also be used to identify inaccurate data elements. There are five types of analysis that can be used to identify inaccurate data (Olson 2003): data element analysis, structural analysis, value correlation, aggregation correlation, and value inspection Companies can create a data quality assurance program to create high-quality databases. For more information about management of data quality issues and data profiling techniques, readers are referred to Olson (2003). 13.1.4 Data Cleaning Raw data usually need to be cleaned before useful analysis can be conducted. In particular, the following areas need attention when preparing data for analysis (Janert 2010): Missing values It is common to have missing values in raw data. Depending on the situations, we can discard the record, discard the variable, or impute the missing values. Outliers Raw data may contain unusual data points such as outliers. We need to handle outliers carefully. We cannot just remove outliers without knowing the reason for their existence. Sometimes the outliers are caused by clerical errors. Sometimes outliers are the effect we are looking for. Junk Raw data may contain junks such as nonprintable characters. Junks are typically rare and not easy to get noticed. However, junks can cause serious problems in downstream applications. Format Raw data may be formatted in a way that is inconvenient for subsequent analysis. For example, components of a record may be split into multiple lines in a text file. In such cases, lines corresponding to a single record should be merged before loading to a data analysis software such as R. Duplicate records Raw data may contain duplicate records. Duplicate records should be recognized and removed. This task may not be trivial depending on what you consider ``duplicate.’’ Merging datasets Raw data may come from different sources. In such cases, we need to merge the data from different sources to ensure compatibility. For more information about how to handle data in R, readers are referred to Forte (2015) and Buttrey and Whitaker (2017). Show Quiz Solution 13.2 Data Analysis Preliminaries Data analysis involves inspecting, cleansing, transforming, and modeling data to discover useful information to suggest conclusions and make decisions. Data analysis has a long history. In 1962, statistician John Tukey defined data analysis as: procedures for analyzing data, techniques for interpreting the results of such procedures, ways of planning the gathering of data to make its analysis easier, more precise or more accurate, and all the machinery and results of (mathematical) statistics which apply to analyzing data. — (Tukey 1962) Recently, Judd and coauthors defined data analysis as the following equation(Judd, McClelland, and Ryan 2017): \\[ \\hbox{Data} = \\hbox{Model} + \\hbox{Error}, \\] where Data represents a set of basic scores or observations to be analyzed, Model is a compact representation of the data, and Error is simply the amount the model fails to represent accurately. Using the above equation for data analysis, an analyst must resolve the following two conflicting goals: to add more parameters to the model so that the model represents the data better. to remove parameters from the model so that the model is simple and parsimonious. In this section, we give a high-level introduction to data analysis, including different types of methods. 13.2.1 Data Analysis Process Data analysis is part of an overall study. For example, Figure 13.1 shows the process of a typical study in behavioral and social sciences as described in Albers (2017). The data analysis part consists of the following steps: Exploratory analysis The purpose of this step is to get a feel of the relationships with the data and figure out what type of analysis for the data makes sense. Statistical analysis This step performs statistical analysis such as determining statistical significance and effect size. Make sense of the results This step interprets the statistical results in the context of the overall study. Determine implications This step interprets the data by connecting it to the study goals and the larger field of this study. The goal of the data analysis as described above focuses on explaining some phenomenon (See Section 13.2.5). Figure 13.1: The process of a typical study in behavioral and social sciences. Shmueli (2010) described a general process for statistical modeling, which is shown in Figure 13.2. Depending on the goal of the analysis, the steps differ in terms of the choice of methods, criteria, data, and information. Figure 13.2: The process of statistical modeling. 13.2.2 Exploratory versus Confirmatory There are two phases of data analysis (Good 1983): exploratory data analysis (EDA) and confirmatory data analysis (CDA). Table 13.1 summarizes some differences between EDA and CDA. EDA is usually applied to observational data with the goal of looking for patterns and formulating hypotheses. In contrast, CDA is often applied to experimental data (i.e., data obtained by means of a formal design of experiments) with the goal of quantifying the extent to which discrepancies between the model and the data could be expected to occur by chance (Gelman 2004). \\[ \\begin{matrix} \\begin{array}{lll} \\hline &amp; \\textbf{EDA} &amp; \\textbf{CDA} \\\\\\hline \\text{Data} &amp; \\text{Observational data} &amp; \\text{Experimental data}\\\\[3mm] \\text{Goal} &amp; \\text{Pattern recognition,} &amp; \\text{Hypothesis testing,} \\\\ &amp; \\text{formulate hypotheses} &amp; \\text{estimation, prediction} \\\\[3mm] \\text{Techniques} &amp; \\text{Descriptive statistics,} &amp; \\text{Traditional statistical tools of} \\\\ &amp; \\text{visualization, clustering} &amp; \\text{inference, significance, and}\\\\ &amp; &amp; \\text{confidence} \\\\ \\hline \\end{array} \\end{matrix} \\] Table 13.1: Comparison of exploratory data analysis and confirmatory data analysis. Techniques for EDA include descriptive statistics (e.g., mean, median, standard deviation, quantiles), distributions, histograms, correlation analysis, dimension reduction, and cluster analysis. Techniques for CDA include the traditional statistical tools of inference, significance, and confidence. 13.2.3 Supervised versus Unsupervised Methods for data analysis can be divided into two types (Abbott 2014; Igual and Segu 2017): supervised learning methods and unsupervised learning methods. Supervised learning methods work with labeled data, which include a target variable. Mathematically, supervised learning methods try to approximate the following function: \\[ Y = f(X_1, X_2, \\ldots, X_p), \\] where \\(Y\\) is a target variable and \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_p\\) are explanatory variables. Other terms are also used to mean a target variable. Table 13.2 gives a list of common names for different types of variables (Edward W. Frees 2009b). When the target variable is a categorical variable, supervised learning methods are called classification methods. When the target variable is continuous, supervised learning methods are called regression methods. \\[ \\begin{matrix} \\begin{array}{ll} \\hline \\textbf{Target Variable} &amp; \\textbf{Explanatory Variable}\\\\\\hline \\text{Dependent variable} &amp; \\text{Independent variable}\\\\ \\text{Response} &amp; \\text{Treatment} \\\\ \\text{Output} &amp; \\text{Input} \\\\ \\text{Endogenous variable} &amp; \\text{Exogenous variable} \\\\ \\text{Predicted variable} &amp; \\text{Predictor variable} \\\\ \\text{Regressand} &amp; \\text{Regressor} \\\\ \\hline \\end{array} \\end{matrix} \\] Table 13.2: Common names of different variables. Unsupervised learning methods work with unlabeled data, which include explanatory variables only. In other words, unsupervised learning methods do not use target variables. As a result, unsupervised learning methods are also called descriptive modeling methods. 13.2.4 Parametric versus Nonparametric Methods for data analysis can be parametric or nonparametric (Abbott 2014). Parametric methods assume that the data follow a certain distribution. Nonparametric methods do not assume distributions for the data and therefore are called distribution-free methods. Parametric methods have the advantage that if the distribution of the data is known, properties of the data and properties of the method (e.g., errors, convergence, coefficients) can be derived. A disadvantage of parametric methods is that analysts need to spend considerable time on figuring out the distribution. For example, analysts may try different transformation methods to transform the data so that it follows a certain distribution. Since nonparametric methods make fewer assumptions, nonparametric methods have the advantage that they are more flexible, more robust, and applicable to non-quantitative data. However, a drawback of nonparametric methods is that the conclusions drawn from nonparametric methods are not as powerful as those drawn from parametric methods. 13.2.5 Explanation versus Prediction There are two goals in data analysis (Breiman 2001; Shmueli 2010): explanation and prediction. In some scientific areas such as economics, psychology, and environmental science, the focus of data analysis is to explain the causal relationships between the input variables and the response variable. In other scientific areas such as natural language processing and bioinformatics, the focus of data analysis is to predict what the responses are going to be given the input variables. Shmueli (2010) discussed in detail the distinction between explanatory modeling and predictive modeling, which reflect the process of using data and methods for explaining or predicting, respectively. Explanatory modeling is commonly used for theory building and testing. However, predictive modeling is rarely used in many scientific fields as a tool for developing theory. Explanatory modeling is typically done as follows: State the prevailing theory. State causal hypotheses, which are given in terms of theoretical constructs rather than measurable variables. A causal diagram is usually included to illustrate the hypothesized causal relationship between the theoretical constructs. Operationalize constructs. In this step, previous literature and theoretical justification are used to build a bridge between theoretical constructs and observable measurements. Collect data and build models alongside the statistical hypotheses, which are operationalized from the research hypotheses. Reach research conclusions and recommend policy. The statistical conclusions are converted into research conclusions. Policy recommendations are often accompanied. Shmueli (2010) defined predictive modeling as the process of applying a statistical model or data mining algorithm to data for the purpose of predicting new or future observations. Predictions include point predictions, interval predictions, regions, distributions, and rankings of new observations. Predictive model can be any method that produces predictions. 13.2.6 Data Modeling versus Algorithmic Modeling Breiman (2001) discussed two cultures in the use of statistical modeling to reach conclusions from data: the data modeling culture and the algorithmic modeling culture. In the data modeling culture, the data are assumed to be generated by a given stochastic data model. In the algorithmic modeling culture, the data mechanism is treated as unknown and algorithmic models are used. Data modeling gives the statistics field many successes in analyzing data and getting information about the data mechanisms. However, Breiman (2001) argued that the focus on data models in the statistical community has led to some side effects such as Produced irrelevant theory and questionable scientific conclusions. Kept statisticians from using algorithmic models that might be more suitable. Restricted the ability of statisticians to deal with a wide range of problems. Algorithmic modeling was used by industrial statisticians long time ago. However, the development of algorithmic methods was taken up by a community outside statistics (Breiman 2001). The goal of algorithmic modeling is predictive accuracy. For some complex prediction problems, data models are not suitable. These prediction problems include speech recognition, image recognition, handwriting recognition, nonlinear time series prediction, and financial market prediction. The theory in algorithmic modeling focuses on the properties of algorithms, such as convergence and predictive accuracy. 13.2.7 Big Data Analysis Unlike traditional data analysis, big data analysis employs additional methods and tools that can extract information rapidly from massive data. In particular, big data analysis uses the following processing methods (Chen et al. 2014): Bloom filter A bloom filter is a space-efficient probabilistic data structure that is used to determine whether an element belongs to a set. It has the advantages of high space efficiency and high query speed. A drawback of using bloom filter is that there is a certain misrecognition rate. Hashing Hashing is a method that transforms data into fixed-length numerical values through a hash function. It has the advantages of rapid reading and writing. However, sound hash functions are difficult to find. Indexing Indexing refers to a process of partitioning data in order to speed up reading. Hashing is a special case of indexing. Tries A trie, also called digital tree, is a method to improve query efficiency by using common prefixes of character strings to reduce comparison on character strings to the greatest extent. Parallel computing Parallel computing uses multiple computing resources to complete a computation task. Parallel computing tools include MPI (Message Passing Interface), MapReduce, and Dryad. Big data analysis can be conducted in the following levels (Chen et al. 2014): memory-level, business intelligence (BI) level, and massive level. Memory-level analysis is conducted when the data can be loaded to the memory of a cluster of computers. Current hardware can handle hundreds of gigabytes (GB) of data in memory. BI level analysis can be conducted when the data surpass the memory level. It is common for BI level analysis products to support data over terabytes (TB). Massive level analysis is conducted when the data surpass the capabilities of products for BI level analysis. Usually Hadoop and MapReduce are used in massive level analysis. 13.2.8 Reproducible Analysis As mentioned in Section 13.2.1, a typical data analysis workflow includes collecting data, analyzing data, and reporting results. The data collected are saved in a database or files. The data are then analyzed by one or more scripts, which may save some intermediate results or always work on the raw data. Finally a report is produced to describe the results, which include relevant plots, tables, and summaries of the data. The workflow may subject to the following potential issues (Mailund 2017, Chapter 2): The data are separated from the analysis scripts. The documentation of the analysis is separated from the analysis itself. If the analysis is done on the raw data with a single script, then the first issue is not a major problem. If the analysis consists of multiple scripts and a script saves intermediate results that are read by the next script, then the scripts describe a workflow of data analysis. To reproduce an analysis, the scripts have to be executed in the right order. The workflow may cause major problems if the order of the scripts is not documented or the documentation is not updated or lost. One way to address the first issue is to write the scripts so that any part of the workflow can be run completely automatically at any time. If the documentation of the analysis is synchronized with the analysis, then the second issue is not a major problem. However, the documentation may become completely useless if the scripts are changed but the documentation is not updated. Literate programming is an approach to address the two issues mentioned above. In literate programming, the documentation of a program and the code of the program are written together. To do literate programming in R, one way is to use the R Markdown and the \\(\\texttt{knitr}\\) package. 13.2.9 Ethical Issues Analysts may face ethical issues and dilemmas during the data analysis process. In some fields, for example, ethical issues and dilemmas include participant consent, benefits, risk, confidentiality, and data ownership (Miles, Hberman, and Sdana 2014). For data analysis in actuarial science and insurance in particular, we face the following ethical matters and issues (Miles, Hberman, and Sdana 2014): Worthiness of the project Is the project worth doing? Will the project contribute in some significant way to a domain broader than my career? If a project is only opportunistic and does not have a larger significance, then it might be pursued with less care. The result may be looked good but not right. Competence Do I or the whole team have the expertise to carry out the project? Incompetence may lead to weakness in the analytics such as collecting large amounts of data poorly and drawing superficial conclusions. Benefits, costs, and reciprocity Will each stakeholder gain from the project? Are the benefit and the cost equitable? A project will likely to fail if the benefit and the cost for a stakeholder do not match. Privacy and confidentiality How do we make sure that the information is kept confidentially? Where raw data and analysis results are stored and how will have access to them should be documented in explicit confidentiality agreements. Show Quiz Solution 13.3 Data Analysis Techniques Techniques for data analysis are drawn from different but overlapping fields such as statistics, machine learning, pattern recognition, and data mining. Statistics is a field that addresses reliable ways of gathering data and making inferences based on them (Bandyopadhyay and Forster 2011; Bluman 2012). The term machine learning was coined by Samuel in 1959 (Samuel 1959). Originally, machine learning refers to the field of study where computers have the ability to learn without being explicitly programmed. Nowadays, machine learning has evolved to the broad field of study where computational methods use experience (i.e., the past information available for analysis) to improve performance or to make accurate predictions (Bishop 2007; Clarke, Fokoue, and Zhang 2009; Mohri, Rostamizadeh, and Talwalkar 2012; Kubat 2017). There are four types of machine learning algorithms (See Table 13.3 depending on the type of the data and the type of the learning tasks. \\[ \\begin{matrix} \\begin{array}{rll} \\hline &amp; \\textbf{Supervised} &amp; \\textbf{Unsupervised} \\\\\\hline \\textbf{Discrete Label} &amp; \\text{Classification} &amp; \\text{Clustering} \\\\ \\textbf{Continuous Label} &amp; \\text{Regression} &amp; \\text{Dimension reduction} \\\\ \\hline \\end{array} \\end{matrix} \\] Table 13.3: Types of machine learning algorithms. Originating in engineering, pattern recognition is a field that is closely related to machine learning, which grew out of computer science. In fact, pattern recognition and machine learning can be considered to be two facets of the same field (Bishop 2007). Data mining is a field that concerns collecting, cleaning, processing, analyzing, and gaining useful insights from data (Aggarwal 2015). 13.3.1 Exploratory Techniques Exploratory data analysis techniques include descriptive statistics as well as many unsupervised learning techniques such as data clustering and principal component analysis. 13.3.1.1 Descriptive Statistics In the mass noun sense, descriptive statistics is an area of statistics that concerns the collection, organization, summarization, and presentation of data (Bluman 2012). In the count noun sense, descriptive statistics are summary statistics that quantitatively describe or summarize data. \\[ \\begin{matrix} \\begin{array}{ll} \\hline &amp; \\textbf{Descriptive Statistics} \\\\\\hline \\text{Measures of central tendency} &amp; \\text{Mean, median, mode, midrange}\\\\ \\text{Measures of variation} &amp; \\text{Range, variance, standard deviation} \\\\ \\text{Measures of position} &amp; \\text{Quantile} \\\\ \\hline \\end{array} \\end{matrix} \\] Table 13.4: Some commonly used descriptive statistics. Table 13.4 lists some commonly used descriptive statistics. In R, we can use the function \\(\\texttt{summary}\\) to calculate some of the descriptive statistics. For numeric data, we can visualize the descriptive statistics using a boxplot. In addition to these quantitative descriptive statistics, we can also qualitatively describe shapes of the distributions (Bluman 2012). For example, we can say that a distribution is positively skewed, symmetric, or negatively skewed. To visualize the distribution of a variable, we can draw a histogram. 13.3.1.2 Principal Component Analysis Principal component analysis (PCA) is a statistical procedure that transforms a dataset described by possibly correlated variables into a dataset described by linearly uncorrelated variables, which are called principal components and are ordered according to their variances. PCA is a technique for dimension reduction. If the original variables are highly correlated, then the first few principal components can account for most of the variation of the original data. The principal components of the variables are related to the eigenvectors and eigenvectors of the covariance matrix of the variables. For \\(i=1,2,\\ldots,d\\), let \\((\\lambda_i, \\textbf{e}_i)\\) be the \\(i\\)th eigenvalue-eigenvector pair of the covariance matrix \\({\\Sigma}\\) of \\(d\\) variables \\(X_1,X_2,\\ldots,X_d\\) such that \\(\\lambda_1\\ge \\lambda_2\\ge \\ldots\\ge \\lambda_d\\ge 0\\) and the eigenvectors are normalized. Then the \\(i\\)th principal component is given by \\[ Z_{i} = \\textbf{e}_i&#39; \\textbf{X} =\\sum_{j=1}^d e_{ij} X_j, \\] where \\(\\textbf{X}=(X_1,X_2,\\ldots,X_d)&#39;\\). It can be shown that \\(\\mathrm{Var~}{(Z_i)} = \\lambda_i\\). As a result, the proportion of variance explained by the \\(i\\)th principal component is calculated as \\[ \\dfrac{\\mathrm{Var~}{(Z_i)}}{ \\sum_{j=1}^{d} \\mathrm{Var~}{(Z_j)}} = \\dfrac{\\lambda_i}{\\lambda_1+\\lambda_2+\\cdots+\\lambda_d}. \\] For more information about PCA, readers are referred to Mirkin (2011). 13.3.1.3 Cluster Analysis Cluster analysis (aka data clustering) refers to the process of dividing a dataset into homogeneous groups or clusters such that points in the same cluster are similar and points from different clusters are quite distinct (Gan, Ma, and Wu 2007; Gan 2011). Data clustering is one of the most popular tools for exploratory data analysis and has found applications in many scientific areas. During the past several decades, many clustering algorithms have been proposed. Among these clustering algorithms, the \\(k\\)-means algorithm is perhaps the most well-known algorithm due to its simplicity. To describe the k-means algorithm, let \\(X=\\{\\textbf{x}_1,\\textbf{x}_2,\\ldots,\\textbf{x}_n\\}\\) be a dataset containing \\(n\\) points, each of which is described by \\(d\\) numerical features. Given a desired number of clusters \\(k\\), the \\(k\\)-means algorithm aims at minimizing the following objective function: \\[ P(U,Z) = \\sum_{l=1}^k\\sum_{i=1}^n u_{il} \\Vert \\textbf{x}_i-\\textbf{z}_l\\Vert^2, \\] where \\(U=(u_{il})_{n\\times k}\\) is an \\(n\\times k\\) partition matrix, \\(Z=\\{\\textbf{z}_1,\\textbf{z}_2,\\ldots,\\textbf{z}_k\\}\\) is a set of cluster centers, and \\(\\Vert\\cdot\\Vert\\) is the \\(L^2\\) norm or Euclidean distance. The partition matrix \\(U\\) satisfies the following conditions: \\[ u_{il}\\in \\{0,1\\},\\quad i=1,2,\\ldots,n,\\:l=1,2,\\ldots,k, \\] \\[ \\sum_{l=1}^k u_{il}=1,\\quad i=1,2,\\ldots,n. \\] The \\(k\\)-means algorithm employs an iterative procedure to minimize the objective function. It repeatedly updates the partition matrix \\(U\\) and the cluster centers \\(Z\\) alternately until some stop criterion is met. For more information about \\(k\\)-means, readers are referred to Gan, Ma, and Wu (2007) and Mirkin (2011). 13.3.2 Confirmatory Techniques Confirmatory data analysis techniques include the traditional statistical tools of inference, significance, and confidence. 13.3.2.1 Linear Models Linear models, also called linear regression models, aim at using a linear function to approximate the relationship between the dependent variable and independent variables. A linear regression model is called a simple linear regression model if there is only one independent variable. When more than one independent variables are involved, a linear regression model is called a multiple linear regression model. Let \\(X\\) and \\(Y\\) denote the independent and the dependent variables, respectively. For \\(i=1,2,\\ldots,n\\), let \\((x_i, y_i)\\) be the observed values of \\((X,Y)\\) in the \\(i\\)th case. Then the simple linear regression model is specified as follows (Edward W. Frees 2009b): \\[ y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i,\\quad i=1,2,\\ldots,n, \\] where \\(\\beta_0\\) and \\(\\beta_1\\) are parameters and \\(\\epsilon_i\\) is a random variable representing the error for the \\(i\\)th case. When there are multiple independent variables, the following multiple linear regression model is used: \\[ y_i = \\beta_0 + \\beta_1 x_{i1} + \\cdots + \\beta_k x_{ik} + \\epsilon_i, \\] where \\(\\beta_0\\), \\(\\beta_1\\), \\(\\ldots\\), \\(\\beta_k\\) are unknown parameters to be estimated. Linear regression models usually make the following assumptions: \\(x_{i1},x_{i2},\\ldots,x_{ik}\\) are nonstochastic variables. \\(\\mathrm{Var~}(y_i)=\\sigma^2\\), where \\(\\mathrm{Var~}(y_i)\\) denotes the variance of \\(y_i\\). \\(y_1,y_2,\\ldots,y_n\\) are independent random variables. For the purpose of obtaining tests and confidence statements with small samples, the following strong normality assumption is also made: \\(\\epsilon_1,\\epsilon_2,\\ldots,\\epsilon_n\\) are normally distributed. 13.3.2.2 Generalized Linear Models The generalized linear model (GLM) is a wide family of regression models that include linear regression models as special cases. In a GLM, the mean of the response (i.e., the dependent variable) is assumed to be a function of linear combinations of the explanatory variables, i.e., \\[ \\mu_i = E[y_i], \\] \\[ \\eta_i = \\textbf{x}_i&#39;\\boldsymbol{\\beta} = g(\\mu_i), \\] where \\(\\textbf{x}_i=(1,x_{i1}, x_{i2}, \\ldots, x_{ik})&#39;\\) is a vector of regressor values, \\(\\mu_i\\) is the mean response for the \\(i\\)th case, and \\(\\eta_i\\) is a systematic component of the GLM. The function \\(g(\\cdot)\\) is known and is called the link function. The mean response can vary by observations by allowing some parameters to change. However, the regression parameters \\(\\boldsymbol{\\beta}\\) are assumed to be the same among different observations. GLMs make the following assumptions: \\(x_{i1},x_{i2},\\ldots,x_{in}\\) are nonstochastic variables. \\(y_1,y_2,\\ldots,y_n\\) are independent. The dependent variable is assumed to follow a distribution from the linear exponential family. The variance of the dependent variable is not assumed to be constant but is a function of the mean, i.e., \\[ \\mathrm{Var~}{(y_i)} = \\phi \\nu(\\mu_i), \\] where \\(\\phi\\) denotes the dispersion parameter and \\(\\nu(\\cdot)\\) is a function. As we can see from the above specification, the GLM provides a unifying framework to handle different types of dependent variables, including discrete and continuous variables. For more information about GLMs, readers are referred to Jong and Heller (2008) and Edward W. Frees (2009b). 13.3.2.3 Tree-based Models Decision trees, also known as tree-based models, involve dividing the predictor space (i.e., the space formed by independent variables) into a number of simple regions and using the mean or the mode of the region for prediction (Breiman et al. 1984). There are two types of tree-based models: classification trees and regression trees. When the dependent variable is categorical, the resulting tree models are called classification trees. When the dependent variable is continuous, the resulting tree models are called regression trees. The process of building classification trees is similar to that of building regression trees. Here we only briefly describe how to build a regression tree. To do that, the predictor space is divided into non-overlapping regions such that the following objective function \\[ f(R_1,R_2,\\ldots,R_J) = \\sum_{j=1}^J \\sum_{i=1}^n I_{R_j}(\\textbf{x}_i)(y_i - \\mu_j)^2 \\] is minimized, where \\(I\\) is an indicator function, \\(R_j\\) denotes the set of indices of the observations that belong to the \\(j\\)th box, \\(\\mu_j\\) is the mean response of the observations in the \\(j\\)th box, \\(\\textbf{x}_i\\) is the vector of predictor values for the \\(i\\)th observation, and \\(y_i\\) is the response value for the \\(i\\)th observation. In terms of predictive accuracy, decision trees generally do not perform to the level of other regression and classification models. However, tree-based models may outperform linear models when the relationship between the response and the predictors is nonlinear. For more information about decision trees, readers are referred to Breiman et al. (1984) and Mitchell (1997). Show Quiz Solution 13.4 Some R Functions R is an open-source software for statistical computing and graphics. The R software can be downloaded from the R project website at . In this section, we give some R function for data analysis, especially the data analysis tasks mentioned in previous sections. \\[ \\begin{matrix} \\begin{array}{lll} \\hline \\text{Data Analysis Task} &amp; \\text{R package} &amp; \\text{R Function} \\\\\\hline \\text{Descriptive Statistics} &amp; \\texttt{base} &amp; \\texttt{summary}\\\\ \\text{Principal Component Analysis} &amp; \\texttt{stats} &amp; \\texttt{prcomp} \\\\ \\text{Data Clustering} &amp; \\texttt{stats} &amp; \\texttt{kmeans}, \\texttt{hclust} \\\\ \\text{Fitting Distributions} &amp; \\texttt{MASS} &amp; \\texttt{fitdistr} \\\\ \\text{Linear Regression Models} &amp; \\texttt{stats} &amp; \\texttt{lm} \\\\ \\text{Generalized Linear Models} &amp; \\texttt{stats} &amp; \\texttt{glm} \\\\ \\text{Regression Trees} &amp; \\texttt{rpart} &amp; \\texttt{rpart} \\\\ \\text{Survival Analysis} &amp; \\texttt{survival} &amp; \\texttt{survfit} \\\\ \\hline \\end{array} \\end{matrix} \\] Table 13.5: Some R functions for data analysis. Table 13.5 lists a few R functions for different data analysis tasks. Readers can read the R documentation for examples of using these functions. There are also other R functions from other packages to do similar things. However, the functions listed in this table provide good start points for readers to conduct data analysis in R. For analyzing large datasets in R in an efficient way, readers are referred to Daroczi (2015). 13.5 Summary In this chapter, we gave a high-level overview of data analysis by introducing data types, data structures, data storages, data sources, data analysis processes, and data analysis techniques. In particular, we presented various aspects of data analysis. In addition, we provided several websites where readers can obtain real-world datasets to horn their data analysis skills. We also listed some R packages and functions that can be used to perform various data analysis tasks. 13.6 Further Resources and Contributors Contributor Guojun Gan, University of Connecticut, is the principal author of the initial version of this chapter. Email: guojun.gan@uconn.edu for chapter comments and suggested improvements. Chapter reviewers include: Min Ji, Toby White. Bibliography "],
["C-DependenceModel.html", "Chapter 14 Dependence Modeling 14.1 Variable Types 14.2 Classic Measures of Scalar Associations 14.3 Introduction to Copulas 14.4 Application Using Copulas 14.5 Types of Copulas 14.6 Why is Dependence Modeling Important? 14.7 Further Resources and Contributors", " Chapter 14 Dependence Modeling Chapter Preview. In practice, there are many types of variables that one encounter and the first step in dependence modeling is identifying the type of variable you are dealing with to help direct you to the appropriate technique. This chapter introduces readers to variable types and techniques for modeling dependence or association of multivariate distributions. Section 14.1 provides an overview of the types of variables. Section 14.2 then elaborates basic measures for modeling the dependence between variables. Section 14.3 introduces a novel approach to modeling dependence using Copulas which is reinforced with practical illustrations in Section 14.4. The types of Copula families and basic properties of Copula functions is explained Section 14.5. The chapter concludes by explaining why the study of dependence modeling is important in Section 14.6. 14.1 Variable Types In this section, you learn how to: Classify variables as qualitative or quantitative. Describe multivariate variables. People, firms, and other entities that we want to understand are described in a dataset by numerical characteristics. As these characteristics vary by entity, they are commonly known as variables. To manage insurance systems, it will be critical to understand the distribution of each variable and how they are associated with one another. It is common for data sets to have many variables (high dimensional) and so it useful to begin by classifying them into different types. As will be seen, these classifications are not strict; there is overlap among the groups. Nonetheless, the grouping summarized in Table 14.1 and explained in the remainder of this section provides a solid first step in framing a data set. \\[ {\\small \\begin{matrix} \\begin{array}{l|l} \\hline \\textbf{Variable Type} &amp; \\textbf{Example} \\\\\\hline Qualitative &amp; \\\\ \\text{Binary} &amp; \\text{Sex} \\\\ \\text{Categorical (Unordered, Nominal)} &amp; \\text{Territory (e.g., state/province) in which an insured resides} \\\\ \\text{Ordered Category (Ordinal)} &amp; \\text{Claimant satisfaction (five point scale ranging from 1=dissatisfied} \\\\ &amp; ~~~ \\text{to 5 =satisfied)} \\\\\\hline Quantitative &amp; \\\\ \\text{Continuous} &amp; \\text{Policyholder&#39;s age, weight, income} \\\\ \\text{Discrete} &amp; \\text{Amount of deductible (0, 250, 500, and 1000)} \\\\ \\text{Count} &amp; \\text{Number of insurance claims} \\\\ \\text{Combinations of} &amp; \\text{Policy losses, mixture of 0&#39;s (for no loss)} \\\\ ~~~ \\text{Discrete and Continuous} &amp; ~~~\\text{and positive claim amount} \\\\ \\text{Interval Variable} &amp; \\text{Driver Age: 16-24 (young), 25-54 (intermediate),} \\\\ &amp; ~~~\\text{55 and over (senior)} \\\\ \\text{Circular Data} &amp; \\text{Time of day measures of customer arrival} \\\\ \\hline Multivariate ~ Variable &amp; \\\\ \\text{High Dimensional Data} &amp; \\text{Characteristics of a firm purchasing worker&#39;s compensation} \\\\ &amp; ~~~\\text{insurance (location of plants, industry, number of employees,} \\\\ &amp;~~~\\text{and so on)} \\\\ \\text{Spatial Data} &amp; \\text{Longitude/latitude of the location an insurance hailstorm claim} \\\\ \\text{Missing Data} &amp; \\text{Policyholder&#39;s age (continuous/interval) and &quot;-99&quot; for} \\\\ &amp;~~~ \\text{&quot;not reported,&quot; that is, missing} \\\\ \\text{Censored and Truncated Data} &amp; \\text{Amount of insurance claims in excess of a deductible} \\\\ \\text{Aggregate Claims} &amp; \\text{Losses recorded for each claim in a motor vehicle policy.} \\\\ \\text{Stochastic Process Realizations} &amp; \\text{The time and amount of each occurrence of an insured loss} \\\\ \\hline \\end{array} \\end{matrix}} \\] Table 14.1 : Variable types In data analysis, it is important to understand what type of variable you are working with. For example, Consider a pair of random variables (Coverage,Claim) from the LGPIF data introduced in chapter 1 as displayed in Figure 14.1 below. We would like to know whether the distribution of Coverage depends on the distribution of Claim or whether they are statistically independent. We would also want to know how the Claim distribution depends on the EntityType variable. Because the EntityType variable belongs to a different class of variables, modeling the dependence between Claim and Coverage may require a different technique from that of Claim and EntityType. Figure 14.1: Scatter plot of (Coverage,Claim) from LGPIF data 14.1.1 Qualitative Variables In this sub-section, you learn how to: Classify qualitative variables as nominal or ordinal Describe binary variable A qualitative, or categorical variable is one for which the measurement denotes membership in a set of groups, or categories. For example, if you were coding which area of the country an insured resides, you might use a 1 for the northern part, 2 for southern, and 3 for everything else. This location variable is an example of a nominal variable, one for which the levels have no natural ordering. Any analysis of nominal variables should not depend on the labeling of the categories. For example, instead of using a 1,2,3 for north, south, other, I should arrive at the same set of summary statistics if I used a 2,1,3 coding instead, interchanging north and south. In contrast, an ordinal variable is a type of categorical variable for which an ordering does exist. For example, with a survey to see how satisfied customers are with our claims servicing department, we might use a five point scale that ranges from 1 meaning dissatisfied to a 5 meaning satisfied. Ordinal variables provide a clear ordering of levels of a variable but the amount of separation between levels is unknown. A binary variable is a special type of categorical variable where there are only two categories commonly taken to be a 0 and a 1. For example, we might code a variable in a dataset to be a 1 if an insured is female and a 0 if male. 14.1.2 Quantitative Variables In this sub-section, you learn how to: Differentiate between continuous and discrete variable Use a combination of continuous and discrete variable Describe circular data Unlike a qualitative variable, a quantitative variable is one in which numerical level is a realization from some scale so that the distance between any two levels of the scale takes on meaning. A continuous variable is one that can take on any value within a finite interval. For example, it is common to represent a policyholder’s age, weight, or income, as a continuous variable. In contrast, a discrete variable is one that takes on only a finite number of values in any finite interval. For example, when examining a policyholder’s choice of deductibles, it may be that values of 0, 250, 500, and 1000 are the only possible outcomes. Like an ordinal variable, these represent distinct categories that are ordered. Unlike an ordinal variable, the numerical difference between levels takes on economic meaning. A special type of discrete variable is a count variable, one with values on the nonnegative integers. For example, we will be particularly interested in the number of claims arising from a policy during a given period. Some variables are inherently a combination of discrete and continuous components. For example, when we analyze the insured loss of a policyholder, we will encounter a discrete outcome at zero, representing no insured loss, and a continuous amount for positive outcomes, representing the amount of the insured loss. Another interesting variation is an interval variable,one that gives a range of possible outcomes. Circular data represent an interesting category typically not analyzed by insurers. As an example of circular data, suppose that you monitor calls to your customer service center and would like to know when is the peak time of the day for calls to arrive. In this context, one can think about the time of the day as a variable with realizations on a circle, e.g., imagine an analog picture of a clock. For circular data, the distance between observations at 00:15 and 00:45 are just as close as observations 23:45 and 00:15 (here, we use the convention HH:MM means hours and minutes). 14.1.3 Multivariate Variables In this sub-section, you learn how to: Differentiate between univariate and multivariate data Handle missing variables Insurance data typically are multivariate in the sense that we can take many measurements on a single entity. For example, when studying losses associated with a firm’s worker’s compensation plan, we might want to know the location of its manufacturing plants, the industry in which it operates, the number of employees, and so forth. The usual strategy for analyzing multivariate data is to begin by examining each variable in isolation of the others. This is known as a univariate approach. In contrast, for some variables, it makes little sense to only look at one dimensional aspects. For example, insurers typically organize spatial data by longitude and latitude to analyze the location of weather related insurance claims due hailstorms. Having only a single number, either longitude or latitude, provides little information in understanding geographical location. Another special case of a multivariate variable, less obvious, involves coding for missing data. Historically, some statistical packages used a -99 to report when a variable, such as policyholder’s age, was not available or not reported. This led to many unsuspecting analysts providing strange statistics when summarizing a set of data. When data are missing, it is better to think about the variable as two dimensions, one to indicate whether or not the variable is reported and the second providing the age (if reported). In the same way, insurance data are commonly censored and truncated. We refer you to Chapter 4 for more on censored and truncated data. Aggregate claims can also be coded as another special type of multivariate variable. We refer you to Chapter 5 for more Aggregate claims. Perhaps the most complicated type of multivariate variable is a realization of a stochastic process. You will recall that a stochastic process is little more than a collection of random variables. For example, in insurance, we might think about the times that claims arrive to an insurance company in a one year time horizon. This is a high dimensional variable that theoretically is infinite dimensional. Special techniques are required to understand realizations of stochastic processes that will not be addressed here. Show Quiz Solution 14.2 Classic Measures of Scalar Associations In this section, you learn how to: Estimate correlation using Pearson method Use rank based measures like Spearman, Kendall to estimate correlation Measure dependence using odds ratio, Pearson chi-square and likelihood ratio test statistic Use normal-based correlations to quantify associations involving ordinal variables 14.2.1 Association Measures for Quantitative Variables For this section, consider a pair of random variables \\((X,Y)\\) having joint distribution function \\(F(\\cdot)\\) and a random sample \\((X_i,Y_i), i=1, \\ldots, n\\). For the continuous case, suppose that \\(F(\\cdot)\\) is absolutely continuous with absolutely continuous marginals. 14.2.1.1 Pearson Correlation Define the sample covariance function \\(\\widehat{Cov}(X,Y) = \\frac{1}{n} \\sum_{i=1}^n (X_i - \\bar{X})(Y_i - \\bar{Y})\\), where \\(\\bar{X}\\) and \\(\\bar{Y}\\) are the sample means of \\(X\\) and \\(Y\\), respectively. Then, the product-moment (Pearson) correlation can be written as \\[\\begin{equation*} r = \\frac{\\widehat{Cov}(X,Y)}{\\sqrt{\\widehat{Cov}(X,X)\\widehat{Cov}(Y,Y)}}. \\end{equation*}\\] The correlation statistic \\(r\\) is widely used to capture linear association between random variables. It is a (nonparametric) estimator of the correlation parameter \\(\\rho\\), defined to be the covariance divided by the product of standard deviations. In this sense, it captures association for any pair of random variables. This statistic has several important features. Unlike regression estimators, it is symmetric between random variables, so the correlation between \\(X\\) and \\(Y\\) equals the correlation between \\(Y\\) and \\(X\\). It is unchanged by linear transformations of random variables (up to sign changes) so that we can multiply random variables or add constants as is helpful for interpretation. The range of the statistic is \\([-1,1]\\) which does not depend on the distribution of either \\(X\\) or \\(Y\\). Further, in the case of independence, the correlation coefficient \\(r\\) is 0. However, it is well known that zero correlation does not imply independence, except for normally distributed random variables. The correlation statistic \\(r\\) is also a (maximum likelihood) estimator of the association parameter for bivariate normal distribution. So, for normally distributed data, the correlation statistic \\(r\\) can be used to assess independence. For additional interpretations of this well-known statistic, readers will enjoy (Lee Rodgers and Nicewander 1998). You can obtain the Pearson correlation statistic \\(r\\) using the cor() function in R and selecting the pearson method. This is demonstrated below by using the Coverage rating variable in millions of dollars and Claim amount variable in dollars from the LGPIF data introduced in chapter 1. R Code for Pearson Correlation Statistic ### Pearson correlation between Claim and Coverage r&lt;-cor(Claim,Coverage, method = c(&quot;pearson&quot;)) round(r,2) Output: [1] 0.31 ### Pearson correlation between Claim and log(Coverage) r&lt;-cor(Claim,log(Coverage), method = c(&quot;pearson&quot;)) round(r,2) Output: [1] 0.1 From R output above, \\(r=0.31\\) , which indicates a positive association between Claim and Coverage. This means that as the coverage amount of a policy increases we expect claim to increase. 14.2.2 Rank Based Measures 14.2.2.1 Spearman’s Rho The Pearson correlation coefficient does have the drawback that it is not invariant to nonlinear transforms of the data. For example, the correlation between \\(X\\) and \\(\\ln Y\\) can be quite different from the correlation between \\(X\\) and \\(Y\\). As we see from the R code for Pearson correlation statistic above, the correlation statistic \\(r\\) between Coverage rating variable in logarithmic millions of dollars and Claim amounts variable in dollars is \\(0.1\\) as compared to \\(0.31\\) when we calculate the correlation between Coverage rating variable in millions of dollars and Claim amounts variable in dollars. This limitation is one reason for considering alternative statistics. Alternative measures of correlation are based on ranks of the data. Let \\(R(X_j)\\) denote the rank of \\(X_j\\) from the sample \\(X_1, \\ldots, X_n\\) and similarly for \\(R(Y_j)\\). Let \\(R(X) = \\left(R(X_1), \\ldots, R(X_n)\\right)&#39;\\) denote the vector of ranks, and similarly for \\(R(Y)\\). For example, if \\(n=3\\) and \\(X=(24, 13, 109)\\), then \\(R(X)=(2,1,3)\\). A comprehensive introduction of rank statistics can be found in, for example, (Hettmansperger 1984). Also, ranks can be used to obtain the empirical distribution function, refer to section 4.1.1 for more on the empirical distribution function. With this, the correlation measure of (Spearman 1904) is simply the product-moment correlation computed on the ranks: \\[\\begin{equation*} r_S = \\frac{\\widehat{Cov}(R(X),R(Y))}{\\sqrt{\\widehat{Cov}(R(X),R(X))\\widehat{Cov}(R(Y),R(Y))}} = \\frac{\\widehat{Cov}(R(X),R(Y))}{(n^2-1)/12} . \\end{equation*}\\] You can obtain the Spearman correlation statistic \\(r_S\\) using the cor() function in R and selecting the spearman method. From below, the Spearman correlation between the Coverage rating variable in millions of dollars and Claim amount variable in dollars is \\(0.41\\). R Code for Spearman Correlation Statistic ### Spearman correlation between Claim and Coverage ### rs&lt;-cor(Claim,Coverage, method = c(&quot;spearman&quot;)) round(rs,2) Output: [1] 0.41 ### Spearman correlation between Claim and log(Coverage) ### rs&lt;-cor(Claim,log(Coverage), method = c(&quot;spearman&quot;)) round(rs,2) Output: [1] 0.41 We can show that the Spearman correlation statistic is invariant under strictly increasing transformations. From the R Code for Spearman correlation statistic above, \\(r_S=0.41\\) between the Coverage rating variable in logarithmic millions of dollars and Claim amount variable in dollars. 14.2.2.2 Kendall’s Tau An alternative measure that uses ranks is based on the concept of concordance. An observation pair \\((X,Y)\\) is said to be concordant (discordant) if the observation with a larger value of \\(X\\) has also the larger (smaller) value of \\(Y\\). Then \\(\\Pr(concordance) = \\Pr[ (X_1-X_2)(Y_1-Y_2) &gt;0 ]\\) , \\(\\Pr(discordance) = \\Pr[ (X_1-X_2)(Y_1-Y_2) &lt;0 ]\\), \\(\\Pr(tie) = \\Pr[ (X_1-X_2)(Y_1-Y_2) =0 ]\\) and \\[\\begin{eqnarray*} \\tau(X,Y)= \\Pr(concordance) - \\Pr(discordance) = 2\\Pr(concordance) - 1 + \\Pr(tie). \\end{eqnarray*}\\] To estimate this, the pairs \\((X_i,Y_i)\\) and \\((X_j,Y_j)\\) are said to be concordant if the product \\(sgn(X_j-X_i)sgn(Y_j-Y_i)\\) equals 1 and discordant if the product equals -1. Here, \\(sgn(x)=1,0,-1\\) as \\(x&gt;0\\), \\(x=0\\), \\(x&lt;0\\), respectively. With this, we can express the association measure of (Kendall 1938), known as Kendall’s tau, as \\[\\begin{equation*} \\begin{array}{rl} \\tau &amp;= \\frac{2}{n(n-1)} \\sum_{i&lt;j}sgn(X_j-X_i)sgn(Y_j-Y_i)\\\\ &amp;= \\frac{2}{n(n-1)} \\sum_{i&lt;j}sgn(R(X_j)-R(X_i))sgn(R(Y_j)-R(Y_i)) \\end{array}. \\end{equation*}\\] Interestingly, (Hougaard 2000), page 137, attributes the original discovery of this statistic to (Fechner 1897), noting that Kendall’s discovery was independent and more complete than the original work. You can obtain the Kendall’s tau, using the cor() function in R and selecting the kendall method. From below, \\(\\tau=0.32\\) between the Coverage rating variable in millions of dollars and Claim amount variable in dollars. When there are ties in the data, the cor() function computes Kendall’s tau_b, as proposed by (Kendall 1945). R Code for Kendall’s Tau ### Kendall&#39;s tau correlation between Claim and Coverage ### tau&lt;-cor(Claim,Coverage, method = c(&quot;kendall&quot;)) round(tau,2) Output: [1] 0.32 ### Kendall&#39;s tau correlation between Claim and log(Coverage) ### tau&lt;-cor(Claim,log(Coverage), method = c(&quot;kendall&quot;)) round(tau,2) Output: [1] 0.32 Also,to show that the Kendall’s tau is invariate under strictly increasing transformations , \\(\\tau=0.32\\) between the Coverage rating variable in logarithmic millions of dollars and Claim amount variable in dollars. 14.2.3 Nominal Variables 14.2.3.1 Bernoulli Variables To see why dependence measures for continuous variables may not be the best for discrete variables, let us focus on the case of Bernoulli variables that take on simple binary outcomes, 0 and 1. For notation, let \\(\\pi_{jk} = \\Pr(X=j, Y=k)\\) for \\(j,k=0,1\\) and let \\(\\pi_X=\\Pr(X=1)\\) and similarly for \\(\\pi_Y\\). Then, the population version of the product-moment (Pearson) correlation can be easily seen to be \\[\\begin{eqnarray*} \\rho = \\frac{\\pi_{11} - \\pi_X \\pi_Y}{\\sqrt{\\pi_X(1-\\pi_X)\\pi_Y(1-\\pi_Y)}} . \\end{eqnarray*}\\] Unlike the case for continuous data, it is not possible for this measure to achieve the limiting boundaries of the interval \\([-1,1]\\). To see this, students of probability may recall the Fr\\(\\acute{e}\\)chet-H\\(\\ddot{o}\\)effding bounds for a joint distribution that turn out to be \\(\\max\\{0, \\pi_X+\\pi_Y-1\\} \\le \\pi_{11} \\le \\min\\{\\pi_X,\\pi_Y\\}\\) for this joint probability. This limit on the joint probability imposes an additional restriction on the Pearson correlation. As an illustration, assume equal probabilities \\(\\pi_X =\\pi_Y = \\pi &gt; 1/2\\). Then, the lower bound is \\[\\begin{eqnarray*} \\frac{2\\pi - 1 - \\pi^2}{\\pi(1-\\pi)} = -\\frac{1-\\pi}{\\pi} . \\end{eqnarray*}\\] For example, if \\(\\pi=0.8\\), then the smallest that the Pearson correlation could be is -0.25. More generally, there are bounds on \\(\\rho\\) that depend on \\(\\pi_X\\) and \\(\\pi_Y\\) that make it difficult to interpret this measure. As noted by (Bishop, Fienberg, and Holland 1975) (page 382), squaring this correlation coefficient yields the Pearson chi-square statistic (introduced in chapter 2) . Despite the boundary problems described above, this feature makes the Pearson correlation coefficient a good choice for describing dependence with binary data. The other is the odds ratio, described as follows. As an alternative measure for Bernoulli variables, the odds ratio is given by \\[\\begin{eqnarray*} OR(\\pi_{11}) = \\frac{\\pi_{11} \\pi_{00}}{\\pi_{01} \\pi_{10}} = \\frac{\\pi_{11} \\left( 1+\\pi_{11}-\\pi_X -\\pi_Y\\right)}{(\\pi_X-\\pi_{11})(\\pi_Y- \\pi_{11})} . \\end{eqnarray*}\\] Pleasant calculations show that \\(OR(z)\\) is \\(0\\) at the lower Fr\\(\\acute{e}\\)chet-H\\(\\ddot{o}\\)effding bound \\(z= \\max\\{0, \\pi_X+\\pi_Y-1\\}\\) and is \\(\\infty\\) at the upper bound \\(z=\\min\\{\\pi_X,\\pi_Y\\}\\). Thus, the bounds on this measure do not depend on the marginal probabilities \\(\\pi_X\\) and \\(\\pi_Y\\), making it easier to interpret this measure. As noted by (Yule 1900), odds ratios are invariant to the labeling of 0 and 1. Further, they are invariant to the marginals in the sense that one can rescale \\(\\pi_X\\) and \\(\\pi_Y\\) by positive constants and the odds ratio remains unchanged. Specifically, suppose that \\(a_i\\), \\(b_j\\) are sets of positive constants and that \\[\\begin{eqnarray*} \\pi_{ij}^{new} &amp;=&amp; a_i b_j \\pi_{ij} \\end{eqnarray*}\\] and \\(\\sum_{ij} \\pi_{ij}^{new}=1.\\) Then, \\[\\begin{eqnarray*} OR^{new} = \\frac{(a_1 b_1 \\pi_{11})( a_0 b_0 \\pi_{00})}{(a_0 b_1 \\pi_{01})( a_1 b_0\\pi_{10})} = \\frac{\\pi_{11} \\pi_{00}}{\\pi_{01} \\pi_{10}} =OR^{old} . \\end{eqnarray*}\\] For additional help with interpretation, Yule proposed two transforms for the odds ratio, the first in (Yule 1900), \\[\\begin{eqnarray*} \\frac{OR-1}{OR+1}, \\end{eqnarray*}\\] and the second in (Yule 1912), \\[\\begin{eqnarray*} \\frac{\\sqrt{OR}-1}{\\sqrt{OR}+1}. \\end{eqnarray*}\\] Although these statistics provide the same information as is the original odds ration \\(OR\\), they have the advantage of taking values in the interval \\([-1,1]\\), making them easier to interpret. In a later section, we will also see that the marginal distributions have no effect on the Fr\\(\\acute{e}\\)chet-H\\(\\ddot{o}\\)effding of the tetrachoric correlation, another measure of association, see also, (Joe 2014), page 48. \\[ {\\small \\begin{matrix} \\begin{array}{l|rr|r} \\hline &amp; \\text{Fire5} &amp; &amp; \\\\ \\text{NoClaimCredit} &amp; 0 &amp; 1 &amp; \\text{Total} \\\\ \\hline 0 &amp; 1611 &amp; 2175 &amp; 3786 \\\\ 1 &amp; 897 &amp; 956 &amp; 1853 \\\\ \\hline \\text{Total} &amp; 2508 &amp; 3131 &amp; 5639 \\\\ \\hline \\end{array} \\end{matrix}} \\] Table 14.2 : 2 \\(\\times\\) 2 table of counts for Fire5 and NoClaimCredit variables from LGPIF data. From Table 14.2, \\(OR(\\pi_{11})=\\frac{1611(956)}{897(2175)}=0.79\\). You can obtain the \\(OR(\\pi_{11})\\), using the oddsratio() function from the epitools library in R. From the output below, \\(OR(\\pi_{11})=0.79\\) for the binary variables NoClaimCredit and Fier5 from the LGPIF data. R Code for Odds Ratios library(epitools) oddsratio(NoClaimCredit, Fire5,method = c(&quot;wald&quot;))$measure Output: [1] 0.79 14.2.3.2 Categorical Variables More generally, let \\((X,Y)\\) be a bivariate pair having \\(ncat_X\\) and \\(ncat_Y\\) numbers of categories, respectively. For a two-way table of counts, let \\(n_{jk}\\) be the number in the \\(j\\)th row, \\(k\\) column. Let \\(n_{j\\centerdot}\\) be the row margin total, \\(n_{\\centerdot k}\\) be the column margin total and \\(n=\\sum_{j,k} n_{j,k}\\). Define Pearson chi-square statistic as \\[\\begin{eqnarray*} \\chi^2 = \\sum_{jk} \\frac{(n_{jk}- n_{j\\centerdot}n_{\\centerdot k}/n)^2}{n_{j\\centerdot}n_{\\centerdot k}/n} . \\end{eqnarray*}\\] The likelihood ratio test statistic is \\[\\begin{eqnarray*} G^2 = 2 \\sum_{jk} n_{jk} \\ln\\frac{n_{jk}}{n_{j\\centerdot}n_{\\centerdot k}/n} . \\end{eqnarray*}\\] Under the assumption of independence, both \\(\\chi^2\\) and \\(G^2\\) have an asymptotic chi-square distribution with \\((ncat_X-1)(ncat_Y-1)\\) degrees of freedom. To help see what these statistics are estimating, let \\(\\pi_{jk} = \\Pr(X=j, Y=k)\\) and let \\(\\pi_{X,j}=\\Pr(X=j)\\) and similarly for \\(\\pi_{Y,k}\\). Assuming that \\(n_{jk}/n \\approx \\pi_{jk}\\) for large \\(n\\) and similarly for the marginal probabilities, we have \\[\\begin{eqnarray*} \\frac{\\chi^2}{n} \\approx \\sum_{jk} \\frac{(\\pi_{jk}- \\pi_{X,j}\\pi_{Y,k})^2}{\\pi_{X,j}\\pi_{Y,k}} \\end{eqnarray*}\\] and \\[\\begin{eqnarray*} \\frac{G^2}{n} \\approx 2 \\sum_{jk} \\pi_{jk} \\ln\\frac{\\pi_{jk}}{\\pi_{X,j}\\pi_{Y,k}} . \\end{eqnarray*}\\] Under the null hypothesis of independence, we have \\(\\pi_{jk} =\\pi_{X,j}\\pi_{Y,k}\\) and it is clear from these approximations that we anticipate that these statistics will be small under this hypothesis. Classical approaches, as described in (Bishop, Fienberg, and Holland 1975) (page 374), distinguish between tests of independence and measures of associations. The former are designed to detect whether a relationship exists whereas the latter are meant to assess the type and extent of a relationship. We acknowledge these differing purposes but also less concerned with this distinction for actuarial applications. \\[ {\\small \\begin{matrix} \\begin{array}{l|rr} \\hline &amp; \\text{NoClaimCredit} &amp; \\\\ \\text{EntityType} &amp; 0 &amp; 1 \\\\ \\hline \\text{City} &amp; 644 &amp; 149 \\\\ \\text{County} &amp; 310 &amp; 18 \\\\ \\text{Misc} &amp; 336 &amp; 273 \\\\ \\text{School} &amp; 1103 &amp; 494 \\\\ \\text{Town} &amp; 492 &amp; 479 \\\\ \\text{Village} &amp; 901 &amp; 440 \\\\ \\hline \\end{array} \\end{matrix}} \\] Table 14.3 : Two-way table of counts for EntityType and NoClaimCredit variables from LGPIF data. You can obtain the Pearson chi-square statistic, using the chisq.test() function from the MASS library in R. Here, we test whether the EntityType variable is independent of NoClaimCredit variable using Table 14.3. R Code for Pearson Chi-square Statistic library(MASS) table = table(EntityType, NoClaimCredit) chisq.test(table) Output: ------------------------------------ Test statistic df P value ---------------- ---- -------------- 344.2 5 3.15e-72 * * * ------------------------------------ Table: Pearson&#39;s Chi-squared test As the p-value is less than the .05 significance level, we reject the null hypothesis that the EntityType is independent of NoClaimCredit. Furthermore, you can obtain the likelihood ratio test statistic , using the likelihood.test() function from the Deducer library in R. From below, we test whether the EntityType variable is independent of NoClaimCredit variable from the LGPIF data. Same conclusion is drawn as the Pearson chi-square test. R Code for Likelihood Ratio Test Statistic library(Deducer) likelihood.test(EntityType, NoClaimCredit) Output: ----------------------------------------- Test statistic X-squared df P value ---------------- -------------- --------- 378.7 5 0 * * * ----------------------------------------- Table: Log likelihood ratio (G-test) test of independence without correction 14.2.4 Ordinal Variables As the analyst moves from the continuous to the nominal scale, there are two main sources of loss of information (Bishop, Fienberg, and Holland 1975) (page 343). The first is breaking the precise continuous measurements into groups. The second is losing the ordering of the groups. So, it is sensible to describe what we can do with variables that in discrete groups but where the ordering is known. As described in Section 14.1.1, ordinal variables provide a clear ordering of levels of a variable but distances between levels are unknown. Associations have traditionally been quantified parametrically using normal-based correlations and nonparametrically using Spearman correlations with tied ranks. 14.2.4.1 Parametric Approach Using Normal Based Correlations Refer to page 60, Section 2.12.7 of (Joe 2014). Let \\((y_1,y_2)\\) be a bivariate pair with discrete values on \\(m_1, \\ldots, m_2\\). For a two-way table of ordinal counts, let \\(n_{st}\\) be the number in the \\(s\\)th row, \\(t\\) column. Let \\((n_{m_1\\centerdot}, \\ldots, n_{m_2\\centerdot})\\) be the row margin total, \\((n_{\\centerdot m_1}, \\ldots, n_{\\centerdot m_2})\\) be the column margin total and \\(n=\\sum_{s,t} n_{s,t}\\). Let \\(\\hat{\\xi}_{1s} = \\Phi^{-1}((n_{m_1}+\\cdots+n_{s\\centerdot})/n)\\) for \\(s=m_1, \\ldots, m_2\\) be a cutpoint and similarly for \\(\\hat{\\xi}_{2t}\\). The polychoric correlation, based on a two-step estimation procedure, is \\[\\begin{eqnarray*} \\begin{array}{cr} \\hat{\\rho_N} &amp;=\\text{argmax}_{\\rho} \\sum_{s=m_1}^{m_2} \\sum_{t=m_1}^{m_2} n_{st} \\log\\left\\{ \\Phi_2(\\hat{\\xi}_{1s}, \\hat{\\xi}_{2t};\\rho) -\\Phi_2(\\hat{\\xi}_{1,s-1}, \\hat{\\xi}_{2t};\\rho) \\right.\\\\ &amp; \\left. -\\Phi_2(\\hat{\\xi}_{1s}, \\hat{\\xi}_{2,t-1};\\rho) +\\Phi_2(\\hat{\\xi}_{1,s-1}, \\hat{\\xi}_{2,t-1};\\rho) \\right\\} \\end{array} \\end{eqnarray*}\\] It is called a tetrachoric correlation for binary variables. \\[ {\\small \\begin{matrix} \\begin{array}{l|rr} \\hline &amp; \\text{NoClaimCredit} &amp; \\\\ \\text{AlarmCredit} &amp; 0 &amp; 1 \\\\ \\hline 1 &amp; 1669 &amp; 942 \\\\ 2 &amp; 121 &amp; 118 \\\\ 3 &amp; 195 &amp; 132 \\\\ 4 &amp; 1801 &amp; 661 \\\\ \\hline \\end{array} \\end{matrix}} \\] Table 14.4 : Two-way table of counts for AlarmCredit and NoClaimCredit variables from LGPIF data. You can obtain the polychoric or tetrachoric correlation using the polychoric() or tetrachoric() function from the psych library in R. The polychoric correlation is illustrated using Table 14.4. \\(\\hat{\\rho}_N=-0.14\\), which means that there is a negative relationship between AlarmCredit and NoClaimCredit. R Code for Polychoric Correlation library(psych) AlarmCredit&lt;-as.numeric(ifelse(Insample$AC00==1,&quot;1&quot;, ifelse(Insample$AC05==1,&quot;2&quot;, ifelse(Insample$AC10==1,&quot;3&quot;, ifelse(Insample$AC15==1,&quot;4&quot;,0))))) x &lt;- table(AlarmCredit,NoClaimCredit) rhoN&lt;-polychoric(x,correct=FALSE)$rho round(rhoN,2) Output: [1] -0.14 14.2.5 Interval Variables As described in Section 14.1.2, interval variables provide a clear ordering of levels of a variable and the numerical distance between any two levels of the scale can be readily interpretable. For example, drivers age group variable is an interval variable. For measuring association, both the continuous variable and ordinal variable approaches make sense. The former takes advantage of knowledge of the ordering although assumes continuity. The latter does not rely on the continuity but also does not make use of the information given by the distance between scales. 14.2.6 Discrete and Continuous Variables The polyserial correlation is defined similarly, when one variable (\\(y_1\\)) is continuous and the other (\\(y_2\\)) ordinal. Define \\(z\\) to be the normal score of \\(y_1\\). The polyserial correlation is \\[\\begin{eqnarray*} \\hat{\\rho_N} = \\text{argmax}_{\\rho} \\sum_{i=1}^n \\log\\left\\{ \\phi(z_{i1})\\left[ \\Phi(\\frac{\\hat{\\xi}_{2,y_{i2}} - \\rho z_{i1}} {(1-\\rho^2)^{1/2}}) -\\Phi(\\frac{\\hat{\\xi}_{2,y_{i2-1}} - \\rho z_{i1}} {(1-\\rho^2)^{1/2}}) \\right] \\right\\} \\end{eqnarray*}\\] The biserial correlation is defined similarly, when one variable is continuous and the other binary. \\[ {\\small \\begin{matrix} \\begin{array}{l|r|r} \\hline \\text{NoClaimCredit} &amp; \\text{Mean} &amp;\\text{Total} \\\\ &amp; \\text{Claim} &amp;\\text{Claim} \\\\ \\hline 0 &amp; 22,505 &amp; 85,200,483 \\\\ 1 &amp; 6,629 &amp; 12,282,618 \\\\ \\hline \\end{array} \\end{matrix}} \\] Table 14.5 : Summary of Claim by NoClaimCredit variable from LGPIF data. You can obtain the polyserial or biserial correlation using the polyserial() or biserial() function from the psych library in R. Table 14.5 gives the summary of Claim by NoClaimCredit and the biserial correlation is illustrated using R code below. The \\(\\hat{\\rho}_N=-0.04\\) which means that there is a negative correlation between Claim and NoClaimCredit. R Code for Biserial Correlation library(psych) rhoN&lt;-biserial(Claim,NoClaimCredit) round(rhoN,2) Output: [1] -0.04 Show Quiz Solution 14.3 Introduction to Copulas Copula functions are widely used in statistics and actuarial science literature for dependency modeling. In this section, you learn how to: Describe a multivariate distribution function in terms of a copula function. A copula is a multivariate distribution function with uniform marginals. Specifically, let \\(U_1, \\ldots, U_p\\) be \\(p\\) uniform random variables on \\((0,1)\\). Their distribution function \\[{C}(u_1, \\ldots, u_p) = \\Pr(U_1 \\leq u_1, \\ldots, U_p \\leq u_p),\\] is a copula. We seek to use copulas in applications that are based on more than just uniformly distributed data. Thus, consider arbitrary marginal distribution functions \\({F}_1(y_1)\\),…,\\({F}_p(y_p)\\). Then, we can define a multivariate distribution function using the copula such that \\[{F}(y_1, \\ldots, y_p)= {C}({F}_1(y_1), \\ldots, {F}_p(y_p)).\\] Here, \\(F\\) is a multivariate distribution function in this equation. Sklar (1959) showed that \\(any\\) multivariate distribution function \\(F\\), can be written in the form of this equation, that is, using a copula representation. Sklar also showed that, if the marginal distributions are continuous, then there is a unique copula representation. In this chapter we focus on copula modeling with continuous variables. For discrete case, readers can see (Joe 2014) and (Genest and Nešlohva 2007). For bivariate case, \\(p=2\\) , the distribution function of two random variables can be written by the bivariate copula function: \\[{C}(u_1, \\, u_2) = \\Pr(U_1 \\leq u_1, \\, U_2 \\leq u_2),\\] \\[{F}(y_1, \\, y_2)= {C}({F}_1(y_1), \\, {F}_p(y_2)).\\] To give an example for bivariate copula, we can look at Frank’s (1979) copula. The equation is \\[{C}(u_1,u_2) = \\frac{1}{\\theta} \\ln \\left( 1+ \\frac{ (\\exp(\\theta u_1) -1)(\\exp(\\theta u_2) -1)} {\\exp(\\theta) -1} \\right).\\] This is a bivariate distribution function with its domain on the unit square \\([0,1]^2.\\) Here \\(\\theta\\) is dependence parameter and the range of dependence is controlled by the parameter \\(\\theta\\). Positive association increases as \\(\\theta\\) increases and this positive association can be summarized with Spearman’s rho (\\(\\rho\\)) and Kendall’s tau (\\(\\tau\\)). Frank’s copula is one of the commonly used copula functions in the copula literature. We will see other copula functions in Section 14.5. Show Quiz Solution 14.4 Application Using Copulas In this section, you learn how to: Discover dependence structure between random variables Model the dependence with a copula function This section analyzes the insurance losses and expenses data with the statistical programming R. This data set was introduced in (Frees and Valdez 1998) and is now readily available in the copula package. The model fitting process is started by marginal modeling of two variables (\\(loss\\) and \\(expense\\)). Then we model the joint distribution of these marginal outcomes. 14.4.1 Data Description We start with getting a sample (\\(n = 1500\\)) from the whole data. We consider first two variables of the data; losses and expenses. losses : general liability claims from Insurance Services Office, Inc. (ISO) expenses : ALAE, specifically attributable to the settlement of individual claims (e.g. lawyer’s fees, claims investigation expenses) To visualize the relationship between losses and expenses (ALAE), scatterplots in figure ?? are created on the real dollar scale and on the log scale. R Code for Scatterplots library(copula) data(loss) # loss data Lossdata &lt;- loss attach(Lossdata) loss &lt;- Lossdata$loss par(mfrow=c(1, 2)) plot(loss,alae, cex=.5) # real dollar scale plot(log(loss),log(alae),cex=.5) # log scale par(mfrow=c(1, 2)) 14.4.2 Marginal Models We first examine the marginal distributions of losses and expenses before going through the joint modeling. The histograms show that both losses and expenses are right-skewed and fat-tailed. For marginal distributions of losses and expenses, we consider a Pareto-type distribution, namely a Pareto type II with distribution function \\[ F(y)=1- \\left( 1 + \\frac{y}{\\theta} \\right) ^{-\\alpha},\\] where \\(\\theta\\) is the scale parameter and \\(\\alpha\\) is the shape parameter. The marginal distributions of losses and expenses are fitted with maximum likelihood. Specifically, we use the \\(vglm\\) function from the R VGAM package. Firstly, we fit the marginal distribution of expenses . R Code for Pareto Fitting library(VGAM) fit = vglm(alae ~ 1, paretoII(location=0, lscale=&quot;loge&quot;, lshape=&quot;loge&quot;)) # fit the model by vlgm function coef(fit, matrix=TRUE) # extract fitted model coefficients, matrix=TRUE gives logarithm of estimated parameters instead of default normal scale estimates Coef(fit) Output: loge(scale) loge(shape) (Intercept) 9.624673 0.7988753 scale shape (Intercept) 15133.603598 2.223039 We repeat this procedure to fit the marginal distribution of the loss variable. Because the loss data also seems right-skewed and heavy-tail data, we also model the marginal distribution with Pareto II distribution. R Code for Pareto Fitting fitloss = vglm(loss ~ 1, paretoII, trace=TRUE) Coef(fit) summary(fit) Output: scale shape 15133.603598 2.223039 To visualize the fitted distribution of expenses and loss variables, we use the estimated parameters and plot the corresponding distribution function and density function. For more details on marginal model selection, see Chapter 4. 14.4.3 Probability Integral Transformation The probability integral transformation shows that any continuous variable can be mapped to a \\(U(0,1)\\) random variable via its distribution function. Given the fitted Pareto II distribution, the variable expenses is transformed to the variable \\(u_1\\), which follows a uniform distribution on \\([0,1]\\): \\[u_1 = 1 - \\left( 1 + \\frac{ALAE}{\\hat{\\theta}} \\right)^{-\\hat{\\alpha}}.\\] After applying the probability integral transformation to expenses variable, we plot the histogram of Transformed Alae in Figure 14.2. Figure 14.2: Histogram of Transformed Alae After fitting process,the variable loss is also transformed to the variable \\(u_2\\), which follows a uniform distribution on \\([0,1]\\). We plot the histogram of Transformed Loss . As an alternative, the variable loss is transformed to \\(normal\\) \\(scores\\) with the quantile function of standard normal distribution. As we see in Figure 14.3, normal scores of the variable loss are approximately marginally standard normal. Figure 14.3: Histogram of Transformed Loss. The left-hand panel shows the distribution of probability integral transformed losses. The right-hand panel shows the distribution for the corresponding normal scores. R Code for Histograms of Transformed Variables u1 &lt;- 1 - (1 + (alae/b))^(-s) # or u1 &lt;- pparetoII(alae, location=0, scale=b, shape=s) hist(u1, main = &quot;&quot;, xlab = &quot;Histogram of Transformed alae&quot;) scaleloss &lt;- Coef(fitloss)[1] shapeloss &lt;- Coef(fitloss)[2] u2 &lt;- 1 - (1 + (loss/scaleloss))^(-shapeloss) par(mfrow = c(1, 2)) hist(u2, main = &quot;&quot;, xlab = &quot;Histogram of Transformed Loss&quot;) hist(qnorm(u2), main = &quot;&quot;, xlab = &quot;Histogram of qnorm(Loss)&quot;) 14.4.4 Joint Modeling with Copula Function Before jointly modeling losses and expenses, we draw the scatterplot of transformed variables \\((u_1, u_2)\\) and the scatterplot of normal scores in Figure 14.4. Then we calculate the Spearman’s rho between these two uniform random variables. Figure 14.4: Left: Scatter plot for transformed variables. Right:Scatter plot for normal scores R Code for Scatter Plots and Correlation par(mfrow = c(1, 2)) plot(u1, u2, cex = 0.5, xlim = c(-0.1,1.1), ylim = c(-0.1,1.1), xlab = &quot;Transformed Alae&quot;, ylab = &quot;Transformed Loss&quot;) plot(qnorm(u1), qnorm(u2)) cor(u1, u2, method = &quot;spearman&quot;) Output: [1] 0.451872 Scatter plots and Spearman’s rho correlation value (0.451) shows us there is a positive dependency between these two uniform random variables. It is more clear to see the relationship with normal scores in the second graph. To learn more details about normal scores and their applications in copula modeling, see (Joe 2014). \\((U_1, U_2)\\), (\\(U_1 = F_1(ALAE)\\) and \\(U_2=F_2(LOSS)\\)), is fit to Frank’s copula with maximum likelihood method. R Code for Modeling with Frank Copula uu = cbind(u1,u2) frank.cop &lt;- archmCopula(&quot;frank&quot;, param= c(5), dim = 2) fit.ml &lt;- fitCopula(frank.cop, uu, method=&quot;ml&quot;, start=c(0.4)) summary(fit.ml) Output: Call: fitCopula(copula, data = data, method = &quot;ml&quot;, start = ..2) Fit based on &quot;maximum likelihood&quot; and 1500 2-dimensional observations. Copula: frankCopula param 3.114 The maximized loglikelihood is 172.6 Convergence problems: code is 52 see ?optim. Call: fitCopula(copula, data = data, method = &quot;ml&quot;, start = ..2) Fit based on &quot;maximum likelihood&quot; and 1500 2-dimensional observations. Frank copula, dim. d = 2 Estimate Std. Error param 3.114 NA The maximized loglikelihood is 172.6 Convergence problems: code is 52 see ?optim. Number of loglikelihood evaluations: function gradient 45 45 The fitted model implies that losses and expenses are positively dependent and their dependence is significant. We use the fitted parameter to update the Frank’s copula. The Spearman’s correlation corresponding to the fitted copula parameter(3.114) is calculated with the rho function. In this case, the Spearman’s correlation coefficient is 0.462, which is very close to the sample Spearman’s correlation coefficient; 0.452. R Code for Spearman’s Correlation Using Frank’s Copula (param = fit.ml@estimate) frank.cop &lt;- archmCopula(&quot;frank&quot;, param= param, dim = 2) rho(frank.cop) Output : [1] 0.4622722 To visualize the fitted Frank’s copula, the distribution function and density function perspective plots are drawn in Figure 14.5. Figure 14.5: Left: Plot for distribution function for Franks Copula. Right:Plot for density function for Franks Copula R Code for Frank’s Copula Plots par(mar=c(3.2,3,.2,.2),mfrow=c(1,2)) persp(frank.cop, pCopula, theta=50, zlab=&quot;C(u,v)&quot;, xlab =&quot;u&quot;, ylab=&quot;v&quot;, cex.lab=1.3) persp(frank.cop, dCopula, theta=0, zlab=&quot;c(u,v)&quot;, xlab =&quot;u&quot;, ylab=&quot;v&quot;, cex.lab=1.3) Frank’s copula models positive dependence for this data set, with \\(\\theta=3.114\\). For Frank’s copula, the dependence is related to values of \\(\\theta\\). That is: \\(\\theta=0\\): independent copula \\(\\theta&gt;0\\): positive dependence \\(\\theta&lt;0\\): negative dependence 14.5 Types of Copulas In this section, you learn how to: Define the basic families of the copula functions Calculate the association coefficients by the help of copula functions There are several families of copulas have been described in the literature. Two main families of the copula families are the Archimedian and Elliptical copulas. 14.5.1 Elliptical Copulas Elliptical copulas are constructed from elliptical distributions. This copula decompose (multivariate) elliptical distributions into their univariate elliptical marginal distributions by Sklar’s theorem (Hofert et al. 2018). Properties of elliptical copulas are typically obtained from the properties of corresponding elliptical distributions (Hofert et al. 2018). For example, the normal distribution is a special type of elliptical distribution. To introduce the elliptical class of copulas, we start with the familiar multivariate normal distribution with probability density function \\[\\phi_N (\\mathbf{z})= \\frac{1}{(2 \\pi)^{p/2}\\sqrt{\\det \\boldsymbol \\Sigma}} \\exp\\left( -\\frac{1}{2} \\mathbf{z}^{\\prime} \\boldsymbol \\Sigma^{-1}\\mathbf{z}\\right).\\] Here, \\(\\boldsymbol \\Sigma\\) is a correlation matrix, with ones on the diagonal. Let \\(\\Phi\\) and \\(\\phi\\) denote the standard normal distribution and density functions. We define the Gaussian (normal) copula density function as \\[{c}_N(u_1, \\ldots, u_p) = \\phi_N \\left(\\Phi^{-1}(u_1), \\ldots, \\Phi^{-1}(u_p) \\right) \\prod_{j=1}^p \\frac{1}{\\phi(\\Phi^{-1}(u_j))}.\\] As with other copulas, the domain is the unit cube \\([0,1]^p\\). Specifically, a \\(p\\)-dimensional vector \\({z}\\) has an \\({elliptical}\\) \\({distribution}\\) if the density can be written as \\[h_E (\\mathbf{z})= \\frac{k_p}{\\sqrt{\\det \\boldsymbol \\Sigma}} g_p \\left( \\frac{1}{2} (\\mathbf{z}- \\boldsymbol \\mu)^{\\prime} \\boldsymbol \\Sigma^{-1}(\\mathbf{z}- \\boldsymbol \\mu) \\right).\\] We will use elliptical distributions to generate copulas. Because copulas are concerned primarily with relationships, we may restrict our considerations to the case where \\(\\mu = \\mathbf{0}\\) and \\(\\boldsymbol \\Sigma\\) is a correlation matrix. With these restrictions, the marginal distributions of the multivariate elliptical copula are identical; we use \\(H\\) to refer to this marginal distribution function and \\(h\\) is the corresponding density. This marginal density is \\(h(z) = k_1 g_1(z^2/2).\\) We are now ready to define the \\(elliptical\\) \\(copula\\), a function defined on the unit cube \\([0,1]^p\\) as \\[{c}_E(u_1, \\ldots, u_p) = h_E \\left(H^{-1}(u_1), \\ldots, H^{-1}(u_p) \\right) \\prod_{j=1}^p \\frac{1}{h(H^{-1}(u_j))}.\\] In the elliptical copula family, the function \\(g_p\\) is known as a generator in that it can be used to generate alternative distributions. \\[ \\small\\begin{array}{lc} \\hline &amp; Generator \\\\ Distribution &amp; \\mathrm{g}_p(x) \\\\ \\hline \\text{Normal distribution} &amp; e^{-x}\\\\ \\text{t-distribution with r degrees of freedom} &amp; (1+2x/r)^{-(p+r)/2}\\\\ \\text{Cauchy} &amp; (1+2x)^{-(p+1)/2}\\\\ \\text{Logistic} &amp; e^{-x}/(1+e^{-x})^2\\\\ \\text{Exponential power} &amp; \\exp(-rx^s)\\\\ \\hline \\end{array} \\] Table 14.6 : Distribution and Generator Functions (\\(\\mathrm{g}_p(x)\\)) for Selected Elliptical Copulas Most empirical work focuses on the normal copula and \\(t\\)-copula. That is, \\(t\\)-copulas are useful for modeling the dependency in the tails of bivariate distributions, especially in financial risk analysis applications. The \\(t\\)-copulas with same association parameter in varying the degrees of freedom parameter show us different tail dependency structures. For more information on about \\(t\\)-copulas readers can see (Joe 2014), (Hofert et al. 2018). 14.5.2 Archimedian Copulas This class of copulas are constructed from a \\(generator\\) function,which is \\(\\mathrm{g}(\\cdot)\\) is a convex, decreasing function with domain [0,1] and range \\([0, \\infty)\\) such that \\(\\mathrm{g}(0)=0\\). Use \\(\\mathrm{g}^{-1}\\) for the inverse function of \\(\\mathrm{g}\\). Then the function \\[\\mathrm{C}_{\\mathrm{g}}(u_1, \\ldots, u_p) = \\mathrm{g}^{-1} \\left(\\mathrm{g}(u_1)+ \\cdots + \\mathrm{g}(u_p) \\right)\\] is said to be an Archimedean copula. The function \\(\\mathrm{g}\\) is known as the generator of the copula \\(\\mathrm{C}_{\\mathrm{g}}\\). For bivariate case; \\(p=2\\) , Archimedean copula function can be written by the function \\[\\mathrm{C}_{\\mathrm{g}}(u_1, \\, u_2) = \\mathrm{g}^{-1} \\left(\\mathrm{g}(u_1) + \\mathrm{g}(u_2) \\right).\\] Some important special cases of Archimedean copulas are Frank copula, Clayton/Cook-Johnson copula, Gumbel/Hougaard copula. This copula classes are derived from different generator functions. We can remember that we mentioned about Frank’s copula with details in Section 14.3 and in Section 14.4. Here we will continue to express the equations for Clayton copula and Gumbel/Hougaard copula. 14.5.2.1 Clayton Copula For \\(p=2\\), the Clayton copula is parameterized by \\(\\theta \\in [-1,\\infty)\\) is defined by \\[C_{\\theta}^C(u)=\\max\\{u_1^{-\\theta}+u_2^{-\\theta}-1,0\\}^{1/\\theta}, \\quad u\\in[0,1]^2.\\] This is a bivariate distribution function of Clayton copula defined in unit square \\([0,1]^2.\\) The range of dependence is controlled by the parameter \\(\\theta\\) as the same as Frank copula. 14.5.2.2 Gumbel-Hougaard copula The Gumbel-Hougaarg copula is parametrized by \\(\\theta \\in [1,\\infty)\\) and defined by \\[C_{\\theta}^{GH}(u)=\\exp\\left(-\\left(\\sum_{i=1}^2 (-\\log u_i)^{\\theta}\\right)^{1/\\theta}\\right), \\quad u\\in[0,1]^2.\\] Readers seeking deeper background on Archimedean copulas can see Joe (2014), Frees and Valdez (1998), and Genest and Mackay (1986). 14.5.3 Properties of Copulas 14.5.3.1 Bounds on Association Like all multivariate distribution functions, copulas are bounded. The Fr\\(&#39;{e}\\)chet-Hoeffding bounds are \\[\\max( u_1 +\\cdots+ u_p + p -1, 0) \\leq \\mathrm{C}(u_1, \\ldots, u_p) \\leq \\min (u_1, \\ldots,u_p).\\] To see the right-hand side of the equation, note that \\[\\mathrm{C}(u_1,\\ldots, u_p) = \\Pr(U_1 \\leq u_1, \\ldots, U_p \\leq u_p) \\leq \\Pr(U_j \\leq u_j)\\], for \\(j=1,\\ldots,p\\). The bound is achieved when \\(U_1 = \\cdots = U_p\\). To see the left-hand side when \\(p=2\\), consider \\(U_2=1-U_1\\). In this case, if \\(1-u_2 &lt; u_1\\) then \\(\\Pr(U_1 \\leq u_1, U_2 \\leq u_2) = \\Pr ( 1-u_2 \\leq U_1 &lt; u_1) =u_1+u_2-1.\\) (Nelson 1997) The product copula is \\(\\mathrm{C}(u_1,u_2)=u_1u_2\\) is the result of assuming independence between random variables. The lower bound is achieved when the two random variables are perfectly negatively related (\\(U_2=1-U_1\\)) and the upper bound is achieved when they are perfectly positively related (\\(U_2=U_1\\)). We can see The Frechet-Hoeffding bounds for two random variables in the Figure 14.6. Figure 14.6: Perfect Positive and Perfect negative dependence plots R Code for Frechet-Hoeffding Bounds for Two Random Variables library(copula) n&lt;-100 set.seed(1980) U&lt;-runif(n) par(mfrow=c(1, 2)) plot(cbind(U,1-U), xlab=quote(U[1]), ylab=quote(U[2]),main=&quot;Perfect Negative Dependency&quot;) # W for p=2 plot (cbind(U,U), xlab=quote(U[1]),ylab=quote(U[2]),main=&quot;Perfect Positive Dependency&quot;) #M for p=2 14.5.3.2 Measures of Association Schweizer and Wolff (1981) established that the copula accounts for all the dependence between two random variables, \\(Y_1\\) and \\(Y_2\\), in the following sense. Consider m\\(_1\\) and m\\(_2\\), strictly increasing functions. Thus, the manner in which \\(Y_1\\) and \\(Y_2\\) “move together” is captured by the copula, regardless of the scale in which each variable is measured. Schweizer and Wolff also showed the two standard nonparametric measures of association could be expressed solely in terms of the copula function. Spearman’s correlation coefficient is given by \\[= 12 \\int \\int \\left\\{\\mathrm{C}(u,v) - uv \\right\\} du dv.\\] Kendall’s tau is given by \\[= 4 \\int \\int \\mathrm{C}(u,v)d\\mathrm{C}(u,v) - 1 .\\] For these expressions, we assume that \\(Y_1\\) and \\(Y_2\\) have a jointly continuous distribution function. Further, the definition of Kendall’s tau uses an independent copy of (\\(Y_1\\), \\(Y_2\\)), labeled (\\(Y_1^{\\ast}\\), \\(Y_2^{\\ast}\\)), to define the measure of “concordance.” the widely used Pearson correlation depends on the margins as well as the copula. Because it is affected by non-linear changes of scale. 14.5.3.3 Tail Dependency There are some applications in which it is useful to distinguish by the part of the distribution in which the association is strongest. For example, in insurance it is helpful to understand association among the largest losses, that is, association in the right tails of the data. To capture this type of dependency, we use the right-tail concentration function. The function is \\[R(z) = \\frac{\\Pr(U_1 &gt;z, U_2 &gt; z)}{1-z} =\\Pr(U_1 &gt; z | U_2 &gt; z) =\\frac{1 - 2z + \\mathrm{C}(z,z)}{1-z} .\\] From this equation , \\(R(z)\\) will equal to \\(z\\) under independence. Joe (1997) uses the term “upper tail dependence parameter” for \\(R = \\lim_{z \\rightarrow 1} R(z)\\). Similarly, the left-tail concentration function is \\[L(z) = \\frac{\\Pr(U_1 \\leq z, U_2 \\leq z)}{z}=\\Pr(U_1 \\leq z | U_2 \\leq z) =\\frac{ \\mathrm{C}(z,z)}{1-z}.\\] Tail dependency concentration function captures the probability of two random variables both catching up extreme values. We calculate the left and right tail concentration functions for four different types of copulas; Normal, Frank,Gumbel and t copula. After getting tail concentration functions for each copula, we show concentration function’s values for these four copulas in Table 14.7. As in Venter (2002), we show \\(L(z)\\) for \\(z\\leq 0.5\\) and \\(R(z)\\) for \\(z&gt;0.5\\) in the tail dependence plot in Figure 14.7. We interpret the tail dependence plot, to mean that both the Frank and Normal copula exhibit no tail dependence whereas the \\(t\\) and the Gumbel may do so. The \\(t\\) copula is symmetric in its treatment of upper and lower tails. \\[ {\\small \\begin{matrix} \\begin{array}{l|rr} \\hline \\text{Copula} &amp; \\text{Lower} &amp; \\text{Upper} \\\\ \\hline \\text{Frank} &amp; 0 &amp; 0 \\\\ \\text{Gumbel} &amp; 0 &amp; 0.74 \\\\ \\text{Normal} &amp; 0 &amp; 0 \\\\ \\text{t} &amp; 0.10 &amp; 0.10 \\\\ \\hline \\end{array} \\end{matrix}} \\] Table 14.7 : Tail concentration function values for different copulas R Code for Tail Copula Functions for Different Copulas library(copula) U1 = seq(0,0.5, by=0.002) U2 = seq(0.5,1, by=0.002) U = rbind(U1, U2) TailFunction &lt;- function(Tailcop) { lowertail &lt;- pCopula(cbind(U1,U1), Tailcop)/U1 uppertail &lt;- (1-2*U2 +pCopula(cbind(U2,U2), Tailcop))/(1-U2) jointtail &lt;- rbind(lowertail,uppertail) } Tailcop1 &lt;- archmCopula(family = &quot;frank&quot;, param= c(0.05), dim = 2) Tailcop2 &lt;- archmCopula(family = &quot;gumbel&quot;,param = 3) Tailcop3 &lt;- ellipCopula(&quot;normal&quot;, param = c(0.25),dim = 2, dispstr = &quot;un&quot;) Tailcop4 &lt;- ellipCopula(&quot;t&quot;, param = c(0.25),dim = 2, dispstr = &quot;un&quot;, df=5) jointtail1 &lt;- TailFunction(Tailcop1) jointtail2 &lt;- TailFunction(Tailcop2) jointtail3 &lt;- TailFunction(Tailcop3) jointtail4 &lt;- TailFunction(Tailcop4) tailIndex(Tailcop1) tailIndex(Tailcop2) tailIndex(Tailcop3) tailIndex(Tailcop4) Figure 14.7: Tail dependence plots R Code for Tail Dependence Plots for Different Copulas plot(U,jointtail1, cex=.2, xlim=c(0,1),ylab=&quot;Tail Dependence&quot;, ylim=c(0,1)) lines(U,jointtail2, type=&quot;p&quot;,lty=1, cex=.2) lines(U,jointtail3, type=&quot;p&quot;,lty=1, cex=.2) lines(U,jointtail4, type=&quot;p&quot;,lty=1, cex=.2) text(0.75, 0.1, &quot;Frank&quot;, cex=1.3) #1 text(0.1, 0.8, &quot;Gumbel&quot;, cex=1.3) #2 text(0.25, 0.1, &quot;normal&quot;, cex=1.3) #3 arrows(.17, 0.1, .07, 0.12,code=2, angle=20, length=0.1) text(0.9, 0.4, &quot;t with 5 df&quot;, cex=1.3) #4 Show Quiz Solution 14.6 Why is Dependence Modeling Important? Dependence Modeling is important because it enables us to understand the dependence structure by defining the relationship between variables in a dataset. In insurance, ignoring dependence modeling may not impact pricing but could lead to misestimation of required capital to cover losses. For instance, from Section 14.4 , it is seen that there was a positive relationship between Loss and Expense. This means that, if there is a large loss then we expect expenses to be large as well and ignoring this relationship could lead to misestimation of reserves. To illustrate the importance of dependence modeling, we refer you back to Portfolio Management example in Chapter 6 that assumed that the property and liability risks are independent. Here, we incorporate dependence by allowing the 4 lines of business to depend on one another through a Gaussian copula. In Table 14.8, we show that dependence affects the portfolio quantiles (\\(VaR_q\\)), although not the expect value. For instance , the \\(VaR_{0.99}\\) for total risk which is the amount of capital required to ensure, with a \\(99\\%\\) degree of certainty that the firm does not become technically insolvent is higher when we incorporate dependence. This leads to less capital being allocated when dependence is ignored and can cause unexpected solvency problems. \\[ {\\small \\begin{matrix} \\begin{array}{l|rrrr} \\hline \\text{Independent} &amp;\\text{Expected} &amp; VaR_{0.9} &amp; VaR_{0.95} &amp; VaR_{0.99} \\\\ &amp;\\text{Value} &amp; &amp; &amp; \\\\ \\hline \\text{Retained} &amp; 269 &amp; 300 &amp; 300 &amp; 300 \\\\ \\text{Insurer} &amp; 2,274 &amp; 4,400 &amp; 6,173 &amp; 11,859 \\\\ \\text{Total} &amp; 2,543 &amp; 4,675 &amp; 6,464 &amp; 12,159 \\\\ \\hline \\text{Gaussian Copula}&amp;\\text{Expected}&amp; VaR_{0.9} &amp; VaR_{0.95} &amp; VaR_{0.99} \\\\ &amp;\\text{Value} &amp; &amp; &amp; \\\\ \\hline \\text{Retained} &amp; 269 &amp; 300 &amp; 300 &amp; 300 \\\\ \\text{Insurer} &amp; 2,340 &amp; 4,988 &amp; 7,339 &amp; 14,905 \\\\ \\text{Total} &amp; 2,609 &amp; 5,288 &amp; 7,639 &amp; 15,205 \\\\ \\hline \\end{array} \\end{matrix}} \\] Table 14.8 : Results for portfolio expected value and quantiles (\\(VaR_q\\)) R Code for Simulation Using Gaussian Copula # For the gamma distributions, use alpha1 &lt;- 2; theta1 &lt;- 100 alpha2 &lt;- 2; theta2 &lt;- 200 # For the Pareto distributions, use alpha3 &lt;- 2; theta3 &lt;- 1000 alpha4 &lt;- 3; theta4 &lt;- 2000 # Deductibles d1 &lt;- 100 d2 &lt;- 200 # Simulate the risks nSim &lt;- 10000 #number of simulations set.seed(2017) #set seed to reproduce work X1 &lt;- rgamma(nSim,alpha1,scale = theta1) X2 &lt;- rgamma(nSim,alpha2,scale = theta2) # For the Pareto Distribution, use library(VGAM) X3 &lt;- rparetoII(nSim,scale=theta3,shape=alpha3) X4 &lt;- rparetoII(nSim,scale=theta4,shape=alpha4) # Portfolio Risks S &lt;- X1 + X2 + X3 + X4 Sretained &lt;- pmin(X1,d1) + pmin(X2,d2) Sinsurer &lt;- S - Sretained # Expected Claim Amounts ExpVec &lt;- t(as.matrix(c(mean(Sretained),mean(Sinsurer),mean(S)))) colnames(ExpVec) &lt;- c(&quot;Retained&quot;, &quot;Insurer&quot;,&quot;Total&quot;) round(ExpVec,digits=2) # Quantiles quantMat &lt;- rbind( quantile(Sretained, probs=c(0.80, 0.90, 0.95, 0.99)), quantile(Sinsurer, probs=c(0.80, 0.90, 0.95, 0.99)), quantile(S , probs=c(0.80, 0.90, 0.95, 0.99))) rownames(quantMat) &lt;- c(&quot;Retained&quot;, &quot;Insurer&quot;,&quot;Total&quot;) round(quantMat,digits=2) plot(density(S), main=&quot;Density of Total Portfolio Risk S&quot;, xlab=&quot;S&quot;) ### Normal Copula ## library(VGAM) library(copula) library(GB2) library(statmod) library(numDeriv) set.seed(2017) parm&lt;-c(0.5,0.5,0.5,0.5,0.5,0.5) nc &lt;- normalCopula(parm, dim = 4, dispstr = &quot;un&quot;) mcc &lt;- mvdc(nc, margins = c(&quot;gamma&quot;, &quot;gamma&quot;,&quot;paretoII&quot;,&quot;paretoII&quot;), paramMargins = list(list(scale = theta1, shape=alpha1), list(scale = theta2, shape=alpha2), list(scale = theta3, shape=alpha3), list(scale = theta4, shape=alpha4))) X &lt;- rMvdc(nSim, mvdc = mcc) X1&lt;-X[,1] X2&lt;-X[,2] X3&lt;-X[,3] X4&lt;-X[,4] # Portfolio Risks S &lt;- X1 + X2 + X3 + X4 Sretained &lt;- pmin(X1,d1) + pmin(X2,d2) Sinsurer &lt;- S - Sretained # Expected Claim Amounts ExpVec &lt;- t(as.matrix(c(mean(Sretained),mean(Sinsurer),mean(S)))) colnames(ExpVec) &lt;- c(&quot;Retained&quot;, &quot;Insurer&quot;,&quot;Total&quot;) round(ExpVec,digits=2) # Quantiles quantMat &lt;- rbind( quantile(Sretained, probs=c(0.80, 0.90, 0.95, 0.99)), quantile(Sinsurer, probs=c(0.80, 0.90, 0.95, 0.99)), quantile(S , probs=c(0.80, 0.90, 0.95, 0.99))) rownames(quantMat) &lt;- c(&quot;Retained&quot;, &quot;Insurer&quot;,&quot;Total&quot;) round(quantMat,digits=2) plot(density(S), main=&quot;Density of Total Portfolio Risk S&quot;, xlab=&quot;S&quot;) Show Quiz Solution 14.7 Further Resources and Contributors Contributors Edward W. (Jed) Frees and Nii-Armah Okine, University of Wisconsin-Madison, and Emine Selin Sarıdaş, Mimar Sinan University, are the principal authors of the initial version of this chapter. Email: jfrees@bus.wisc.edu for chapter comments and suggested improvements. TS 14.A. Other Classic Measures of Scalar Associations TS 14.A.1. Blomqvist’s Beta Blomqvist (1950) developed a measure of dependence now known as Blomqvist’s beta, also called the median concordance coefficient and the medial correlation coefficient. Using distribution functions, this parameter can be expressed as \\[\\begin{equation*} \\beta = 4F\\left(F^{-1}_X(1/2),F^{-1}_Y(1/2) \\right) - 1. \\end{equation*}\\] That is, first evaluate each marginal at its median (\\(F^{-1}_X(1/2)\\) and \\(F^{-1}_Y(1/2)\\), respectively). Then, evaluate the bivariate distribution function at the two medians. After rescaling (multiplying by 4 and subtracting 1), the coefficient turns out to have a range of \\([-1,1]\\), where 0 occurs under independence. Like Spearman’s rho and Kendall’s tau, an estimator based on ranks is easy to provide. First write \\(\\beta = 4C(1/2,1/2)-1 = 2\\Pr((U_1-1/2)(U_2-1/2))-1\\) where \\(U_1, U_2\\) are uniform random variables. Then, define \\[\\begin{equation*} \\hat{\\beta} = \\frac{2}{n} \\sum_{i=1}^n I\\left( (R(X_{i})-\\frac{n+1}{2})(R(Y_{i})-\\frac{n+1}{2}) \\ge 0 \\right)-1 . \\end{equation*}\\] See, for example, (Joe 2014), page 57 or (Hougaard 2000), page 135, for more details. Because Blomqvist’s parameter is based on the center of the distribution, it is particularly useful when data are censored; in this case, information in extreme parts of the distribution are not always reliable. How does this affect a choice of association measures? First, recall that association measures are based on a bivariate distribution function. So, if one has knowledge of a good approximation of the distribution function, then calculation of an association measure is straightforward in principle. Second, for censored data, bivariate extensions of the univariate Kaplan-Meier distribution function estimator are available. For example, the version introduced in (Dabrowska 1988) is appealing. However, because of instances when large masses of data appear at the upper range of the data, this and other estimators of the bivariate distribution function are unreliable. This means that, summary measures of the estimated distribution function based on Spearman’s rho or Kendall’s tau can be unreliable. For this situation, Blomqvist’s beta appears to be a better choice as it focuses on the center of the distribution. (Hougaard 2000), Chapter 14, provides additional discussion. You can obtain the Blomqvist’s beta, using the betan() function from the copula library in R. From below, \\(\\beta=0.3\\) between the Coverage rating variable in millions of dollars and Claim amount variable in dollars. R Code for Blomqvist’s Beta ### Blomqvist&#39;s beta correlation between Claim and Coverage ### library(copula) n&lt;-length(Claim) U&lt;-cbind(((n+1)/n*pobs(Claim)),((n+1)/n*pobs(Coverage))) beta&lt;-betan(U, scaling=FALSE) round(beta,2) Output: [1] 0.3 ### Blomqvist&#39;s beta correlation between Claim and log(Coverage) ### n&lt;-length(Claim) Fx&lt;-cbind(((n+1)/n*pobs(Claim)),((n+1)/n*pobs(log(Coverage)))) beta&lt;-betan(Fx, scaling=FALSE) round(beta,2) Output: [1] 0.3 In addition,to show that the Blomqvist’s beta is invariate under strictly increasing transformations , \\(\\beta=0.3\\) between the Coverage rating variable in logarithmic millions of dollars and Claim amount variable in dollars. TS 14.A.2. Nonparametric Approach Using Spearman Correlation with Tied Ranks For the first variable, the average rank of observations in the \\(s\\)th row is \\[\\begin{equation*} r_{1s} = n_{m_1\\centerdot}+ \\cdots+ n_{s-1,\\centerdot}+ \\frac{1}{2} \\left(1+ n_{s\\centerdot}\\right) \\end{equation*}\\] and similarly \\(r_{2t} = \\frac{1}{2} \\left[(n_{\\centerdot m_1}+ \\cdots+ n_{\\centerdot,s-1}+1)+ (n_{\\centerdot m_1}+ \\cdots+ n_{\\centerdot s})\\right]\\). With this, we have Spearman’s rho with tied rank is \\[\\begin{equation*} \\hat{\\rho}_S = \\frac{\\sum_{s=m_1}^{m_2} \\sum_{t=m_1}^{m_2} n_{st}(r_{1s} - \\bar{r})(r_{2t} - \\bar{r})} {\\left[\\sum_{s=m_1}^{m_2}n_{s \\centerdot}(r_{1s} - \\bar{r})^2 \\sum_{t=m_1}^{m_2} n_{\\centerdot t}(r_{2t} - \\bar{r})^2 \\right]^2} \\end{equation*}\\] where the average rank is \\(\\bar{r} = (n+1)/2\\). Click to Show Proof for Special Case: Binary Data. Special Case: Binary Data. Here, \\(m_1=0\\) and \\(m_2=1\\). For the first variable ranks, we have \\(r_{10} = (1+n_{0\\centerdot})/2\\) and \\(r_{11} = (n_{0\\centerdot}+1+n)/2\\). Thus, \\(r_{10} -\\bar{r}= (n_{0\\centerdot}-n)/2\\) and \\(r_{11}-\\bar{r} = n_{0\\centerdot}/2\\). This means that we have \\(\\sum_{s=0}^{1}n_{s\\centerdot}(r_{1s} - \\bar{r})^2 = n (n-n_{0\\centerdot})n_{0\\centerdot}/4\\) and similarly for the second variable. For the numerator, we have \\[\\begin{eqnarray*} \\sum_{s=0}^{1} \\sum_{t=0}^{1} &amp;&amp; n_{st}(r_{1s} - \\bar{r})(r_{2t} - \\bar{r})\\\\ &amp;=&amp; n_{00} \\frac{n_{0\\centerdot}-n}{2} \\frac{n_{\\centerdot 0}-n}{2} +n_{01} \\frac{n_{0\\centerdot}-n}{2} \\frac{n_{\\centerdot 0}}{2} +n_{10} \\frac{n_{0\\centerdot}}{2} \\frac{n_{\\centerdot 0}-n}{2} +n_{11} \\frac{n_{0\\centerdot}}{2} \\frac{n_{\\centerdot 0}}{2} \\\\ &amp;=&amp; \\frac{1}{4}(n_{00} (n_{0\\centerdot}-n) (n_{\\centerdot 0}-n) +(n_{0\\centerdot}-n_{00}) (n_{0\\centerdot}-n)n_{\\centerdot 0} \\\\ &amp;&amp; ~ ~ ~ +(n_{\\centerdot 0}-n_{00}) n_{0\\centerdot}(n_{\\centerdot 0}-n) +(n-n_{\\centerdot 0}-n_{0\\centerdot}+n_{00}) n_{0\\centerdot}n_{\\centerdot 0} ) \\\\ &amp;=&amp; \\frac{1}{4}(n_{00} n^2 - n_{0\\centerdot} (n_{0\\centerdot}-n)n_{\\centerdot 0} \\\\ &amp;&amp; ~ ~ ~ +n_{\\centerdot 0} n_{0\\centerdot}(n_{\\centerdot 0}-n) +(n-n_{\\centerdot 0}-n_{0\\centerdot}) n_{0\\centerdot}n_{\\centerdot 0} ) \\\\ &amp;=&amp; \\frac{1}{4}(n_{00} n^2 - n_{0\\centerdot}n_{\\centerdot 0} (n_{0\\centerdot}-n +n_{\\centerdot 0}-n +n-n_{\\centerdot 0}-n_{0\\centerdot}) \\\\ &amp;=&amp; \\frac{n}{4}(n n_{00} - n_{0\\centerdot}n_{\\centerdot 0}) . \\end{eqnarray*}\\] This yields \\[\\begin{eqnarray*} \\hat{\\rho}_S &amp;=&amp; \\frac{n(n n_{00} - n_{0\\centerdot}n_{\\centerdot 0})} {4\\sqrt{(n (n-n_{0\\centerdot})n_{0\\centerdot}/4)(n (n-n_{\\centerdot 0})n_{\\centerdot 0}/4)}} \\\\ &amp;=&amp; \\frac{n n_{00} - n_{0\\centerdot}n_{\\centerdot 0}} {\\sqrt{ n_{0\\centerdot} n_{\\centerdot 0}(n-n_{0\\centerdot}) (n-n_{\\centerdot 0})}} \\\\ &amp;=&amp; \\frac{n_{00} - n (1-\\hat{\\pi}_X)(1- \\hat{\\pi}_Y)} {\\sqrt{\\hat{\\pi}_X(1-\\hat{\\pi}_X)\\hat{\\pi}_Y(1-\\hat{\\pi}_Y) }} \\end{eqnarray*}\\] where \\(\\hat{\\pi}_X = (n-n_{0\\centerdot})/n\\) and similarly for \\(\\hat{\\pi}_Y\\). Note that this is same form as the Pearson measure. From this, we see that the joint count \\(n_{00}\\) drives this association measure. You can obtain the ties-corrected Spearman correlation statistic \\(r_S\\) using the cor() function in R and selecting the spearman method. From below \\(\\hat{\\rho}_S=-0.09\\). R Code for Ties-corrected Spearman Correlation rs_ties&lt;-cor(AlarmCredit,NoClaimCredit, method = c(&quot;spearman&quot;)) round(rs_ties,2) Output: [1] -0.09 Bibliography "],
["C-AppA.html", "Chapter 15 Apéndice A: Revisión de la Inferencia Estadística 15.1 Conceptos Básicos 15.2 Estimación Puntual y Propiedades 15.3 Estimación de Intervalo 15.4 Pruebas de Hipótesis", " Chapter 15 Apéndice A: Revisión de la Inferencia Estadística Vista previa del capítulo. El apéndice ofrece una visión general de los conceptos y métodos relacionados con la inferencia estadística sobre la población de interés, utilizando una muestra aleatoria de observaciones de la población. En el apéndice, la Sección 15.1 presenta los conceptos básicos relacionados con la población y la muestra utilizada para hacer la inferencia. La sección 15.2 presenta los métodos utilizados habitualmente para la estimación puntual de las características de la población. La sección 15.3 muestra la estimación de intervalos que tiene en cuenta la incertidumbre en la estimación, debido al uso de una muestra aleatoria de la población. La sección 15.4 presenta el concepto de prueba de hipótesis con el propósito de seleccionar variables y modelos. 15.1 Conceptos Básicos En esta sección, aprenderemos los siguientes conceptos relacionados con la inferencia estadística. Muestreo aleatorio de una población que se puede resumir usando una lista de unidades o individuos dentro de la población Distribuciones de muestreo que caracterizan las distribuciones de posibles resultados para un estadístico calculada a partir de una muestra aleatoria El teorema central del límite que guía la distribución de la media de una muestra aleatoria de la población. La inferencia estadística es el proceso de sacar conclusiones sobre las características de un gran conjunto de ítems/individuos (es decir, la población), utilizando un conjunto representativo de datos (por ejemplo, una muestra aleatoria) de una lista de ítems o individuos de la población que se pueden muestrear. Si bien el proceso tiene un amplio espectro de aplicaciones en diversas áreas, que incluyen ciencia, ingeniería, salud, ciencias sociales y economía, la inferencia estadística es importante para las compañías de seguros que usan datos de sus titulares de pólizas existentes para hacer inferencia sobre las características (p. ej., perfiles de riesgo) de un segmento específico de clientes objetivo (es decir, la población) a quienes las compañías de seguros no observan directamente. Mostrar ejemplo empírico usando el Wisconsin Property Fund Ejemplo – Wisconsin Property Fund. Supongamos que hay 1.377 siniestros individuales de la experiencia adquirida en 2010. Mínimo Primer cuartil Mediana Media Tercer cuartil Máximo Desviación estándar Siniestros 1 788 2.250 26.620 6.171 12.920.000 368.030 Siniestros en logaritmos 0 6,670 7,719 7,804 8,728 16,370 1,683 ClaimLev &lt;- read.csv(&quot;Data/CLAIMLEVEL.csv&quot;, header=TRUE) ClaimLevBC10&lt;-subset(ClaimLev,Year==2010); cat(&quot;Sample size: &quot;, nrow(ClaimLevBC10), &quot;\\n&quot;) par(mfrow=c(1, 2)) hist(ClaimLevBC10$Claim, main=&quot;&quot;, xlab=&quot;Siniestros&quot;) hist(log(ClaimLevBC10$Claim), main=&quot;&quot;, xlab=&quot;Siniestros en logarítmos&quot;) Figure 15.1: Distribución de siniestros ## Sample size: 1377 Utilizando la experiencia de siniestros de 2010 (la muestra), el Wisconsin Property Fund puede estar interesado en evaluar la gravedad de todos los siniestros que podrían ocurrir en 2010, 2011, etc. (la población). Este proceso es importante en los contextos de tarificación o modelos predictivos de siniestralidad. Para que dicha inferencia sea válida, debemos suponer que el conjunto de siniestros de 2010 es una muestra aleatoria que es representativa de la población, se puede estimar la distribución muestral del coste promedio del siniestro, de modo que podamos cuantificar el sesgo y la incertidumbre en la estimación debido al uso de una muestra finita. 15.1.1 Muestreo Aleatorio En estadística, se produce un error de muestreo cuando el marco de muestreo, la lista de la que se extrae la muestra, no es una aproximación adecuada de la población de interés. Una muestra debe ser un subconjunto representativo de una población, o universo, de interés. Si la muestra no es representativa, tomar una muestra más grande no elimina el sesgo, ya que el mismo error se repite una y otra vez. Por lo tanto, presentamos el concepto de muestreo aleatorio que da lugar a una simple muestra aleatoria que es representativa de la población. Suponemos que la variable aleatoria \\(X\\) representa una elección de una población con una función de distribución \\(F(\\cdot)\\) con media \\(\\mathrm{E}[X]=\\mu\\) y varianza \\(\\mathrm{Var}[X]=\\mathrm{E}[(X-\\mu)^2]\\), donde \\(E(\\cdot)\\) denota la esperanza de una variable aleatoria. En un muestreo aleatorio, hacemos un total de \\(n\\) sorteos o elecciones representados por \\(X_1, \\ldots, X_n\\), cada uno de ellos no relacionados entre sí (es decir, estadísticamente independientes). Nos referimos a \\(X_1, \\ldots, X_n\\) como una muestra aleatoria (con reemplazo) de \\(F(\\cdot)\\), que toma una forma paramétrica o no paramétrica. Alternativamente, podemos decir que \\(X_1, \\ldots, X_n\\) se distribuyen de forma idéntica e independiente (iid) con la función de distribución \\(F(\\cdot)\\). 15.1.2 Distribución Muestral Usando la muestra aleatoria \\(X_1, \\ldots, X_n\\), estamos interesados en llegar a una conclusión sobre un atributo específico de la distribución de la población \\(F(\\cdot)\\). Por ejemplo, podemos estar interesados en hacer una inferencia sobre la media de la población, denotada \\(\\mu\\). Es natural pensar en la media muestral, \\(\\bar{X} = \\sum_{i = 1}^n X_i\\), como una estimación de la media de la población \\(\\mu\\). Llamamos a la media de la muestra como estadístico calculado a partir de la muestra aleatoria \\(X_1, \\ldots, X_n\\). Otros estadísticos de resumen de uso común incluyen la desviación estándar muestral y los cuantiles muestrales. Cuando se utiliza un estadístico (por ejemplo, la media de la muestra \\(\\bar{X}\\)) para hacer inferencia estadística sobre el atributo de la población (por ejemplo, la media de la población \\(\\mu\\)), la calidad de la inferencia está determinada por el sesgo y la incertidumbre en la estimación, debido al uso de una muestra en lugar de la población. Por lo tanto, es importante estudiar la distribución de un estadístico que cuantifique el sesgo y la variabilidad del estadístico. En particular, la distribución de la media muestral, \\(\\bar {X}\\) (o cualquier otro estadístico), se llama distribución muestral. La distribución muestral depende del proceso de muestreo, el estadístico, el tamaño de la muestra \\(n\\) y la distribución de la población \\(F(\\cdot )\\). El teorema central del límite proporciona la distribución en muestras grandes (muestral) de la media muestral bajo ciertas condiciones. 15.1.3 Teorema Central del Límite En estadística, existen variaciones del teorema central del límite (TCL) que aseguran que, bajo ciertas condiciones, la media de la muestra se acercará a la media de la población con su distribución muestral acercándose a la distribución normal a medida que el tamaño de la muestra tienda a infinito. Exponemos el TCL de Lindeberg - Levy que establece la distribución muestral asintótica de la media de la muestra \\(\\bar{X}\\) calculada usando una muestra aleatoria de una población universal que tiene una distribución \\(F(\\cdot)\\). TCL de Lindeberg–Levy. Sea \\(X_1, \\ldots, X_n\\) una muestra aleatoria de una distribución \\(F(\\cdot)\\) con media \\(\\mu\\) y varianza \\(\\sigma^2&lt;\\infty\\). La diferencia entre la media muestral \\(\\bar{X}\\) y \\(\\mu\\), cuando se multiplica por \\(\\sqrt{n}\\), converge en distribución a una distribución normal a medida que el tamaño de la muestra tiende a infinito. Es decir, \\[\\sqrt{n}(\\bar{X}-\\mu)\\xrightarrow[]{d}N(0,\\sigma).\\] Hay que tener en cuenta que el TCL no requiere una forma paramétrica para \\(F(\\cdot)\\). Con base al TCL, podemos realizar inferencia estadística sobre la media de la población (inferimos, no deducimos). Los tipos de inferencia que podemos realizar incluyen estimación de la población, contraste de hipótesis sobre si una afirmación nula es verdadera y predicción de muestras futuras de la población. 15.2 Estimación Puntual y Propiedades En esta sección, aprendemos cómo estimar parámetros poblacionales utilizando el método de estimación de momentos estimar parámetros poblacionales basados en la estimación de máxima verosimilitud La función de distribución de población \\(F(\\cdot)\\) generalmente se puede caracterizar por un número limitado (finito) de terminos llamados parámetros, en cuyo caso nos referimos a la distribución como una distribución paramétrica. En cambio, en el análisis no paramétrico, los atributos de la distribución muestral no se limitan a un pequeño número de parámetros. Para obtener las características de la población, existen diferentes atributos relacionados con la distribución poblacional \\(F(\\cdot)\\). Dichas medidas incluyen la media, la mediana, los percentiles (es decir, el percentil 95) y la desviación estándar. Dado que estas medidas de resumen no dependen de un parámetro específico, son medidas de resumen no paramétricas. En el análisis paramétrico, por otro lado, podemos suponer familias específicas de distribuciones con parámetros específicos. Por ejemplo, generalmente se piensa que el logaritmo de las cuantías de los siniestros se distribuye normalmente con una media \\(\\mu\\) y una desviación estándar \\(\\sigma\\). Es decir, suponemos que los siniestros tienen una distribución lognormal con parámetros \\(\\mu\\) y \\(\\sigma\\). Alternativamente, las compañías de seguros suelen suponer que la gravedad de un siniestro sigue una distribución gamma con un parámetro de forma \\(\\alpha\\) y un parámetro de escala \\(\\theta\\). Aquí, las distribuciones normal, lognormal y gamma son ejemplos de distribuciones paramétricas. En los ejemplos anteriores, las cuantías \\(\\mu\\), \\(\\sigma\\), \\(\\alpha\\) y \\(\\theta\\) se conocen como parámetros. Para una familia de distribución paramétrica dada, la distribución está determinada únicamente por los valores de los parámetros. A menudo se usa \\(\\theta\\) para denotar un atributo de resumen de la población. En los modelos paramétricos, \\(\\theta\\) puede ser un parámetro o una función de parámetros de una distribución como los parámetros de la media y varianza en la normal. En el análisis no paramétrico, puede tomar la forma de una medida resumen no paramétrica, como la media de la población o la desviación estándar. Supongamos que \\(\\hat {\\theta} = \\hat {\\theta} (X_1, \\ldots, X_n)\\) es una función de la muestra que proporciona una proxy, o una estimación, de \\(\\theta\\). Toda función de la muestra \\(X_1, \\ldots, X_n\\) se conoce como estadístico. Mostrar ejemplo Wisconsin Property Fund - Continuación Ejemplo – Wisconsin Property Fund. La media muestral igual a 7,804 y la desviación estándar de la muestra igual a 1,683 pueden considerarse estimaciones no paramétricas de la media poblacional y la desviación estándar, o como estimaciones paramétricas de \\(\\mu\\) y \\(\\sigma\\) de la distribución normal para un siniestro en logarítmos. Usando los resultados de la distribución lognormal, podemos estimar el coste esperado, es decir la media lognormal, como 10.106,8 (\\(= \\exp (7,804 + 1,683^2/2)\\)). Para los datos del Wisconsin Property Fund, podemos denotar \\(\\hat{\\mu} = 7,804\\) y \\(\\hat{\\sigma} = 1,683\\), con la notación de sombrero (acento circumflejo) que indica una estimación del parámetro basada en el muestra. En particular, dicha estimación se conoce como estimación puntual, una sola aproximación del parámetro correspondiente. Para la estimación puntual, presentamos los dos métodos más utilizados llamados método de estimación de momentos y estimación de máxima verosimilitud. 15.2.1 Método de Estimación de Momentos Antes de definir el método de estimación de momentos, definimos el concepto de momentos. Los momentos son atributos de la población que caracterizan la función de distribución \\(F(\\cdot)\\). Dado una elección aleatoria \\(X\\) de \\(F(\\cdot)\\), la esperanza \\(\\mu_k = \\ mathrm {E} [X^k]\\) se llama momento \\(k\\)-ésimo de \\(X\\), \\(k = 1,2,3, \\ldots\\) Por ejemplo, la media poblacional \\(\\mu\\) es el primer momento. Además, la esperanza \\(\\mathrm{E}[(X-\\mu)^k]\\) se denomina momento central \\(k\\)-ésimo. Por lo tanto, la varianza es el segundo momento central. Usando la muestra aleatoria \\(X_1, \\ldots, X_n\\), podemos construir el momento muestral correspondiente, \\(\\hat {\\mu}_k = (1 / n) \\sum_{i = 1}^n X_i^k\\), para estimar el atributo de población \\(\\mu_k\\). Por ejemplo, hemos utilizado la media muestral \\(\\bar {X}\\) como estimador de la media poblacional \\(\\mu\\). Del mismo modo, el segundo momento central puede estimarse como \\((1 / n) \\sum_{i = 1}^n(X_i- \\bar {X})^2\\). Sin asumir una forma paramétrica para \\(F (\\cdot)\\), los momentos muestrales constituyen estimaciones no paramétricas de los atributos de la población correspondiente. Dicho estimador basado en la coincidencia entre los momentos de la muestra correspondiente y los de la población se llama método de estimador de momentos (MEM). Si bien el MEM funciona de forma natural en un modelo no paramétrico, se puede usar para estimar parámetros cuando se supone una familia de distribución paramétrica específica \\(F(\\cdot)\\). Denotamos por \\(\\boldsymbol{\\theta}=(\\theta_1,\\cdots,\\theta_m)\\) al vector de parámetros correspondiente a una distribución paramétrica \\(F(\\cdot)\\). Dada una familia de distribuciones, habitualmente se conoce las relaciones entre los parámetros y los momentos. En particular, conocemos las formas específicas de las funciones \\(h_1(\\cdot),h_2(\\cdot),\\cdots,h_m(\\cdot)\\) tales que \\(\\mu_1=h_1(\\boldsymbol{\\theta}),\\,\\mu_2=h_2(\\boldsymbol{\\theta}),\\,\\cdots,\\,\\mu_m=h_m(\\boldsymbol{\\theta})\\). Dado el MEM \\(\\hat{\\mu}_1, \\ldots, \\hat{\\mu}_m\\) de la muestra aleatoria, el MEM de los parámetros \\(\\hat{\\theta}_1,\\cdots,\\hat{\\theta}_m\\) se puede obtener resolviendo las ecuaciones \\[\\hat{\\mu}_1=h_1(\\hat{\\theta}_1,\\cdots,\\hat{\\theta}_m);\\] \\[\\hat{\\mu}_2=h_2(\\hat{\\theta}_1,\\cdots,\\hat{\\theta}_m);\\] \\[\\cdots\\] \\[\\hat{\\mu}_m=h_m(\\hat{\\theta}_1,\\cdots,\\hat{\\theta}_m).\\] Mostrar ejemplo Wisconsin Property Fund - Continuación Ejemplo – Wisconsin Property Fund. Supongamos que el coste de los siniestros sigue una distribución lognormal, de modo que el logaritmo del coste de los siniestros sigue una distribución normal. Concretamente supongamos que \\(\\ln (X)\\) tiene una distribución normal con una media \\(\\mu\\) y una varianza \\(\\sigma^2\\), denotada como \\(\\ln(X) \\sim N (\\mu, \\sigma^2)\\) . Es sencillo ver que el MEM \\(\\hat{\\mu}=\\bar{X}\\) y \\(\\hat{\\sigma}=\\sqrt{(1/n)\\sum_{i=1}^n(X_i-\\bar{X})^2}\\). Para el ejemplo del Wisconsin Property Fund, las estimaciones por el método de los momentos son \\(\\hat{\\mu} =7,804\\) y \\(\\hat{\\sigma} = 1,6834\\). 15.2.2 Estimación por Máxima Verosimilitud Cuando \\(F(\\cdot)\\) toma forma paramétrica, habitualmente se usa el método de máxima verosimilitud para estimar los parámetros de la población \\(\\boldsymbol {\\theta}\\). La estimación máximo verosímil se basa en la función de verosimilitud, una función de los parámetros dada la muestra observada. Denotamos por \\(f(x_i| \\boldsymbol {\\theta})\\) a la función de probabilidad de \\(X_i\\) evaluada en \\(X_i = x_i\\) \\((i = 1,2, \\cdots, n)\\) es la función de masa de probabilidad en el caso de una \\(X\\) discreta y la función de densidad de probabilidad en el caso de una \\(X\\) continua. Suponiendo independencia, la función de verosimilitud de \\(\\boldsymbol{\\theta}\\) asociada a la observación \\((X_1,X_2,\\cdots,X_n)=(x_1,x_2,\\cdots,x_n)=\\mathbf{x}\\) se puede escribir como \\[L(\\boldsymbol{\\theta}|\\mathbf{x})=\\prod_{i=1}^nf(x_i|\\boldsymbol{\\theta}),\\] con la correspondiente función de log-verosimilitud dada por \\[l(\\boldsymbol{\\theta}|\\mathbf{x})=\\ln(L(\\boldsymbol{\\theta}|\\mathbf{x}))=\\sum_{i=1}^n\\ln f(x_i|\\boldsymbol{\\theta}).\\] El estimador de máxima verosimilitud (EMV, en inglés MLE) de \\(\\boldsymbol{\\theta}\\) es el conjunto de valores de \\(\\boldsymbol {\\theta}\\) que maximizan la función de verosimilitud (función log-verosimilitud), dada la muestra observada. Es decir, el MLE \\(\\hat {\\boldsymbol {\\theta}}\\) se puede escribir como \\[\\hat{\\boldsymbol{\\theta}}={\\mbox{argmax}}_{\\boldsymbol{\\theta}\\in\\Theta}l(\\boldsymbol{\\theta}|\\mathbf{x}),\\] donde \\(\\Theta\\) es el espacio de parámetros de \\(\\boldsymbol {\\theta}\\) y \\({\\mbox{argmax}}_{\\boldsymbol{\\theta}\\in\\Theta}l(\\boldsymbol{\\theta}|\\mathbf{x})\\) se define como el valor de \\(\\boldsymbol {\\theta}\\) en el cual la función \\(l(\\boldsymbol {\\theta} | \\mathbf {x})\\) alcanza su máximo. Dada la forma analítica de la función de verosimilitud, el MLE se puede obtener tomando la primera derivada de la función de verosimilitud con respecto a \\(\\boldsymbol {\\theta}\\), e igualando los valores de las derivadas parciales a cero. Es decir, los MLE son las soluciones de las siguientes ecuaciones \\[\\frac{\\partial l(\\hat{\\boldsymbol{\\theta}}|\\mathbf{x})}{\\partial\\hat{\\theta}_1}=0;\\] \\[\\frac{\\partial l(\\hat{\\boldsymbol{\\theta}}|\\mathbf{x})}{\\partial\\hat{\\theta}_2}=0;\\] \\[ \\cdots \\] \\[\\frac{\\partial l(\\hat{\\boldsymbol{\\theta}}|\\mathbf{x})}{\\partial\\hat{\\theta}_m}=0,\\] siempre que las segundas derivadas parciales sean negativas. Para los modelos paramétricos, el estimador MLE de los parámetros puede obtenerse analíticamente (por ejemplo, en el caso de distribuciones normales y estimadores lineales) o numéricamente mediante algoritmos iterativos como el método de Newton-Raphson y sus versiones adaptativas (por ejemplo, en el caso de modelos lineales generalizados con una variable de respuesta no normal). Distribución Normal. Supongamos que \\((X_1,X_2,\\cdots,X_n)\\) es una muestra aleatoria de la distribución normal \\(N(\\mu, \\sigma^2)\\). Con una muestra observada \\((X_1,X_2,\\cdots,X_n)=(x_1,x_2,\\cdots,x_n)\\), podemos escribir la función de verosimilitud de \\(\\mu,\\sigma^2\\) como \\[L(\\mu,\\sigma^2)=\\prod_{i=1}^n\\left[\\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{\\left(x_i-\\mu\\right)^2}{2\\sigma^2}}\\right],\\] con la correspondiente función de log-verosimilitud dada por \\[l(\\mu,\\sigma^2)=-\\frac{n}{2}[\\ln(2\\pi)+\\ln(\\sigma^2)]-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n\\left(x_i-\\mu\\right)^2.\\] Resolviendo \\[\\frac{\\partial l(\\hat{\\mu},\\sigma^2)}{\\partial \\hat{\\mu}}=0,\\] obtenemos \\(\\hat{\\mu}=\\bar{x}=(1/n)\\sum_{i=1}^nx_i\\). Es sencillo verificar que \\(\\frac{\\partial l^2(\\hat{\\mu},\\sigma^2)}{\\partial \\hat{\\mu}^2}\\left|_{\\hat{\\mu}=\\bar{x}}\\right.&lt;0\\). Como el mismo razonamiento funciona para cualquier \\(x\\) arbitrario, \\(\\hat{\\mu}=\\bar{X}\\) es el estimador MLE de \\(\\mu\\). Del mismo modo, resolviendo \\[\\frac{\\partial l(\\mu,\\hat{\\sigma}^2)}{\\partial \\hat{\\sigma}^2}=0,\\] obtenemos \\(\\hat{\\sigma}^2=(1/n)\\sum_{i=1}^n(x_i-\\mu)^2\\). Además, reemplazando \\(\\mu\\) por \\(\\hat {\\mu}\\), obtenemos el estimador MLE de \\(\\sigma^2\\) como \\(\\hat{\\sigma}^2=(1/n)\\sum_{i=1}^n(X_i-\\bar{X})^2\\). Por lo tanto, la media de la muestra \\(\\bar{X}\\) y \\(\\hat{\\sigma}^ 2\\) son tanto estimadores MEM como MLE para la media \\(\\mu\\) y la varianza \\(\\sigma^2\\), bajo el supuesto de una distribución de población normal \\(F(\\cdot)\\). En el Apéndice del Capítulo 16 se proporcionan más detalles sobre las propiedades de la función de verosimilitud y la derivación de MLE bajo distribuciones paramétricas distintas de la distribución normal. 15.3 Estimación de Intervalo En esta sección, se aprende como derivar la distribución muestral exacta del MLE de la media normal obtener la aproximación para muestra grande de la distribución muestral utilizando las propiedades de muestra grande del MLE construir un intervalo de confianza de un parámetro basado en las propiedades de las muestras de tamaño elevado para el MLE Ahora que hemos introducido el estimador MEM y el estimador MLE, podemos realizar el primer tipo de inferencia estadística, estimación por intervalo que cuantifica la incertidumbre resultante del uso de una muestra finita. Derivando la distribución muestral del estimador MLE, se puede estimar un intervalo (un intervalo de confianza) para el parámetro. Bajo el enfoque frecuentista (por ejemplo, el basado en la estimación de máxima verosimilitud), los intervalos de confianza generados a partir del mismo marco de muestreo aleatorio cubrirán el valor verdadero la mayoría de las veces (por ejemplo, el 95% de las veces), si repetimos el proceso de muestreo y volvemos a calcular el intervalo una y otra vez. Dicho proceso requiere la derivación de la distribución muestral para el estimador MLE. 15.3.1 Distribución Exacta para la Media de Muestra Normal Debido a la propiedad de aditividad de la distribución normal (es decir, una suma de variables aleatorias normales que sigue una distribución normal multivariante tiene una distribución normal) y que la distribución normal pertenece a la familia de localización-escala (es decir, un cambio de ubicación y/o de escala de una variable aleatoria normal tiene una distribución normal), la media muestral \\(\\bar {X}\\) de una muestra aleatoria de una \\(F(\\cdot)\\) normal tiene una distribución muestral normal para cualquier valor finito \\(n\\). Dado \\(X_i \\sim^{iid} N(\\mu, \\sigma^2)\\), \\(i = 1, \\dots, n\\), el estimador MLE de \\(\\mu\\) tiene una distribución exacta \\[\\bar{X} \\sim N \\left (\\mu, \\frac {\\sigma^2} {n} \\right).\\] Por lo tanto, la media muestral es un estimador insesgado de \\(\\mu\\). Además, la incertidumbre en la estimación se puede cuantificar mediante su varianza \\(\\sigma^2 / n\\), que disminuye con el tamaño de la muestra \\(n\\). Cuando el tamaño de la muestra tiende a infinito, la media muestral se acercará en una sola masa al valor verdadero. 15.3.2 Propiedades de Muestra Grande del Estimador MLE No obstante, para el estimador MLE del parámetro de la media y cualquier otro parámetro de otras familias de distribución paramétrica, generalmente no podemos derivar una distribución muestral exacta para muestras finitas. Afortunadamente, cuando el tamaño de la muestra es suficientemente grande, los estimadores MLE pueden aproximarse mediante una distribución normal. Debido a la teoría general de máxima verosimilitud, el MLE tiene algunas buenas propiedades para muestras grandes. El estimador MLE \\(\\hat {\\theta}\\) de un parámetro \\(\\theta\\), es un estimador consistente. Es decir, \\(\\hat {\\theta}\\) converge en probabilidad al valor verdadero \\(\\theta\\), cuando el tamaño de la muestra \\(n\\) tiende a infinito. El MLE cumple la propiedad de normalidad asintótica, lo que significa que el estimador convergerá en distribución a una distribución normal centrada alrededor del valor verdadero, cuando el tamaño de la muestra tienda a infinito. Es decir, \\[\\sqrt{n}(\\hat{\\theta}-\\theta)\\rightarrow_d N\\left(0,\\,V\\right),\\quad \\mbox{as}\\quad n\\rightarrow \\infty,\\] donde \\(V\\) es la inversa de la información de Fisher. Por lo tanto, el estimador MLE \\(\\hat {\\theta}\\) sigue aproximadamente una distribución normal con una media \\(\\theta\\) y una varianza \\(V / n\\), cuando el tamaño de la muestra es grande. El estimador MLE es eficiente, lo que significa que tiene la varianza asintótica más pequeña posible, \\(V\\), denominada frecuentemente la cota inferior de Cramer-Rao. En particular, la cota inferior de Cramer-Rao es la inversa de la información de Fisher definida como \\(\\mathcal{I}(\\theta)=-\\mathrm{E}(\\partial^2\\ln f(X;\\theta)/\\partial \\theta^2)\\). Por lo tanto, \\(\\mathrm{Var}(\\hat{\\theta})\\) se puede estimar en función de la información de Fisher observada que se puede escribir como \\(-\\sum_{i=1}^n \\partial^2\\ln f(X_i;\\theta)/\\partial \\theta^2\\). Para muchas distribuciones paramétricas, la información de Fisher puede derivarse analíticamente para el estimador MLE de los parámetros. Para modelos paramétricos más sofisticados, la información de Fisher se puede evaluar numéricamente mediante la integración numérica para distribuciones continuas, o la suma numérica para distribuciones discretas. 15.3.3 Intervalo de confianza Dado que el estimador MLE \\(\\hat{\\theta}\\) tiene una distribución normal exacta o aproximada con una media \\(\\theta\\) y una varianza \\(\\mathrm{Var} (\\hat {\\theta})\\), podemos tomar la raíz cuadrada de la varianza e incorporar la estimación para definir \\(se (\\hat {\\theta}) = \\sqrt {\\mathrm {Var} (\\hat {\\theta})}\\). Un error estándar es una desviación estándar estimada que cuantifica la incertidumbre en la estimación resultante del uso de una muestra finita. Bajo algunas condiciones de regularidad que rigen la distribución de la población, podemos establecer que el estadístico \\[\\frac {\\hat {\\theta} - \\theta} {se (\\hat {\\theta})}\\] converge en distribución a una distribución \\(t\\)-Student con \\({np}\\) grados de libertad (un parámetro de la distribución), donde \\(p\\) es el número de parámetros en el modelo distintos a la varianza. Por ejemplo, para el caso de la distribución normal, tenemos \\(p = 1\\) para el parámetro \\(\\mu\\); para un modelo de regresión lineal con una variable independiente, tenemos \\(p = 2\\) para los parámetros de la intersección y la variable independiente. Si denotamos por \\(t_{np} (1- \\alpha / 2)\\) el \\(100 \\times (1- \\alpha / 2)\\)-ésimo percentil de la distribución \\(t\\)-Student que satisface \\(\\Pr\\left[t&lt; t_{n-p}\\left(1-{\\alpha}/{2}\\right) \\right]= 1-{\\alpha}/{2}\\). Tenemos, \\[\\Pr\\left[-t_{n-p}\\left(1-\\frac{\\alpha}{2}\\right)&lt;\\frac{\\hat{\\theta}-\\theta}{se(\\hat{\\theta})}&lt; t_{n-p}\\left(1-\\frac{\\alpha}{2}\\right) \\right]= 1-{\\alpha},\\] de donde podemos derivar un intervalo de confianza para \\(\\theta\\). De la ecuación anterior podemos derivar un par de estadísticos, \\(\\hat{\\theta}_1\\) y \\(\\hat {\\theta}_2\\), que proporcionan un intervalo de la forma \\([\\hat{\\theta}_1, \\hat{\\theta}_2]\\). Este intervalo es un intervalo de confianza de nivel \\(1-\\alpha\\) para \\(\\theta\\) tal que \\(\\Pr\\left(\\hat{\\theta}_1 \\le \\theta \\le \\hat{\\theta}_2\\right) = 1-\\alpha,\\) donde la probabilidad \\(1-\\alpha\\) se conoce como el nivel de confianza. Hay que tener en cuenta que el intervalo de confianza anterior no es válido para muestras pequeñas, excepto para el caso de la media normal. Distribución Normal. Para la media de la población normal \\(\\mu\\), el estimador MLE tiene una distribución muestral exacta \\(\\bar{X}\\sim N(\\mu,\\sigma/\\sqrt{n})\\), en la que podemos estimar \\(se (\\hat {\\theta})\\) mediante \\(\\hat {\\sigma} / \\sqrt {n}\\). Basándonos en el teorema de Cochran, el estadístico resultante tiene una distribución exacta \\(t\\)-Student con \\(n-1\\) grados de libertad. Por lo tanto, podemos derivar los límites inferior y superior del intervalo de confianza como \\[\\hat{\\mu}_1 = \\hat{\\mu} - t_{n-1}\\left(1-\\frac{\\alpha}{2}\\right)\\frac{ \\hat{\\sigma}}{\\sqrt{n}}\\] y \\[\\hat{\\mu}_2 = \\hat{\\mu} + t_{n-1}\\left(1-\\frac{\\alpha}{2}\\right)\\frac{ \\hat{\\sigma}}{\\sqrt{n}}.\\] Cuando \\(\\alpha = 0,05\\), \\(t_{n-1} (1- \\alpha / 2) \\approx 1,96\\) para valores grandes de \\(n\\). Por el teorema de Cochran, el intervalo de confianza es válido independientemente del tamaño de la muestra. Mostrar ejemplo del Wisconsin Property Fund - Continuación Ejemplo – Wisconsin Property Fund. Para el modelo lognormal de los costes de siniestros, (7,715235, 7,893208) es un intervalo de confianza para el nivel 95% para \\(\\mu\\). En el Apéndice del Capítulo 17 se proporcionan más detalles sobre la estimación por intervalos basada en el estimador MLE de otros parámetros y familias de distribución. 15.4 Pruebas de Hipótesis En esta sección, se aprende cómo comprender los conceptos básicos en la prueba de hipótesis, incluido el nivel de significación y la potencia de una prueba realizar pruebas de hipótesis como un contraste \\(t\\)-Student basado en las propiedades del estimador MLE construir una prueba de la razón de verosimilitud para un solo parámetro o múltiples parámetros del mismo modelo estadístico utilizar criterios de información como el criterio de información de Akaike o el criterio de información bayesiano para realizar la selección del modelo Para los parámetros \\(\\boldsymbol {\\theta}\\) de una distribución paramétrica, un tipo alternativo de inferencia estadística que se llama prueba de hipótesis verifica si una hipótesis con respecto a los parámetros es verdadera, bajo una probabilidad dada llamada nivel de significación \\(\\alpha\\) (por ejemplo, 5%). En las pruebas de hipótesis, rechazamos la hipótesis nula, una afirmación restrictiva sobre los parámetros, si la probabilidad de observar una muestra aleatoria tan extrema como la observada es menor que \\(\\alpha\\), si la hipótesis nula fuera cierta. 15.4.1 Conceptos Básicos En un test estadístico, generalmente estamos interesados en probar si una afirmación con respecto a algunos parámetros, una hipótesis nula (denotada por \\(H_0\\)), es verdadera dados los datos observados. La hipótesis nula puede tomar una forma general \\(H_0:\\theta\\in\\Theta_0\\), donde \\(\\Theta_0\\) es un subconjunto del espacio de parámetros \\(\\Theta\\) de \\(\\theta\\) que puede contener múltiples parámetros. Para el caso de un solo parámetro \\(\\theta\\), la hipótesis nula generalmente toma la forma \\(H_0: \\theta = \\theta_0\\) o \\(H_0: \\theta \\leq \\theta_0\\). Lo opuesto a la hipótesis nula se llama hipótesis alternativa que se puede escribir como \\(H_a: \\theta \\neq \\theta_0\\) o \\(H_a: \\theta&gt; \\theta_0\\). La prueba estadística en \\(H_0: \\theta = \\theta_0\\) se llama de dos colas ya que la hipótesis alternativa contiene dos desigualdades de la \\(H_a: \\theta &lt;\\theta_0\\) o \\(\\theta&gt; \\theta_0\\). Por el contrario, la prueba estadística en \\(H_0: \\theta \\leq \\theta_0\\) o \\(H_0: \\theta \\geq \\theta_0\\) se llama prueba de una cola. Una prueba estadística generalmente se construye en base a un estadístico \\(T\\) y su distribución muestral exacta o de gran tamaño. El contraste generalmente rechaza una prueba de dos colas cuando \\(T&gt; c_1\\) o \\(T &lt;c_2\\), donde las dos constantes \\(c_1\\) y \\(c_2\\) se obtienen en función de la distribución muestral de \\(T\\) a un nivel de probabilidad \\(\\alpha\\) llamado nivel de significación. En particular, el nivel de significación \\(\\alpha\\) satisface \\[\\alpha=\\Pr(\\mbox{rechazar }H_0|H_0\\mbox{ es cierta}),\\] lo que significa que si la hipótesis nula fuese cierta, rechazaríamos la hipótesis nula solo el 5% de las veces, si repetimos el proceso de muestreo y realizamos la prueba una y otra vez. Por lo tanto, el nivel de significación es la probabilidad de cometer un error tipo I (error del primer tipo), el error de rechazar incorrectamente una hipótesis nula verdadera. Por esta razón, el nivel de significación \\(\\alpha\\) también se conoce como el porcentaje de error tipo I. Otro tipo de error que podemos cometer en la prueba de hipótesis es el error tipo II (error del segundo tipo), el error de aceptar incorrectamente una hipótesis nula falsa. De manera similar, podemos definir el porcentaje de error de tipo II como la probabilidad de no rechazar (aceptar) una hipótesis nula cuando no es cierta. Es decir, el porcentaje de error tipo II viene dada por \\[\\Pr (\\mbox {aceptar } H_0 | H_0 \\mbox { es falsa}).\\] Otro importante valor con respecto a la calidad de la prueba estadística se llama potencia del contraste \\(\\beta\\), definida como la probabilidad de rechazar una hipótesis nula falsa. La definición matemática de la potencia es \\[\\beta = \\Pr (\\mbox {rechazar } H_0 | H_0 \\mbox { es falsa}).\\] Hay que tener en cuenta que la potencia del contraste generalmente se calcula en función de un valor alternativo específico de \\(\\theta = \\theta_a\\), dada una distribución muestral específica y un tamaño de muestra dado. En estudios experimentales reales, generalmente se calcula el tamaño muestral requerido para elegir un tamaño de muestra que garantice una elevada posibilidad de obtener una prueba estadísticamente significativa (es decir, con una potencia estadística preespecificada como el 85%). 15.4.2 Contraste \\(t\\)-Student Basado en el Estimador MLE En base a los resultados de la Sección 15.3.1, podemos definir un contraste \\(t\\) de Student para probar que se cumple \\(H_0: \\theta = \\theta_0\\). En particular, definimos el estadístico de prueba como \\[t\\text{-stat}=\\frac{\\hat{\\theta}-\\theta_0}{se(\\hat{\\theta})},\\] que tiene como distribución para muestra grande una distribución \\(t\\)-Student con \\({np}\\) grados de libertad, cuando la hipótesis nula es verdadera (es decir, cuando \\(\\theta = \\theta_0\\)). Para un nivel de significación \\(\\alpha\\), por ejemplo 5%, rechazamos la hipótesis nula si se cumple \\(t\\text{-stat}&lt;-t_{n-p}\\left(1-{\\alpha}/{2}\\right)\\) o \\(t\\text{-stat}&gt; t_{n-p}\\left(1-{\\alpha}/{2}\\right)\\) (la región de rechazo). Bajo la hipótesis nula \\(H_0\\), tenemos \\[\\Pr\\left[t\\text{-stat}&lt;-t_{n-p}\\left(1-\\frac{\\alpha}{2}\\right)\\right]=\\Pr\\left[t\\text{-stat}&gt; t_{n-p}\\left(1-\\frac{\\alpha}{2}\\right) \\right]= \\frac{\\alpha}{2}.\\] Además del concepto de región de rechazo, podemos rechazar el test a partir del \\(p\\)-valor definido como \\(2\\Pr(T&gt;|t\\text{-stat}|)\\) para el contraste a dos colas mencionado anteriormente, donde la variable aleatoria \\(T \\sim T_{np}\\). Rechazamos la hipótesis nula si el \\(p\\)-valor es menor o igual a \\(\\alpha\\). Para una muestra dada, el \\(p\\)-valor se define como el nivel de significación más pequeño para el cual la hipótesis nula sería rechazada. Del mismo modo, podemos construir una prueba a una cola para la hipótesis nula \\(H_0:\\theta\\leq\\theta_0\\) (o \\(H_0:\\theta\\geq\\theta_0\\)). Usando el mismo estadístico de prueba, rechazamos la hipótesis nula cuando \\(t\\text{-stat}&gt; t_{n-p}\\left(1-{\\alpha}\\right)\\) (o \\(t\\text{-stat}&lt;- t_{n-p}\\left(1-{\\alpha}\\right)\\) para la prueba \\(H_0:\\theta\\geq\\theta_0\\)). El \\(p\\)-valor correspondiente se define como \\(\\Pr(T&gt;|t\\text{-stat}|)\\) (o \\(\\Pr(T&lt;|t\\text{-stat}|)\\) para el contraste en \\(H_0:\\theta\\geq\\theta_0\\)). Hay que tener en cuenta que la prueba no es válida para muestras pequeñas, excepto para el caso de la prueba para la media normal. Test \\(t\\) en una muestra para la media Normal. Para el test de la media normal de la forma \\(H_0:\\mu=\\mu_0\\), \\(H_0:\\mu\\leq\\mu_0\\) o \\(H_0:\\mu\\geq\\mu_0\\), podemos definir el estadístico del contraste como \\[t\\text{-stat}=\\frac{\\bar{X}-\\mu_0}{{\\hat{\\sigma}}/{\\sqrt{n}}},\\] para el cual tenemos una distribución muestral exacta \\(t\\text{-stat}\\sim T_{n-1}\\) por el teorema de Cochran, con \\(T_ {n-1}\\) que denota una distribución \\(t\\)-Student con \\(n-1\\) grados de libertad. Según el teorema de Cochran, la prueba es válida tanto para muestras pequeñas como grandes. Mostrar ejemplo de Wisconsin Property Fund - Continuación Ejemplo – Wisconsin Property Fund. Supongamos que los costes en logaritmos de los siniestros han sido históricamente en promedio aproximadamente \\(\\mu_0 = \\ln (5000) = 8,517\\). Es posible que queramos utilizar los datos de 2010 para evaluar si la media de la distribución ha cambiado (una prueba a dos colas) o si ha aumentado (una prueba a una sola cola). Dado el promedio real de 2010 \\(\\hat {\\mu} = 7,804\\), podemos usar la prueba de una muestra \\(t\\) para evaluar si esta es una desviación significativa de \\(\\mu_0 = 8,517\\) (es decir, en este contraste \\(H_0 : \\mu = 8,517\\)). El estadístico de prueba \\(t \\text{-estad} = (8,517-7,804) / (1,683 / \\sqrt {1377}) = 15,72&gt; t_{1376} \\left(0,975 \\right)\\). Por lo tanto, rechazamos la prueba a dos colas con un nivel de significación \\(\\alpha = 5 \\%\\). Del mismo modo, rechazamos la prueba a una cola con \\(\\alpha = 5 \\%\\). Mostrar ejemplo Wisconsin Property Fund - Continuación Ejemplo – Wisconsin Property Fund. Para garantizar estabilidad numérica y realizar extensiones a las aplicaciones de regresión, los paquetes estadísticos a menudo funcionan con versiones transformadas de los parámetros. Las siguientes estimaciones son del paquete R VGAM (función). Se proporcionan más detalles sobre el estimador MLE de otras familias de distribución en el Apéndice del Capítulo 17. Distribución Estimación Error \\(t\\)-estad Parámetro Estándar Gamma 10,190 0,050 203,831 -1,236 0,030 -41,180 Lognormal 7,804 0,045 172,089 0,520 0,019 27,303 Pareto 7,733 0,093 82,853 -0,001 0,054 -0,016 GB2 2,831 1,000 2,832 1,203 0,292 4,120 6,329 0,390 16,220 1,295 0,219 5,910 15.4.3 Prueba de la Razón de Verosimilitud En la subsección anterior, hemos introducido la prueba \\(t\\)-Student para un único parámetro, basada en las propiedades del estimador MLE. En esta sección, definimos un contraste alternativo llamado prueba de la razón de verosimilitud (LRT, por sus siglas en inglés). La LRT se puede usar para contrastar múltiples parámetros del mismo modelo estadístico. Dada la función de verosimilitud \\(L(\\theta|\\mathbf{x})\\) y \\(\\Theta_0 \\subset \\Theta\\), el estadístico de prueba de la razón de probabilidad para contrastar \\(H_0:\\theta\\in\\Theta_0\\) frente a \\(H_a:\\theta\\notin\\Theta_0\\) viene dado por \\[L=\\frac{\\sup_{\\theta\\in\\Theta_0}L(\\theta|\\mathbf{x})}{\\sup_{\\theta\\in\\Theta}L(\\theta|\\mathbf{x})},\\] y de manera similar, para contrastar \\(H_0:\\theta=\\theta_0\\) frente a \\(H_a:\\theta\\neq\\theta_0\\) es \\[L=\\frac{L(\\theta_0|\\mathbf{x})}{\\sup_{\\theta\\in\\Theta}L(\\theta|\\mathbf{x})}.\\] El contraste LRT rechaza la hipótesis nula cuando \\(L &lt;c\\), con el umbral dependiendo del nivel de significación \\(\\alpha\\), el tamaño de la muestra \\(n\\) y el número de parámetros en \\(\\theta\\). Basándonos en el Lema de Neyman-Pearson, la LRT es la prueba uniformemente más potente (UMP) para contrastar \\(H_0: \\theta = \\theta_0\\) frente a \\(H_a: \\theta = \\theta_a\\). Es decir, proporciona la mayor potencia \\(\\beta\\) para un determinado \\(\\alpha\\) y un valor alternativo dado \\(\\theta_a\\). Basándonos en el Teorema de Wilks, el estadístico de prueba de la razón de verosimilitud \\(-2\\ln (L)\\) converge en distribución a una distribución Chi-cuadrado con tantos grados de libertad como la diferencia entre la dimensionalidad de los espacios de parámetros \\(\\Theta\\) y \\(\\Theta_0\\), cuando el tamaño de la muestra tiende a infinito y cuando el modelo nulo está anidado dentro del modelo alternativo. Es decir, cuando el modelo nulo es un caso especial del modelo alternativo que contiene un espacio muestral restringido, podemos aproximar \\(c\\) por \\(\\chi^2_{p_1 - p_2} (1-\\alpha)\\), el \\(100 \\times (1- \\alpha)\\)-ésimo percentil de la distribución Chi-cuadrado, con \\(p_1-p_2\\) grados de libertad, tomando \\(p_1\\) y \\(p_2\\) como los correspondientes números de parámetros en los modelos alternativo y nulo respectivamente. Se ha de tener en cuenta que la LRT también es un contraste asintótico que no será válido para muestras pequeñas. 15.4.4 Criterios de Información En aplicaciones reales, la LRT se usa frecuentemente para comparar dos modelos anidados. Sin embargo, el enfoque LRT como herramienta de selección de modelos tiene dos inconvenientes fundamentales: 1) Por lo general, requiere que el modelo nulo esté anidado dentro del modelo alternativo; 2) los modelos seleccionados mediante la LRT tienden a proporcionar un ajuste excesivo (sobreajuste) dentro de la muestra, lo que conduce a una predicción deficiente fuera de la muestra. Para superar estos problemas, la selección del modelo basada en criterios de información, aplicable a modelos no anidados y teniendo en cuenta la complejidad del modelo, se usa más ampliamente para la selección del modelo que la LRT. Aquí, presentamos los dos criterios más utilizados, el criterio de información de Akaike y el criterio de información bayesiano. En particular, el criterio de información de Akaike (\\(AIC\\)) se define como \\[AIC = -2\\ln L(\\hat{\\boldsymbol \\theta}) + 2p,\\] donde \\(\\hat{\\boldsymbol \\theta}\\) denota el estimador MLE de \\({\\boldsymbol \\theta}\\), y \\(p\\) es el número de parámetros del modelo. El término adicional \\(2p\\) representa una penalización por la complejidad del modelo. Es decir, con la misma función de verosimilitud maximizada, el \\(AIC\\) favorece el modelo con menos parámetros. Nótese que \\(AIC\\) no tiene en cuenta el impacto del tamaño de la muestra \\(n\\). Alternativamente, se usa el criterio de información bayesiano (\\(BIC\\)) que toma en consideración el tamaño de la muestra. El \\(BIC\\) se define como \\[BIC = -2\\ln L(\\hat{\\boldsymbol \\theta}) + p\\,\\ln(n).\\] Observamos que el \\(BIC\\) generalmente asigna un mayor peso al número de parámetros. Con la misma función de verosimilitud maximizada, el \\(BIC\\) sugerirá un modelo más parsimonioso que el \\(AIC\\). Mostrar ejemplo Wisconsin Property Fund - Continuación Ejemplo – Wisconsin Property Fund. Tanto el estadístico \\(AIC\\) como el \\(BIC\\) indican que el modelo GB2 es el que mejor ajusta, mientras que el peor es el gamma. Distribución AIC BIC Gamma 28.305,2 28.315,6 Lognormal 26.837,7 26.848,2 Pareto 26.813,3 26.823,7 GB2 26.768,1 26.789,0 En este gráfico, el negro representa los costes reales en logaritmos de siniestros (suavizados) la mejor aproximación, en verde, obtenida con el modelo GB2 Los ajustes de Pareto (violeta) y Lognormal (azul claro) que también son bastante buenos los peores ajustes son el exponencial (en rojo) y el gamma (en azul oscuro) Figure 15.2: Distribución ajustada de siniestros ## Sample size: 6258 Mostrar el código en R Código R para el ajuste de las distribuciones de los costes de los siniestros #Codigo R para el ajuste de varias distribuciones a los costes de los siniestros ClaimLev &lt;- read.csv(&quot;Data/CLAIMLEVEL.csv&quot;, header=TRUE); nrow(ClaimLev) ClaimData&lt;-subset(ClaimLev,Year==2010); #Usa la librería &quot;VGAM&quot; para la estimación de los parámetros library(VGAM) fit.LN &lt;- vglm(Claim ~ 1, family=lognormal, data = ClaimData) fit.gamma &lt;- vglm(Claim ~ 1, family=gamma2, data = ClaimData) theta.gamma&lt;-exp(coef(fit.gamma)[1])/exp(coef(fit.gamma)[2]) alpha.gamma&lt;-exp(coef(fit.gamma)[2]) fit.exp &lt;- vglm(Claim ~ 1, exponential, data = ClaimData) fit.pareto &lt;- vglm(Claim ~ 1, paretoII, loc=0, data = ClaimData) ################################################### # Inferencia suponiendo una distribución GB2 - ésto es más complicado # La función de verosimilitud de la distribución GB2 (en negativo para su optimización) likgb2 &lt;- function(param) { a1 &lt;- param[1] a2 &lt;- param[2] mu &lt;- param[3] sigma &lt;- param[4] yt &lt;- (log(ClaimData$Claim)-mu)/sigma logexpyt&lt;-ifelse(yt&gt;23,yt,log(1+exp(yt))) logdens &lt;- a1*yt - log(sigma) - log(beta(a1,a2)) - (a1+a2)*logexpyt -log(ClaimData$Claim) return(-sum(logdens)) } # &quot;optim&quot; es una función genérica para optimizar gb2bop &lt;- optim(c(1,1,0,1),likgb2,method=c(&quot;L-BFGS-B&quot;), lower=c(0.01,0.01,-500,0.01),upper=c(500,500,500,500),hessian=TRUE) ################################################### # Gráficos de los ajustes usando las densidades (en una escala logarítmica) plot(density(log(ClaimData$Claim)), ylim=c(0,0.36),main=&quot;&quot;, xlab=&quot;Log Gastos&quot;) x &lt;- seq(0,15,by=0.01) fexp_ex = dgamma(exp(x), scale = exp(-coef(fit.exp)), shape = 1)*exp(x) lines(x,fexp_ex, col=&quot;red&quot;) fgamma_ex = dgamma(exp(x), shape = alpha.gamma, scale=theta.gamma)*exp(x) lines(x,fgamma_ex,col=&quot;blue&quot;) fpareto_ex = dparetoII(exp(x),loc=0,shape = exp(coef(fit.pareto)[2]), scale = exp(coef(fit.pareto)[1]))*exp(x) lines(x,fpareto_ex,col=&quot;purple&quot;) flnorm_ex = dlnorm(exp(x), mean = coef(fit.LN)[1], sd = exp(coef(fit.LN)[2]))*exp(x) lines(x,flnorm_ex, col=&quot;lightblue&quot;) # density for GB II gb2density &lt;- function(x){ a1 &lt;- gb2bop$par[1] a2 &lt;- gb2bop$par[2] mu &lt;- gb2bop$par[3] sigma &lt;- gb2bop$par[4] xt &lt;- (log(x)-mu)/sigma logexpxt&lt;-ifelse(xt&gt;23,yt,log(1+exp(xt))) logdens &lt;- a1*xt - log(sigma) - log(beta(a1,a2)) - (a1+a2)*logexpxt -log(x) exp(logdens) } fGB2_ex = gb2density(exp(x))*exp(x) lines(x,fGB2_ex, col=&quot;green&quot;) Autoría Lei (Larry) Hua, Northern Illinois University, y Edward W. (Jed) Frees, University of Wisconsin-Madison, son los autores principales de la versión inicial de este capítulo. Email: lhua@niu.edu o jfrees@bus.wisc.edu para enviar comentarios o sugerencias de mejora. Traducción al español: Montserrat Guillen y Manuela Alcañiz (Universitat de Barcelona). "],
["C-AppB.html", "Chapter 16 Apéndice B: Esperanzas Iteradas 16.1 Distribución Condicionada y Esperanza Condicional 16.2 Esperanzas Iteradas y Varianza Total 16.3 Distribuciones Conjugadas", " Chapter 16 Apéndice B: Esperanzas Iteradas Este apéndice presenta las leyes relacionadas con las esperanzas iteradas. En particular, la Sección 16.1 presenta los conceptos de distribución condicional y esperanza condicional. La sección 16.2 presenta la Ley de las Esperanzas Iteradas y la Ley de la Varianza Total. En algunas situaciones, solo observamos un único resultado, pero podemos conceptualizar dicho resultado como la culminación de dos (o más) etapas en un proceso de modelización. Dichos tipos de modelos estadísticos se denominan modelos de dos etapas o jerárquicos. Algunos casos especiales de modelos jerárquicos incluyen: modelos donde los parámetros de la distribución son variables aleatorias distribución de la mixtura, donde la Etapa 1 representa la extracción de una subpoblación y la Etapa 2 representa una variable aleatoria de una distribución determinada por la subpoblación extraída en la Etapa 1; una distribución compuesta, donde la Etapa 1 representa la realización del número de eventos y la Etapa 2 representa la cuantía de las pérdidas ocurridas en cada evento. En estas situaciones, el proceso da lugar a una distribución condicional de una variable aleatoria (el resultado de la Etapa 2) dada la otra (el resultado de la Etapa 1). La Ley de Esperanzas Iteradas puede ser útil para obtener la esperanza incondicional o la varianza de una variable aleatoria en tales casos. 16.1 Distribución Condicionada y Esperanza Condicional En esta sección, se aprenden los conceptos relacionados con la distribución condicional de una variable aleatoria dada otra cómo definir la esperanza y varianza condicionadas en función de la función de distribución condicional Las esperanzas iteradas son las leyes relativas al cálculo de la esperanza y la varianza de una variable aleatoria que utiliza una distribución condicional de la variable dada otra variable. Por lo tanto, primero presentamos los conceptos relacionados con la distribución condicional, y el cálculo de la esperanza condicional y la variable en función de una distribución condicional determinada. 16.1.1 Distribución Condicional Aquí presentamos el concepto de distribución condicional para variables aleatorias discretas y continuas, respectivamente. 16.1.1.1 Caso Discreto Supongamos que \\(X\\) e \\(Y\\) son variables aleatorias discretas, lo que significa que pueden tomar un número finito o contable de valores posibles con una probabilidad positiva. La función de probabilidad conjunta (masa) de (\\(X\\), \\(Y\\)) se define como \\[p(x, y) = \\Pr [X = x, Y = y].\\] Cuando \\(X\\) y \\(Y\\) son independientes (el valor de \\(X\\) no depende del valor de \\(Y\\)), tenemos \\[p (x, y) = p (x) p (y),\\] con \\(p (x) = \\Pr [X = x]\\) y \\(p (y) = \\Pr [Y = y]\\) siendo cada función de probabilidad marginal de \\(X\\) e \\(Y\\), respectivamente. Dada la función de probabilidad conjunta, podemos obtener la función de probabilidad marginal de \\(Y\\) como \\[p (y) = \\sum_x p (x, y),\\] donde la suma es sobre todos los valores posibles de \\(x\\), y la función de probabilidad marginal de \\(X\\) se puede obtener de manera similar. La función de probabilidad condicional (masa) de \\((Y | X)\\) se define como \\[p(y|x) =\\Pr[Y=y|X=x]= \\frac{p(x,y)}{\\Pr[X=x]},\\] donde podemos obtener la función de probabilidad condicional de \\((X | Y)\\) de manera similar. En particular, la probabilidad condicional anterior representa la probabilidad del evento \\(Y = y\\) dado el evento \\(X = x\\). Por tanto, incluso en los casos en que \\(\\Pr [X = x] = 0\\), la función se puede definir como caso particular, en aplicaciones reales. 16.1.2 Caso Continuo Para las variables aleatorias continuas \\(X\\) y \\(Y\\), podemos definir su función conjunta de probabilidad (densidad) basada en la función de distribución acumulada conjunta. La función de distribución conjunta de (\\(X\\), \\(Y\\)) se define como \\[F(x,y) = \\Pr[X\\leq x, Y\\leq y].\\] Cuando \\(X\\) e \\(Y\\) son independientes, tenemos \\[F (x, y) = F (x) F (y),\\] con \\(F (x) = \\Pr [X \\leq x]\\) y \\(F (y) = \\Pr [Y \\leq y]\\) siendo la función de distribución (cdf, según sus siglas en inglés) de \\(X\\) e \\(Y\\), respectivamente. La variable aleatoria \\(X\\) se conoce como una variable aleatoria continua si su cdf es continua en \\(x\\). Cuando la cdf \\(F (x)\\) es continua en \\(x\\), entonces definimos \\(f (x) = \\partial F (x) / \\partial x\\) como la función de densidad de probabilidad (marginal) (pdf, según sus siglas en inglés) de \\(X\\). De manera similar, si la cdf conjunta \\(F (x, y)\\) es continua tanto en \\(x\\) como en \\(y\\), definimos \\[f (x, y) = \\frac {\\partial^2 F (x, y)} {\\partial x \\partial y}\\] como la función de densidad de probabilidad conjunta de (\\(X\\), \\(Y\\)), en cuyo caso nos referimos a las variables aleatorias como conjuntamente continuas. Cuando \\(X\\) y \\(Y\\) son independientes, tenemos \\[f (x, y) = f (x) f (y).\\] Dada la función de densidad conjunta, podemos obtener la función de densidad marginal de \\(Y\\) como \\[f (y) = \\int_x f (x, y) \\, dx,\\] donde la integral está definida sobre todos los valores posibles de \\(x\\), y la función de densidad de probabilidad marginal de \\(X\\) se puede obtener de manera similar. En base a la pdf conjunta y a la pdf marginal, definimos la función de densidad condicional de \\((Y | X)\\) como \\[f (y | x) = \\frac {f (x, y)} {f (x)},\\] donde podemos obtener la función de densidad condicional de \\((X | Y)\\) de manera similar. Aquí, la función de densidad condicional es la función de densidad de \\(y\\) dado \\(X = x\\). Por lo tanto, incluso en los casos en que \\(\\Pr [X = x] = 0\\) o cuando \\(f (x)\\) no está definida, la función se puede obtener como caso particular en aplicaciones reales. 16.1.3 Esperanza Condicional y Varianza Condicional Ahora definimos la esperanza y la varianza condicional en función de la distribución condicional definida en la subsección anterior. 16.1.3.1 Caso Discreto Para una variable aleatoria discreta \\(Y\\), su esperanza se define como \\(\\mathrm{E} [Y] = \\sum_y y \\, p (y)\\) si su valor es finito y su varianza se define como \\(\\mathrm{Var}[Y]=\\mathrm{E}\\{(Y-\\mathrm{E}[Y])^2\\}=\\sum_y y^2\\,p(y)-\\{\\mathrm{E}[Y]\\}^2\\) si su valor es finito. Para una variable aleatoria discreta \\(Y\\), la esperanza condicional de la variable aleatoria \\(Y\\) dado el suceso \\(X = x\\) se define como \\[\\mathrm{E}[Y|X=x]=\\sum_y y\\,p(y|x),\\] donde \\(X\\) no tiene por qué ser una variable discreta, para una función de probabilidad condicional conocida \\(p (y | x)\\). Se ha de tener en cuenta que la esperanza condicional \\(\\mathrm{E}[Y|X=x]\\) es un número concreto. Cuando reemplazamos \\(x\\) por \\(X\\) en el lado derecho de la ecuación anterior, podemos definir la esperanza de \\(Y\\) dada la variable aleatoria \\(X\\) como \\[\\mathrm{E}[Y|X]=\\sum_y y\\,p(y|X),\\] que ahora sigue siendo una variable aleatoria, y la aleatoriedad proviene de \\(X\\). De manera similar, podemos definir la varianza condicional de la variable aleatoria \\(Y\\) dado el suceso \\(X = x\\) como \\[\\mathrm{Var}[Y|X=x]=\\mathrm{E}[Y^2|X=x]-\\{\\mathrm{E}[Y|X=x]\\}^2=\\sum_y y^2\\,p(y|x)-\\{\\mathrm{E}[Y|X=x]\\}^2.\\] La varianza de \\(Y\\) dado \\(X\\), \\(\\mathrm{Var}[Y|X]\\) se puede definir reemplazando \\(x\\) por \\(X\\) en la ecuación anterior, y \\(\\mathrm{Var}[Y|X]\\) sigue siendo una variable aleatoria y la aleatoriedad proviene de \\(X\\). 16.1.3.2 Caso Continuo Para una variable aleatoria continua \\(Y\\), su esperanza se define como \\(\\mathrm{E}[Y]=\\int_y y\\,f(y)dy\\) si la integral existe, y su varianza se define como \\(\\mathrm{Var}[Y]=\\mathrm{E}\\{(X-\\mathrm{E}[Y])^2\\}=\\int_y y^2\\,f(y)dy-\\{\\mathrm{E}[Y]\\}^2\\) si su valor es finito. Para variables aleatorias continuas conjuntas \\(X\\) e \\(Y\\), la esperanza condicional de la variable aleatoria \\(Y\\) dado \\(X = x\\) se define como \\[\\mathrm{E}[Y|X=x]=\\int_y y\\,f(y|x)dy.\\] donde \\(X\\) no tiene que ser una variable continua, para la función de densidad de probabilidad condicional conocida \\(f (y | x)\\). Del mismo modo, la esperanza condicional \\(\\mathrm{E}[Y|X=x]\\) es un número concreto. Cuando reemplazamos \\(x\\) por \\(X\\) en el lado derecho de la ecuación anterior, podemos definir la esperanza de \\(Y\\) dada la variable aleatoria \\(X\\) como \\[\\mathrm{E}[Y|X]=\\int_y y\\,p(y|X)\\,dy,\\] que sigue siendo una variable aleatoria, y la aleatoriedad proviene de \\(X\\). De manera similar, podemos definir la varianza condicional de la variable aleatoria \\(Y\\) dado el suceso \\(X = x\\) como \\[\\mathrm{Var}[Y|X=x]=\\mathrm{E}[Y^2|X=x]-\\{\\mathrm{E}[Y|X=x]\\}^2=\\int_y y^2\\,f(y|x)\\,dy-\\{\\mathrm{E}[Y|X=x]\\}^2.\\] La varianza de \\(Y\\) dado \\(X\\), \\(\\mathrm{Var}[Y|X]\\) se puede definir reemplazando \\(x\\) por \\(X\\) en la ecuación anterior, y de manera similar \\(\\mathrm{Var}[Y|X]\\) también es una variable aleatoria y el carácter aleatorio proviene de \\(X\\). 16.2 Esperanzas Iteradas y Varianza Total En esta sección, se aprende la Ley de Esperanzas Iteradas para calcular la esperanza de una variable aleatoria basada en su distribución condicional dada por otra variable aleatoria la Ley de la Varianza Total para calcular la varianza de una variable aleatoria en función de su distribución condicional dada por otra variable aleatoria cómo calcular la esperanza y la varianza en base a un ejemplo de un modelo de dos etapas 16.2.1 Ley de las Esperanzas Iteradas Considere dos variables aleatorias \\(X\\) e \\(Y\\), y \\(h (X, Y)\\), una variable aleatoria que depende de la función \\(h\\), \\(X\\) e \\(Y\\). Suponiendo que todas las esperanzas existen y son finitas, la Ley de las Esperanzas Iteradas establece que \\[\\mathrm{E}[h(X,Y)]= \\mathrm{E} \\left\\{ \\mathrm{E} \\left[ h(X,Y) | X \\right] \\right \\},\\] donde se toma la primera esperanza (interna) con respecto a la variable aleatoria \\(Y\\) y la segunda esperanza (externa) con respecto a \\(X\\). Para la Ley de las Esperanzas Iteradas, las variables aleatorias pueden ser discretas, continuas o una combinación híbrida de las dos. Utilizamos el ejemplo de variables discretas de \\(X\\) e \\(Y\\) para ilustrar el cálculo de la esperanza incondicional usando la Ley de las Esperanzas Iteradas. Para variables aleatorias continuas, solo necesitamos reemplazar el sumatorio con la integral, como se ilustra anteriormente en el apéndice. Siendo \\(p (y | x)\\) la función de probabilidad condicional de \\((Y | X)\\), la esperanza condicional de \\(h (X, Y)\\) dado el suceso \\(X = x\\) se define como \\[\\mathrm{E} \\left[ h(X,Y) | X=x \\right] = \\sum_y h(x,y) p(y|x),\\] y la esperanza condicional de \\(h (X, Y)\\) dado que \\(X\\) es una variable aleatoria puede escribirse como \\[\\mathrm{E} \\left[ h(X,Y) | X \\right] = \\sum_y h(X,y) p(y|X).\\] La esperanza no condicional de \\(h (X, Y)\\) se puede obtener tomando la esperanza de \\(\\mathrm{E} \\left[ h(X,Y) | X \\right]\\) con respecto a la variable aleatoria \\(X\\). Es decir, podemos obtener \\(\\mathrm{E}[ h(X,Y)]\\) como \\[\\begin{aligned} \\mathrm{E} \\left\\{ \\mathrm{E} \\left[ h(X,Y) | X \\right] \\right \\} &amp;= \\sum_x \\left\\{\\sum_y h(x,y) p(y|x) \\right \\} p(x) \\\\ &amp;= \\sum_x \\sum_y h(x,y) p(y|x)p(x) \\\\ &amp;= \\sum_x \\sum_y h(x,y) p(x,y) = \\mathrm{E}[h(X,Y)] \\end{aligned}.\\] La Ley de las Esperanzas Iteradas para los casos continuos e híbridos puede probarse de manera similar, reemplazando la(s) suma(s) correspondiente(s) por integral(es). 16.2.2 Ley de la Varianza Total Suponiendo que existan todas las varianzas y que sean finitas, la Ley de la Varianza Total establece que \\[\\mathrm{Var}[h(X,Y)]= \\mathrm{E} \\left\\{ \\mathrm{Var} \\left[h(X,Y) | X \\right] \\right \\} +\\mathrm{Var} \\left\\{ \\mathrm{E} \\left[ h(X,Y) | X \\right] \\right \\},\\] donde se toma la primera esperanza/varianza (interna) con respecto a la variable aleatoria \\(Y\\) y la segunda esperanza/varianza (externa) con respecto a \\(X\\). Por lo tanto, la varianza no condicional es igual a la esperanza de la varianza condicional más la varianza de la esperanza condicional. Mostrar detalle técnico Para verificar esta regla, primero tengamos en cuenta que podemos calcular una varianza condicional como \\[\\mathrm{Var} \\left[ h(X,Y) | X \\right] = \\mathrm{E} [ h(X,Y)^2 | X ] -\\left\\{\\mathrm{E} \\left[ h(X,Y) | X \\right] \\right\\}^2.\\] A partir de aquí, la esperanza de la varianza condicional es \\[\\begin{align} \\mathrm{E}\\{\\mathrm{Var} \\left[ h(X,Y) | X \\right] \\} &amp;= \\mathrm{E}\\left\\{\\mathrm{E} \\left[ h(X,Y)^2 | X \\right] \\right\\} - \\mathrm{E}\\left(\\left\\{\\mathrm{E} \\left[ h(X,Y) | X \\right] \\right\\}^2\\right) \\notag \\\\ &amp;=\\mathrm{E} \\left[ h(X,Y)^2\\right] - \\mathrm{E}\\left(\\left\\{\\mathrm{E} \\left[ h(X,Y) | X \\right] \\right\\}^2\\right).\\tag{16.1} \\end{align}\\] Además, si se tiene en cuenta que la esperanza condicional, \\(\\mathrm{E} \\left[ h(X,Y) | X \\right]\\), es una función de \\(X\\), denotada como \\(g(X)\\). Entonces, \\(g(X)\\) es una variable aleatoria cuya media es \\(\\mathrm{E}[h(X,Y)]\\) y su varianza es \\[\\begin{align} \\mathrm{Var} \\left\\{ \\mathrm{E} \\left[ h(X,Y) | X \\right] \\right \\} &amp;=\\mathrm{Var}[g(X)] \\notag \\\\ &amp;= \\mathrm{E}[g(X)^2]\\ - \\left\\{\\mathrm{E}[g(X)]\\right\\}^2 \\nonumber\\\\ &amp;= \\mathrm{E}\\left(\\left\\{\\mathrm{E} \\left[ h(X,Y) | X \\right] \\right\\}^2\\right) - \\left\\{\\mathrm{E}[h(X,Y)]\\right\\}^2.\\tag{16.2} \\end{align}\\] Por lo tanto, agregando las ecuaciones (16.1) y (16.2) se obtienen la varianza no condicional \\(\\mathrm{Var} \\left[ h(X,Y) \\right]\\). 16.2.3 Aplicación Para aplicar la Ley de las Esperanzas Iteradas y la Ley de la Varianza Total, generalmente adoptamos el siguiente procedimiento. Se identifica la variable aleatoria a la que se está condicionando, normalmente se realiza en la etapa 1 (que no se observa). Condicionado al resultado en la etapa 1, se calculan las medidas de resumen como la media, varianza y similares. Se obtienen varios resultados en el paso 2, uno para cada resultado de la etapa 1. Luego, se combinan dichos resultados usando las reglas de las esperanzas iteradas o de la varianza total. Mixturas de poblaciones finitas. Supongamos que la variable aleatoria \\(N_1\\) representa una realización del número de siniestros en un año de una póliza de la población de buenos conductores y \\(N_2\\) representa la de la población de malos conductores. Para un conductor específico, hay una probabilidad \\(\\alpha\\) de que sea un buen conductor. Para una determinada variable \\(N\\), tenemos \\[N = \\begin{cases} N_1, &amp; \\text{si el(ella) es un(a) buen(a) conductor(a);}\\\\ N_2, &amp; \\text{en otro caso}.\\\\ \\end{cases}\\] Supongamos que \\(T\\) es el indicador de si es un buen conductor, con \\(T = 1\\) que representa que el conductor es un buen conductor con \\(\\Pr [T = 1] = \\alpha\\) y \\(T = 2\\) representa que el conductor es un mal conductor con \\(\\Pr [T = 2] = 1- \\alpha\\). De la Ley de Esperanzas Iteradas, podemos obtener el número esperado de siniestros como \\[\\mathrm{E}[N]= \\mathrm{E} \\left\\{ \\mathrm{E} \\left[ N | T \\right] \\right \\}= \\mathrm{E}[N_1] \\times \\alpha + \\mathrm{E}[N_2] \\times (1-\\alpha).\\] De la Ley de la Varianza Total, podemos obtener la varianza de \\(N\\) como \\[\\mathrm{Var}[N]= \\mathrm{E} \\left\\{ \\mathrm{Var} \\left[ N | T \\right] \\right \\} +\\mathrm{Var} \\left\\{ \\mathrm{E} \\left[ N | T \\right] \\right \\}.\\] Para ser más concretos, supongamos que \\(N_j\\) sigue una distribución de Poisson con media \\(\\lambda_j\\), \\(j = 1,2\\). Entonces tenemos \\[\\mathrm{Var}[N|T=j]= \\mathrm{E}[N|T=j] = \\lambda_j, \\quad j = 1,2.\\] Por lo tanto, podemos derivar la esperanza de la varianza condicional como \\[\\mathrm{E} \\left\\{ \\mathrm{Var} \\left[ N | T \\right] \\right \\} = \\alpha \\lambda_1+ (1-\\alpha) \\lambda_2\\] y la varianza de la esperanza condicional como \\[\\mathrm{Var} \\left\\{ \\mathrm{E} \\left[ N | T \\right] \\right \\} = (\\lambda_1-\\lambda_2)^2 \\alpha (1-\\alpha).\\] Cabe señalar que esta última es la varianza para una Bernoulli con resultados \\(\\lambda_1\\) y \\(\\lambda_2\\), y probabilidad binomial \\(\\alpha\\). En base a la Ley de la Varianza Total, la varianza no condicional de \\(N\\) viene dada por \\[\\mathrm{Var}[N]= \\alpha \\lambda_1+ (1-\\alpha) \\lambda_2 + (\\lambda_1-\\lambda_2)^2 \\alpha (1-\\alpha).\\] 16.3 Distribuciones Conjugadas Como se describe en la Sección 4.4.1, para las distribuciones conjugadas, las distribuciones a posteriori y a priori provienen de la misma familia de distribuciones. En las aplicaciones de seguros, esto ocurre habitualmente en una “familia de familias de distribuciones” conocida como la familia exponencial lineal que presentamos a continuación. 16.3.1 Familia Exponencial Lineal Definición. La distribución de la familia exponencial lineal es \\[\\begin{equation} f( x; \\gamma ,\\theta ) = \\exp \\left( \\frac{x\\gamma -b(\\gamma )}{\\theta} +S\\left( x,\\theta \\right) \\right). \\end{equation}\\] Aquí, \\(x\\) es una variable dependiente y \\(\\gamma\\) es el parámetro de interés. El valor \\(\\theta\\) es un parámetro de escala. El término \\(b (\\gamma)\\) depende solo del parámetro \\(\\gamma\\), no de la variable dependiente. El estadístico \\(S \\left(x, \\theta \\right)\\) es una función de la variable dependiente y el parámetro de escala, no del parámetro \\(\\gamma\\). La variable dependiente \\(x\\) puede ser discreta, continua o una combinación híbrida de las dos. Por lo tanto, \\(f \\left(. \\right)\\) puede interpretarse como una función de densidad o de masa, dependiendo de la aplicación. La siguiente tabla proporciona varios ejemplos, incluida la distribución normal, binomial y de Poisson. \\[ {\\small \\begin{matrix} \\text{Selección de distribuciones de la familia exponencial lineal}\\\\ \\begin{array}{l|ccccc} \\hline &amp; &amp; \\text{Densidad o} &amp; &amp; &amp; \\\\ \\text{Distribución} &amp; \\text{Parámetros} &amp; \\text{Función de masa} &amp; \\text{Componentes} \\\\ \\hline \\text{General} &amp; \\gamma,~ \\theta &amp; \\exp \\left( \\frac{x\\gamma -b(\\gamma )}{\\theta} +S\\left( x,\\theta \\right) \\right) &amp; \\gamma,~ \\theta, b(\\gamma), S(x, \\theta)\\\\ \\text{Normal} &amp; \\mu, \\sigma^2 &amp; \\frac{1}{\\sigma \\sqrt{2\\pi }}\\exp \\left(-\\frac{(x-\\mu )^{2}}{2\\sigma ^{2}}\\right) &amp; \\mu, \\sigma^2, \\frac{\\gamma^2}{2}, - \\left(\\frac{x^2}{2\\theta} + \\frac{\\ln(2 \\pi \\theta)}{2} \\right) \\\\ \\text{Binomal} &amp; \\pi &amp; {n \\choose x} \\pi ^x (1-\\pi)^{n-x} &amp; \\ln \\left(\\frac{\\pi}{1-\\pi} \\right), 1, n \\ln(1+e^{\\gamma} ), \\\\ &amp; &amp; &amp; \\ln {n \\choose x} \\\\ \\text{Poisson} &amp; \\lambda &amp; \\frac{\\lambda^x}{x!} \\exp(-\\lambda) &amp; \\ln \\lambda, 1, e^{\\gamma}, - \\ln (x!) \\\\ \\text{Binomial } &amp; r,p &amp; \\frac{\\Gamma(x+r)}{x!\\Gamma(r)} p^r ( 1-p)^x &amp; \\ln(1-p), 1, -r \\ln(1-e^{\\gamma}), \\\\ ~~~\\text{negativa}^{\\ast} &amp; &amp; &amp; ~~~\\ln \\left[ \\frac{\\Gamma(x+r)}{x! \\Gamma(r)} \\right] \\\\ \\text{Gamma} &amp; \\alpha, \\theta &amp; \\frac{1}{\\Gamma (\\alpha)\\theta ^ \\alpha} x^{\\alpha -1 }\\exp(-x/ \\theta) &amp; - \\frac{1}{\\alpha \\gamma}, \\frac{1}{\\alpha}, - \\ln ( - \\gamma), -\\theta^{-1} \\ln \\theta \\\\ &amp; &amp; &amp; - \\ln \\left( \\Gamma(\\theta ^{-1}) \\right) + (\\theta^{-1} - 1) \\ln x &amp; &amp; \\\\ \\hline \\end{array}\\\\ ^{\\ast} \\text{Se supone que el parámetro r es fijo pero no necesariamente un entero.}\\\\ \\end{matrix} } \\] Las distribuciones Tweedie (ver Sección ??) e inversa gaussiana también son miembros de la familia exponencial lineal. La familia exponencial lineal de las familias de distribuciones se utiliza ampliamente como base de los modelos lineales generalizados como se describe, por ejemplo, en Edward W. Frees (2009a). 16.3.2 Distribuciones Conjugadas Ahora supongamos que el parámetro \\(\\gamma\\) es aleatorio con distribución \\(\\pi (\\gamma, \\tau)\\), donde \\(\\tau\\) es un vector de parámetros que describe la distribución \\(\\gamma\\). En los modelos bayesianos, la distribución \\(\\pi\\) se conoce como a priori y refleja nuestra creencia o información sobre \\(\\gamma\\). La probabilidad \\(f (x | \\gamma)\\) es una probabilidad condicional en \\(\\gamma\\). La distribución de \\(\\gamma\\) con conocimiento de las variables aleatorias, \\(\\pi (\\gamma, \\tau | x)\\), se denomina distribución a posteriori. Para una distribución de probabilidad dada, las distribuciones a priori y a posteriori que provienen de la misma familia paramétrica se conocen como familias conjugadas de distribuciones. Para una verosimilitud exponencial lineal, existe una familia conjugada natural. Concretamente, consideremos una probabilidad de la forma \\(f(x|\\gamma) = \\exp \\left\\{(x\\gamma -b(\\gamma))/\\theta\\right\\} \\exp \\left\\{S\\left( x,\\theta \\right) \\right\\}\\). Para esta probabilidad, definamos la distribución a priori \\[\\pi(\\gamma,\\tau) = C \\exp\\left\\{ \\gamma a_1(\\tau) - b(\\gamma)a_2(\\tau))\\right\\},\\] donde \\(C\\) es una constante de normalización. Aquí, \\(a_1 (\\tau) = a_1\\) y \\(a_2 (\\tau) = a_2\\) son funciones de los parámetros \\(\\tau\\), aunque simplificamos la notación eliminando la dependencia explícita de \\(\\tau\\). La distribución conjunta de \\(x\\) y \\(\\gamma\\) viene dada por \\(f (x, \\gamma) = f (x | \\gamma) \\pi (\\gamma, \\tau)\\). Usando el Teorema de Bayes, la distribución a posteriori es \\[\\pi(\\gamma,\\tau|x) = C_1 \\exp\\left\\{ \\gamma \\left( a_1+\\frac{x}{\\theta}\\right) - b(\\gamma)\\left( a_2+\\frac{1}{\\theta}\\right)\\right\\},\\] donde \\(C_1\\) es una constante de normalización. Por lo tanto, vemos que \\(\\pi (\\gamma, \\tau | x)\\) tiene la misma forma que \\(\\pi (\\gamma, \\tau)\\). Caso particular. El modelo Poisson-Gamma. Consideremos una verosimilitud de Poisson para la que \\(b (\\gamma) = e^{\\gamma}\\) y el parámetro de escala (\\(\\theta\\)) sea igual a uno. Por lo tanto, tenemos \\[\\pi(\\gamma,\\tau) = C \\exp\\left\\{ \\gamma a_1 - a_2 e^{\\gamma} \\right\\}= C ~ \\left( e^{\\gamma}\\right)^{a_1} \\exp\\left(-a_2e^{\\gamma} \\right).\\] De la tabla de las distribuciones de la familia exponencial, se observa que es una distribución gamma. Es decir, tenemos que la distribución a priori de \\(\\lambda = e^{\\gamma}\\) es una distribución gamma con parámetros \\(\\alpha_{prior} = a_1 + 1\\) y \\(\\theta_ {prior}^{- 1} = a_2\\). La distribución a posteriori es una distribución gamma con parámetros \\(\\alpha_{post} = a_1 + x + 1 = \\alpha_{prior} + x\\) y \\(\\theta_ {post}^{- 1} = a_2 + 1 = \\theta_{prior}^{- 1} + 1\\). Esto es consistente con el resultado de nuestra Sección ??. Caso especial. El modelo Normal-Normal. Consideremos una verosimilitud normal para la que \\(b(\\gamma) = \\gamma^2/2\\) y el parámetro de escala es \\(\\sigma^2\\). Por lo tanto, tenemos \\[\\pi(\\gamma,\\tau) = C \\exp\\left\\{ \\gamma a_1 - \\frac{\\gamma^2}{2}a_2\\right\\}= C_1(\\tau)\\exp\\left\\{ - \\frac{a_2}{2}\\left(\\gamma -\\frac{a_1}{a_2}\\right)^2\\right\\},\\] La distribución a priori de \\(\\gamma\\) es normal con una media igual a \\(a_1 / a_2\\) y una varianza igual a \\(a_2^{-1}\\). La distribución a posteriori de \\(\\gamma\\) dado \\(x\\) es normal con una media \\((a_1 + x / \\sigma^2) / (a_2 + \\sigma ^ {- 2})\\) y la varianza \\((a_2 + \\sigma^{- 2})^{-1}\\). Caso especial. El modelo Beta-Binomial. Consideremos una distribución binomial para la que \\(b(\\gamma) = n \\ln(1+e^{\\gamma})\\) y el parámetro de escala es igual a uno. Entonces tenemos que \\[\\pi(\\gamma,\\tau) = C \\exp\\left\\{ \\gamma a_1 - n a_2 \\ln(1+e^{\\gamma}) \\right\\}= C ~ \\left( \\frac{e^{\\gamma}}{1+e^{\\gamma}}\\right)^{a_1} \\left(1-\\frac{e^{\\gamma}}{1+e^{\\gamma}}\\right)^{-na_2+a_1}.\\] Esta es una distribución beta. Como en los otros casos, los parámetros a priori \\(a_1\\) y \\(a_2\\) se actualizan de forma que se convierten en parámetros a posteriori \\(a_1 + x\\) y \\(a_2 + 1\\). Autoría Lei (Larry) Hua, Northern Illinois University, y Edward W. (Jed) Frees, University of Wisconsin-Madison, son los autores principales de la versión inicial de este capítulo. Email: lhua@niu.edu o jfrees@bus.wisc.edu para enviar comentarios o sugerencias de mejora. Traducción al español: Montserrat Guillen y Manuela Alcañiz (Universitat de Barcelona). Bibliography "],
["C-AppC.html", "Chapter 17 Apéndice C: Teoría de la Máxima Verosimilitud 17.1 Función de Verosimilitud 17.2 Estimadores de Máxima Verosimilitud 17.3 Inferencia Estadística Basada en la Estimación de Báxima Verosimilitud", " Chapter 17 Apéndice C: Teoría de la Máxima Verosimilitud Resumen del capítulo. El Apéndice del Capítulo 15 introdujo la teoría de la máxima verosimilitud con respecto a la estimación de parámetros de una familia paramétrica. Este apéndice ofrece ejemplos más específicos y amplía algunos de los conceptos. La sección 17.1 revisa la definición de la función de verosimilitud e introduce sus propiedades. La sección 17.2 revisa los estimadores de máxima verosimilitud y extiende sus propiedades en muestra grande al caso en el que hay múltiples parámetros en el modelo. La sección 17.3 revisa la inferencia estadística basada en estimadores de máxima verosimilitud, con ejemplos específicos en casos con múltiples parámetros. 17.1 Función de Verosimilitud En esta sección, se aprenden las definiciones de la función de verosimilitud y la función de log-verosimilitud las propiedades de la función de verosimilitud. Del Apéndice 15 sabemos que la función de verosimilitud es una función de parámetros dado los datos observados. Aquí, revisamos los conceptos de la función de verosimilitud y presentamos sus propiedades que son la base para la inferencia a través del método de máxima verosimilitud. 17.1.1 La Función de Verosimilitud y de Log-verosimilitud Aquí, presentamos una breve revisión de la función de verosimilitud y la función de log-verosimilitud del Apéndice 15. Sea \\(f(\\cdot | \\boldsymbol\\theta)\\) la función de probabilidad de \\(X\\), la función de masa de probabilidad (pmf, según sus siglas en inglés) si \\(X\\) es discreta o la función de densidad de probabilidad (pdf, según sus siglas en inglés) si es continua. La verosimilitud es una función de los parámetros (\\(\\boldsymbol\\theta\\)) dados los datos (\\(\\mathbf{x}\\)). Por lo tanto, es una función de los parámetros con los datos fijados, en lugar de una función de los datos con los parámetros fijados. El vector de datos \\(\\mathbf{x}\\) suele ser una realización de una muestra aleatoria como se define en el Apéndice 15. Dada una realización de una muestra aleatoria \\(\\mathbf{x} = (x_1, x_2, \\cdots, x_n)\\) de tamaño \\(n\\), la función de verosimilitud se define como \\[L(\\boldsymbol{\\theta}|\\mathbf{x})=f(\\mathbf{x}|\\boldsymbol{\\theta})=\\prod_{i=1}^nf(x_i|\\boldsymbol{\\theta}),\\] con la correspondiente función de log-verosimilitud dada por \\[l(\\boldsymbol{\\theta}|\\mathbf{x})=\\ln L(\\boldsymbol{\\theta}|\\mathbf{x})=\\sum_{i=1}^n\\ln f(x_i|\\boldsymbol{\\theta}),\\] donde \\(f(\\mathbf{x} | \\boldsymbol{\\theta})\\) denota la función de probabilidad conjunta de \\(\\mathbf{x}\\). La función log-verosimilitud genera una estructura aditiva con la que es fácil trabajar. En el Apéndice 15, hemos utilizado la distribución normal para ilustrar los conceptos de la función de verosimilitud y la función de log-verosimilitud. Aquí, derivamos las funciones de verosimilitud y log-verosimilitud correspondientes cuando la distribución de la población proviene de la familia de distribuciones de Pareto. Mostrar Ejemplo Ejemplo – Distribución de Pareto. Supongamos que \\(X_1, \\ldots, X_n\\) representa una muestra aleatoria de una distribución de Pareto de un solo parámetro con la función de distribución dada por \\[F(x) = \\Pr(X_i\\leq x)=1- \\left(\\frac{500}{x}\\right)^{\\alpha}, ~~~~ x&gt;500,\\] donde el parámetro \\(\\theta = \\alpha\\). La correspondiente función de densidad de probabilidad es \\(f(x) = 500^{\\alpha} \\alpha x^{-\\alpha-1}\\) y la función de log-verosimilitud se puede derivar como \\[l(\\boldsymbol \\alpha|\\mathbf{x}) = \\sum_{i=1}^n \\ln f(x_i;\\alpha) = n \\alpha \\ln 500 +n \\ln \\alpha -(\\alpha+1) \\sum_{i=1}^n \\ln x_i .\\] 17.1.2 Propiedades de las Funciones de Verosimilitud En estadística matemática, la primera derivada de la función log-verosimilitud con respecto a los parámetros, \\(u(\\boldsymbol\\theta)=\\partial l(\\boldsymbol \\theta|\\mathbf{x})/\\partial \\boldsymbol \\theta\\), se conoce como la función de score, o el vector de score (puntuación) cuando hay múltiples parámetros en \\(\\boldsymbol \\theta\\). La función de score o vector de puntuación se puede escribir como \\[u(\\boldsymbol\\theta)=\\frac{ \\partial}{\\partial \\boldsymbol \\theta} l(\\boldsymbol \\theta|\\mathbf{x}) =\\frac{ \\partial}{\\partial \\boldsymbol \\theta} \\ln \\prod_{i=1}^n f(x_i;\\boldsymbol \\theta ) =\\sum_{i=1}^n \\frac{ \\partial}{\\partial \\boldsymbol \\theta} \\ln f(x_i;\\boldsymbol \\theta ),\\] donde \\(u(\\boldsymbol\\theta)=(u_1(\\boldsymbol\\theta),u_2(\\boldsymbol\\theta),\\cdots,u_p(\\boldsymbol\\theta))\\) cuando \\(\\boldsymbol\\theta=(\\theta_1,\\cdots,\\theta_p)\\) contiene \\(p&gt; 2\\) parámetros, siendo el elemento \\(u_k(\\boldsymbol\\theta)=\\partial l(\\boldsymbol \\theta|\\mathbf{x})/\\partial \\theta_k\\) la derivada parcial con respecto a \\(\\theta_k\\) (\\(k = 1,2, \\cdots, p\\)). La función de veosimilitud tiene las siguientes propiedades: Una propiedad básica de la función de verosimilitud es que la esperanza de la función de score con respecto a \\(\\mathbf{x}\\) es 0. Es decir, \\[\\mathrm{E}[u(\\boldsymbol\\theta)]=\\mathrm{E} \\left[ \\frac{ \\partial}{\\partial \\boldsymbol \\theta} l(\\boldsymbol \\theta|\\mathbf{x}) \\right] = \\mathbf 0\\] Para ilustrarlo, tenemos que \\[\\begin{aligned} \\mathrm{E} \\left[ \\frac{ \\partial}{\\partial \\boldsymbol \\theta} l(\\boldsymbol \\theta|\\mathbf{x}) \\right] &amp;= \\mathrm{E} \\left[ \\frac{\\frac{\\partial}{\\partial \\boldsymbol \\theta}f(\\mathbf{x};\\boldsymbol \\theta)}{f(\\mathbf{x};\\boldsymbol \\theta )} \\right] = \\int\\frac{\\partial}{\\partial \\boldsymbol \\theta} f(\\mathbf{y};\\boldsymbol \\theta ) d \\mathbf y \\\\ &amp;= \\frac{\\partial}{\\partial \\boldsymbol \\theta} \\int f(\\mathbf{y};\\boldsymbol \\theta ) d \\mathbf y = \\frac{\\partial}{\\partial \\boldsymbol \\theta} 1 = \\mathbf 0.\\end{aligned}\\] Denotemos por \\({ \\partial^2 l(\\boldsymbol \\theta|\\mathbf{x}) }/{\\partial \\boldsymbol \\theta\\partial \\boldsymbol \\theta^{\\prime}}={ \\partial^2 l(\\boldsymbol \\theta|\\mathbf{x}) }/{\\partial \\boldsymbol \\theta^{2}}\\) a la segunda derivada de la función de log-verosimilitud cuando \\(\\boldsymbol\\theta\\) es un único parámetro, o por \\({ \\partial^2 l(\\boldsymbol \\theta|\\mathbf{x}) }/{\\partial \\boldsymbol \\theta\\partial \\boldsymbol \\theta^{\\prime}}=(h_{jk})=({ \\partial^2 l(\\boldsymbol \\theta|\\mathbf{x}) }/\\partial x_j\\partial x_k)\\) la matriz hessina de la función de log-verosimilitud cuando contiene múltiples parámetros. Denotemos por \\([{ \\partial l(\\boldsymbol \\theta|\\mathbf{x})}{\\partial\\boldsymbol \\theta}][{ \\partial l(\\boldsymbol \\theta|\\mathbf{x})}{\\partial\\boldsymbol \\theta&#39;}]=u^2(\\boldsymbol \\theta)\\) con \\(\\boldsymbol\\theta\\) si hay un único parámetro o por \\([{ \\partial l(\\boldsymbol \\theta|\\mathbf{x})}{\\partial\\boldsymbol \\theta}][{ \\partial l(\\boldsymbol \\theta|\\mathbf{x})}{\\partial\\boldsymbol \\theta&#39;}]=(uu_{jk})\\) que es una matriz \\(p\\times p\\) cuando \\(\\boldsymbol\\theta\\) contiene un total de \\(p\\) parámetros, con cada elemento definido como \\(uu_{jk}=u_j(\\boldsymbol \\theta)u_k(\\boldsymbol \\theta)\\) y siendo \\(u_j(\\boldsymbol \\theta)\\) el \\(j\\)-ésimo elemento del vector de scores como se ha definido antes. Otra propiedad básica de la función de verosimilitud es que la suma de la esperanza de la matriz hessiana y la esperanza del producto de Kronecker del vector de puntuación y su transposición es \\(\\mathbf 0\\). Es decir, \\[\\mathrm{E} \\left( \\frac{ \\partial^2 }{\\partial \\boldsymbol \\theta\\partial \\boldsymbol \\theta^{\\prime}} l(\\boldsymbol \\theta|\\mathbf{x}) \\right) + \\mathrm{E} \\left( \\frac{ \\partial l(\\boldsymbol \\theta|\\mathbf{x})}{\\partial\\boldsymbol \\theta} \\frac{ \\partial l(\\boldsymbol \\theta|\\mathbf{x})}{\\partial\\boldsymbol \\theta^{\\prime}}\\right) = \\mathbf 0.\\] Se define la matriz de información de Fisher como \\[ \\mathcal{I}(\\boldsymbol \\theta) = \\mathrm{E} \\left( \\frac{ \\partial l(\\boldsymbol \\theta|\\mathbf{x})}{\\partial \\boldsymbol \\theta} \\frac{ \\partial l(\\boldsymbol \\theta|\\mathbf{x})}{\\partial \\boldsymbol \\theta^{\\prime}} \\right) = -\\mathrm{E} \\left( \\frac{ \\partial^2}{\\partial \\boldsymbol \\theta \\partial \\boldsymbol \\theta^{\\prime}} l(\\boldsymbol \\theta|\\mathbf{x}) \\right).\\] A medida que el tamaño de la muestra \\(n\\) se acerca a infinito, la función (vector) de score converge en distribución a una distribución normal (o distribución normal multivariante cuando \\(\\boldsymbol \\theta\\) contiene múltiples parámetros) con media 0 y varianza (o matriz de covarianzas en el caso multivariante) dada por \\(\\mathcal{I}(\\boldsymbol \\theta)\\). 17.2 Estimadores de Máxima Verosimilitud En esta sección, se aprende la definición y derivación del estimador de máxima verosimilitud (MLE, según sus siglas en inglés) para los parámetros de una familia de distribución específica las propiedades de los estimadores de máxima verosimilitud que aseguran una inferencia de los parámetros válida en muestras grandes por qué se ha de usar el método MLE y qué precauciones se deben tomar al usarlo. En estadística, los estimadores de máxima verosimilitud son los valores de los parámetros \\(\\boldsymbol \\theta\\) que es más probable que hayan sido producidos por los datos. 17.2.1 Definición y Derivación del Estimador MLE Según la definición dada en el Apéndice 15, el valor de \\(\\boldsymbol \\theta\\), llamado \\(\\hat{\\boldsymbol \\theta}_{MLE}\\), que maximiza la función de verosimilitud, se denomina el estimador de máxima verosimilitud (MLE) de \\(\\boldsymbol\\theta\\). Dado que la función logaritmo \\(\\ln (\\cdot)\\) es una función biunívoca, también podemos determinar \\(\\hat{\\boldsymbol{\\theta}}_{MLE}\\) maximizando la función de log-verosimilitud, \\(l(\\boldsymbol \\theta|\\mathbf{x})\\). Es decir, el estimador MLE se define como \\[\\hat{\\boldsymbol \\theta}_{MLE}={\\mbox{argmax}}_{\\boldsymbol{\\theta}\\in\\Theta}l(\\boldsymbol{\\theta}|\\mathbf{x}).\\] Dada la forma analítica de la función de verosimilitud, el estimador MLE se puede obtener tomando la primera derivada de la función de log-verosimilitud con respecto a \\(\\boldsymbol{\\theta}\\), e igualando los valores de las derivadas parciales a cero. Es decir, los estimadores MLE son las soluciones de las siguientes ecuaciones \\[\\frac{\\partial l(\\hat{\\boldsymbol{\\theta}}|\\mathbf{x})}{\\partial\\hat{\\boldsymbol{\\theta}}}=\\mathbf 0.\\] Mostrar ejemplo Ejemplo. Curso C/Examen 4. 21 de Mayo del 2000. Supongamos que se tienen las siguientes cinco observaciones: 521, 658, 702, 819, 1217. Se usa la distribución de Pareto de un solo parámetro con función de distribución: \\[F(x) = 1- \\left(\\frac{500}{x}\\right)^{\\alpha}, ~~~~ x&gt;500 .\\] Calculad la estimación de máxima verosimilitud del parámetro \\(\\alpha\\). Mostrar solución Solución. Con \\(n=5\\), la función de log-verosimilitud es \\[l(\\alpha|\\mathbf{x} ) = \\sum_{i=1}^5 \\ln f(x_i;\\alpha ) = 5 \\alpha \\ln 500 + 5 \\ln \\alpha -(\\alpha+1) \\sum_{i=1}^5 \\ln x_i.\\] Encontrando la raíz (solución) de la función de scores, se obtiene que \\[\\frac{ \\partial}{\\partial \\alpha } l(\\alpha |\\mathbf{x}) = 5 \\ln 500 + 5 / \\alpha - \\sum_{i=1}^5 \\ln x_i =_{set} 0 \\Rightarrow \\hat{\\alpha}_{MLE} = \\frac{5}{\\sum_{i=1}^5 \\ln x_i - 5 \\ln 500 } = 2,453 .\\] 17.2.2 Propiedades Asintóticas del Estimador MLE Usando los conceptos del Apéndice 15, el estimador MLE tiene algunas buenas propiedades en muestras grandes, bajo ciertas condiciones de regularidad. Presentamos los resultados para un solo parámetro en el Apéndice 15, pero los resultados son ciertos también cuando \\(\\boldsymbol{\\theta}\\) contiene múltiples parámetros. En particular, tenemos los siguientes resultados, en el caso general cuando \\(\\boldsymbol{\\theta}=(\\theta_1,\\theta_2,\\cdots,\\theta_p)\\). El estimador MLE de un parámetro \\(\\boldsymbol{\\theta}\\), \\(\\hat{\\boldsymbol{\\theta}}_{MLE}\\), es un estimador consistente. Es decir, el estimador MLE \\(\\hat{\\boldsymbol{\\theta}}_{MLE}\\) converge en probabilidad al valor verdadero \\(\\boldsymbol{\\theta}\\), cuando el tamaño de la muestra \\(n\\) tiende a infinito. El estimador MLE tiene la propiedad de normalidad asintótica, lo que significa que el estimador convergerá en distribución a una distribución normal multivariante centrada en el valor verdadero, cuando el tamaño de la muestra tienda a infinito. Es decir, \\[\\sqrt{n}(\\hat{\\boldsymbol{\\theta}}_{MLE}-\\boldsymbol{\\theta})\\rightarrow N\\left(\\mathbf 0,\\,\\boldsymbol{V}\\right),\\quad \\mbox{as}\\quad n\\rightarrow \\infty,\\] donde \\(\\boldsymbol{V}\\) denota la varianza asintótica (o matriz de covarianzas) del estimador. Por lo tanto, el estimador MLE \\(\\hat{\\boldsymbol{\\theta}}_{MLE}\\) sigue aproximadamente una distribución normal con media \\(\\boldsymbol{\\theta}\\) y varianza (matriz de covarianzas cuando \\(p&gt;1\\)) \\(\\boldsymbol{V}/n\\), cuando el tamaño de la muestra es grande. El estimador MLE es eficiente, lo que significa que tiene la varianza asintótica más pequeña posible \\(\\boldsymbol{V}\\), comúnmente conocida como la cota inferior de Cramer–Rao. En particular, la cota inferior de Cramer–Rao es la inversa de la (matriz de) información de Fisher \\(\\mathcal{I}(\\boldsymbol{\\theta})\\) definida anteriormente en este apéndice. Por lo tanto, \\(\\mathrm{Var}(\\hat{\\boldsymbol{\\theta}}_{MLE})\\) puede estimarse en función de la información de Fisher observada. En base a los resultados anteriores, podemos realizar inferencia estadística basada en los procedimientos definidos en el Apéndice 15. Mostrar ejemplo Ejemplo. Curso C/Examen 4. 13 de Noviembre del 2000. Partimos de una muestra de diez observaciones de una familia paramétrica \\(f(x,; \\theta_1, \\theta_2)\\) con función de verosimilitud \\[l(\\theta_1, \\theta_2)= \\sum_{i=1}^{10} f(x_i; \\theta_1, \\theta_2) = -2,5 \\theta_1^2 - 3 \\theta_1 \\theta_2 - \\theta_2^2 + 5 \\theta_1 + 2 \\theta_2 + k,\\] donde \\(k\\) es una constante. Se ha de determinar la matriz de covarianzas estimada del estimador de máxima verosimilitud, \\(\\hat{\\theta_1}, \\hat{\\theta_2}\\). Mostrar solución Solución. Denotando \\(l=l(\\theta_1, \\theta_2)\\), la matriz hessiana de segundas derivadas es \\[\\left( \\begin{array}{cc} \\frac{ \\partial ^2}{\\partial \\theta_1 ^2 } l &amp; \\frac{ \\partial ^2}{\\partial \\theta_1 \\partial \\theta_2 } l \\\\ \\frac{ \\partial ^2}{\\partial \\theta_1 \\partial \\theta_2 } l &amp; \\frac{ \\partial ^2}{\\partial \\theta_1 ^2 } l \\end{array} \\right) = \\left( \\begin{array}{cc} -5 &amp; -3 \\\\ -3 &amp; -2 \\end{array} \\right)\\] Por lo tanto, la matriz de información es: \\[\\mathcal{I}(\\theta_1, \\theta_2) = -\\mathrm{E} \\left( \\frac{ \\partial^2}{\\partial \\boldsymbol \\theta \\partial \\boldsymbol \\theta^{\\prime}} l(\\boldsymbol \\theta|\\mathbf{x}) \\right) = \\left( \\begin{array}{cc} 5 &amp; 3 \\\\ 3 &amp; 2 \\end{array} \\right)\\] y \\[\\mathcal{I}^{-1}(\\theta_1, \\theta_2) = \\frac{1}{5(2) - 3(3)}\\left( \\begin{array}{cc} 2 &amp; -3 \\\\ -3 &amp; 5 \\end{array} \\right) = \\left( \\begin{array}{cc} 2 &amp; -3 \\\\ -3 &amp; 5 \\end{array} \\right) .\\] 17.2.3 Uso de la Estimación de Máxima Verosimilitud El método de máxima verosimilitud tiene muchas ventajas sobre otros métodos alternativos, como el método de momentos introducido en el Apéndice 15. Es un método general que funciona en muchas situaciones. Por ejemplo, podemos escribir la función de verosimilitud de forma cerrada para datos censurados y truncados. La estimación de máxima verosimilitud se puede utilizar para modelos de regresión que incluyen covariables, como la regresión de supervivencia, modelos lineales generalizados y modelos mixtos, que pueden incluir covariables que dependen del tiempo. Debido a la eficiencia del estimador MLE, éste es óptimo, el mejor, en el sentido de que tiene la varianza más pequeña entre la clase de todos los estimadores insesgados para tamaños de muestra grandes. A partir de los resultados sobre normalidad asintótica del estimador MLE, podemos obtener una distribución en muestras grandes para dicho estimador, lo que permite evaluar la variabilidad en la estimación y realizar inferencia estadística sobre los parámetros. El enfoque es menos costoso computacionalmente que los métodos de remuestreo que requieren realizar una gran cantidad de ajustes del modelo. A pesar de sus numerosas ventajas, el estimador MLE tiene sus inconvenientes en casos como los modelos lineales generalizados cuando no tiene una forma analítica cerrada. En tales casos, los estimadores de máxima verosimilitud se calculan iterativamente utilizando métodos de optimización numérica. Por ejemplo, podemos usar el algoritmo iterativo de Newton-Raphson o sus variantes para obtener la estimación MLE. Los algoritmos iterativos requieren establecer valores iniciales. En algunos problemas, la elección de un valor inicial cercano a la solución es fundamental, particularmente en los casos en los que la función de verosimilitud tiene mínimos o máximos locales. En consecuencia, puede haber un problema de convergencia cuando el valor inicial está lejos del máximo. Por lo tanto, es importante comenzar desde diferentes valores en el espacio de parámetros y comparar la verosimilitud maximizada o el logaritmo de verosimilitud maximizado para asegurarse de que los algoritmos hayan convergido a un máximo global. 17.3 Inferencia Estadística Basada en la Estimación de Báxima Verosimilitud En esta sección, se aprende como realizar pruebas de hipótesis basadas en el estimador MLE para casos en los que hay múltiples parámetros en \\(\\boldsymbol\\theta\\) realizar un contraste de la razón de verosimilitud para casos en los que hay múltiples parámetros en \\(\\boldsymbol\\theta\\) En el Apéndice 15, hemos introducido métodos basados en la máxima verosimilitud para realizar inferencia estadística cuando \\(\\boldsymbol\\theta\\) contiene un solo parámetro. Aquí, extenderemos los resultados a casos en los que haya múltiples parámetros en \\(\\boldsymbol\\theta\\). 17.3.1 Contraste de Hipótesis En el Apéndice 15, definimos las pruebas de hipótesis relativas a la hipótesis nula, una condición sobre los parámetros de una distribución o modelo. Un tipo importante de inferencia es evaluar si una estimación del parámetro es estadísticamente significativa, lo que significa si el valor del parámetro es cero o no. Hemos aprendido antes que el estimador MLE \\(\\hat{\\boldsymbol{\\theta}}_{MLE}\\) tiene una distribución normal en muestras grandes con media \\(\\boldsymbol\\theta\\) y matriz de varianzas y covarianzas \\(\\mathcal{I}^{-1}(\\boldsymbol \\theta)\\). Basándonos en la distribución normal multivariante, el elemento \\(j\\)-ésimo de \\(\\hat{\\boldsymbol{\\theta}}_{MLE}\\), es decir \\(\\hat{\\theta}_{MLE,j}\\), tiene una distribución normal univariante en muestras grandes. Definimos \\(se(\\hat{\\theta}_{MLE,j})\\) el error estándar (desviación estándar estimada) como la raíz cuadrada del elemento diagonal \\(j\\)-ésimo de \\(\\mathcal{I}^{-1}(\\boldsymbol \\theta)_{MLE}\\). Para evaluar la hipótesis nula en la que se establece que \\(\\theta_j=\\theta_0\\), definimos el estadístico \\(t\\) o el \\(t\\)-ratio como \\(t(\\hat{\\theta}_{MLE,j})=(\\hat{\\theta}_{MLE,j}-\\theta_0)/se(\\hat{\\theta}_{MLE,j})\\). Bajo la hipótesis nula, el estadístico tiene una distribución \\(t\\)-Student con \\(np\\) grados de libertad, siendo \\(p\\) la dimensión de \\(\\boldsymbol{\\theta}\\). En la mayoría de las aplicaciones actuariales, tenemos un tamaño de muestra \\(n\\) grande, por lo que la distribución \\(t\\) está muy cerca de la distribución normal (estándar). En el caso en que \\(n\\) sea muy grande o cuando se conozca el error estándar, el estadístico \\(t\\) se puede denominar estadístico \\(z\\) o \\(z\\)-score. Basándonos en los resultados del Apéndice 15, si el estadístico \\(t\\) , \\(t(\\hat{\\theta}_{MLE,j})\\) supera un punto de corte (en valor absoluto), entonces el contraste para el parámetro \\(j\\), \\(\\theta_j\\), determina que es estadísticamente significativo. Si \\(\\theta_j\\) es el coeficiente de regresión de la variable independiente \\(j\\)-ésima, entonces decimos que la variable \\(j\\)-ésima es estadísticamente significativa. Por ejemplo, si usamos un nivel de significación del 5%, entonces el valor del punto de corte es 1,96 usando una aproximación a la distribución normal para casos con un tamaño de muestra grande. En términos más generales, usando un nivel de significación de \\(100\\alpha\\%\\), el punto de corte es un cuantil de \\(100(1-\\alpha/ 2)\\%\\) de una distribución de \\(t\\)-Student con \\(n-p\\) grados de libertad. Otro concepto útil en la prueba de hipótesis es el \\(p\\)-valor, abreviatura de valor de probabilidad. A partir de la definición matemática presentada en el Apéndice 15, el \\(p\\)-valor se define como el nivel de significación más pequeño para el cual se rechazaría la hipótesis nula. Por lo tanto, el \\(p\\)-valor es un estadístico de resumen útil para el analista de datos porque le permite comprender la fuerza de la evidencia estadística respecto a la desviación de la hipótesis nula. 17.3.2 Validación del Modelo y MLE Además de las pruebas de hipótesis y la estimación por intervalos introducidas en el Apéndice 15 y la subsección anterior, otro tipo importante de inferencia es la selección de un modelo entre dos opciones, donde una opción es un caso especial de la otra en el que ciertos parámetros están restringidos. Para elegir entre dos modelos en los que uno está anidado en el otro, hemos introducido la prueba de razón de verosimilitud (LRT, según sus siglas en inglés) en el Apéndice 15. Aquí, revisaremos brevemente el proceso para realizar una LRT basada en un ejemplo específico de dos modelos alternativos. Supongamos que tenemos un modelo (grande) bajo el cual derivamos el estimador de máxima verosimilitud, \\(\\hat{\\boldsymbol{\\theta}}_{MLE}\\). Ahora supongamos que algunos de los elementos \\(p\\) en \\(\\boldsymbol\\theta\\) son iguales a cero y determinamos el estimador de máxima verosimilitud sobre el conjunto restante, con el estimador resultante denotado por \\(\\hat{\\boldsymbol{\\theta}}_{Reducido}\\). Según la definición del Apéndice @ref(C: Aplicación A), el estadístico, \\(LRT= 2 \\left( l(\\hat{\\boldsymbol{\\theta}}_{MLE}) - l(\\hat{\\boldsymbol{\\theta}}_{Reducido}) \\right)\\), se llama estadístico de la razón de verosimilitud. Bajo la hipótesis nula de que el modelo reducido es correcto, la razón de verosimilitud sigue una distribución Chi-cuadrado con \\(d\\) grados de libertad, siendo \\(d\\) el número de variables fijadas en cero. Este tipo de contraste permite juzgar cuál de los dos modelos es más probable que sea correcto con los datos observados. Si el estadístico \\(LRT\\) es grande en relación con el valor crítico de la distribución Chi-cuadrado, entonces rechazamos el modelo reducido a favor del más grande. En el Apéndice 15 se proporcionan detalles sobre el valor crítico y métodos alternativos basados en criterios de información. Autoría Lei (Larry) Hua, Northern Illinois University, y Edward W. (Jed) Frees, University of Wisconsin-Madison, son los autores principales de la versión inicial de este capítulo. Email: lhua@niu.edu o jfrees@bus.wisc.edu para enviar comentarios o sugerencias de mejora. Traducción al español: Montserrat Guillen y Manuela Alcañiz (Universitat de Barcelona). "],
["C-SummaryDistributions.html", "Chapter 18 Appendix D: Summary of Distributions 18.1 Discrete Distributions 18.2 Continuous Distributions 18.3 Limited Expected Values", " Chapter 18 Appendix D: Summary of Distributions User Notes The R functions are from the packages actuar and invgamma. Tables appear when first loaded by the browser. To hide them, click on one of the distributions, e.g., Poisson, and then click on the Hide button. More information on the R codes is available at the R Codes for Loss Data Analytics site. 18.1 Discrete Distributions Overview. This section summarizes selected discrete probability distributions used throughout Loss Data Analytics. Relevant functions and R code are provided. 18.1.1 The (a,b,0) Class Poisson Geometric Binomial Negative Binomial Hide Poisson Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\lambda&gt;0 \\\\ \\hline ~~p_0 &amp; e^{-\\lambda} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\frac{e^{-\\lambda}\\lambda^k}{k!} \\\\ ~~p_k &amp; \\\\ \\hline \\small{\\text{Expected value}} &amp; \\lambda \\\\ ~~\\mathrm{E}[N] &amp; \\\\ \\hline \\small{\\text{Variance}} &amp; \\lambda \\\\ \\hline \\small{\\text{Probability generating function}} &amp; e^{\\lambda(z-1)} \\\\ ~~P(z) &amp; \\\\ \\hline a \\small{\\text{ and }} b \\small{\\text{ for recursion}} &amp; a=0 \\\\ &amp; b=\\lambda \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\text{dpois}(x=, lambda=\\lambda) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{ppois}(p=, lambda=\\lambda) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qpois}(q=, lambda=\\lambda) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rpois}(n=, lambda=\\lambda) \\\\ \\hline \\end{array} \\end{matrix} \\] Hide Geometric Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\beta&gt;0 \\\\ \\hline ~~p_0 &amp; \\frac{1}{1+\\beta} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\frac{\\beta^k}{(1+\\beta)^{k+1}} \\\\ ~~p_k &amp; \\\\ \\hline \\small{\\text{Expected value}} &amp; \\beta \\\\ ~~\\mathrm{E}[N] &amp; \\\\ \\hline \\small{\\text{Variance}} &amp; \\beta(1+\\beta) \\\\ \\hline \\small{\\text{Probability generating function}} &amp; [1-\\beta(z-1)]^{-1} \\\\ ~~P(z) &amp; \\\\ \\hline a \\small{\\text{ and }} b \\small{\\text{ for recursion}} &amp; a=\\frac{\\beta}{1+\\beta} \\\\ &amp; b=0 \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\text{dgeom}(x=, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pgeom}(p=, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qgeom}(q=, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rgeom}(n=, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\end{array} \\end{matrix} \\] Hide Binomial Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; 0&lt;q&lt;1,~\\text{m is an integer} \\\\ &amp; 0 \\leq k \\leq m\\\\ \\hline ~~p_0 &amp;(1-q)^m \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\binom{m}{k}q^k(1-q)^{m-k} \\\\ ~~p_k &amp; \\\\ \\hline \\small{\\text{Expected value}} &amp; mq \\\\ ~~\\mathrm{E}[N] &amp; \\\\ \\hline \\small{\\text{Variance}} &amp; mq(1-q) \\\\ \\hline \\small{\\text{Probability generating function}} &amp; [1+q(z-1)]^m \\\\ ~~P(z) &amp; \\\\ \\hline a \\small{\\text{ and }} b \\small{\\text{ for recursion}} &amp; a=\\frac{-q}{1-q} \\\\ &amp; b=\\frac{(m+1)q}{1-q} \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\text{dbinom}(x=, size=m, prob=p) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pbinom}(p=, size=m, prob=p) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qbinom}(q=, size=m, prob=p) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rbinom}(n=, size=m, prob=p) \\\\ \\hline \\end{array} \\end{matrix} \\] Hide Negative Binomial Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; r&gt;0, \\beta&gt;0 \\\\ \\hline ~~p_0 &amp; (1+\\beta)^{-r} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\frac{r(r+1)\\cdots(r+k-1)\\beta^k}{k!(1+\\beta)^{r+k}} \\\\ ~~p_k &amp; \\\\ \\hline \\small{\\text{Expected value}} &amp; r\\beta \\\\ ~~\\mathrm{E}[N] &amp; \\\\ \\hline \\small{\\text{Variance}} &amp; r\\beta(1+\\beta) \\\\ \\hline \\small{\\text{Probability generating function}} &amp; [1-\\beta(z-1)]^{-r} \\\\ ~~P(z) &amp; \\\\ \\hline a \\small{\\text{ and }} b \\small{\\text{ for recursion}} &amp; a=\\frac{\\beta}{1+\\beta} \\\\ &amp; b=\\frac{(r-1)\\beta}{1+\\beta} \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\text{dnbinom}(x=, size=r, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pnbinom}(p=, size=r, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qnbinom}(q=, size=r, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rnbinom}(n=, size=r, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\end{array} \\end{matrix} \\] 18.1.2 The (a,b,1) Class Zero Truncated Poisson Zero Truncated Geometric Zero Truncated Binomial Zero Truncated Negative Binomial Logarithmic Hide Zero Truncated Poisson Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\lambda&gt;0 \\\\ \\hline ~~p^T_1 &amp; \\frac{\\lambda}{e^\\lambda-1} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\frac{\\lambda^k}{k!(e^\\lambda-1)} \\\\ ~~p^T_k &amp; \\\\ \\hline \\small{\\text{Expected value}} &amp; \\frac{\\lambda}{1-e^{-\\lambda}} \\\\ ~~\\mathrm{E}[N] &amp; \\\\ \\hline \\small{\\text{Variance}} &amp; \\frac{\\lambda[1-(\\lambda+1)e^{-\\lambda}]}{(1-e^{-\\lambda})^2} \\\\ \\hline \\small{\\text{Probability generating function}} &amp; \\frac{e^{\\lambda z}-1}{e^\\lambda-1} \\\\ ~~P(z) &amp; \\\\ \\hline a \\small{\\text{ and }} b \\small{\\text{ for recursion}} &amp; a=0 \\\\ &amp; b=\\lambda \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\text{dztpois}(x=, lambda=\\lambda) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pztpois}(p=, lambda=\\lambda) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qztpois}(q=, lambda=\\lambda) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rztpois}(n=, lambda=\\lambda) \\\\ \\hline \\end{array} \\end{matrix} \\] Hide Zero Truncated Geometric Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\beta&gt;0 \\\\ \\hline ~~p^T_1 &amp; \\frac{1}{1+\\beta} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\frac{\\beta^{k-1}}{(1+\\beta)^k} \\\\ ~~p^T_k &amp; \\\\ \\hline \\small{\\text{Expected value}} &amp; 1+\\beta \\\\ ~~\\mathrm{E}[N] &amp; \\\\ \\hline \\small{\\text{Variance}} &amp; \\beta(1+\\beta) \\\\ \\hline \\small{\\text{Probability generating function}} &amp; \\frac{[1-\\beta(z-1)]^{-1}-(1+\\beta)^{-1}}{1-(1+\\beta)^{-1}} \\\\ ~~P(z) &amp; \\\\ \\hline a \\small{\\text{ and }} b \\small{\\text{ for recursion}} &amp; a=\\frac{\\beta}{1+\\beta} \\\\ &amp; b=0 \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\text{dztgeom}(x=, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pztgeom}(p=, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qztgeom}(q=, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rztgeom}(n=, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\end{array} \\end{matrix} \\] Hide Zero Truncated Binomial Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; 0&lt;q&lt;1,~\\text{m is an integer} \\\\ &amp; 0 \\leq k \\leq m\\\\ \\hline ~~p^T_1 &amp; \\frac{m(1-q)^{m-1}q}{1-(1-q)^m} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\frac{\\binom{m}{k}q^k(1-q)^{m-k}}{1-(1-q)^m} \\\\ ~~p^T_k &amp; \\\\ \\hline \\small{\\text{Expected value}} &amp; \\frac{mq}{1-(1-q)^m} \\\\ ~~\\mathrm{E}[N] &amp; \\\\ \\hline \\small{\\text{Variance}} &amp; \\frac{mq[(1-q)-(1-q+mq)(1-q)^m]}{[1-(1-q)^m]^2} \\\\ \\hline \\small{\\text{Probability generating function}} &amp; \\frac{[1+q(z-1)^m]-(1-q)^m}{1-(1-q)^m} \\\\ ~~P(z) &amp; \\\\ \\hline a \\small{\\text{ and }} b \\small{\\text{ for recursion}} &amp; a=\\frac{-q}{1-q} \\\\ &amp; b=\\frac{(m+1)q}{1-q} \\\\ \\hline \\end{array} \\end{matrix} \\] R Commmands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\text{dztbinom}(x=, size=m, prob=p) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pztbinom}(p=, size=m, prob=p) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qztbinom}(q=, size=m, prob=p) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rztbinom}(n=, size=m, prob=p) \\\\ \\hline \\end{array} \\end{matrix} \\] Hide Zero Truncated Negative Binomial Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; r&gt;-1, r\\neq0 \\\\ \\hline ~~p^T_1 &amp; \\frac{r\\beta}{(1+\\beta)^{r+1}-(1+\\beta)} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\frac{r(r+1)\\cdots(r+k-1)}{k![(1+\\beta)^r-1]}(\\frac{\\beta}{1+\\beta})^k \\\\ ~~p^T_k &amp; \\\\ \\hline \\small{\\text{Expected value}} &amp; \\frac{r\\beta}{1-(1+\\beta)^{-r}} \\\\ ~~\\mathrm{E}[N] &amp; \\\\ \\hline \\small{\\text{Variance}} &amp; \\frac{r\\beta[(1+\\beta)-(1+\\beta+r\\beta)(1+\\beta)^{-r}]}{[1-(1+\\beta)^{-r}]^2} \\\\ \\hline \\small{\\text{Probability generating function}} &amp; \\frac{[1-\\beta(z-1)]^{-r}-(1+\\beta)^{-r}}{1-(1+\\beta)^{-r}} \\\\ ~~P(z) &amp; \\\\ \\hline a \\small{\\text{ and }} b \\small{\\text{ for recursion}} &amp; a=\\frac{\\beta}{1+\\beta} \\\\ &amp; b=\\frac{(r-1)\\beta}{1+\\beta} \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\text{dztnbinom}(x=, size=r, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pztnbinom}(p=, size=r, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qztnbinom}(q=, size=r, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rztnbinom}(n=, size=r, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\end{array} \\end{matrix} \\] Hide Logarithmic Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\beta&gt;0 \\\\ \\hline ~~p^T_1 &amp; \\frac{\\beta}{(1+\\beta)ln(1+\\beta)} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\frac{\\beta^k}{k(1+\\beta)^k \\ln (1+\\beta)} \\\\ ~~p^T_k &amp; \\\\ \\hline \\small{\\text{Expected value}} &amp; \\frac{\\beta}{\\ln (1+\\beta)} \\\\ ~~\\mathrm{E}[N] &amp; \\\\ \\hline \\small{\\text{Variance}} &amp; \\frac{\\beta[1+\\beta-\\frac{\\beta}{ln(1+\\beta)}]}{\\ln (1+\\beta)} \\\\ \\hline \\small{\\text{Probability generating function}} &amp; 1-\\frac{ln[1-\\beta(z-1)]}{\\ln (1+\\beta)} \\\\ ~~P(z) &amp; \\\\ \\hline a \\small{\\text{ and }} b \\small{\\text{ for recursion}} &amp; a=\\frac{\\beta}{1+\\beta} \\\\ &amp; b=\\frac{-\\beta}{1+\\beta} \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\text{dnbinom}(x=,prob=\\frac{\\beta}{1+\\beta}) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pnbinom}(p=,prob=\\frac{\\beta}{1+\\beta}) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qnbinom}(q=,prob=\\frac{\\beta}{1+\\beta}) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rnbinom}(n=,prob=\\frac{\\beta}{1+\\beta}) \\\\ \\hline \\end{array} \\end{matrix} \\] 18.2 Continuous Distributions Overview. This section summarizes selected continuous probability distributions used throughout Loss Data Analytics. Relevant functions, R code, and illustrative graphs are provided. 18.2.1 One Parameter Distributions Exponential Inv Exponential Single Parameter Pareto Hide Exponential Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0 \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{1}{\\theta}e^{-x/\\theta} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; 1-e^{-x/\\theta} \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\theta^k\\Gamma(k+1) \\\\ ~~\\mathrm{E}[X^k] &amp; k&gt;-1 \\\\ \\hline VaR_p(x) &amp; -\\theta \\ln (1-p) \\\\ \\hline \\small{\\text{Limited Expected Value}} &amp; \\theta(1-e^{-x/\\theta}) \\\\ ~~\\mathrm{E}[X\\wedge x] &amp; \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dexp}(x=, rate=1/\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pexp}(p=, rate=1/\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qexp}(q=, rate=1/\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rexp}(n=, rate=1/\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph theta &lt;- 100 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x=X,y=dexp(X,rate=1/theta),type=&quot;l&quot;, ylab=&quot;Probability density&quot;,col=&quot;red&quot;,main=&quot;Exponential Distribution&quot;) Hide Inverse Exponential Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0 \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{\\theta e^{-\\theta/x}}{x^2} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; e^{-\\theta/x} \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\theta^k\\Gamma(1-k) \\\\ ~~\\mathrm{E}[X^k] &amp; k&lt;1 \\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; \\theta^kG(1-k;\\theta/x)+x^k (1 - e^{-\\theta/x}) \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dinvexp}(x=, scale=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pinvexp}(p=, scale=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qinvexp}(q=, scale=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rinvexp}(n=, scale=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph theta &lt;- 0.01 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x=X,y=dinvexp(X, rate = 1/theta),type=&quot;l&quot;, ylab=&quot;Probability density&quot;,col=&quot;red&quot;,main=&quot;Inverse Exponential Distribution&quot;) Hide Single Parameter Pareto Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta~\\text{is known},~x&gt;\\theta, \\alpha &gt; 0 \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{\\alpha\\theta^\\alpha}{x^{\\alpha+1}} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; 1-(\\theta/x)^\\alpha \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\frac{\\alpha\\theta^k}{\\alpha-k} \\\\ ~~\\mathrm{E}[X^k] &amp; k &lt; \\alpha \\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; \\frac{\\alpha\\theta^k}{\\alpha-k}-\\frac{k\\theta^{\\alpha}}{(\\alpha-k)x^{\\alpha-k}} \\\\ &amp; x \\geq\\theta \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dpareto1}(x=, shape=\\alpha,min=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{ppareto1}(p=, shape=\\alpha,min=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qpareto1}(q=, shape=\\alpha,min=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rpareto1}(n=, shape=\\alpha,min=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph alpha &lt;- 3 theta &lt;- 100 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x=X,y=dpareto1(X,shape=alpha,min=theta),type=&quot;l&quot;, ylab=&quot;Probability density&quot;,col=&quot;red&quot;,main=&quot;Single Parameter Pareto Distribution&quot;) 18.2.2 Two Parameter Distributions Pareto Inv Pareto Loglogistic Paralogistic Gamma Inv Gamma Weibull Inv Weibull Uniform Normal Hide Pareto Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0, \\alpha&gt;0 \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{\\alpha\\theta^\\alpha}{(x+\\theta)^{\\alpha+1}} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; 1-\\Big(\\frac{\\theta}{x+\\theta}\\Big)^\\alpha \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\frac{\\theta^k\\Gamma(k+1)\\Gamma(\\alpha-k)}{\\Gamma(\\alpha)} \\\\ ~~\\mathrm{E}[X^k] &amp; -1&lt;k&lt;\\alpha \\\\ \\hline \\small{\\text{Limited Expected Value:}}~\\alpha\\neq1 &amp; \\frac{\\theta}{\\alpha-1}\\Big[1-\\Big(\\frac{\\theta}{x+\\theta}\\Big)^{\\alpha-1}\\Big] \\\\ ~~\\mathrm{E}[X\\wedge x] &amp; \\\\ \\hline \\small{\\text{Limited Expected Value:}}~\\alpha=1 &amp; -\\theta \\ln \\left(\\frac{\\theta}{x+\\theta}\\right) \\\\ ~~\\mathrm{E}[X\\wedge x] &amp; \\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; \\frac{\\theta^k\\Gamma(k+1)\\Gamma(\\alpha-k)}{\\Gamma(\\alpha)}\\beta(k+1,\\alpha-k;\\frac{x}{x+\\theta})+x^k(\\frac{\\theta}{x+\\theta})^\\alpha \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dpareto}(x=, shape=\\alpha, scale=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{ppareto}(p=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qpareto}(q=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rpareto}(n=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph alpha &lt;- 3 theta &lt;- 200 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x=X,y=dpareto(X,shape=alpha,scale=theta),type=&quot;l&quot;, ylab=&quot;Probability density&quot;,col=&quot;red&quot;,main=&quot;Pareto Distribution&quot;) Hide Inverse Pareto Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0, \\tau&gt;0 \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{\\tau\\theta x^{\\tau-1}}{(x+\\theta)^\\tau-1} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\Big(\\frac{x}{x+\\theta}\\Big)^\\tau \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\frac{\\theta^k\\Gamma(\\tau+k)\\Gamma(1-k)}{\\Gamma(\\tau)} \\\\ ~~\\mathrm{E}[X^k] &amp; -\\tau&lt;k&lt;1 \\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; \\theta^k\\tau\\int^{x/(x+\\theta)}_0~y^{\\tau+k-1}(1-y)^{-k}dy+x^k[1-\\Big(\\frac{x}{x+\\theta}\\Big)^\\tau] \\\\ &amp; k&gt;-\\tau \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dinvpareto}(x=, shape=\\tau, scale=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pinvpareto}(p=, shape=\\tau,scale=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qinvpareto}(q=, shape=\\tau,scale=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rinvpareto}(n=, shape=\\tau,scale=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph tau &lt;- 5 theta &lt;- 100 X &lt;- seq(from=0,to=3000,by=1) plot(x=X,y=dinvpareto(X,shape=tau,scale=theta),type=&quot;l&quot;, ylab=&quot;Probability density&quot;,col=&quot;red&quot;,main=&quot;Inverse Pareto Distribution&quot;) Hide Loglogistic Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0, \\gamma &gt; 0, u=\\frac{(x/\\theta)^\\gamma}{1+(x/\\theta)^\\gamma} \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{\\gamma(x/\\theta)^\\gamma}{x[1+(x/\\theta)^\\gamma]^2} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; u \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\theta^k\\Gamma(1+(k/\\gamma))\\Gamma(1-(k/\\gamma)) \\\\ ~~\\mathrm{E}[X^k] &amp; -\\gamma&lt;k&lt;\\gamma \\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; \\theta^k\\Gamma(1+(k/\\gamma))\\Gamma(1-(k/\\gamma))\\beta(1+(k/\\gamma),1-(k/\\gamma);u)+x^k(1-u) \\\\ &amp; k&gt;-\\gamma \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph dloglogistic &lt;- function(x, gamma, theta){ p=gamma*(x/theta)^gamma/(x*(1+(x/theta)^gamma)^2) return(p) } gamma &lt;- 2 theta &lt;- 100 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x=X,y=dloglogistic(X,gamma=gamma,theta=theta),type=&quot;l&quot;,col=&quot;red&quot;) Hide Paralogistic Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0, \\alpha&gt;0, u=\\frac{1}{1+(x/\\theta)^\\alpha} \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{\\alpha^2(x/\\theta)^\\alpha}{x[1+(x/\\theta)^\\alpha]^{\\alpha+1}} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; 1-u^\\alpha \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\frac{\\theta^k\\Gamma(1+(k/\\alpha))\\Gamma(\\alpha-(k/\\alpha))}{\\Gamma(\\alpha)} \\\\ ~~\\mathrm{E}[X^k] &amp; -\\alpha&lt;k&lt;\\alpha^2 \\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; \\frac{\\theta^k\\Gamma(1+(k/\\alpha))\\Gamma(\\alpha-(k/\\alpha))}{\\Gamma(\\alpha)}\\beta(1+(k/\\alpha),\\alpha-(k/\\alpha);1-u)+x^ku^\\alpha \\\\ &amp; k&gt;-\\alpha \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dparalogis}(x=, shape=\\alpha, scale=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pparalogis}(p=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qparalogis}(q=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rparalogis}(n=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph alpha &lt;- 2 theta &lt;- 100 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x=X,y=dparalogis(X,shape=alpha,scale=theta),type=&quot;l&quot;, ylab=&quot;Probability density&quot;,col=&quot;red&quot;,main=&quot;Paralogistic Distribution&quot;) Hide Gamma Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0,~\\alpha&gt;0 \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{1}{\\theta^{\\alpha}\\Gamma(\\alpha)}x^{\\alpha-1}e^{-x/\\theta} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\Gamma(\\alpha;\\frac{x}{\\theta}) \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\theta^k\\frac{\\Gamma(\\alpha+k)}{\\Gamma(\\alpha)} \\\\ ~~\\mathrm{E}[X^k] &amp; k&gt;-\\alpha \\\\ \\hline &amp; \\frac{\\theta^k\\Gamma(k+\\alpha)}{\\Gamma(\\alpha)}\\Gamma(k+\\alpha; x/\\theta)+x^k[1-\\Gamma(\\alpha; x/\\theta)] \\\\ ~~\\mathrm{E}[X\\wedge x]^k &amp; k &gt; -\\alpha \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\small{\\text{Density function}} &amp; \\text{dgamma}(x=, shape=\\alpha, scale=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pgamma}(p=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qgamma}(q=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rgamma}(n=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph alpha &lt;- 2 theta &lt;- 50 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x=X,y=dgamma(X,shape=alpha,scale=theta),type=&quot;l&quot;, ylab=&quot;Probability density&quot;,col=&quot;red&quot;,main=&quot;Gamma Distribution&quot;) Hide Inverse Gamma Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{(\\theta/x)^\\alpha e^{-\\theta/x}}{x\\Gamma(\\alpha)} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; 1-\\Gamma(\\alpha;\\theta/x) \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\frac{\\theta^k\\Gamma(\\alpha-k)}{\\Gamma(\\alpha)} \\\\ ~~\\mathrm{E}[X^k] &amp; k&lt;\\alpha \\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; \\frac{\\theta^k\\Gamma(\\alpha-k)}{\\Gamma(\\alpha)}[1-\\Gamma(\\alpha-k;\\theta/x)]+x^k\\Gamma(\\alpha;\\theta/x) \\\\ &amp; \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dinvgamma}(x=, shape=\\alpha, scale=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pinvgamma}(p=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qinvgamma}(q=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rinvgamma}(n=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph alpha &lt;- 3 theta &lt;- 100 X &lt;- seq(from=0,to=400,by=1) plot(x=X,y=dinvgamma(X,shape=alpha,scale=theta),type=&quot;l&quot;, ylab=&quot;Probability density&quot;,col=&quot;red&quot;,main=&quot;Inverse Gamma Distribution&quot;) Hide Weibull Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0,\\alpha&gt;0 \\\\ \\hline\\ \\small{\\text{Probability density}} &amp; \\frac{\\alpha \\Big(\\frac{x}{\\theta}\\Big)^\\alpha \\exp\\Big(-\\Big(\\frac{x}{\\theta}\\Big)^\\alpha\\Big)}{x} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; 1-\\exp\\Big(-\\Big(\\frac{x}{\\theta}\\Big)^\\alpha\\Big) \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\theta^k \\Gamma(1 + \\frac{k}{\\alpha}) \\\\ ~~\\mathrm{E}[X^k] &amp; k&gt;-\\alpha \\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; \\theta^k\\Gamma(1+\\frac{k}{\\alpha})\\Gamma\\Big[1+\\frac{k}{\\alpha};\\Big(\\frac{x}{\\theta}\\Big)^\\alpha\\Big]+x^k\\exp\\Big(-\\Big(\\frac{x}{\\theta}\\Big)^\\alpha\\Big) \\\\ &amp; k&gt;-\\alpha \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dweibull}(x=, shape=\\alpha, scale=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pweibull}(p=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qweibull}(q=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rweibull}(n=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph alpha &lt;- 2 theta &lt;- 100 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x=X,y=dweibull(X,shape=alpha, scale=theta),type=&quot;l&quot;, ylab=&quot;Probability density&quot;,col=&quot;red&quot;,main=&quot;Weibull Distribution&quot;) Hide Inverse Weibull Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0,\\tau&gt;0 \\\\ \\hline\\ \\small{\\text{Probability density}} &amp; \\frac{\\tau(\\theta/x)^\\tau \\exp\\Big(-\\Big(\\frac{\\theta}{x}\\Big)^\\tau\\Big)}{x} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\exp\\Big(-\\Big(\\frac{\\theta}{x}\\Big)^\\tau\\Big) \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\theta^k\\Gamma(1-(k/\\tau)) \\\\ ~~\\mathrm{E}[X^k] &amp; k&lt;\\tau \\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; \\theta^k\\Gamma(1-(k/\\tau))[1-\\Gamma(1-(k/\\tau);(\\theta/x)^\\tau)]+x^k[1-e^{-(\\theta/x)^\\tau}] \\\\ &amp; \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dinvweibull}(x=, shape=\\tau, scale=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pinvweibull}(p=, shape=\\tau,scale=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qinvweibull}(q=, shape=\\tau,scale=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rinvweibull}(n=, shape=\\tau,scale=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph tau &lt;- 5 theta &lt;- 100 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x=X,y=dinvweibull(X,shape=tau,scale=theta),type=&quot;l&quot;, ylab=&quot;Probability density&quot;,col=&quot;red&quot;,main=&quot;Inverse Weibull Distribution&quot;) Hide Uniform Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; -\\infty&lt;\\alpha&lt;\\beta&lt;\\infty \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{1}{\\beta-\\alpha} \\\\ \\text{f(x)} &amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\frac{x-\\alpha}{\\beta-\\alpha} \\\\ ~~F(x) &amp; \\\\ \\hline \\text{Mean} &amp; \\frac{\\beta+\\alpha}{2} \\\\ \\text{E[X]} &amp; \\\\ \\hline \\text{Variance} &amp; \\frac{(\\beta-\\alpha)^2}{12} \\\\ E[(X-\\mu)^2] &amp; \\\\ \\hline \\mathrm{E}[(X-\\mu)^k] &amp; \\mu_k=0~~~\\text{for odd }\\textit{k} \\\\ &amp; \\mu_k=\\frac{(\\beta-\\alpha)^k}{2^k (k+1)}~~~\\text{for even }\\textit{k} \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dunif}(x=, min=a, max=b) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{punif}(p=, min=a, max=b) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qunif}(q=, min=a, max=b) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{runif}(n=, min=a, max=b) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph alpha &lt;- 50 beta &lt;- 100 X &lt;- seq(alpha,beta,1) plot(x=X,y=dunif(X,alpha,beta),type=&quot;l&quot;, ylab=&quot;Probability density&quot;,col=&quot;red&quot;,main=&quot;Continuous Uniform Distribution&quot;) Hide Normal Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; -\\infty&lt;\\mu&lt;\\infty,~\\sigma&gt;0 \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left( -\\frac{(x-\\mu)^2}{2\\sigma^2}\\right) \\\\ \\text{f(x)} &amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\Phi\\left(\\frac{x-\\mu}{\\sigma}\\right) \\\\ ~~F(x) &amp; \\\\ \\hline \\text{Mean} &amp; \\mu \\\\ \\text{E[X]} &amp; \\\\ \\hline \\text{Variance} &amp; \\sigma^2 \\\\ E[(X-\\mu)^2] &amp; \\\\ \\hline \\mathrm{E}[(x-\\mu)^k] &amp; \\mu_k=0~~~\\text{for even k} \\\\ &amp; \\mu_k=\\frac{k!\\sigma^2}{(\\frac{k}{2})! 2^{k/2}}~~~\\text{for odd k} \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dnorm}(x=, mean=\\mu, sd=\\sigma) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pnorm}(p=, mean=\\mu, sd=\\sigma) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qnorm}(q=, mean=\\mu, sd=\\sigma) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rnorm}(n=, mean=\\mu, sd=\\sigma) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph mu &lt;- 100 sigma &lt;- 10 X &lt;- seq(from=0,to=200,by=1) plot(x=X,y=dnorm(X,mean=mu,sd=sigma),type=&quot;l&quot;, ylab=&quot;Probability density&quot;,col=&quot;red&quot;,main=&quot;Normal Distribution&quot;) Hide Cauchy Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; -\\infty &lt;\\alpha &lt;\\infty, \\beta&gt;0 \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{1}{\\pi\\beta}[1+\\left( \\frac{x-\\alpha}{\\beta}\\right)^2]^{-1} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dcauchy}(x=, location=\\alpha, scale=\\beta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pcauchy}(p=, location=\\alpha, scale=\\beta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qcauchy}(q=, location=\\alpha, scale=\\beta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rcauchy}(n=, location=\\alpha, scale=\\beta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph alpha &lt;- 50 beta &lt;- 100 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x=X,y=dcauchy(X,location=alpha,scale=beta), type=&quot;l&quot;,ylab=&quot;Probability density&quot;,col=&quot;red&quot;,main=&quot;Cauchy Distribution&quot;) 18.2.3 Three Parameter Distributions Generalized Pareto Burr Inv Burr Hide Generalized Pareto Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0, \\alpha&gt;0, \\tau&gt;0, u=\\frac{x}{x+\\theta} \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{\\Gamma(\\alpha+\\tau)}{\\Gamma(\\alpha)\\Gamma(\\tau)}\\frac{\\theta^\\alpha x^{\\tau-1}}{(x+\\theta)^{\\alpha+\\tau}} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\beta(\\tau,\\alpha;u) \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\frac{\\theta^k\\Gamma(\\tau+1)\\Gamma(\\alpha-k)}{\\Gamma(\\alpha)\\Gamma(\\tau)} \\\\ ~~~~\\mathrm{E}[X^k] &amp; -\\tau&lt;k&lt;\\alpha \\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; \\frac{\\theta^k\\Gamma(\\tau+k)\\Gamma(\\alpha-k)}{\\Gamma(\\alpha)\\Gamma(\\tau)}\\beta(\\tau+k,\\alpha-k;u)+x^k[1-\\beta(\\tau,\\alpha;u)] \\\\ &amp; k&gt;-\\tau \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dgenpareto}(x=, shape1=\\alpha, shape2=\\tau, scale=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pgenpareto}(q=, shape1=\\alpha, shape2=\\tau, scale=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qgenpareto}(p=, shape1=\\alpha, shape2=\\tau, scale=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rgenpareto}(r=, shape1=\\alpha, shape2=\\tau, scale=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph alpha &lt;- 3 tau &lt;- 5 theta &lt;- 100 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x=X,y=dgenpareto(X,shape1=alpha,shape2=tau,scale=theta),type=&quot;l&quot;, ylab=&quot;Probability density&quot;,col=&quot;red&quot;,main=&quot;Generalized Pareto Distribution&quot;) Hide Burr Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0, \\alpha&gt;0, \\gamma&gt;0, u=\\frac{1}{1+(x/\\theta)^\\gamma} \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{\\alpha\\gamma(x/\\theta)^\\gamma}{x[1+(x/\\theta)^\\gamma]^{\\alpha+1}} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; 1-u^\\alpha \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\frac{\\theta^k\\Gamma(1+(k/\\gamma))\\Gamma(\\alpha-(k/\\gamma))}{\\Gamma(\\alpha)} \\\\ ~~~~\\mathrm{E}[X^k] &amp; -\\gamma&lt;k&lt;\\alpha\\gamma \\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; \\frac{\\theta^k\\Gamma(1+(k/\\gamma))\\Gamma(\\alpha-(k/\\gamma))}{\\Gamma(\\alpha)}\\beta(1+(k/\\gamma),\\alpha-(k/\\gamma);1-u)+x^ku^\\alpha \\\\ &amp; k&gt;-\\gamma \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dburr}(x=, shape1=\\alpha, shape2=\\gamma, scale=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pburr}(p=, shape1=\\alpha, shape2=\\gamma, scale=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qburr}(q=, shape1=\\alpha, shape2=\\gamma, scale=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rburr}(n=, shape1=\\alpha, shape2=\\gamma, scale=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph alpha &lt;- 2 gamma &lt;- 3 theta &lt;- 100 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x=X,y=dburr(X,shape1=alpha,shape2=gamma,scale=theta),type=&quot;l&quot;, ylab=&quot;Probability density&quot;,col=&quot;red&quot;,main=&quot;Burr Distribution&quot;) Hide Inverse Burr Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0, \\tau&gt;0, \\gamma&gt;0, u=\\frac{(x/\\theta)^\\gamma}{1+(x/\\theta)^\\gamma} \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{\\tau\\gamma(x/\\theta)^{\\tau \\gamma}}{x[1+(x/\\theta)^\\gamma]^{\\tau+1}} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; u^\\tau \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\frac{\\theta^k\\Gamma(\\tau+(k/\\gamma))\\Gamma(1-(k/\\gamma))}{\\Gamma(\\tau)} \\\\ ~~~~\\mathrm{E}[X^k] &amp; -\\tau\\gamma&lt;k&lt;\\gamma \\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; \\frac{\\theta^k\\Gamma(\\tau+(k/\\gamma))\\Gamma(1-(k/\\gamma))}{\\Gamma(\\tau)}\\beta(\\tau+(k/\\gamma),1-(k/\\gamma);u)+x^k[1-u^\\tau] \\\\ &amp; k&gt;-\\tau\\gamma \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dinvburr}(x=, shape1=\\tau, shape2=\\gamma, scale=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pinvburr}(p=, shape1=\\tau, shape2=\\gamma, scale=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qinvburr}(q=, shape1=\\tau, shape2=\\gamma, scale=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rinvburr}(n=, shape1=\\tau, shape2=\\gamma, scale=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph tau &lt;- 2 gamma &lt;- 3 theta &lt;- 100 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x=X,y=dinvburr(X,shape1=tau,shape2=gamma,scale=theta),type=&quot;l&quot;, ylab=&quot;Probability density&quot;,col=&quot;red&quot;,main=&quot;Inverse Burr Distribution&quot;) 18.2.4 Four Parameter Distribution GB2 Hide Generalized Beta of the Second Kind (GB2) Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0, \\alpha_1&gt;0, \\alpha_2&gt;0, \\sigma&gt;0 \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{(x/\\theta)^{\\alpha_2/\\sigma}}{x \\sigma~\\mathrm{B}\\left( \\alpha_1,\\alpha_2\\right)\\left\\lbrack 1 + \\left( x/\\theta \\right)^{1/\\sigma} \\right\\rbrack^{\\alpha_1 + \\alpha_2}} \\\\ ~~ \\small{\\text{function }} f(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\frac{\\theta^{k}~\\mathrm{B}\\left( \\alpha_1 +k \\sigma,\\alpha_2 - k \\sigma \\right)}{\\mathrm{B}\\left( \\alpha_1,\\alpha_2 \\right)} \\\\ ~~~~\\mathrm{E}[X^k] &amp; \\textit{k}&gt;0 \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands Please see the R Codes for Loss Data Analytics site for information about this distribution. 18.2.5 Other Distributions Lognormal Inv Gaussian Hide Lognormal Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; -\\infty &lt;\\mu &lt;\\infty, \\sigma&gt;0 \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{1}{x\\sqrt{2\\pi}\\sigma} \\exp\\left( -\\frac{(\\ln x-\\mu)^2}{2\\sigma^2}\\right) \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\Phi\\left(\\frac{\\ln (x)-\\mu}{\\sigma}\\right) \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\exp(k\\mu+\\frac{k^2\\sigma^2}{2}) \\\\ ~~\\mathrm{E}[X^k] &amp; \\\\ \\hline \\small{\\text{Limited Expected Value}} &amp; \\exp\\Big(k\\mu+\\frac{k^2\\sigma^2}{2}\\Big)\\Phi\\Big(\\frac{\\ln (x)-\\mu-k\\sigma^2}{\\sigma}\\Big)+x^k\\Big[1-\\Phi\\Big(\\frac{\\ln (x)-\\mu}{\\sigma}\\Big)\\Big] \\\\ ~~\\mathrm{E}[X\\wedge x] &amp; \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph dlognorm &lt;- function(x,mu,sigma){ p=(1/(x*sigma*sqrt(2*pi)))*exp(-((log(x)-mu)/sigma)^2) return(p) } mu &lt;- 20 sigma &lt;- 12 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x=X,y=dlognorm(X,mu=mu,sigma=sigma),type=&quot;l&quot;,col=&quot;red&quot;) Hide Inverse Gaussian Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0, \\mu&gt;0, z=\\frac{x-\\mu}{\\mu}~,~y=\\frac{x+\\mu}{\\mu} \\\\ \\hline \\small{\\text{Probability density}} &amp; \\Big(\\frac{\\theta}{2\\pi x^3}\\Big)^{1/2}\\exp\\Big(\\frac{-\\theta z^2}{2x}\\Big) \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\Phi\\Big[z\\Big(\\frac{\\theta}{x}\\Big)^{1/2}\\Big]+\\exp\\Big(\\frac{2\\theta}{\\mu}\\Big)\\Phi\\Big[-y\\Big(\\frac{\\theta}{x}\\Big)^{1/2}\\Big] \\\\ ~~F(x) &amp; \\\\ \\hline \\text{Mean} &amp; \\mu \\\\ \\mathrm{E}[X] &amp; \\\\ \\hline \\mathrm{Var[X]} &amp; \\frac{\\mu^3}{\\theta}\\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; x-\\mu x\\Phi\\Big[z\\Big(\\frac{\\theta}{x}\\Big)^{1/2}\\Big]-(\\mu y)\\exp\\Big(\\frac{2\\theta}{\\mu}\\Big)\\Phi\\Big[-y\\Big(\\frac{\\theta}{x}\\Big)^{1/2}\\Big] \\\\ &amp; \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dinvgauss}(x=, mean=\\mu,dispersion=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pinvgauss}(p=, mean=\\mu,dispersion=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qinvgauss}(q=, mean=\\mu,dispersion=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rinvgauss}(n=, mean=\\mu,dispersion=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph mu &lt;- 100 theta &lt;- 1000 X &lt;- seq(from=0,to=100,by=1) plot(x=X,y=dinvgauss(X,mean=mu,dispersion=theta),type=&quot;l&quot;, ylab=&quot;Probability density&quot;,col=&quot;red&quot;,main=&quot;Inverse Gaussian Distribution&quot;) 18.2.6 Distributions with Finite Support Beta Generalized Beta Hide Beta Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0, ~a&gt;0,~b&gt;0, u=\\frac{x}{\\theta},~0&lt;x&lt;\\theta \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)} u^a(1-u)^{b-1}\\frac{1}{x} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\beta(a,b;u) \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\frac{\\theta^k \\Gamma(a+b)\\Gamma(a+k)}{\\Gamma(a)\\Gamma(a+b+k)} \\\\ ~~\\mathrm{E}[X^k] &amp; k&gt;-a \\\\ \\hline &amp; \\frac{\\theta^k a(a+1)\\cdots(a+k-1)}{(a+b)(a+b+1)\\cdots(a+b+k-1)}\\beta(a+k,b;u)+x^k[1-\\beta(a,b;u)] \\\\ ~~\\mathrm{E}[X\\wedge x]^k &amp; \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dbeta}(x=, shape1=a,shape2=b,ncp=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pbeta}(p=, shape1=a,shape2=b,ncp=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qbeta}(q=, shape1=a,shape2=b,ncp=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rbeta}(n=, shape1=a,shape2=b,ncp=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] a &lt;- 2 b &lt;- 4 theta &lt;- 1 X &lt;- seq(from=0,to=1,by=.0001) plot(x=X,y=dbeta(X,shape1=a,shape2=b,ncp=theta),type=&quot;l&quot;, ylab=&quot;Probability density&quot;,col=&quot;red&quot;,main=&quot;Beta Distribution&quot;) Hide Generalized Beta Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0, a&gt;0, b&gt;0, \\tau&gt;0, 0&lt;x&lt;\\theta~,~u=(x/\\theta)^\\tau \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}u^\\alpha(1-u)^{b-1}\\frac{\\tau}{x} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\beta(a,b;u) \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\frac{\\theta^k\\Gamma(a+b)\\Gamma(a+(k/\\tau))}{\\Gamma(a)\\Gamma(a+b+(k/\\tau))} \\\\ ~~\\mathrm{E}[X^k] &amp; k&gt;-\\alpha\\tau \\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; \\frac{\\theta^k\\Gamma(a+b)\\Gamma(a+(k/\\tau))}{\\Gamma(a)\\Gamma(a+b+(k/\\tau))}\\beta(a+(k/\\tau),b;u)+x^k[1-\\beta(a,b;u)] \\\\ \\hline \\end{array} \\end{matrix} \\] R Commmands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dgenbeta}(x=, shape1=a,shape2=b,shape3=\\tau,scale=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pgenbeta}(p=, shape1=a,shape2=b,shape3=\\tau,scale=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qgenbeta}(q=, shape1=a,shape2=b,shape3=\\tau,scale=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rgenbeta}(n=, shape1=a,shape2=b,shape3=\\tau,scale=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph a &lt;- 3 b &lt;- 5 tau &lt;- 2 theta &lt;- 1000 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x=X,y=dgenbeta(X,shape1=a,shape2=b,shape3=tau,scale=theta),type=&quot;l&quot;, ylab=&quot;Probability density&quot;,col=&quot;red&quot;,main=&quot;Generalized Beta Distribution&quot;) 18.3 Limited Expected Values Overview. This section summarizes limited expected values for selected continuous distributions. Functions Graph Hide Functions Limited Expected Value Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Distribuion} &amp; \\text{Function} \\\\ \\hline \\text{GB2} &amp; \\frac{\\theta\\Gamma(\\tau+1)\\Gamma(\\alpha-1)}{\\Gamma(\\alpha)\\Gamma(\\tau)}\\beta(\\tau+1,\\alpha-1;\\frac{x}{x+\\beta})+x[1-\\beta(\\tau,\\alpha;\\frac{x}{x+\\beta})] \\\\ \\hline \\text{Burr} &amp; \\frac{\\theta\\Gamma(1+\\frac{1}{\\gamma})\\Gamma(\\alpha-\\frac{1}{\\gamma})}{\\Gamma(\\alpha)}\\beta(1+\\frac{1}{\\gamma},\\alpha-\\frac{1}{\\gamma};1-\\frac{1}{1+(x/\\theta)^\\gamma})+x\\Big(\\frac{1}{1+(x/\\theta)^\\gamma}\\Big)^\\alpha \\\\ \\hline \\text{Inverse Burr} &amp; \\frac{\\theta\\Gamma(\\tau+(1/\\gamma))\\Gamma(1-(1/\\gamma))}{\\Gamma(\\tau)}\\beta(\\tau+\\frac{1}{\\gamma},1-\\frac{1}{\\gamma};\\frac{(x/\\theta)^\\gamma}{1+(x/\\theta)^\\gamma})+x[1-\\Big(\\frac{(x/\\theta)^\\gamma}{1+(x/\\theta)^\\gamma}\\Big)^\\tau] \\\\ \\hline \\text{Pareto} &amp; \\\\ \\alpha=1 &amp; -\\theta \\ln \\Big(\\frac{\\theta}{x+\\theta}\\Big) \\\\ \\alpha\\neq1 &amp; \\frac{\\theta}{\\alpha-1}[1-\\Big(\\frac{\\theta}{x+\\theta}\\Big)^{\\alpha-1}] \\\\ \\hline \\text{Inverse Pareto} &amp; \\theta\\tau\\int^{x/(x+\\theta)}_0~y^\\tau(1-y)^{-1}dy+x[1-\\Big(\\frac{x}{x+\\theta}\\Big)^\\tau] \\\\ \\hline \\text{Loglogistic} &amp; \\theta\\Gamma(1+\\frac{1}{\\gamma})\\Gamma(1-\\frac{1}{\\gamma})\\beta(1+\\frac{1}{\\gamma},1-\\frac{1}{\\gamma};\\frac{(x/\\theta)^\\gamma}{1+(x/\\theta)^\\gamma})+x(1-\\frac{(x/\\theta)^\\gamma}{1+(x/\\theta)^\\gamma}) \\\\ \\hline \\text{Paralogistic} &amp; \\frac{\\theta\\Gamma(1+\\frac{1}{\\alpha})\\Gamma(\\alpha-\\frac{1}{\\alpha})}{\\Gamma(\\alpha)}\\beta(1+\\frac{1}{\\alpha},\\alpha-\\frac{1}{\\alpha};1-\\frac{1}{1+(x/\\theta)^\\alpha})+x\\Big(\\frac{1}{1+(x/\\theta)^\\alpha}\\Big)^\\alpha \\\\ \\hline \\text{Inverse Paralogistic} &amp; \\frac{\\theta\\Gamma(\\tau+\\frac{1}{\\tau})\\Gamma(1-\\frac{1}{\\tau})}{\\Gamma(\\tau)}\\beta(\\tau+\\frac{1}{\\tau},1-\\frac{1}{\\tau};\\frac{(x/\\theta)^\\tau}{1+(x/\\theta)^\\tau})+x[1-\\Big(\\frac{(x/\\theta)^\\tau}{1+(x/\\theta)^\\tau}\\Big)^\\tau] \\\\ \\hline \\text{Gamma} &amp; \\frac{\\theta\\Gamma(\\alpha+1)}{\\Gamma(\\alpha)}\\Gamma(\\alpha+1;\\frac{x}{\\theta})+x[1-\\Gamma(\\alpha;\\frac{x}{\\theta})] \\\\ \\hline \\text{Inverse Gamma} &amp; \\frac{\\theta\\Gamma(\\alpha-1)}{\\Gamma(\\alpha)}[1-\\Gamma(\\alpha-1;\\frac{\\theta}{x})]+x\\Gamma(\\alpha;\\frac{\\theta}{x}) \\\\ \\hline \\text{Weibull} &amp; \\theta\\Gamma(1+\\frac{1}{\\alpha})\\Gamma(1+\\frac{1}{\\alpha};\\Big(\\frac{x}{\\theta}\\Big)^\\alpha)+x*\\exp(-(x/\\theta)^\\alpha) \\\\ \\hline \\text{Inverse Weibull} &amp; \\theta\\Gamma(1-\\frac{1}{\\alpha})[1-\\Gamma(1-\\frac{1}{\\alpha};\\Big(\\frac{\\theta}{x}\\Big)^\\alpha)]+x[1-\\exp(-(\\theta/x)^\\alpha)] \\\\ \\hline \\text{Exponential} &amp; \\theta(1-\\exp(-(x/\\theta))) \\\\ \\hline \\text{Inverse Exponential} &amp; \\theta G(0;\\frac{\\theta}{x})+x(1-\\exp(-(\\theta/x))) \\\\ \\hline \\text{Lognormal} &amp; \\exp(\\mu+\\sigma^2/2)\\Phi\\Big(\\frac{\\ln (x)-\\mu-\\sigma^2}{\\sigma}\\Big)+x[1-\\Phi\\Big(\\frac{\\ln (x)-\\mu}{\\sigma}\\Big)] \\\\ \\hline \\text{Inverse Gaussian} &amp; x-\\mu\\Big(\\frac{x-\\mu}{\\mu}\\Big)\\Phi\\Big[\\Big(\\frac{x-\\mu}{\\mu}\\Big)\\Big(\\frac{\\theta}{x}\\Big)^{1/2}\\Big]-\\mu\\Big(\\frac{x+\\mu}{\\mu}\\Big)\\exp\\Big(\\frac{2\\theta}{\\mu}\\Big)\\Phi\\Big[-\\Big(\\frac{x+\\mu}{\\mu}\\Big)\\Big(\\frac{\\theta}{x}\\Big)^{1/2}\\Big] \\\\ \\hline \\text{Single-Parameter Pareto} &amp; \\frac{\\alpha\\theta}{\\alpha-1}-\\frac{\\theta^\\alpha}{(\\alpha-1)x^{\\alpha-1}} \\\\ \\hline \\text{Generalized Beta} &amp; \\frac{\\theta\\Gamma(a+b)\\Gamma(a+\\frac{1}{\\tau})}{\\Gamma(a)\\Gamma(a+b+\\frac{1}{\\tau})}\\beta(a+\\frac{1}{\\tau},b;\\Big(\\frac{x}{\\theta}\\Big)^\\tau)+x\\Big[1-\\beta(a,b;\\Big(\\frac{x}{\\theta}\\Big)^\\tau)\\Big] \\\\ \\hline \\text{Beta} &amp; \\frac{\\theta a}{(a+b)}\\beta(a+1,b;\\frac{x}{\\theta})+x[1-\\beta(a,b;\\frac{x}{\\theta})] \\\\ \\hline \\end{array} \\end{matrix} \\] Hide Illustrative Graph Comparison of Limited Expected Values for Selected Distributions \\[ \\begin{matrix} \\begin{array}{l|c|c|c|c|c|c} \\hline \\text{Distribution} &amp; \\text{Parameters} &amp; \\mathrm{E}[x] &amp; E[X\\wedge100] &amp; E[X\\wedge250] &amp; E[X\\wedge500] &amp;E[X\\wedge1000] \\\\ \\hline \\text{Pareto} &amp; \\alpha = 3, \\theta = 200 &amp; 100 &amp; 55.55 &amp;80.25 &amp; 91.84 &amp; 97.22 \\\\ \\hline \\text{Exponential} &amp; \\theta = 100 &amp; 100 &amp; 63.21 &amp; 91.79 &amp; 99.33 &amp; 99.99 \\\\ \\hline \\text{Gamma} &amp; \\alpha = 2, \\theta = 50 &amp; 100 &amp; 72.93 &amp; 97.64 &amp; 99.97 &amp; 100 \\\\ \\hline \\text{Weibull} &amp; \\tau=2, \\theta=\\frac{200}{\\sqrt[]{\\pi}} &amp; 100 &amp; 78.99 &amp; 99.82 &amp; 100 &amp; 100 \\\\ \\hline \\text{GB2} &amp; \\alpha = 3,\\tau=2,\\theta = 100 &amp; 100 &amp; 62.50 &amp; 86.00 &amp; 94.91 &amp; 98.42 \\\\ \\hline \\end{array} \\end{matrix} \\] ## Warning in levpareto2(X, 3, 200): NaNs produced "],
["bibliography.html", "Bibliography", " Bibliography "]
]
